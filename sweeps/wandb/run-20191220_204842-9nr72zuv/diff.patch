diff --git a/notebooks/.ipynb_checkpoints/ToyModelTrackML-checkpoint.ipynb b/notebooks/.ipynb_checkpoints/ToyModelTrackML-checkpoint.ipynb
index c1ebb79..396f68c 100644
--- a/notebooks/.ipynb_checkpoints/ToyModelTrackML-checkpoint.ipynb
+++ b/notebooks/.ipynb_checkpoints/ToyModelTrackML-checkpoint.ipynb
@@ -11,7 +11,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 17,
+   "execution_count": 3,
    "metadata": {
     "cell_style": "center",
     "code_folding": []
@@ -33,28 +33,31 @@
     "import matplotlib.colors\n",
     "import numpy as np\n",
     "import torch\n",
+    "import torch.multiprocessing as mp\n",
+    "import torch.nn as nn\n",
+    "# mp.set_start_method(\"forkserver\", force=True)\n",
     "from torch_geometric.data import Data\n",
     "from torch_geometric.data import DataLoader\n",
     "import seaborn as sns\n",
     "import wandb\n",
     "# os.environ['WANDB_MODE'] = 'dryrun'\n",
-    "from numba import jit, njit, prange, float32\n",
     "\n",
     "import ipywidgets as widgets\n",
     "from ipywidgets import interact, interact_manual\n",
     "\n",
     "# Limit CPU usage on Jupyter\n",
-    "os.environ['OMP_NUM_THREADS'] = '4'\n",
+    "os.environ['OMP_NUM_THREADS'] = '1'\n",
     "\n",
     "# Local imports\n",
-    "from utils.toy_utils import *\n",
-    "from datasets.hitgraphs_params import *\n",
+    "from utils.toy_utils import load_data, make_mlp\n",
     "%matplotlib inline"
    ]
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "## Loading TrackML Dataset"
    ]
@@ -62,7 +65,9 @@
   {
    "cell_type": "code",
    "execution_count": 6,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -79,8 +84,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 20,
-   "metadata": {},
+   "execution_count": 2,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "input_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/\"\n",
@@ -90,8 +97,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 21,
-   "metadata": {},
+   "execution_count": 3,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "full_graphs = [load_graph(fi) for fi in filenames]"
@@ -100,7 +109,9 @@
   {
    "cell_type": "code",
    "execution_count": 5,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "cut_mask = [~(np.isnan(g[3]).any()) for g in full_graphs]\n",
@@ -109,8 +120,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 22,
-   "metadata": {},
+   "execution_count": 4,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "cut_full_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),\n",
@@ -118,6 +131,15 @@
     "                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in full_graphs]"
    ]
   },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "metadata": {
+    "hidden": true
+   },
+   "outputs": [],
+   "source": []
+  },
   {
    "cell_type": "markdown",
    "metadata": {
@@ -1441,19 +1463,15 @@
     "## Combined Edge & Track Param Classifier"
    ]
   },
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "How to do a double scatter..."
-   ]
-  },
   {
    "cell_type": "code",
-   "execution_count": 26,
+   "execution_count": 4,
    "metadata": {
     "code_folding": [
-     52
+     0,
+     26,
+     52,
+     97
     ]
    },
    "outputs": [],
@@ -1599,37 +1617,43 @@
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "#### Generate data"
    ]
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "#### Load data"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 37,
-   "metadata": {},
+   "execution_count": 3,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
-    "train_size = int(0.5 * len(cut_full_dataset))\n",
-    "test_size = int(0.1 * len(cut_full_dataset))\n",
-    "train_dataset = cut_full_dataset[:train_size]\n",
-    "test_dataset = cut_full_dataset[-test_size:]\n",
-    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
+    "train_size, test_size = 300, 50\n",
+    "train_dataset, test_dataset = load_data(train_size, test_size)\n",
+    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
     "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
     "t_configs = {'train_size': train_size, 'test_size': test_size}"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 28,
-   "metadata": {},
+   "execution_count": 4,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -1643,7 +1667,8 @@
     "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
     "print(\"Using \", device)\n",
     "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
-    "m_configs = {'input_dim': 3, 'hidden_dim': 16, 'n_graph_iters': 3, 'output_dim': 1}\n",
+    "m_configs = {'hidden_dim': 16, 'n_graph_iters': 3}\n",
+    "m_configs = {'input_dim': 3, **m_configs, 'output_dim': 1}\n",
     "model = Edge_Track_Truth_Net(**m_configs).to(device)\n",
     "# data = dataset[0].to(device)\n",
     "o_configs = {'lr': 0.001, 'weight_decay': 1e-4}\n",
@@ -1664,16 +1689,19 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 29,
-   "metadata": {},
+   "execution_count": 9,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "data": {
       "text/html": [
        "\n",
-       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
-       "            Call wandb.login() to authenticate this machine.<br/>\n",
-       "        "
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression/runs/fwpw76ra\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression/runs/fwpw76ra</a><br/>\n",
+       "            "
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -1686,6 +1714,7 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
+      "wandb: Network error resolved after 0:00:23.785435, resuming normal operation.\n",
       "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
       "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
      ]
@@ -1693,12 +1722,22 @@
     {
      "data": {
       "text/plain": [
-       "[<wandb.wandb_torch.TorchGraph at 0x2aab86bb2710>]"
+       "[<wandb.wandb_torch.TorchGraph at 0x2aab57ea34a8>]"
       ]
      },
-     "execution_count": 29,
+     "execution_count": 9,
      "metadata": {},
      "output_type": "execute_result"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:11.332204, resuming normal operation.\n",
+      "wandb: Network error resolved after 0:00:23.334204, resuming normal operation.\n",
+      "wandb: Network error resolved after 0:00:37.807275, resuming normal operation.\n",
+      "wandb: Network error resolved after 0:00:38.484777, resuming normal operation.\n"
+     ]
     }
    ],
    "source": [
@@ -1707,158 +1746,442 @@
     "wandb.watch(model, log='all')"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "metadata": {
+    "heading_collapsed": true
+   },
+   "source": [
+    "### Training and Validation"
+   ]
+  },
   {
    "cell_type": "code",
-   "execution_count": 16,
-   "metadata": {},
+   "execution_count": 10,
+   "metadata": {
+    "code_folding": [],
+    "hidden": true
+   },
    "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Network error resolved after 0:00:11.345432, resuming normal operation.\n",
+      "Failed to connect to W&B servers after 10 seconds.                    Letting user process proceed while attempting to reconnect.\n"
+     ]
+    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Traceback (most recent call last):\r\n",
-      "  File \"/global/homes/d/danieltm/.local/bin/wandb\", line 6, in <module>\r\n",
-      "    from wandb.cli import cli\r\n",
-      "ModuleNotFoundError: No module named 'wandb'\r\n"
+      "Epoch:  1 , loss:  0.6007898449897766 , node accuracy:  10.242046834801204 %, lr:  [0.001]\n"
      ]
-    }
-   ],
-   "source": [
-    "!wandb"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 47,
-   "metadata": {},
-   "outputs": [
+    },
     {
-     "data": {
-      "text/plain": [
-       "[<matplotlib.lines.Line2D at 0x2aab7fcdaf60>]"
-      ]
-     },
-     "execution_count": 47,
-     "metadata": {},
-     "output_type": "execute_result"
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "Retry attempt failed:\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
+      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
+      "    raise err\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
+      "    sock.connect(sa)\n",
+      "socket.timeout: timed out\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
+      "    chunked=chunked,\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
+      "    self._validate_conn(conn)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
+      "    conn.connect()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
+      "    conn = self._new_conn()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 164, in _new_conn\n",
+      "    % (self.host, self.timeout),\n",
+      "urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fab8d0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)')\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
+      "    timeout=timeout\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
+      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
+      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
+      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fab8d0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
+      "    result = self._call_fn(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 103, in execute\n",
+      "    return self.client.execute(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 50, in execute\n",
+      "    result = self._get_result(document, *args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 58, in _get_result\n",
+      "    return self.transport.execute(document, *args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/transport/requests.py\", line 37, in execute\n",
+      "    request = requests.post(self.url, **post_args)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 116, in post\n",
+      "    return request('post', url, data=data, json=json, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 504, in send\n",
+      "    raise ConnectTimeout(e, request=request)\n",
+      "requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fab8d0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
+      "wandb: Network error (ConnectTimeout), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n"
+     ]
     },
     {
-     "data": {
-      "image/png": "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\n",
-      "text/plain": [
-       "<Figure size 1152x288 with 2 Axes>"
-      ]
-     },
-     "metadata": {
-      "needs_background": "light"
-     },
-     "output_type": "display_data"
-    }
-   ],
-   "source": [
-    "fig, axs = plt.subplots(1,2)\n",
-    "fig.set_size_inches(16,4)\n",
-    "axs[0].plot(np.arange(len(loss_v_node)), loss_v_node)\n",
-    "# axs[1].plot(np.arange(len(loss_v_edge)), loss_v_edge)\n",
-    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
-    "# axs[3].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 39,
-   "metadata": {},
-   "outputs": [
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  2 , loss:  0.817642867565155 , node accuracy:  10.806555227684166 %, lr:  [0.001]\n",
+      "Epoch:  3 , loss:  0.9038619995117188 , node accuracy:  11.966084468880512 %, lr:  [0.001]\n",
+      "Epoch:  4 , loss:  2.6982123851776123 , node accuracy:  12.011629412664599 %, lr:  [0.001]\n",
+      "Epoch:  5 , loss:  2.588160753250122 , node accuracy:  11.906975326302884 %, lr:  [0.001]\n",
+      "Epoch:  6 , loss:  1.5540924072265625 , node accuracy:  11.722250515928984 %, lr:  [0.001]\n"
+     ]
+    },
     {
-     "data": {
-      "text/html": [
-       "<iframe src=\"https://app.wandb.ai/murnanedaniel/node_regression/runs/xrckpu24?jupyter=true&state=paused\" style=\"border:none;width:100%;height:420px\">\n",
-       "                </iframe>"
-      ],
-      "text/plain": [
-       "<wandb.jupyter.Run at 0x2aab86b7af60>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:58.266933, resuming normal operation.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  7 , loss:  8.183475494384766 , node accuracy:  11.767347980989985 %, lr:  [0.001]\n",
+      "Epoch:  8 , loss:  1.7046161890029907 , node accuracy:  11.827561836665232 %, lr:  [0.001]\n"
+     ]
     },
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
-      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
+      "wandb: Network error resolved after 0:00:11.470606, resuming normal operation.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  9 , loss:  0.42751920223236084 , node accuracy:  11.777570073070478 %, lr:  [0.001]\n",
+      "Epoch:  10 , loss:  2.032323122024536 , node accuracy:  11.7880718393529 %, lr:  [0.001]\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: ERROR Error uploading \"config.yaml\": CommError, <Response [400]>\n",
+      "Retry attempt failed:\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
+      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
+      "    raise err\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
+      "    sock.connect(sa)\n",
+      "socket.timeout: timed out\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
+      "    chunked=chunked,\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
+      "    self._validate_conn(conn)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
+      "    conn.connect()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
+      "    conn = self._new_conn()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 164, in _new_conn\n",
+      "    % (self.host, self.timeout),\n",
+      "urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57f7def0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)')\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
+      "    timeout=timeout\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
+      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
+      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
+      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57f7def0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
+      "    result = self._call_fn(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 103, in execute\n",
+      "    return self.client.execute(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 50, in execute\n",
+      "    result = self._get_result(document, *args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 58, in _get_result\n",
+      "    return self.transport.execute(document, *args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/transport/requests.py\", line 37, in execute\n",
+      "    request = requests.post(self.url, **post_args)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 116, in post\n",
+      "    return request('post', url, data=data, json=json, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 504, in send\n",
+      "    raise ConnectTimeout(e, request=request)\n",
+      "requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57f7def0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
+      "wandb: Network error (ConnectTimeout), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  11 , loss:  0.9068647623062134 , node accuracy:  11.77572422333775 %, lr:  [0.001]\n",
+      "Epoch:  12 , loss:  3.974558115005493 , node accuracy:  11.754566869961844 %, lr:  [0.001]\n",
+      "Epoch:  13 , loss:  0.7298269271850586 , node accuracy:  11.784953472001396 %, lr:  [0.001]\n",
+      "Epoch:  14 , loss:  0.7682395577430725 , node accuracy:  11.689500666883134 %, lr:  [0.001]\n",
+      "Epoch:  15 , loss:  5.155138969421387 , node accuracy:  11.852173166434957 %, lr:  [0.001]\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:56.379144, resuming normal operation.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  16 , loss:  2.4475228786468506 , node accuracy:  11.88984528143475 %, lr:  [0.001]\n",
+      "Epoch:  17 , loss:  8.945351600646973 , node accuracy:  11.948003531725822 %, lr:  [0.001]\n",
+      "Epoch:  18 , loss:  0.800361692905426 , node accuracy:  11.82655500953829 %, lr:  [0.001]\n",
+      "Epoch:  19 , loss:  4.170938968658447 , node accuracy:  12.117542032934994 %, lr:  [0.001]\n",
+      "Epoch:  20 , loss:  13.88068675994873 , node accuracy:  11.96797226974353 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  21 , loss:  9.681962013244629 , node accuracy:  12.113640577818089 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  22 , loss:  4.359136581420898 , node accuracy:  12.098664024304808 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  23 , loss:  0.9145486354827881 , node accuracy:  12.054405581849592 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  24 , loss:  1.0942814350128174 , node accuracy:  12.114088056541174 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  25 , loss:  1.8272830247879028 , node accuracy:  12.160220316149312 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  26 , loss:  1.0419292449951172 , node accuracy:  12.065564582506546 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  27 , loss:  1.8605482578277588 , node accuracy:  12.224559366303007 %, lr:  [0.0009000000000000001]\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: ERROR Error uploading \"diff.patch\": CommError, <Response [400]>\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  28 , loss:  1.0357260704040527 , node accuracy:  12.188509361674399 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  29 , loss:  5.578948974609375 , node accuracy:  12.176371501310692 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  30 , loss:  7.798847675323486 , node accuracy:  12.258595716677728 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  31 , loss:  6.776310920715332 , node accuracy:  12.162583563155609 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  32 , loss:  0.6156641840934753 , node accuracy:  12.182356529231967 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  33 , loss:  0.6728848814964294 , node accuracy:  12.12583437302218 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  34 , loss:  3.6187450885772705 , node accuracy:  12.225244568097732 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  35 , loss:  3.693549633026123 , node accuracy:  12.218280680469707 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  36 , loss:  2.0439088344573975 , node accuracy:  12.09069330954984 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  37 , loss:  2.4835045337677 , node accuracy:  12.212533375620072 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  38 , loss:  0.6139274835586548 , node accuracy:  12.270803495591915 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  39 , loss:  1.7037460803985596 , node accuracy:  12.20246510435064 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  40 , loss:  2.4318125247955322 , node accuracy:  12.192159110009568 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  41 , loss:  0.7220551371574402 , node accuracy:  12.29498133034865 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  42 , loss:  1.5551996231079102 , node accuracy:  12.163674292543131 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  43 , loss:  1.789021372795105 , node accuracy:  12.291037924101456 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  44 , loss:  1.3258136510849 , node accuracy:  12.261140751915278 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  45 , loss:  9.340996742248535 , node accuracy:  12.195263493650977 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  46 , loss:  1.5705657005310059 , node accuracy:  12.157493492680507 %, lr:  [0.0008100000000000001]\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "Retry attempt failed:\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
+      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
+      "    raise err\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
+      "    sock.connect(sa)\n",
+      "OSError: [Errno 101] Network is unreachable\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
+      "    chunked=chunked,\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
+      "    self._validate_conn(conn)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
+      "    conn.connect()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
+      "    conn = self._new_conn()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 169, in _new_conn\n",
+      "    self, \"Failed to establish a new connection: %s\" % e\n",
+      "urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9dd8>: Failed to establish a new connection: [Errno 101] Network is unreachable\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
+      "    timeout=timeout\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
+      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
+      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
+      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576270804&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=hOWZqur9%2FE%2B63Tc6ZLj%2BSd3y2tX%2BgKVvtLWi%2F%2FMYrPOhGJNdbcjIzm2AycX83SiOXjK8%2FnFTHL06nfSMiGX138tS3JjMTVQXFJSfQ34KfGCe%2FDmN2hRZOv6RI46nJ7oC4bW4XuPL6r7%2F%2Fi3ifrnD6Bsn7ieg5wEntYKQuFmCSVGENS78lGvvF6OA4btweX2muj2fY83GxbrFx7QKltvImU4pWsYeYU4RMMqOoggZUQ9QpWWPXEWcwjAGZZrLnjghaX5hrWRAmAPsDApbsQpN7Xm7immu7hxXIJUq18t98MGmdiXGz9eIhQiEd3Mwk3RogxGGkN9eE52xf1WIcagLtA%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9dd8>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
+      "    url, data=progress, headers=extra_headers)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
+      "    return request('put', url, data=data, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
+      "    raise ConnectionError(e, request=request)\n",
+      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576270804&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=hOWZqur9%2FE%2B63Tc6ZLj%2BSd3y2tX%2BgKVvtLWi%2F%2FMYrPOhGJNdbcjIzm2AycX83SiOXjK8%2FnFTHL06nfSMiGX138tS3JjMTVQXFJSfQ34KfGCe%2FDmN2hRZOv6RI46nJ7oC4bW4XuPL6r7%2F%2Fi3ifrnD6Bsn7ieg5wEntYKQuFmCSVGENS78lGvvF6OA4btweX2muj2fY83GxbrFx7QKltvImU4pWsYeYU4RMMqOoggZUQ9QpWWPXEWcwjAGZZrLnjghaX5hrWRAmAPsDApbsQpN7Xm7immu7hxXIJUq18t98MGmdiXGz9eIhQiEd3Mwk3RogxGGkN9eE52xf1WIcagLtA%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9dd8>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
+      "    result = self._call_fn(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 980, in upload_file\n",
+      "    util.sentry_reraise(retry.TransientException(exc=e))\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/util.py\", line 92, in sentry_reraise\n",
+      "    six.reraise(type(exc), exc, sys.exc_info()[2])\n",
+      "  File \"/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/six.py\", line 692, in reraise\n",
+      "    raise value.with_traceback(tb)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
+      "    url, data=progress, headers=extra_headers)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
+      "    return request('put', url, data=data, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
+      "    raise ConnectionError(e, request=request)\n",
+      "wandb.retry.TransientException: None\n",
+      "wandb: Network error (TransientException), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n",
+      "wandb: ERROR Error uploading \"wandb-metadata.json\": CommError, <Response [400]>\n"
      ]
     },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Epoch:  51 , loss:  1.0130443572998047 , node accuracy:  17.62983665068888 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  52 , loss:  1.304320216178894 , node accuracy:  17.497257095264583 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  53 , loss:  0.2536078691482544 , node accuracy:  17.806618713728003 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  54 , loss:  0.5005673766136169 , node accuracy:  16.359346669877326 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  55 , loss:  0.7102632522583008 , node accuracy:  18.416588148134476 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  56 , loss:  0.44991207122802734 , node accuracy:  19.216805958402936 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  57 , loss:  1.6711790561676025 , node accuracy:  19.13799376829943 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  58 , loss:  1.8175777196884155 , node accuracy:  16.412596637924548 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  59 , loss:  0.5086053609848022 , node accuracy:  20.52232513300606 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  60 , loss:  1.4643304347991943 , node accuracy:  16.340916139970226 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  61 , loss:  10.858916282653809 , node accuracy:  20.98266886938068 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  62 , loss:  1.1947903633117676 , node accuracy:  22.18321233228987 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  63 , loss:  0.5516257882118225 , node accuracy:  22.195671817985794 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  64 , loss:  0.5449832081794739 , node accuracy:  22.43950577093732 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  65 , loss:  4.906266689300537 , node accuracy:  22.502824010253974 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  66 , loss:  0.8653304576873779 , node accuracy:  22.80020158916475 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  67 , loss:  3.713456630706787 , node accuracy:  24.615790573245416 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  68 , loss:  0.15667743980884552 , node accuracy:  25.90436149121166 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  69 , loss:  0.8753616809844971 , node accuracy:  27.252992444042086 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  70 , loss:  0.30628612637519836 , node accuracy:  27.26599729443177 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  71 , loss:  1.2008047103881836 , node accuracy:  29.070189554783845 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  72 , loss:  8.908965110778809 , node accuracy:  27.333216988865335 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  73 , loss:  0.3511810600757599 , node accuracy:  27.442555618109353 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  74 , loss:  30.64867401123047 , node accuracy:  30.093783150132747 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  75 , loss:  0.4458775222301483 , node accuracy:  19.537983811897845 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  76 , loss:  0.2321305274963379 , node accuracy:  27.016318150659934 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  77 , loss:  1.303676962852478 , node accuracy:  25.187612446508812 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  78 , loss:  0.2609845995903015 , node accuracy:  17.050953003826784 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  79 , loss:  0.5831493139266968 , node accuracy:  25.560823685272556 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  80 , loss:  0.5291023254394531 , node accuracy:  29.28110585416836 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  81 , loss:  0.693770706653595 , node accuracy:  29.831980129707304 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  82 , loss:  3.381126880645752 , node accuracy:  30.931029824736566 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  83 , loss:  1.255566120147705 , node accuracy:  28.218665512171558 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  84 , loss:  3.4112496376037598 , node accuracy:  31.34714308607617 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  85 , loss:  0.9732820391654968 , node accuracy:  27.529170718446665 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  86 , loss:  0.8045064806938171 , node accuracy:  28.596603244947893 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  87 , loss:  2.2349295616149902 , node accuracy:  33.107188773653796 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  88 , loss:  0.44516462087631226 , node accuracy:  32.64589414499262 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  89 , loss:  0.9409404993057251 , node accuracy:  34.64910256743714 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  90 , loss:  0.8439923524856567 , node accuracy:  30.35480308279279 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  91 , loss:  0.6240589618682861 , node accuracy:  32.98351684156093 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  92 , loss:  1.0759775638580322 , node accuracy:  32.821641413484606 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  93 , loss:  0.2878401577472687 , node accuracy:  33.36514627380272 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  94 , loss:  0.7029196619987488 , node accuracy:  30.96589121400698 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  95 , loss:  0.1989344358444214 , node accuracy:  32.94222294564616 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  96 , loss:  0.2367507964372635 , node accuracy:  28.472176192509824 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  97 , loss:  2.6421658992767334 , node accuracy:  33.324537579682676 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  98 , loss:  3.5272955894470215 , node accuracy:  31.251816134348775 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  99 , loss:  19.012252807617188 , node accuracy:  31.749006946827503 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  100 , loss:  1.5425626039505005 , node accuracy:  34.279778800080216 %, lr:  [0.00059049]\n"
+      "Epoch:  47 , loss:  1.369815468788147 , node accuracy:  12.232641950738746 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  48 , loss:  29.94580841064453 , node accuracy:  12.380771391790276 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  49 , loss:  18.640899658203125 , node accuracy:  14.612893148513434 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  50 , loss:  2.596501350402832 , node accuracy:  10.714682252350592 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  51 , loss:  2.0275228023529053 , node accuracy:  11.03620969859791 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  52 , loss:  3.6572177410125732 , node accuracy:  11.914134985872257 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  53 , loss:  0.4805273115634918 , node accuracy:  12.153172526260708 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  54 , loss:  3.2910521030426025 , node accuracy:  12.409647753139414 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  55 , loss:  1.5877015590667725 , node accuracy:  13.966789807217776 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  56 , loss:  0.7358959913253784 , node accuracy:  14.979811717733776 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  57 , loss:  1.8266561031341553 , node accuracy:  10.73860838032559 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  58 , loss:  0.43270111083984375 , node accuracy:  11.64315865162355 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  59 , loss:  1.9536621570587158 , node accuracy:  15.584453358593509 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  60 , loss:  2.093195915222168 , node accuracy:  10.692825713469865 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  61 , loss:  0.814365565776825 , node accuracy:  11.901745418726817 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  62 , loss:  31.9005126953125 , node accuracy:  18.31162642015064 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  63 , loss:  0.4563229978084564 , node accuracy:  19.494844066250344 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  64 , loss:  0.7945733070373535 , node accuracy:  15.855052132669611 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  65 , loss:  1.1281858682632446 , node accuracy:  14.559545294495535 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  66 , loss:  0.7465262413024902 , node accuracy:  13.159398353669843 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  67 , loss:  2.0372366905212402 , node accuracy:  11.426355210288431 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  68 , loss:  8.939661979675293 , node accuracy:  13.123586072112875 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  69 , loss:  0.4237460196018219 , node accuracy:  12.844974632151516 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  70 , loss:  0.5248408913612366 , node accuracy:  12.198731453754892 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  71 , loss:  0.8191898465156555 , node accuracy:  10.694475791261244 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  72 , loss:  0.9275200366973877 , node accuracy:  11.33827182039099 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  73 , loss:  1.2797634601593018 , node accuracy:  14.771706144078639 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  74 , loss:  10.561777114868164 , node accuracy:  16.505462456674973 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  75 , loss:  2.1823747158050537 , node accuracy:  22.458146056495867 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  76 , loss:  0.9706612229347229 , node accuracy:  21.41686306787497 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  77 , loss:  0.5489035844802856 , node accuracy:  24.637744998096817 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  78 , loss:  0.23864111304283142 , node accuracy:  21.300770306654375 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  79 , loss:  0.24089452624320984 , node accuracy:  26.019265637074056 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  80 , loss:  3.169557809829712 , node accuracy:  22.959755721365067 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  81 , loss:  25.155071258544922 , node accuracy:  11.18468873240185 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  82 , loss:  0.4444100260734558 , node accuracy:  18.682824004660493 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  83 , loss:  0.6307412385940552 , node accuracy:  23.607872716914613 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  84 , loss:  0.44871583580970764 , node accuracy:  26.412082037393 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  85 , loss:  2.9424526691436768 , node accuracy:  26.181966104046072 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  86 , loss:  0.749906063079834 , node accuracy:  25.233884543217915 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  87 , loss:  0.8655756115913391 , node accuracy:  27.588335795864683 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  88 , loss:  0.6294488310813904 , node accuracy:  29.389437656285438 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  89 , loss:  0.7006829977035522 , node accuracy:  30.015194699390786 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  90 , loss:  3.337183952331543 , node accuracy:  29.120223269508884 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  91 , loss:  1.1927621364593506 , node accuracy:  28.581990267897122 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  92 , loss:  0.8216007351875305 , node accuracy:  27.44835885779937 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  93 , loss:  1.9755046367645264 , node accuracy:  28.335289654375824 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  94 , loss:  0.5349218249320984 , node accuracy:  19.199410223042975 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  95 , loss:  7.208506107330322 , node accuracy:  19.29010856672845 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  96 , loss:  2.0792455673217773 , node accuracy:  25.51820133689862 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  97 , loss:  2.0596158504486084 , node accuracy:  12.411269863510599 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  98 , loss:  3.1164815425872803 , node accuracy:  22.995064589358563 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  99 , loss:  0.15878534317016602 , node accuracy:  26.6925113596669 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  100 , loss:  0.3312382102012634 , node accuracy:  27.46971198311663 %, lr:  [0.00059049]\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "[<matplotlib.lines.Line2D at 0x2aab56a34ba8>]"
+       "[<matplotlib.lines.Line2D at 0x2aab57fab198>]"
       ]
      },
-     "execution_count": 39,
+     "execution_count": 10,
      "metadata": {},
      "output_type": "execute_result"
     },
     {
      "data": {
-      "image/png": "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\n",
+      "image/png": "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\n",
       "text/plain": [
        "<Figure size 1152x288 with 2 Axes>"
       ]
@@ -1867,17 +2190,23 @@
       "needs_background": "light"
      },
      "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:23.512588, resuming normal operation.\n"
+     ]
     }
    ],
    "source": [
-    "%%wandb\n",
     "model.train()\n",
-    "# loss_v_node = []\n",
+    "loss_v_node = []\n",
     "# loss_v_edge = []\n",
-    "# acc_v_node = []\n",
+    "acc_v_node = []\n",
     "# acc_v_edge = []\n",
-    "# ep = 0\n",
-    "for epoch in range(50):\n",
+    "ep = 0\n",
+    "for epoch in range(100):\n",
     "    ep += 1\n",
     "    node_correct = 0\n",
     "#     edge_correct = 0\n",
@@ -1930,7 +2259,9 @@
   {
    "cell_type": "code",
    "execution_count": 52,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -3369,955 +3700,1372 @@
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": 42,
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "13.484405994415283 13.484405994415283\n"
-     ]
-    }
-   ],
-   "source": [
-    "torch.cuda.empty_cache()\n",
-    "torch.cuda.reset_max_memory_allocated()\n",
-    "torch.cuda.reset_max_memory_cached()\n",
-    "print(torch.cuda.memory_allocated(0)/1024**3, torch.cuda.max_memory_allocated(0)/1024**3)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
+   "cell_type": "markdown",
    "metadata": {},
-   "outputs": [],
    "source": [
-    "print(full_graphs[0][0])"
+    "### Debug"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 125,
+   "execution_count": 47,
    "metadata": {},
    "outputs": [
     {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "tensor([1.8922e+01, 3.6313e+00, 3.0467e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.2187, -35.0857,   0.6955], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([ 1.8613e+01,  3.5876e+00, -1.0034e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([ 1.8996e+01,  2.9768e+00, -4.8119e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([25.8152, 16.9260, -1.2471], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([25.4800, 16.8262, -1.2453], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([24.8583, 16.6111, -1.2062], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([21.5880, -2.6879,  0.8381], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([16.9862,  3.8774,  0.1122], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([ 41.1885, -32.8211,   1.0185], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([ 40.7710, -30.7252,   1.2782], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([25.7639, 18.2869, -1.1607], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([16.9630,  2.1817,  0.0223], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([24.5119, -4.3527,  0.6603], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([ 44.5465, -35.2413,   1.0523], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([ 45.1856, -40.0252,   1.1841], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([24.6620, 16.4957, -1.1209], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([1.7948e+01, 5.2398e-01, 7.7200e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([ 45.7709, -35.0205,   1.2817], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([ 44.2098, -33.7250,   1.2481], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([22.9125, -3.6225,  0.6602], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([16.7419,  3.0845,  0.0594], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([26.6395, 17.5330, -0.8474], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([23.7234, -3.3299,  1.1437], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([27.5753, 17.9557, -0.5238], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([21.8177, -2.6738,  1.0679], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([ 44.8839, -32.5191,   1.1000], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([21.9020, -3.5113,  1.1277], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([1.8384e+01, 6.1529e-01, 3.2547e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([25.4626, 16.8129, -1.2414], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([25.4351, 17.4593, -1.2281], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([16.8515,  3.8994,  0.0608], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([23.3092, -1.9636,  0.5303], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([25.9646, 17.7169, -1.2468], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.9991, -33.8223,   0.1652], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([21.1459, -2.2798,  0.9505], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([23.1696, -3.5011,  1.1510], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([21.5713, -3.3363,  1.0770], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.2006, -35.3662,   1.1758], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([1.7263e+01, 1.0393e+00, 1.6066e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([27.7684, 17.3738,  0.4669], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([45.3506, 18.0112,  0.9953], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([50.5027, 18.5959,  1.0513], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([37.3744, -5.8386,  0.6888], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.2743, -27.2447,   0.5555], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([ 51.6387, -31.0397,   0.8468], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([24.5524, 19.4569,  0.9050], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([24.2394, 18.8239,  0.8832], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([45.0087, 16.7298,  0.2292], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([44.5156, 15.5085,  1.1685], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([ 1.7541e+01,  2.0131e+00, -4.8630e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([48.6423, 16.9927,  1.0624], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([27.6775, 16.9265,  1.0528], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([23.6196, 18.5726,  0.9916], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([1.7953e+01, 9.1990e-03, 5.6586e-01], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([28.0753, 17.4585,  1.0053], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([20.5719, 12.1217, -1.0629], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([21.2473, 11.5207, -0.8434], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([34.1981, -3.6442,  0.7675], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([35.5160, -5.8147,  0.7135], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([17.7641,  0.0203,  0.2386], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([26.3771, 16.5180,  1.0986], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([23.0741,  8.3208, -0.6991], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([21.7606, 12.2207, -1.2206], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([ 51.5355, -31.3089,   0.8295], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([47.0115, 18.1877,  0.6074], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([38.1979, -4.7878,  1.0353], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([24.2371, 19.3842,  0.5825], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([24.3078, 19.6725,  1.0566], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([37.0417, -5.9561,  0.7059], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([ 1.7006e+01,  1.8718e+00, -3.3896e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([ 47.2504, -27.9689,   1.1573], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([20.9418, 12.1344, -1.0992], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([45.6598, 17.6850,  0.9116], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([22.2479, 12.4092, -1.2084], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([47.0971, 18.5995,  1.0467], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([ 48.1816, -27.8349,   1.0276], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([26.3400, 16.4928,  1.0442], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([27.0130, 16.4426,  1.0671], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([36.6436, -5.3281,  0.9428], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([ 49.8435, -29.2734,   0.8564], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([27.7259, 17.4203,  1.0643], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.2559e+01,  1.6479e+01, -7.1920e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([24.3839, 18.9240,  0.9832], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([1.8226e+01, 6.0504e-01, 6.6561e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([ 47.6424, -27.5069,   1.3200], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([18.5114,  0.3200,  0.0315], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([27.6347, 17.0694,  1.0836], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([17.6981,  0.1550,  0.0968], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([ 45.3533, -26.1198,   0.2132], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([28.8183, 17.7870,  0.8339], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([20.1620, 11.9863, -1.1321], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([48.3909, 18.0284,  0.7943], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([37.8586, -5.2764,  0.7718], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.1128, -26.8198,   1.3595], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([36.0578, -6.1242,  0.8403], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([38.0319, -5.8003,  1.1152], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([1.7983e+01, 1.5616e-02, 4.1088e-01], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([20.5953, 12.0102, -1.1903], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([ 1.7714e+01,  8.4727e-01, -1.6490e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([27.2588, 16.8424,  1.0697], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([24.0996, 19.1311,  1.1166], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([25.2157, 19.9593,  0.5026], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([37.2529, -6.4199,  0.9335], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([21.1143, 11.9102, -0.9114], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([24.5080, 18.7854,  0.8182], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([ 1.7304e+01,  1.5815e+00, -2.6718e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([ 52.6274, -29.6235,   0.7102], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([21.7299, 12.2777, -1.1904], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([24.5432, 19.5908,  1.0037], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([ 48.1639, -28.5145,  -1.3257], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([32.0019, 26.6397, -1.1649], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([32.1165, 12.5905,  0.0456], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([28.7304, 14.3607,  0.9624], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([2.0859e+01, 8.6323e+00, 3.1196e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([47.7461, -8.3849,  1.1690], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([25.8597, 20.8922, -0.9945], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([46.4431, -6.8762,  0.9621], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([18.2406,  5.1905,  0.0713], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([ 54.1077, -30.4465,  -1.2699], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([17.1021,  3.1857,  0.1222], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([17.2286, 13.7583, -1.1431], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([4.6069e+01, 4.6449e+00, 1.8598e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([24.2882, 11.2915,  1.0395], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([24.4959, 11.5860,  0.8428], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([43.2275,  4.4356, -0.1100], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.4589, -29.3233,  -1.2642], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([29.5395, 13.9458,  1.0556], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([1.5784e+01, 1.2392e+01, 4.4193e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([32.3649, 12.6060,  0.7098], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([ 42.0881, -26.7149,  -0.8660], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([31.0216, 26.6414, -1.1206], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([23.7804, 11.2889,  0.9542], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([ 42.3342, -26.9702,  -1.2818], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([31.6662, 26.6305, -1.1397], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([ 41.3861, -26.5129,  -1.1880], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([30.7623, 25.6517, -0.5856], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.0461, -10.6148,   1.0503], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.8343, -17.1875,  -1.1948], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([1.8842e+01, 4.8756e+00, 1.1441e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([1.7010e+01, 1.0998e+00, 6.0374e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([ 41.6420, -26.5655,  -1.1666], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([27.8856, 23.0059, -0.4784], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([ 4.6144e+01,  4.0165e+00, -1.2932e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([15.9573, 12.7325, -0.0453], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([30.1603, 25.6759, -1.1075], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([33.0890, 28.8386, -0.8282], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([44.9079, -7.6834,  1.2577], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([ 48.7111, -25.7130,  -1.4429], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([ 41.6861, -26.8061,  -1.3106], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([1.7741e+01, 3.0308e-01, 9.8991e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([17.5335,  4.3753,  0.2962], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([33.2634, 12.2586,  0.3365], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([24.2539, 11.3417,  0.9970], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([29.9662, 26.8041, -1.0218], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([49.1592, -7.7543,  1.1602], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([42.5250, -7.2680,  1.1907], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([45.2285, -9.9877,  1.1006], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.4435e+01,  6.0937e+00, -3.4538e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([24.4202, 11.0299,  1.0440], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([29.6907, 24.8335, -1.1392], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([2.8395e+01, 9.9921e+00, 1.9658e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.5632e+01,  4.1621e+00, -3.9749e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([31.0132, 26.7924, -1.1592], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([24.7528, 11.4088,  1.0851], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([46.1363, -8.4528,  1.1295], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([ 41.6044, -27.0621,  -1.0020], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 40.1575, -25.1728,  -1.2345], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.7806e+01,  5.0180e+00, -1.6837e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([4.1045e+01, 6.2937e+00, 1.2046e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([29.7276, 14.2327,  0.9999], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([28.7566, 14.1472,  1.1039], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([1.7636e+01, 1.1737e+01, 2.9489e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([17.8668, 15.0071, -1.1991], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([28.8045, 14.2918,  1.0584], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([3.8797e+01, 6.2271e+00, 3.3374e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([29.5629, 14.0177,  1.0133], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([ 47.2604, -29.8391,  -1.1907], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([1.6598e+01, 1.2691e+01, 2.2851e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([ 39.0897, -25.0488,  -1.1440], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([46.1941, -9.5500,  1.0726], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([4.0250e+01, 6.5744e+00, 1.9062e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([17.0370,  1.2464,  0.0194], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([23.4191, 10.2125,  0.8028], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([ 52.5991, -30.6360,  -1.1983], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([22.7708, 11.3404,  0.5429], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([32.0703, 26.3512, -1.1672], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([ 4.8828e+01,  6.4398e+00, -7.5582e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([16.4979,  2.3589,  0.0554], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([28.8272, 13.8015,  1.0916], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([ 37.9628, -24.4737,  -0.9050], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 43.8031, -28.4171,  -1.2870], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([1.7140e+01, 6.3404e-05, 6.3291e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([23.0901, 18.6425, -1.1632], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([22.5966, 11.1689,  0.8177], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([49.2041, -8.4592,  1.0448], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.2717, -30.4173,  -1.0776], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 41.9591, -26.0762,  -0.9106], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 43.6489, -29.1443,  -1.1057], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.4414e+01,  4.0448e+00, -8.6032e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([20.4732,  7.7521, -0.8678], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([ 3.0361e+01, -9.0684e-01,  1.4020e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([2.3867e+01, 1.5737e+00, 6.2276e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([2.8793e+01, 1.6137e-02, 1.9421e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([18.1009,  7.2010, -0.5217], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([20.4995,  6.1244, -0.3843], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([ 2.4375e+01,  5.3006e-01, -2.2653e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.9346e+01, -2.1110e+00,  6.9283e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([ 1.9825e+01,  2.6374e+00, -5.3469e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.2607e+01,  2.6042e+00, -5.4687e-06], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([2.2622e+01, 1.7777e-01, 8.2684e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([19.3176,  7.6769, -0.7170], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([2.3651e+01, 3.5793e-01, 6.9781e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([2.3212e+01, 2.8957e-01, 1.6484e-07], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([20.5678,  6.4029, -0.9347], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([20.6440,  7.0543, -0.5203], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([19.4577,  6.7390, -0.8307], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([25.7861, -2.1049, -0.9565], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([26.9044, -2.0418, -0.9875], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([32.0293, -2.8769,  0.0618], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([ 3.4346e+01, -4.0661e-01,  6.4398e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([25.9423, -1.9959, -0.4250], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([26.4303, -2.0085, -0.1088], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([ 2.1563e+01,  2.6869e+00, -2.6040e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([26.0292, -1.0818, -0.6359], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([20.7453,  6.8437, -0.9572], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([18.3152,  6.8623, -0.6716], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([28.0052, -2.1346, -0.9193], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([18.1486,  7.7711, -0.3882], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([26.0147, -2.3663, -0.7187], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([37.6316, 17.6384,  0.6327], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([38.4320, -5.6872,  1.0864], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([39.4602, 29.9535, -1.1194], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([37.6067, 28.3178, -0.9100], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([41.1823, -6.8072,  0.9684], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.2778, -12.4251,  -1.1322], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([37.0519, 18.6641,  1.0256], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.2364, -11.8132,  -1.0391], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.4481e+01, -6.5600e-01, -5.0757e-08], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([ 30.7749, -12.7462,  -1.1717], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([38.3575, 19.1815,  1.0025], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([41.0319, -3.1314, -0.6708], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([36.5603, 18.9082,  0.9219], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([ 29.2684, -12.0046,  -0.7118], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([40.8006, -8.1951,  0.8819], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.8053e+01, -2.9964e+00,  2.2435e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([23.6557,  5.3420,  0.4148], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([20.6691,  5.0161,  0.4992], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([27.3522,  2.0463,  0.0655], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([39.3495, 30.9496, -1.0776], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([ 28.3781, -12.0150,  -1.0010], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([37.1208, 18.8004,  1.1111], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.9178e+01, -1.0264e+01, -3.6540e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([24.6353,  4.4781,  0.1336], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([39.0446, 18.4038,  1.1690], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([ 29.7751, -11.9870,  -1.0337], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([39.1089, -7.1186,  1.3860], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([39.6200, 29.3303, -0.4647], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([39.4916, 30.8150, -1.0854], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([39.6167, -8.1484,  1.0453], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([43.2562, -3.6169, -0.9345], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([40.7500, -7.5464,  0.9650], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([41.2075, -1.7224, -0.2210], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([41.8914, -6.7456,  1.1842], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([22.6407,  4.9817,  0.0567], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([41.0046, -2.9481, -0.6774], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([37.8384, 29.9754, -1.1338], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([41.1329, 19.6691,  0.1152], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([41.6940, -3.3429,  0.1971], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([ 4.5591e+01, -2.7471e+00,  3.4420e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([40.9958, -6.8056,  0.9397], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([40.8906, -7.7229,  0.9011], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([39.2874, 31.5213, -1.0686], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([ 30.1761, -11.8717,  -1.0767], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([25.5830,  4.6412,  0.3656], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.0866, -11.9596,  -1.0088], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([24.0881,  5.5311,  0.3139], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([43.6374, -3.3421, -0.7984], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([38.3118, 17.2446,  0.8301], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([39.1915, 29.7655, -1.1314], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([36.4061, 18.3137,  1.0203], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([39.7809, -8.1087,  1.0083], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.1692e+01,  3.9961e+00, -1.3708e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([38.3595, 19.1461,  1.0342], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([37.6707, 29.5908, -1.0714], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([40.0692, 32.2023, -1.0258], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([2.2357e+01, 4.9793e+00, 2.5894e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.3413, -12.3630,  -1.1304], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([22.5654,  6.4018,  0.1331], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.8627e+01, -1.5483e+00,  1.0832e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([25.0635, 20.6621,  0.9118], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 32.3412, -21.4295,  -0.4783], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([24.8563, 20.7228,  0.9519], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.5998, -21.6088,  -0.9220], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([ 38.3277, -27.7195,  -1.0626], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([24.3583, 21.3949,  1.1643], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([24.7492, 20.6866,  1.0289], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 36.1638, -25.0830,  -1.0250], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([25.0523, 21.1409,  0.4789], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([23.5665, 20.8937,  0.5312], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 32.5937, -21.2133,  -1.0758], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([23.3976, 20.0892,  0.9583], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([24.1440, 20.5512,  1.0356], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 33.6129, -23.0956,  -0.9738], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([ 30.0960, -15.5063,  -1.1366], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([ 38.0785, -29.6126,  -1.0845], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([24.8373, 21.4133,  1.1694], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([23.4217, 19.6150,  0.9108], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.4280, -20.8386,  -0.9225], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.3170, -22.2782,  -1.0892], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([27.2292,  7.9937, -0.8391], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 31.8698, -18.5931,   1.4277], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 48.1254, -30.4452,  -0.8618], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.5653, -19.2922,  -1.1136], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 33.5700, -20.4197,   1.2511], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 39.1715, -22.6338,   1.1657], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 33.3085, -20.2111,   1.0551], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 42.2549, -26.4990,  -1.3056], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([24.7784,  8.8442, -0.4713], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([27.0000,  8.2584, -0.2980], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 44.0308, -23.1981,   0.7422], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 42.6640, -24.9193,   1.0270], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 48.1079, -32.5155,  -0.8624], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 43.0763, -25.1173,  -1.0208], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.7897, -18.1567,  -1.2757], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.2616, -19.1610,   0.9457], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 50.7671, -27.0119,  -1.0360], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 31.1080, -17.7125,   0.6052], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 39.6060, -23.2370,  -1.2991], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([26.9951,  8.1046, -0.8100], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 29.6949, -16.4559,   1.0694], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.1768, -20.4686,   0.6178], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 45.3915, -21.4775,   0.9351], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 29.9549, -18.3827,   1.1334], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.7118, -21.7746,   0.8704], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 51.9191, -35.4677,  -1.1198], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 46.7065, -30.8349,  -1.2729], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 45.9194, -26.0154,  -1.3024], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 27.8645, -16.0591,   1.1560], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([25.9221,  9.7349, -0.3596], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 40.1617, -22.3173,  -1.3455], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 33.0416, -20.6618,   1.0726], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([25.0358,  7.8745, -0.6312], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 35.2067, -17.9522,   1.1347], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([26.5732,  8.0706, -0.7725], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 35.0165, -15.6279,   0.7247], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 48.9671, -30.7986,  -1.3131], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 41.9918, -24.1578,  -1.2832], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 46.2006, -30.1672,  -0.8878], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 43.5084, -25.8403,  -1.3615], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 48.5722, -31.7141,  -1.0249], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([25.8978,  7.6763, -0.7499], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([24.7793,  7.4680, -0.6518], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([24.9587,  6.3740, -0.5758], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 48.6529, -26.0149,  -0.9965], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 46.3356, -30.3369,  -0.7518], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 50.1795, -34.1627,  -1.0129], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 29.1484, -15.9217,   1.3702], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 44.0147, -25.0389,   1.0110], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 38.0040, -21.0520,   0.8675], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([19.1694, -8.4264,  0.9726], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([19.3052, 14.7226, -1.2652], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([19.9093, 14.4648, -1.2532], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([43.7420, -9.4681, -0.9711], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([24.6558, -1.0284, -0.7798], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([40.4085, 23.6050, -1.1083], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([ 45.7367, -11.8549,   1.2197], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([15.9912,  1.8245,  0.0539], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([20.4814, 14.6420, -1.1478], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([ 1.7310e+01,  1.3532e+01, -2.5872e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([ 45.8967, -11.2985,   1.1787], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([19.1737,  6.5416,  0.4160], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([17.7633,  4.8228,  0.3674], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.0003e+01,  1.8229e-02, -5.8753e-01], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([45.6128, -9.8662, -1.0718], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([39.9717, -9.6078, -0.5851], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([ 28.3255, -17.3660,  -0.9996], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 50.5374, -10.9733,   1.1294], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([2.2874e+01, 3.3643e-04, 2.0508e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([1.7383e+01, 5.4251e-01, 2.2851e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([41.7526, -9.6131,  1.1053], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([38.8679, 22.0989, -1.0209], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([42.2459, 24.2224, -1.1425], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([23.0029, -0.4130, -0.5072], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([37.1308, 20.9270, -0.6662], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([24.6513, -1.0274, -0.7799], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([36.7437, 21.7721, -0.5055], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([38.8172, 22.1275, -1.0668], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([32.5541, -7.1424, -0.4088], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([ 21.7859, -10.9481,   0.9601], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 27.7086, -17.2293,  -1.0346], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.4475, -15.1250,   1.1521], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 29.3695, -17.8955,  -1.0002], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([17.9851, -7.8031,  1.0950], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.4604e+01, -9.2402e+00, -2.2697e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([ 34.6389, -22.0240,   1.0612], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([2.1917e+01, 3.7318e-04, 1.0870e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([45.7130, -9.6971, -1.1591], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([ 48.5334, -11.1791,   1.1318], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([20.6993, 13.5720, -0.8054], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([ 2.2089e+01, -3.6863e-02, -1.7284e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([ 27.2232, -16.6841,  -1.0463], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 28.3570, -17.2013,  -1.0628], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([18.6096, -8.1778,  1.0952], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 41.1040, -10.5154,  -0.4078], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([2.2622e+01, 4.7181e-05, 9.8465e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.9590, -10.0802,   1.0000], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([ 31.0548, -19.3935,  -0.9932], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.7773, -15.3948,   0.4964], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 33.4972, -22.4312,  -1.0192], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 46.2448, -12.3461,   1.2108], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([17.7250,  3.3450,  0.0559], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([ 45.7980, -10.8379,  -1.0088], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([ 47.2279, -11.1517,   1.1422], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([18.1354,  0.1791, -0.6717], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([ 28.9363, -17.8795,  -1.1328], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([21.1007, -9.8037,  1.0609], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.0315e+01,  1.5277e+01, -5.1279e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([22.0932, -0.3574, -0.8531], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([17.2614, 13.4807, -0.1066], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([45.1314, -9.8459,  1.3050], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([39.3175, 22.6438, -1.1115], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([45.1563, -9.9030, -1.3124], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([23.0284, -0.3491, -0.1983], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([17.9584, 13.7529, -0.9381], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([40.2954, 23.0237, -1.1225], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([39.6436, 22.8016, -1.1094], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([16.3021,  4.4033,  0.4693], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([49.8576, -9.7559,  1.2227], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([45.7060, -9.8630, -1.2551], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([ 1.8570e+01,  1.4343e+01, -5.7742e-08], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([36.4904, 20.6650, -0.9052], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([ 43.3137, -10.5829,   0.0456], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([16.3764,  2.3267,  0.0347], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([ 26.4741, -15.8986,  -0.2672], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 30.3962, -15.5043,   0.7691], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 1.9314e+01, -3.2709e-01,  8.9996e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([20.2633, 14.9293, -1.2018], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([19.7943, -8.5712,  1.0701], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 27.5721, -16.4542,  -1.0861], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 36.8004, -14.0253,  -0.1525], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 37.6987, -12.7500,  -0.9818], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 36.8323, -13.1476,  -0.8427], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 37.0691, -13.0756,  -1.2426], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 37.7271, -12.7907,  -1.1204], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.7225e+01,  3.1429e+00, -5.7094e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([4.8059e+01, 4.4811e-01, 1.0074e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([5.0588e+01, 5.3723e-01, 1.1402e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([4.5107e+01, 1.1715e+00, 3.5800e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.4905e+01,  2.2869e+00, -3.3138e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 35.8117, -13.7389,  -0.5532], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.6455e+01,  3.2318e+00, -2.4588e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 37.7274, -12.8226,  -1.1574], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 37.3657, -12.9295,  -1.1164], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([42.8013,  3.1678, -0.0764], device='cuda:0', grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 37.8884, -13.3035,  -1.2201], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.4989e+01,  3.4468e+00, -2.9004e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 36.7744, -12.8364,  -1.1663], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.5628e+01,  3.1252e+00, -8.4812e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.8861e+01,  1.6628e+00, -6.3367e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([21.1452, 14.2958,  1.0402], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 34.3848, -21.0683,   0.4999], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.1567, -22.2870,   0.9020], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([20.7149, -8.4735, -0.9143], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([22.1994, 14.6790,  0.9295], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 31.6820, -19.2839,   1.0733], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([43.4429, -9.6276, -0.5950], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 45.2725, -13.6588,   1.2365], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([ 47.2706, -11.9890,   1.1404], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([37.7684,  9.9255, -0.3758], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([21.2967, -9.2416, -0.7403], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([46.9732, -9.0880, -1.1894], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 41.1978, -11.2936,  -1.3125], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([45.6473, -8.7864, -1.0961], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 33.3934, -13.4733,  -0.0717], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.2767, -13.3457,   1.3039], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([ 35.7915, -23.1989,   1.4267], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([24.5251, -8.3163, -1.0842], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([19.2190, -8.1142, -0.0356], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([23.9683, -9.7375, -1.1503], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([21.8635, -9.6428, -1.1142], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([ 47.6516, -11.7902,   1.0446], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([28.3642, -9.4880, -1.0699], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([45.1132, -8.6117, -0.9859], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([34.4113,  8.6637, -0.7571], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([ 4.4134e+01, -8.3850e+00,  1.2796e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([22.0105, 14.7682,  0.4353], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 42.1805, -14.1110,  -1.3199], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([ 33.1469, -12.6442,  -0.5486], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([22.9424, 13.8233,  0.7787], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 39.9691, -30.4766,   1.3957], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([ 46.1071, -32.6982,   0.8277], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.9858, -22.7988,   0.9687], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([ 47.4768, -12.7926,   0.9172], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([43.5278, -8.5838, -0.9152], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 37.6509, -23.5464,   1.0267], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([36.0453,  9.8700, -0.2599], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([ 37.4979, -26.4122,   1.0523], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([22.5580, 15.2765,  0.9946], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 39.3663, -27.1656,   1.0368], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([20.3253, -8.3980, -1.0026], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([34.1808, -8.9038, -1.1762], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([35.4480,  9.0929, -0.6705], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([36.7542,  9.2998, -0.5362], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([ 35.5665, -14.0888,  -0.1037], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([ 43.2548, -30.9784,   0.8108], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([ 43.7007, -11.5399,   1.3480], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([ 40.7450, -11.0795,   0.8547], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.3603, -22.9301,   0.9941], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([25.3835, -8.7454, -1.0970], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([ 43.7655, -32.5143,   1.4511], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([21.9805, 14.6549,  0.9896], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 42.7131, -14.0731,  -1.2423], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([36.3246,  9.1050, -0.6384], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([22.2379, 15.5507,  0.3626], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([41.2401, -9.1022,  0.0708], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 47.5700, -32.0633,   0.7148], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([ 44.4812, -29.9610,   0.1999], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([21.5474, -9.3747, -0.6336], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([22.3830, -9.6972, -1.0111], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([44.0308, -9.5210, -0.1934], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 24.7156, -11.5502,  -1.0125], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.2647, -12.7126,   1.1559], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([21.9339, 13.5515,  0.6462], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([22.3797, 15.6557,  0.4092], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([44.3779, -9.2008, -0.8399], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([39.1298,  8.9210, -0.5924], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([39.6513,  9.4132, -0.8297], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([ 22.2594, -10.0362,  -1.0848], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([ 39.1314, -27.1075,   1.1799], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([ 48.3564, -12.1008,   1.0983], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([28.6191, -9.6940, -0.8227], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([ 43.2633, -15.0926,  -1.2950], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([24.7170, -8.7339, -1.1214], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([29.0598,  3.9818,  0.2646], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([21.7672, 14.6257,  0.9070], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([34.6777,  9.0611, -0.7263], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([25.9458, -8.9930, -1.1087], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([36.9219,  8.8780, -0.7726], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([ 36.9911, -23.7474,   1.3183], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([34.7247, -9.9405, -0.9778], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([ 34.3366, -22.1937,   0.8130], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([21.8759, 14.8030,  1.0215], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([46.1893, -9.2882, -1.2502], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.0888, -12.8163,   1.2269], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([ 30.9451, -11.3676,  -0.3238], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.2089, -33.2701,   1.1292], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([26.8774, -9.5045, -1.0295], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([ 37.6442, -23.3092,   0.8890], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.6121, -12.8179,  -0.8288], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n"
-     ]
-    }
-   ],
-   "source": [
-    "for pred, dat in zip(node_pred, data.y_nodes):\n",
-    "    print(pred, dat)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 65,
-   "metadata": {
-    "collapsed": true,
-    "jupyter": {
-     "outputs_hidden": true
+     "data": {
+      "text/plain": [
+       "[<matplotlib.lines.Line2D at 0x2aab7fcdaf60>]"
+      ]
+     },
+     "execution_count": 47,
+     "metadata": {},
+     "output_type": "execute_result"
+    },
+    {
+     "data": {
+      "image/png": "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\n",
+      "text/plain": [
+       "<Figure size 1152x288 with 2 Axes>"
+      ]
+     },
+     "metadata": {
+      "needs_background": "light"
+     },
+     "output_type": "display_data"
+    }
+   ],
+   "source": [
+    "fig, axs = plt.subplots(1,2)\n",
+    "fig.set_size_inches(16,4)\n",
+    "axs[0].plot(np.arange(len(loss_v_node)), loss_v_node)\n",
+    "# axs[1].plot(np.arange(len(loss_v_edge)), loss_v_edge)\n",
+    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
+    "# axs[3].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 10,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "0.0 0.0\n"
+     ]
     }
+   ],
+   "source": [
+    "torch.cuda.empty_cache()\n",
+    "torch.cuda.reset_max_memory_allocated()\n",
+    "torch.cuda.reset_max_memory_cached()\n",
+    "print(torch.cuda.memory_allocated(0)/1024**3, torch.cuda.max_memory_allocated(0)/1024**3)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {
+    "heading_collapsed": true
+   },
+   "source": [
+    "## Getting Weights & Bias to Work"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 18,
+   "metadata": {
+    "hidden": true
    },
    "outputs": [
     {
      "data": {
       "text/plain": [
-       "['AGNNConv',\n",
-       " 'APPNP',\n",
-       " 'ARGA',\n",
-       " 'ARGVA',\n",
-       " 'ARMAConv',\n",
-       " 'ChebConv',\n",
-       " 'DNAConv',\n",
-       " 'DataParallel',\n",
-       " 'DeepGraphInfomax',\n",
-       " 'DenseGCNConv',\n",
-       " 'DenseGINConv',\n",
-       " 'DenseSAGEConv',\n",
-       " 'DynamicEdgeConv',\n",
-       " 'ECConv',\n",
-       " 'EdgeConv',\n",
-       " 'FeaStConv',\n",
-       " 'GAE',\n",
-       " 'GATConv',\n",
-       " 'GCNConv',\n",
-       " 'GINConv',\n",
-       " 'GMMConv',\n",
-       " 'GatedGraphConv',\n",
-       " 'GlobalAttention',\n",
-       " 'GraphConv',\n",
-       " 'HypergraphConv',\n",
-       " 'InnerProductDecoder',\n",
-       " 'JumpingKnowledge',\n",
-       " 'MessagePassing',\n",
-       " 'MetaLayer',\n",
-       " 'NNConv',\n",
-       " 'PPFConv',\n",
-       " 'PointConv',\n",
-       " 'RENet',\n",
-       " 'RGCNConv',\n",
-       " 'Reshape',\n",
-       " 'SAGEConv',\n",
-       " 'SAGPooling',\n",
-       " 'SGConv',\n",
-       " 'Set2Set',\n",
-       " 'SignedConv',\n",
-       " 'SignedGCN',\n",
-       " 'SplineConv',\n",
-       " 'TopKPooling',\n",
-       " 'VGAE',\n",
-       " 'XConv',\n",
-       " '__all__',\n",
-       " '__builtins__',\n",
-       " '__cached__',\n",
-       " '__doc__',\n",
-       " '__file__',\n",
-       " '__loader__',\n",
-       " '__name__',\n",
-       " '__package__',\n",
-       " '__path__',\n",
-       " '__spec__',\n",
-       " 'avg_pool',\n",
-       " 'avg_pool_x',\n",
-       " 'conv',\n",
-       " 'data_parallel',\n",
-       " 'dense',\n",
-       " 'dense_diff_pool',\n",
-       " 'fps',\n",
-       " 'glob',\n",
-       " 'global_add_pool',\n",
-       " 'global_max_pool',\n",
-       " 'global_mean_pool',\n",
-       " 'global_sort_pool',\n",
-       " 'graclus',\n",
-       " 'inits',\n",
-       " 'knn',\n",
-       " 'knn_graph',\n",
-       " 'knn_interpolate',\n",
-       " 'max_pool',\n",
-       " 'max_pool_x',\n",
-       " 'meta',\n",
-       " 'models',\n",
-       " 'nearest',\n",
-       " 'pool',\n",
-       " 'radius',\n",
-       " 'radius_graph',\n",
-       " 'reshape',\n",
-       " 'unpool',\n",
-       " 'voxel_grid']"
+       "Sequential(\n",
+       "  (0): Linear(in_features=19, out_features=16, bias=True)\n",
+       "  (1): ReLU()\n",
+       "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
+       "  (3): ReLU()\n",
+       "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
+       ")"
       ]
      },
-     "execution_count": 65,
+     "execution_count": 18,
      "metadata": {},
      "output_type": "execute_result"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "Retry attempt failed:\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
+      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
+      "    raise err\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
+      "    sock.connect(sa)\n",
+      "OSError: [Errno 101] Network is unreachable\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
+      "    chunked=chunked,\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
+      "    self._validate_conn(conn)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
+      "    conn.connect()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
+      "    conn = self._new_conn()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 169, in _new_conn\n",
+      "    self, \"Failed to establish a new connection: %s\" % e\n",
+      "urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
+      "    timeout=timeout\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
+      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
+      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
+      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576271582&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=MmIGu%2F4ONY2zZtXV60r4n2VtQ%2F7%2BfOmVBHMam3wT3aKVoHGK84OediGBAASfRnCU%2ByxJnJoe6wgqBm8OA4RFnwbWS%2BT1gP1VBHVekU3e0%2FBjKnK8lLsunIwyrwC9DhNkHSaiPTduRingNiJZ1K096%2BHtW8DSs%2BVkivZt%2FHH4Sh24d1JcpFjjkb8GUWGOc2XuFhCKq%2FQ6v7cIiQPmaCfZ7tIsPYZNaEJ5WnLcgsMIcUFlMpayxtmovih59VHK9%2Bu7pLnnEIleq%2FVVwSp1Nxn3Cuvyf%2FefL9nIOD9RrfbYHqTIWZB2cEMVI4XuNkEPrYUuV5aNadYZ%2BXP1VYzyt%2BGgVQ%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
+      "    url, data=progress, headers=extra_headers)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
+      "    return request('put', url, data=data, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
+      "    raise ConnectionError(e, request=request)\n",
+      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576271582&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=MmIGu%2F4ONY2zZtXV60r4n2VtQ%2F7%2BfOmVBHMam3wT3aKVoHGK84OediGBAASfRnCU%2ByxJnJoe6wgqBm8OA4RFnwbWS%2BT1gP1VBHVekU3e0%2FBjKnK8lLsunIwyrwC9DhNkHSaiPTduRingNiJZ1K096%2BHtW8DSs%2BVkivZt%2FHH4Sh24d1JcpFjjkb8GUWGOc2XuFhCKq%2FQ6v7cIiQPmaCfZ7tIsPYZNaEJ5WnLcgsMIcUFlMpayxtmovih59VHK9%2Bu7pLnnEIleq%2FVVwSp1Nxn3Cuvyf%2FefL9nIOD9RrfbYHqTIWZB2cEMVI4XuNkEPrYUuV5aNadYZ%2BXP1VYzyt%2BGgVQ%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
+      "    result = self._call_fn(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 980, in upload_file\n",
+      "    util.sentry_reraise(retry.TransientException(exc=e))\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/util.py\", line 92, in sentry_reraise\n",
+      "    six.reraise(type(exc), exc, sys.exc_info()[2])\n",
+      "  File \"/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/six.py\", line 692, in reraise\n",
+      "    raise value.with_traceback(tb)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
+      "    url, data=progress, headers=extra_headers)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
+      "    return request('put', url, data=data, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
+      "    raise ConnectionError(e, request=request)\n",
+      "wandb.retry.TransientException: None\n",
+      "wandb: Network error (TransientException), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n",
+      "wandb: ERROR Error uploading \"wandb-metadata.json\": CommError, None\n"
+     ]
+    }
+   ],
+   "source": [
+    "model.output_network"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Sweep"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 11,
+   "metadata": {
+    "code_folding": []
+   },
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Create sweep with ID: zra8ov9k\n",
+      "Sweep URL: https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\n"
+     ]
+    }
+   ],
+   "source": [
+    "# System imports\n",
+    "import os\n",
+    "import sys\n",
+    "from pprint import pprint as pp\n",
+    "from time import time as tt\n",
+    "sys.path.append('..')\n",
+    "sys.path.append('/global/common/cori_cle7/software/jupyter/19-11/lib/python3.7/site-packages')\n",
+    "sys.path.append('/global/homes/d/danieltm/.local/lib/python3.7/site-packages')\n",
+    "import wandb\n",
+    "# External imports\n",
+    "import numpy as np\n",
+    "import torch\n",
+    "import torch.nn.functional as F\n",
+    "import torch.nn as nn\n",
+    "\n",
+    "sweep_config = {\n",
+    "    \"name\": \"Track Param Sweep\",\n",
+    "    \"method\": \"random\",\n",
+    "#     \"controller\": \"local\",\n",
+    "    \"metric\": {\n",
+    "        \"name\": \"Best Accuracy\",\n",
+    "        \"goal\": \"maximize\"\n",
+    "    },\n",
+    "#     \"early_terminate\": {\n",
+    "#         \"type\": \"hyperband\",\n",
+    "#         \"min_iter\": 3\n",
+    "#     },\n",
+    "    \"parameters\": {\n",
+    "        \"n_graph_iters\": {\n",
+    "            \"min\": 1,\n",
+    "            \"max\": 8\n",
+    "        },\n",
+    "        \"hidden_dim\": {\n",
+    "            \"min\": 4,\n",
+    "            \"max\": 64\n",
+    "        },\n",
+    "        \"lr\": {\n",
+    "            \"distribution\": \"log_uniform\",\n",
+    "            \"min\": -11.5,\n",
+    "            \"max\": -2.3\n",
+    "        },\n",
+    "#         \"step_size\": {\n",
+    "#             \"min\": 1,\n",
+    "#             \"max\": 100\n",
+    "#         },\n",
+    "#         \"gamma\": {\n",
+    "#             \"min\": 0.01,\n",
+    "#             \"max\": 0.99\n",
+    "#         },\n",
+    "#         \"weight_decay\": {\n",
+    "#             \"distribution\": \"log_uniform\",\n",
+    "#             \"min\": -11.5,\n",
+    "#             \"max\": -4.6\n",
+    "#         },\n",
+    "        \"network\": {\n",
+    "            \"values\": [\"Edge_Track_Truth_Net\"]\n",
+    "        },\n",
+    "        \"optimizer\": {\n",
+    "            \"values\": [\"AdamW\"] #, \"Adam\", \"Adamax\", \"SGD\"] \n",
+    "        },\n",
+    "        \"train_size\": {\n",
+    "            \"min\": 100,\n",
+    "            \"max\": 800\n",
+    "        },\n",
+    "        \"epochs\": {\n",
+    "            \"min\": 30,\n",
+    "            \"max\": 250\n",
+    "        }\n",
+    "    }\n",
+    "}\n",
+    "\n",
+    "sweep_id = wandb.sweep(sweep_config, entity= \"murnanedaniel\", project= \"node_regression_sweep\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {
+    "code_folding": [
+     38,
+     64,
+     109,
+     150,
+     163
+    ]
+   },
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "wandb: Agent Starting Run: fsh2uyeg with config:\n",
+      "\tepochs: 77\n",
+      "\thidden_dim: 61\n",
+      "\tlr: 1.8854813537267455e-05\n",
+      "\tn_graph_iters: 7\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 535\n",
+      "wandb: Agent Started Run: fsh2uyeg\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fsh2uyeg\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fsh2uyeg</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 77, 'hidden_dim': 61, 'lr': 1.8854813537267455e-05, 'n_graph_iters': 7, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 535}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 61, 'n_graph_iters': 7, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  3.2173675537109374 , validation accuracy:  0.0 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  2 , validation loss:  2.0348384857177733 , validation accuracy:  12.014543408394923 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  3 , validation loss:  2.0008333206176756 , validation accuracy:  11.867377966303442 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  4 , validation loss:  1.9651144027709961 , validation accuracy:  11.491889669202385 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  5 , validation loss:  1.9387147903442383 , validation accuracy:  10.85164785618185 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  6 , validation loss:  1.9064964294433593 , validation accuracy:  11.70542384008022 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  7 , validation loss:  1.890129852294922 , validation accuracy:  13.788824804590986 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  8 , validation loss:  1.8820430755615234 , validation accuracy:  13.578897629842842 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  9 , validation loss:  1.8787841796875 , validation accuracy:  11.21487236644195 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  10 , validation loss:  1.8771022796630858 , validation accuracy:  11.056164536735452 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  11 , validation loss:  1.8764215469360352 , validation accuracy:  11.019012476599613 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  12 , validation loss:  1.8761882781982422 , validation accuracy:  10.811249499529287 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  13 , validation loss:  1.8757246017456055 , validation accuracy:  10.970678728461724 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  14 , validation loss:  1.876316452026367 , validation accuracy:  10.584369442971587 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  15 , validation loss:  1.8753456115722655 , validation accuracy:  10.922344980323837 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  16 , validation loss:  1.8752079010009766 , validation accuracy:  10.863190243796868 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  17 , validation loss:  1.875006866455078 , validation accuracy:  10.96779313155797 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  18 , validation loss:  1.8757440567016601 , validation accuracy:  10.549020880900596 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  19 , validation loss:  1.8747888565063477 , validation accuracy:  10.907916995805063 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  20 , validation loss:  1.8747465133666992 , validation accuracy:  11.078527912739549 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  21 , validation loss:  1.875246238708496 , validation accuracy:  10.577155450712201 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  22 , validation loss:  1.8748184204101563 , validation accuracy:  10.700514718347707 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  23 , validation loss:  1.874533462524414 , validation accuracy:  10.796100115784576 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  24 , validation loss:  1.8743282318115235 , validation accuracy:  10.906113497740217 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  25 , validation loss:  1.8766510009765625 , validation accuracy:  10.305187942533339 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  26 , validation loss:  1.8745595932006835 , validation accuracy:  10.62476779962415 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  27 , validation loss:  1.8743480682373046 , validation accuracy:  10.694382824927228 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  28 , validation loss:  1.874081802368164 , validation accuracy:  10.794657317332698 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  29 , validation loss:  1.874489974975586 , validation accuracy:  10.600600925555206 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  30 , validation loss:  1.8739404678344727 , validation accuracy:  10.782754230104711 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  31 , validation loss:  1.8737707138061523 , validation accuracy:  10.869322137217347 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  32 , validation loss:  1.8737693786621095 , validation accuracy:  11.079610011578458 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  33 , validation loss:  1.873524284362793 , validation accuracy:  10.967071732332032 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  34 , validation loss:  1.8760786056518555 , validation accuracy:  10.297252551048013 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  35 , validation loss:  1.8733858108520507 , validation accuracy:  10.929558972583223 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  36 , validation loss:  1.873359489440918 , validation accuracy:  10.8675186391525 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  37 , validation loss:  1.8745513916015626 , validation accuracy:  10.4725525629511 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  38 , validation loss:  1.873743438720703 , validation accuracy:  10.606732818975685 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  39 , validation loss:  1.873090934753418 , validation accuracy:  10.928476873744314 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  40 , validation loss:  1.8730995178222656 , validation accuracy:  10.821349088692427 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  41 , validation loss:  1.872916030883789 , validation accuracy:  10.940019261359332 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  42 , validation loss:  1.872874641418457 , validation accuracy:  10.948676052070597 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  43 , validation loss:  1.872788429260254 , validation accuracy:  10.936772964842609 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  44 , validation loss:  1.8731853485107421 , validation accuracy:  10.664444757050775 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  45 , validation loss:  1.873497772216797 , validation accuracy:  10.554070675482166 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  46 , validation loss:  1.8727989196777344 , validation accuracy:  10.749209166098565 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  47 , validation loss:  1.8724172592163086 , validation accuracy:  11.001338195564117 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  48 , validation loss:  1.8723691940307616 , validation accuracy:  10.912606090773664 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  49 , validation loss:  1.8739023208618164 , validation accuracy:  10.422415316748365 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  50 , validation loss:  1.8724851608276367 , validation accuracy:  10.743437972291057 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  51 , validation loss:  1.872181510925293 , validation accuracy:  10.971039428074695 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  52 , validation loss:  1.873704719543457 , validation accuracy:  10.418086921392733 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  53 , validation loss:  1.8720338821411133 , validation accuracy:  10.8310879782426 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  54 , validation loss:  1.871882438659668 , validation accuracy:  10.990517207175037 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  55 , validation loss:  1.8719385147094727 , validation accuracy:  10.90503139890131 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  56 , validation loss:  1.871800994873047 , validation accuracy:  10.859222548054207 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  57 , validation loss:  1.8717533111572267 , validation accuracy:  11.043540050281527 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  58 , validation loss:  1.871912384033203 , validation accuracy:  10.728649288159314 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  59 , validation loss:  1.8718534469604493 , validation accuracy:  10.737666778483547 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  60 , validation loss:  1.872329330444336 , validation accuracy:  11.382597686472682 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  61 , validation loss:  1.8713041305541993 , validation accuracy:  10.897456707028953 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  62 , validation loss:  1.8715900421142577 , validation accuracy:  11.208379773408502 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  63 , validation loss:  1.872120475769043 , validation accuracy:  10.523050508766804 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  64 , validation loss:  1.8751829147338868 , validation accuracy:  10.188321267931281 %, lr:  1.8854813537267455e-05\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  65 , validation loss:  1.8711935043334962 , validation accuracy:  10.775900937458294 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  66 , validation loss:  1.8734149932861328 , validation accuracy:  10.322862223568833 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  67 , validation loss:  1.8712543487548827 , validation accuracy:  10.665166156276715 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  68 , validation loss:  1.8707679748535155 , validation accuracy:  10.887717817478782 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  69 , validation loss:  1.8706295013427734 , validation accuracy:  11.042818651055587 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  70 , validation loss:  1.8704252243041992 , validation accuracy:  10.954807945491075 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  71 , validation loss:  1.8705272674560547 , validation accuracy:  10.855615551924513 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  72 , validation loss:  1.870419692993164 , validation accuracy:  10.818102792175704 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  73 , validation loss:  1.8703176498413085 , validation accuracy:  10.871125635282192 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  74 , validation loss:  1.8700416564941407 , validation accuracy:  10.9991739978863 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  75 , validation loss:  1.8704484939575194 , validation accuracy:  10.661559160147021 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  76 , validation loss:  1.8717390060424806 , validation accuracy:  10.413037126811163 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  77 , validation loss:  1.8696632385253906 , validation accuracy:  10.933165968712915 %, lr:  1.8854813537267455e-05\n",
+      "wandb: Agent Finished Run: fsh2uyeg \n",
+      "\n",
+      "wandb: Agent Starting Run: b1emq1m4 with config:\n",
+      "\tepochs: 37\n",
+      "\thidden_dim: 58\n",
+      "\tlr: 1.5547456939150375e-05\n",
+      "\tn_graph_iters: 2\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 454\n",
+      "wandb: Agent Started Run: b1emq1m4\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/b1emq1m4\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/b1emq1m4</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 37, 'hidden_dim': 58, 'lr': 1.5547456939150375e-05, 'n_graph_iters': 2, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 454}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 58, 'n_graph_iters': 2, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  2.8571355819702147 , validation accuracy:  0.0 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  2 , validation loss:  2.7673583984375 , validation accuracy:  0.0 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  3 , validation loss:  1.944607925415039 , validation accuracy:  11.817962119326646 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  4 , validation loss:  1.9348716735839844 , validation accuracy:  11.49946436107474 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  5 , validation loss:  1.9292457580566407 , validation accuracy:  11.388368880280192 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  6 , validation loss:  1.9213788986206055 , validation accuracy:  11.606592146126628 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  7 , validation loss:  1.9147760391235351 , validation accuracy:  12.027528594461819 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  8 , validation loss:  1.9084299087524415 , validation accuracy:  11.432734932675418 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  9 , validation loss:  1.9026792526245118 , validation accuracy:  11.524713333982593 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  10 , validation loss:  1.8961021423339843 , validation accuracy:  13.350574774833266 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  11 , validation loss:  1.891566848754883 , validation accuracy:  13.70802809128586 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  12 , validation loss:  1.8860797882080078 , validation accuracy:  12.530704554554012 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  13 , validation loss:  1.8821338653564452 , validation accuracy:  11.904890726052251 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  14 , validation loss:  1.8819236755371094 , validation accuracy:  10.720713896673988 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  15 , validation loss:  1.8784551620483398 , validation accuracy:  11.182048701661742 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  16 , validation loss:  1.8777942657470703 , validation accuracy:  10.970318028848755 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  17 , validation loss:  1.8781505584716798 , validation accuracy:  10.632342491496507 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  18 , validation loss:  1.877005386352539 , validation accuracy:  11.154635531076075 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  19 , validation loss:  1.8768970489501953 , validation accuracy:  10.782754230104711 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  20 , validation loss:  1.8767522811889648 , validation accuracy:  10.75750525719686 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  21 , validation loss:  1.877646255493164 , validation accuracy:  10.52557540605759 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  22 , validation loss:  1.8781600952148438 , validation accuracy:  10.412676427198193 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  23 , validation loss:  1.876469039916992 , validation accuracy:  10.716385501318356 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  24 , validation loss:  1.8765369415283204 , validation accuracy:  10.67310154776204 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  25 , validation loss:  1.8760759353637695 , validation accuracy:  10.79357521849379 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  26 , validation loss:  1.8757495880126953 , validation accuracy:  10.915852387290387 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  27 , validation loss:  1.8774555206298829 , validation accuracy:  10.436843301267137 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  28 , validation loss:  1.876645851135254 , validation accuracy:  10.569220059226875 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  29 , validation loss:  1.8755924224853515 , validation accuracy:  10.794657317332698 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  30 , validation loss:  1.8755172729492187 , validation accuracy:  10.79790361384942 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  31 , validation loss:  1.875286865234375 , validation accuracy:  11.000977495951147 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  32 , validation loss:  1.8753164291381836 , validation accuracy:  10.836498472437139 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  33 , validation loss:  1.8752912521362304 , validation accuracy:  10.803314108043963 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  34 , validation loss:  1.8750947952270507 , validation accuracy:  10.923066379549775 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  35 , validation loss:  1.875575065612793 , validation accuracy:  10.623325001172274 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  36 , validation loss:  1.875286865234375 , validation accuracy:  10.697989821056922 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  37 , validation loss:  1.8749725341796875 , validation accuracy:  10.793214518880822 %, lr:  1.5547456939150375e-05\n",
+      "wandb: Agent Finished Run: b1emq1m4 \n",
+      "\n",
+      "wandb: Agent Starting Run: fid9vcvf with config:\n",
+      "\tepochs: 84\n",
+      "\thidden_dim: 6\n",
+      "\tlr: 0.07936130195768072\n",
+      "\tn_graph_iters: 4\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 687\n",
+      "wandb: Agent Started Run: fid9vcvf\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fid9vcvf\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fid9vcvf</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 84, 'hidden_dim': 6, 'lr': 0.07936130195768072, 'n_graph_iters': 4, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 687}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 6, 'n_graph_iters': 4, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.890950584411621 , validation accuracy:  11.508842551011943 %, lr:  0.07936130195768072\n",
+      "Epoch:  2 , validation loss:  1.8901582717895509 , validation accuracy:  11.364202006211247 %, lr:  0.07936130195768072\n",
+      "Epoch:  3 , validation loss:  1.8889724731445312 , validation accuracy:  10.965628933880154 %, lr:  0.07936130195768072\n",
+      "Epoch:  4 , validation loss:  1.8894882202148438 , validation accuracy:  10.685726034215966 %, lr:  0.07936130195768072\n",
+      "Epoch:  5 , validation loss:  1.8927127838134765 , validation accuracy:  10.200224355159266 %, lr:  0.07936130195768072\n",
+      "Epoch:  6 , validation loss:  1.889016342163086 , validation accuracy:  11.019012476599613 %, lr:  0.07936130195768072\n",
+      "Epoch:  7 , validation loss:  1.8891872406005858 , validation accuracy:  10.806921104173655 %, lr:  0.07936130195768072\n",
+      "Epoch:  8 , validation loss:  1.8889984130859374 , validation accuracy:  10.868240038378438 %, lr:  0.07936130195768072\n",
+      "Epoch:  9 , validation loss:  1.8891313552856446 , validation accuracy:  11.029112065762753 %, lr:  0.07936130195768072\n",
+      "Epoch:  10 , validation loss:  1.8889781951904296 , validation accuracy:  10.941822759424179 %, lr:  0.07936130195768072\n",
+      "Epoch:  11 , validation loss:  1.888910675048828 , validation accuracy:  10.911523991934757 %, lr:  0.07936130195768072\n",
+      "Epoch:  12 , validation loss:  1.889869499206543 , validation accuracy:  11.377547891891112 %, lr:  0.07936130195768072\n",
+      "Epoch:  13 , validation loss:  1.8890119552612306 , validation accuracy:  11.061935730542961 %, lr:  0.07936130195768072\n",
+      "Epoch:  14 , validation loss:  1.8887672424316406 , validation accuracy:  10.947954652844658 %, lr:  0.07936130195768072\n",
+      "Epoch:  15 , validation loss:  1.8891851425170898 , validation accuracy:  10.755341059519044 %, lr:  0.07936130195768072\n",
+      "Epoch:  16 , validation loss:  1.8896678924560546 , validation accuracy:  10.600600925555206 %, lr:  0.07936130195768072\n",
+      "Epoch:  17 , validation loss:  1.8887239456176759 , validation accuracy:  10.937133664455578 %, lr:  0.07936130195768072\n",
+      "Epoch:  18 , validation loss:  1.8889545440673827 , validation accuracy:  11.032358362279478 %, lr:  0.07936130195768072\n",
+      "Epoch:  19 , validation loss:  1.893239974975586 , validation accuracy:  10.136019824050729 %, lr:  0.07936130195768072\n",
+      "Epoch:  20 , validation loss:  1.8903152465820312 , validation accuracy:  10.4996050339238 %, lr:  0.07936130195768072\n",
+      "Epoch:  21 , validation loss:  1.8907855987548827 , validation accuracy:  10.33548671002276 %, lr:  0.07936130195768072\n",
+      "Epoch:  22 , validation loss:  1.8935272216796875 , validation accuracy:  10.095621467398166 %, lr:  0.07936130195768072\n",
+      "Epoch:  23 , validation loss:  1.8899717330932617 , validation accuracy:  11.392336576022855 %, lr:  0.07936130195768072\n",
+      "Epoch:  24 , validation loss:  1.8887479782104493 , validation accuracy:  10.892767612060354 %, lr:  0.07936130195768072\n",
+      "Epoch:  25 , validation loss:  1.8905900955200194 , validation accuracy:  11.473854688553919 %, lr:  0.07936130195768072\n",
+      "Epoch:  26 , validation loss:  1.8886688232421875 , validation accuracy:  11.019012476599613 %, lr:  0.07936130195768072\n",
+      "Epoch:  27 , validation loss:  1.8977415084838867 , validation accuracy:  9.76594202114421 %, lr:  0.07936130195768072\n",
+      "Epoch:  28 , validation loss:  1.8891681671142577 , validation accuracy:  11.126861660877438 %, lr:  0.07936130195768072\n",
+      "Epoch:  29 , validation loss:  1.891387367248535 , validation accuracy:  10.30951633788897 %, lr:  0.07936130195768072\n",
+      "Epoch:  30 , validation loss:  1.8889190673828125 , validation accuracy:  10.76255505177843 %, lr:  0.07936130195768072\n",
+      "Epoch:  31 , validation loss:  1.8893285751342774 , validation accuracy:  10.668773152406407 %, lr:  0.07936130195768072\n",
+      "Epoch:  32 , validation loss:  1.889305877685547 , validation accuracy:  10.679233441182518 %, lr:  0.07936130195768072\n",
+      "Epoch:  33 , validation loss:  1.8897727966308593 , validation accuracy:  11.364562705824216 %, lr:  0.07936130195768072\n",
+      "Epoch:  34 , validation loss:  1.8895675659179687 , validation accuracy:  10.624046400398212 %, lr:  0.07936130195768072\n",
+      "Epoch:  35 , validation loss:  1.8955631256103516 , validation accuracy:  9.952423721049348 %, lr:  0.023808390587304214\n",
+      "Epoch:  36 , validation loss:  1.8886144638061524 , validation accuracy:  10.943986957101995 %, lr:  0.023808390587304214\n",
+      "Epoch:  37 , validation loss:  1.8891597747802735 , validation accuracy:  10.696186322992075 %, lr:  0.023808390587304214\n",
+      "Epoch:  38 , validation loss:  1.8901126861572266 , validation accuracy:  10.510065322699909 %, lr:  0.023808390587304214\n",
+      "Epoch:  39 , validation loss:  1.8885255813598634 , validation accuracy:  10.96310403658937 %, lr:  0.023808390587304214\n",
+      "Epoch:  40 , validation loss:  1.8884716033935547 , validation accuracy:  10.970678728461724 %, lr:  0.023808390587304214\n",
+      "Epoch:  41 , validation loss:  1.8892208099365235 , validation accuracy:  10.679954840408456 %, lr:  0.023808390587304214\n",
+      "Epoch:  42 , validation loss:  1.8883905410766602 , validation accuracy:  11.024783670407121 %, lr:  0.023808390587304214\n",
+      "Epoch:  43 , validation loss:  1.890584373474121 , validation accuracy:  10.400051940744268 %, lr:  0.023808390587304214\n",
+      "Epoch:  44 , validation loss:  1.8887283325195312 , validation accuracy:  11.13623985081464 %, lr:  0.023808390587304214\n",
+      "Epoch:  45 , validation loss:  1.889310073852539 , validation accuracy:  10.631981791883538 %, lr:  0.023808390587304214\n",
+      "Epoch:  46 , validation loss:  1.8886383056640625 , validation accuracy:  10.897096007415984 %, lr:  0.023808390587304214\n",
+      "Epoch:  47 , validation loss:  1.8885383605957031 , validation accuracy:  10.942183459037148 %, lr:  0.023808390587304214\n",
+      "Epoch:  48 , validation loss:  1.88861026763916 , validation accuracy:  10.872207734121101 %, lr:  0.023808390587304214\n",
+      "Epoch:  49 , validation loss:  1.8905147552490233 , validation accuracy:  10.41484062487601 %, lr:  0.023808390587304214\n",
+      "Epoch:  50 , validation loss:  1.8885833740234375 , validation accuracy:  10.841548267018709 %, lr:  0.023808390587304214\n",
+      "Epoch:  51 , validation loss:  1.8892995834350585 , validation accuracy:  10.650377472144973 %, lr:  0.023808390587304214\n",
+      "Epoch:  52 , validation loss:  1.8884614944458007 , validation accuracy:  10.97789272072111 %, lr:  0.023808390587304214\n",
+      "Epoch:  53 , validation loss:  1.8883832931518554 , validation accuracy:  11.003863092854901 %, lr:  0.023808390587304214\n",
+      "Epoch:  54 , validation loss:  1.8884735107421875 , validation accuracy:  10.986549511432374 %, lr:  0.023808390587304214\n",
+      "Epoch:  55 , validation loss:  1.8884414672851562 , validation accuracy:  10.933887367938855 %, lr:  0.023808390587304214\n",
+      "Epoch:  56 , validation loss:  1.8891193389892578 , validation accuracy:  10.659394962469205 %, lr:  0.023808390587304214\n",
+      "Epoch:  57 , validation loss:  1.8901399612426757 , validation accuracy:  10.463174373013898 %, lr:  0.023808390587304214\n",
+      "Epoch:  58 , validation loss:  1.8885015487670898 , validation accuracy:  11.017208978534766 %, lr:  0.023808390587304214\n",
+      "Epoch:  59 , validation loss:  1.888559913635254 , validation accuracy:  10.853090654633728 %, lr:  0.023808390587304214\n",
+      "Epoch:  60 , validation loss:  1.8885417938232423 , validation accuracy:  10.92486987761462 %, lr:  0.007142517176191264\n",
+      "Epoch:  61 , validation loss:  1.8884889602661132 , validation accuracy:  10.982221116076744 %, lr:  0.007142517176191264\n",
+      "Epoch:  62 , validation loss:  1.8888664245605469 , validation accuracy:  10.766162047908123 %, lr:  0.007142517176191264\n",
+      "Epoch:  63 , validation loss:  1.8885644912719726 , validation accuracy:  10.89312831167332 %, lr:  0.007142517176191264\n",
+      "Epoch:  64 , validation loss:  1.888533592224121 , validation accuracy:  10.957693542394829 %, lr:  0.007142517176191264\n",
+      "Epoch:  65 , validation loss:  1.888840103149414 , validation accuracy:  10.7722939413286 %, lr:  0.007142517176191264\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  66 , validation loss:  1.8886472702026367 , validation accuracy:  10.89348901128629 %, lr:  0.007142517176191264\n",
+      "Epoch:  67 , validation loss:  1.8885601043701172 , validation accuracy:  10.897096007415984 %, lr:  0.007142517176191264\n",
+      "Epoch:  68 , validation loss:  1.8888973236083983 , validation accuracy:  10.769769044037817 %, lr:  0.007142517176191264\n",
+      "Epoch:  69 , validation loss:  1.8889055252075195 , validation accuracy:  10.76724414674703 %, lr:  0.007142517176191264\n",
+      "Epoch:  70 , validation loss:  1.8888429641723632 , validation accuracy:  10.771572542102662 %, lr:  0.007142517176191264\n",
+      "Epoch:  71 , validation loss:  1.8885353088378907 , validation accuracy:  10.942183459037148 %, lr:  0.007142517176191264\n",
+      "Epoch:  72 , validation loss:  1.8887718200683594 , validation accuracy:  10.787443325073312 %, lr:  0.007142517176191264\n",
+      "Epoch:  73 , validation loss:  1.8888639450073241 , validation accuracy:  10.774458139006416 %, lr:  0.007142517176191264\n",
+      "Epoch:  74 , validation loss:  1.889153289794922 , validation accuracy:  10.68356183653815 %, lr:  0.007142517176191264\n",
+      "Epoch:  75 , validation loss:  1.8888444900512695 , validation accuracy:  10.779868633200957 %, lr:  0.007142517176191264\n",
+      "Epoch:  76 , validation loss:  1.8886754989624024 , validation accuracy:  10.860665346506083 %, lr:  0.007142517176191264\n",
+      "Epoch:  77 , validation loss:  1.88846435546875 , validation accuracy:  11.023701571568214 %, lr:  0.007142517176191264\n",
+      "Epoch:  78 , validation loss:  1.8917648315429687 , validation accuracy:  10.265510985106713 %, lr:  0.007142517176191264\n",
+      "Epoch:  79 , validation loss:  1.8891443252563476 , validation accuracy:  10.68284043731221 %, lr:  0.007142517176191264\n",
+      "Epoch:  80 , validation loss:  1.8884172439575195 , validation accuracy:  10.919459383420081 %, lr:  0.007142517176191264\n",
+      "Epoch:  81 , validation loss:  1.8888059616088868 , validation accuracy:  10.782032830878773 %, lr:  0.002142755152857379\n",
+      "Epoch:  82 , validation loss:  1.8887155532836915 , validation accuracy:  10.803314108043963 %, lr:  0.002142755152857379\n",
+      "Epoch:  83 , validation loss:  1.8885906219482422 , validation accuracy:  10.870043536443285 %, lr:  0.002142755152857379\n",
+      "Epoch:  84 , validation loss:  1.8885770797729493 , validation accuracy:  10.866075840700622 %, lr:  0.002142755152857379\n",
+      "wandb: Agent Finished Run: fid9vcvf \n",
+      "\n",
+      "wandb: Agent Starting Run: 72hns7u5 with config:\n",
+      "\tepochs: 140\n",
+      "\thidden_dim: 63\n",
+      "\tlr: 0.00040529151979869715\n",
+      "\tn_graph_iters: 8\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 245\n",
+      "wandb: Agent Started Run: 72hns7u5\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/72hns7u5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/72hns7u5</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 140, 'hidden_dim': 63, 'lr': 0.00040529151979869715, 'n_graph_iters': 8, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 245}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 63, 'n_graph_iters': 8, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.882688331604004 , validation accuracy:  10.684643935377057 %, lr:  0.00040529151979869715\n",
+      "Epoch:  2 , validation loss:  1.8795074462890624 , validation accuracy:  10.439007498944953 %, lr:  0.00040529151979869715\n",
+      "Epoch:  3 , validation loss:  1.8895965576171876 , validation accuracy:  9.626351270925086 %, lr:  0.00040529151979869715\n",
+      "Epoch:  4 , validation loss:  1.8758415222167968 , validation accuracy:  10.391755849645973 %, lr:  0.00040529151979869715\n",
+      "Epoch:  5 , validation loss:  1.8731542587280274 , validation accuracy:  12.400852693885058 %, lr:  0.00040529151979869715\n",
+      "Epoch:  6 , validation loss:  1.8710269927978516 , validation accuracy:  11.491889669202385 %, lr:  0.00040529151979869715\n",
+      "Epoch:  7 , validation loss:  1.8722675323486329 , validation accuracy:  12.973282979667363 %, lr:  0.00040529151979869715\n",
+      "Epoch:  8 , validation loss:  1.8742469787597655 , validation accuracy:  10.631260392657598 %, lr:  0.00040529151979869715\n",
+      "Epoch:  9 , validation loss:  1.8775257110595702 , validation accuracy:  10.234130118778383 %, lr:  0.00040529151979869715\n",
+      "Epoch:  10 , validation loss:  1.872615432739258 , validation accuracy:  11.073478118157979 %, lr:  0.00040529151979869715\n",
+      "Epoch:  11 , validation loss:  1.8748590469360351 , validation accuracy:  12.601762378308967 %, lr:  0.00040529151979869715\n",
+      "Epoch:  12 , validation loss:  1.8722930908203126 , validation accuracy:  12.550182333654355 %, lr:  0.00040529151979869715\n",
+      "Epoch:  13 , validation loss:  1.8745834350585937 , validation accuracy:  12.872647787648924 %, lr:  0.00040529151979869715\n",
+      "Epoch:  14 , validation loss:  1.869740104675293 , validation accuracy:  12.56893871352876 %, lr:  0.00040529151979869715\n",
+      "Epoch:  15 , validation loss:  1.870656967163086 , validation accuracy:  11.535895021984642 %, lr:  0.00040529151979869715\n",
+      "Epoch:  16 , validation loss:  1.868846321105957 , validation accuracy:  13.02847002045167 %, lr:  0.00040529151979869715\n",
+      "Epoch:  17 , validation loss:  1.8704694747924804 , validation accuracy:  12.355404542650925 %, lr:  0.00040529151979869715\n",
+      "Epoch:  18 , validation loss:  1.868006134033203 , validation accuracy:  12.69518357806802 %, lr:  0.00040529151979869715\n",
+      "Epoch:  19 , validation loss:  1.8698230743408204 , validation accuracy:  13.030994917742452 %, lr:  0.00040529151979869715\n",
+      "Epoch:  20 , validation loss:  1.8681161880493165 , validation accuracy:  12.991317960315829 %, lr:  0.00040529151979869715\n",
+      "Epoch:  21 , validation loss:  1.8675399780273438 , validation accuracy:  13.562305447646256 %, lr:  0.00040529151979869715\n",
+      "Epoch:  22 , validation loss:  1.867624282836914 , validation accuracy:  11.617413134515706 %, lr:  0.00040529151979869715\n",
+      "Epoch:  23 , validation loss:  1.8706693649291992 , validation accuracy:  12.325466474774473 %, lr:  0.00040529151979869715\n",
+      "Epoch:  24 , validation loss:  1.8673109054565429 , validation accuracy:  11.768185572736881 %, lr:  0.00040529151979869715\n",
+      "Epoch:  25 , validation loss:  1.8689140319824218 , validation accuracy:  11.334624637947764 %, lr:  0.00040529151979869715\n",
+      "Epoch:  26 , validation loss:  1.865308952331543 , validation accuracy:  12.098947117829741 %, lr:  0.00040529151979869715\n",
+      "Epoch:  27 , validation loss:  1.8659494400024415 , validation accuracy:  13.890902795061299 %, lr:  0.00040529151979869715\n",
+      "Epoch:  28 , validation loss:  1.8721323013305664 , validation accuracy:  12.260901244052965 %, lr:  0.00040529151979869715\n",
+      "Epoch:  29 , validation loss:  1.871261215209961 , validation accuracy:  13.187177850158166 %, lr:  0.00040529151979869715\n",
+      "Epoch:  30 , validation loss:  1.8716968536376952 , validation accuracy:  11.63653021400308 %, lr:  0.00040529151979869715\n",
+      "Epoch:  31 , validation loss:  1.869661521911621 , validation accuracy:  13.008270842125386 %, lr:  0.00040529151979869715\n",
+      "Epoch:  32 , validation loss:  1.8712310791015625 , validation accuracy:  11.81038742745429 %, lr:  0.00040529151979869715\n",
+      "Epoch:  33 , validation loss:  1.871405792236328 , validation accuracy:  11.635087415551203 %, lr:  0.00040529151979869715\n",
+      "Epoch:  34 , validation loss:  1.8749662399291993 , validation accuracy:  10.8675186391525 %, lr:  0.00040529151979869715\n",
+      "Epoch:  35 , validation loss:  1.8670331954956054 , validation accuracy:  12.364061333362189 %, lr:  0.00040529151979869715\n",
+      "Epoch:  36 , validation loss:  1.8678709030151368 , validation accuracy:  12.466860723058444 %, lr:  0.00040529151979869715\n",
+      "Epoch:  37 , validation loss:  1.8675003051757812 , validation accuracy:  13.55437005616093 %, lr:  0.00040529151979869715\n",
+      "Epoch:  38 , validation loss:  1.8702310562133788 , validation accuracy:  10.807281803786625 %, lr:  0.00040529151979869715\n",
+      "Epoch:  39 , validation loss:  1.865042495727539 , validation accuracy:  12.6742630005158 %, lr:  0.00040529151979869715\n",
+      "Epoch:  40 , validation loss:  1.8638404846191405 , validation accuracy:  13.597654009717248 %, lr:  0.00040529151979869715\n",
+      "Epoch:  41 , validation loss:  1.8689132690429688 , validation accuracy:  10.645327677563401 %, lr:  0.00040529151979869715\n",
+      "Epoch:  42 , validation loss:  1.8671974182128905 , validation accuracy:  11.017569678147735 %, lr:  0.00040529151979869715\n",
+      "Epoch:  43 , validation loss:  1.8631256103515625 , validation accuracy:  13.510004003765705 %, lr:  0.00040529151979869715\n",
+      "Epoch:  44 , validation loss:  1.8669515609741212 , validation accuracy:  11.444638019903405 %, lr:  0.00040529151979869715\n",
+      "Epoch:  45 , validation loss:  1.8629352569580078 , validation accuracy:  12.340615858519184 %, lr:  0.00040529151979869715\n",
+      "Epoch:  46 , validation loss:  1.8622636795043945 , validation accuracy:  12.388949606657071 %, lr:  0.00040529151979869715\n",
+      "Epoch:  47 , validation loss:  1.8580398559570312 , validation accuracy:  12.34710845155263 %, lr:  0.00040529151979869715\n",
+      "Epoch:  48 , validation loss:  1.8606000900268556 , validation accuracy:  11.366726903502032 %, lr:  0.00040529151979869715\n",
+      "Epoch:  49 , validation loss:  1.869348907470703 , validation accuracy:  11.068789023189378 %, lr:  0.00040529151979869715\n",
+      "Epoch:  50 , validation loss:  1.8583181381225586 , validation accuracy:  12.56929941314173 %, lr:  0.00040529151979869715\n",
+      "Epoch:  51 , validation loss:  1.875990867614746 , validation accuracy:  10.327912018150405 %, lr:  0.00040529151979869715\n",
+      "Epoch:  52 , validation loss:  1.8635055541992187 , validation accuracy:  11.962241964514373 %, lr:  0.00040529151979869715\n",
+      "Epoch:  53 , validation loss:  1.8605792999267579 , validation accuracy:  13.062736483683754 %, lr:  0.00040529151979869715\n",
+      "Epoch:  54 , validation loss:  1.8537044525146484 , validation accuracy:  13.890902795061299 %, lr:  0.00040529151979869715\n",
+      "Epoch:  55 , validation loss:  1.863745880126953 , validation accuracy:  12.067566251501411 %, lr:  0.00040529151979869715\n",
+      "Epoch:  56 , validation loss:  1.8601160049438477 , validation accuracy:  12.52709755842432 %, lr:  0.00040529151979869715\n",
+      "Epoch:  57 , validation loss:  1.8506528854370117 , validation accuracy:  12.06864835034032 %, lr:  0.00040529151979869715\n",
+      "Epoch:  58 , validation loss:  1.814938735961914 , validation accuracy:  12.49571669209599 %, lr:  0.00040529151979869715\n",
+      "Epoch:  59 , validation loss:  1.8314273834228516 , validation accuracy:  14.125718243104323 %, lr:  0.00040529151979869715\n",
+      "Epoch:  60 , validation loss:  1.7999895095825196 , validation accuracy:  14.385782664055203 %, lr:  0.00040529151979869715\n",
+      "Epoch:  61 , validation loss:  1.8970146179199219 , validation accuracy:  13.794595998398492 %, lr:  0.00040529151979869715\n",
+      "Epoch:  62 , validation loss:  1.6219976425170899 , validation accuracy:  16.4240961769448 %, lr:  0.00040529151979869715\n",
+      "Epoch:  63 , validation loss:  1.870442771911621 , validation accuracy:  11.65781149116827 %, lr:  0.00040529151979869715\n",
+      "Epoch:  64 , validation loss:  1.7534782409667968 , validation accuracy:  14.458643985875003 %, lr:  0.00040529151979869715\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  65 , validation loss:  1.7953168869018554 , validation accuracy:  16.591100097749596 %, lr:  0.00040529151979869715\n",
+      "Epoch:  66 , validation loss:  1.8660079956054687 , validation accuracy:  13.17996385789878 %, lr:  0.00040529151979869715\n",
+      "Epoch:  67 , validation loss:  1.6023454666137695 , validation accuracy:  19.290936700824922 %, lr:  0.00040529151979869715\n",
+      "Epoch:  68 , validation loss:  1.9239873886108398 , validation accuracy:  18.91256280682011 %, lr:  0.00040529151979869715\n",
+      "Epoch:  69 , validation loss:  1.7817808151245118 , validation accuracy:  13.802892089496787 %, lr:  0.00040529151979869715\n",
+      "Epoch:  70 , validation loss:  1.634653663635254 , validation accuracy:  12.754338314594987 %, lr:  0.00040529151979869715\n",
+      "Epoch:  71 , validation loss:  1.5395904541015626 , validation accuracy:  22.38321448281086 %, lr:  0.00040529151979869715\n",
+      "Epoch:  72 , validation loss:  1.4895971298217774 , validation accuracy:  22.2299171472989 %, lr:  0.00040529151979869715\n",
+      "Epoch:  73 , validation loss:  1.5465834617614747 , validation accuracy:  20.48737731704414 %, lr:  0.00040529151979869715\n",
+      "Epoch:  74 , validation loss:  1.7435176849365235 , validation accuracy:  12.89140416752333 %, lr:  0.00040529151979869715\n",
+      "Epoch:  75 , validation loss:  2.0652864456176756 , validation accuracy:  10.23521221761729 %, lr:  0.00040529151979869715\n",
+      "Epoch:  76 , validation loss:  1.6491647720336915 , validation accuracy:  20.824992154783416 %, lr:  0.00040529151979869715\n",
+      "Epoch:  77 , validation loss:  1.6111122131347657 , validation accuracy:  14.679752848625194 %, lr:  0.00040529151979869715\n",
+      "Epoch:  78 , validation loss:  1.3881535530090332 , validation accuracy:  23.55693102341301 %, lr:  0.00040529151979869715\n",
+      "Epoch:  79 , validation loss:  1.7228122711181642 , validation accuracy:  12.843791818611377 %, lr:  0.00040529151979869715\n",
+      "Epoch:  80 , validation loss:  1.4816035270690917 , validation accuracy:  20.141827087819536 %, lr:  0.00040529151979869715\n",
+      "Epoch:  81 , validation loss:  1.2203012466430665 , validation accuracy:  23.076839838550853 %, lr:  0.00040529151979869715\n",
+      "Epoch:  82 , validation loss:  1.338029670715332 , validation accuracy:  26.523685340085628 %, lr:  0.00040529151979869715\n",
+      "Epoch:  83 , validation loss:  1.5771217346191406 , validation accuracy:  18.531303315911543 %, lr:  0.00040529151979869715\n",
+      "Epoch:  84 , validation loss:  1.5024579048156739 , validation accuracy:  22.37311489364772 %, lr:  0.00040529151979869715\n",
+      "Epoch:  85 , validation loss:  1.664764976501465 , validation accuracy:  13.308012220502889 %, lr:  0.00040529151979869715\n",
+      "Epoch:  86 , validation loss:  1.4394637107849122 , validation accuracy:  28.71709968655204 %, lr:  0.00040529151979869715\n",
+      "Epoch:  87 , validation loss:  1.738860511779785 , validation accuracy:  22.278972294662726 %, lr:  0.00040529151979869715\n",
+      "Epoch:  88 , validation loss:  1.8669649124145509 , validation accuracy:  22.211160767424495 %, lr:  0.00040529151979869715\n",
+      "Epoch:  89 , validation loss:  1.1751954078674316 , validation accuracy:  28.287145747892612 %, lr:  0.00040529151979869715\n",
+      "Epoch:  90 , validation loss:  1.753047561645508 , validation accuracy:  21.61239940989543 %, lr:  0.00040529151979869715\n",
+      "Epoch:  91 , validation loss:  1.5224130630493165 , validation accuracy:  14.439526906387629 %, lr:  0.00040529151979869715\n",
+      "Epoch:  92 , validation loss:  1.3494009017944335 , validation accuracy:  25.77090524781867 %, lr:  0.00040529151979869715\n",
+      "Epoch:  93 , validation loss:  1.4178248405456544 , validation accuracy:  23.581819296707895 %, lr:  0.00040529151979869715\n",
+      "Epoch:  94 , validation loss:  1.1727103233337401 , validation accuracy:  24.425134991830152 %, lr:  0.00040529151979869715\n",
+      "Epoch:  95 , validation loss:  1.5962361335754394 , validation accuracy:  18.78126814769928 %, lr:  0.00040529151979869715\n",
+      "Epoch:  96 , validation loss:  1.1153325080871581 , validation accuracy:  25.95919044578865 %, lr:  0.00040529151979869715\n",
+      "Epoch:  97 , validation loss:  1.5793312072753907 , validation accuracy:  16.594346394266317 %, lr:  0.00040529151979869715\n",
+      "Epoch:  98 , validation loss:  1.2693220138549806 , validation accuracy:  26.790963753295895 %, lr:  0.00040529151979869715\n",
+      "Epoch:  99 , validation loss:  1.168563461303711 , validation accuracy:  24.993958281482765 %, lr:  0.00040529151979869715\n",
+      "Epoch:  100 , validation loss:  1.333677101135254 , validation accuracy:  16.455116343660166 %, lr:  0.00040529151979869715\n",
+      "Epoch:  101 , validation loss:  1.6238197326660155 , validation accuracy:  12.446300845119193 %, lr:  0.00040529151979869715\n",
+      "Epoch:  102 , validation loss:  1.374245548248291 , validation accuracy:  20.769083714773174 %, lr:  0.00040529151979869715\n",
+      "Epoch:  103 , validation loss:  1.6903800964355469 , validation accuracy:  17.918113973863704 %, lr:  0.00040529151979869715\n",
+      "Epoch:  104 , validation loss:  1.1714872360229491 , validation accuracy:  28.53566778122847 %, lr:  0.00040529151979869715\n",
+      "Epoch:  105 , validation loss:  1.1454018592834472 , validation accuracy:  24.802066087383086 %, lr:  0.00040529151979869715\n",
+      "Epoch:  106 , validation loss:  1.891851806640625 , validation accuracy:  18.224347945274655 %, lr:  0.00040529151979869715\n",
+      "Epoch:  107 , validation loss:  1.985902976989746 , validation accuracy:  15.438304134699662 %, lr:  0.00040529151979869715\n",
+      "Epoch:  108 , validation loss:  1.8504314422607422 , validation accuracy:  13.615328290752743 %, lr:  0.00040529151979869715\n",
+      "Epoch:  109 , validation loss:  1.8092126846313477 , validation accuracy:  15.234508853372 %, lr:  0.00040529151979869715\n",
+      "Epoch:  110 , validation loss:  1.4013818740844726 , validation accuracy:  22.48240687637742 %, lr:  0.00040529151979869715\n",
+      "Epoch:  111 , validation loss:  2.0715915679931642 , validation accuracy:  21.323118320294043 %, lr:  0.00040529151979869715\n",
+      "Epoch:  112 , validation loss:  1.082310104370117 , validation accuracy:  24.477436435710704 %, lr:  0.00040529151979869715\n",
+      "Epoch:  113 , validation loss:  1.2288690567016602 , validation accuracy:  26.14278654879003 %, lr:  0.00040529151979869715\n",
+      "Epoch:  114 , validation loss:  1.0748522758483887 , validation accuracy:  23.22616947832015 %, lr:  0.00040529151979869715\n",
+      "Epoch:  115 , validation loss:  1.6727092742919922 , validation accuracy:  15.417744256760413 %, lr:  0.00040529151979869715\n",
+      "Epoch:  116 , validation loss:  1.2935080528259277 , validation accuracy:  24.87997720378446 %, lr:  0.00040529151979869715\n",
+      "Epoch:  117 , validation loss:  1.1843378067016601 , validation accuracy:  29.423710228358924 %, lr:  0.00040529151979869715\n",
+      "Epoch:  118 , validation loss:  1.2883545875549316 , validation accuracy:  18.694339540973672 %, lr:  0.00040529151979869715\n",
+      "Epoch:  119 , validation loss:  1.7033748626708984 , validation accuracy:  14.651978978426555 %, lr:  0.00040529151979869715\n",
+      "Epoch:  120 , validation loss:  1.673853874206543 , validation accuracy:  13.187899249384106 %, lr:  0.00040529151979869715\n",
+      "Epoch:  121 , validation loss:  1.2839898109436034 , validation accuracy:  21.970213425960992 %, lr:  0.00040529151979869715\n",
+      "Epoch:  122 , validation loss:  1.594283103942871 , validation accuracy:  15.701614852167264 %, lr:  0.00040529151979869715\n",
+      "Epoch:  123 , validation loss:  1.7626672744750977 , validation accuracy:  16.06123236629767 %, lr:  0.00040529151979869715\n",
+      "Epoch:  124 , validation loss:  1.680528450012207 , validation accuracy:  19.029068781809197 %, lr:  0.00040529151979869715\n",
+      "Epoch:  125 , validation loss:  1.209015464782715 , validation accuracy:  19.303921886891814 %, lr:  0.00040529151979869715\n",
+      "Epoch:  126 , validation loss:  1.0501109123229981 , validation accuracy:  28.291474143248248 %, lr:  0.00040529151979869715\n",
+      "Epoch:  127 , validation loss:  1.7532888412475587 , validation accuracy:  24.19031954378713 %, lr:  0.00040529151979869715\n",
+      "Epoch:  128 , validation loss:  0.9601589202880859 , validation accuracy:  29.871338448053848 %, lr:  0.00040529151979869715\n",
+      "Epoch:  129 , validation loss:  1.261592483520508 , validation accuracy:  24.335681487813762 %, lr:  0.00040529151979869715\n",
+      "Epoch:  130 , validation loss:  1.4924325942993164 , validation accuracy:  24.007084140398717 %, lr:  0.00040529151979869715\n",
+      "Epoch:  131 , validation loss:  1.4112680435180665 , validation accuracy:  30.455671821064133 %, lr:  0.00040529151979869715\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  132 , validation loss:  1.2047532081604004 , validation accuracy:  29.49116105598419 %, lr:  0.00040529151979869715\n",
+      "Epoch:  133 , validation loss:  1.0326483726501465 , validation accuracy:  28.328626203384083 %, lr:  0.00040529151979869715\n",
+      "Epoch:  134 , validation loss:  1.688622283935547 , validation accuracy:  15.944004992082645 %, lr:  0.00040529151979869715\n",
+      "Epoch:  135 , validation loss:  1.291691493988037 , validation accuracy:  16.344020862865612 %, lr:  0.00040529151979869715\n",
+      "Epoch:  136 , validation loss:  1.4093527793884277 , validation accuracy:  20.38061023160522 %, lr:  0.00040529151979869715\n",
+      "Epoch:  137 , validation loss:  1.0362444877624513 , validation accuracy:  32.688041725731225 %, lr:  0.00040529151979869715\n",
+      "Epoch:  138 , validation loss:  1.3224504470825196 , validation accuracy:  27.16212365504132 %, lr:  0.00040529151979869715\n",
+      "Epoch:  139 , validation loss:  1.3797142028808593 , validation accuracy:  27.14084237787613 %, lr:  0.00040529151979869715\n",
+      "Epoch:  140 , validation loss:  0.982572364807129 , validation accuracy:  24.499078412488863 %, lr:  0.00040529151979869715\n",
+      "wandb: Agent Finished Run: 72hns7u5 \n",
+      "\n",
+      "wandb: Agent Starting Run: ooxxqerw with config:\n",
+      "\tepochs: 188\n",
+      "\thidden_dim: 37\n",
+      "\tlr: 0.00331255104784123\n",
+      "\tn_graph_iters: 1\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 172\n",
+      "wandb: Agent Started Run: ooxxqerw\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ooxxqerw\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ooxxqerw</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 188, 'hidden_dim': 37, 'lr': 0.00331255104784123, 'n_graph_iters': 1, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 172}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 37, 'n_graph_iters': 1, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.882065200805664 , validation accuracy:  11.232185947864478 %, lr:  0.00331255104784123\n",
+      "Epoch:  2 , validation loss:  1.8823436737060546 , validation accuracy:  10.10355685888349 %, lr:  0.00331255104784123\n",
+      "Epoch:  3 , validation loss:  1.8830812454223633 , validation accuracy:  9.850345730579031 %, lr:  0.00331255104784123\n",
+      "Epoch:  4 , validation loss:  1.874594497680664 , validation accuracy:  12.040153080915744 %, lr:  0.00331255104784123\n",
+      "Epoch:  5 , validation loss:  1.8763639450073242 , validation accuracy:  11.25707422115936 %, lr:  0.00331255104784123\n",
+      "Epoch:  6 , validation loss:  1.8824262619018555 , validation accuracy:  14.567935968604706 %, lr:  0.00331255104784123\n",
+      "Epoch:  7 , validation loss:  1.8726068496704102 , validation accuracy:  12.170726340810637 %, lr:  0.00331255104784123\n",
+      "Epoch:  8 , validation loss:  1.8732316970825196 , validation accuracy:  12.723678847492598 %, lr:  0.00331255104784123\n",
+      "Epoch:  9 , validation loss:  1.8713899612426759 , validation accuracy:  12.476238912995646 %, lr:  0.00331255104784123\n",
+      "Epoch:  10 , validation loss:  1.8762117385864259 , validation accuracy:  11.103416186034433 %, lr:  0.00331255104784123\n",
+      "Epoch:  11 , validation loss:  1.871786117553711 , validation accuracy:  11.80605903209866 %, lr:  0.00331255104784123\n",
+      "Epoch:  12 , validation loss:  1.870396041870117 , validation accuracy:  13.541024170481064 %, lr:  0.00331255104784123\n",
+      "Epoch:  13 , validation loss:  1.871455192565918 , validation accuracy:  12.11662139886524 %, lr:  0.00331255104784123\n",
+      "Epoch:  14 , validation loss:  1.8766464233398437 , validation accuracy:  14.85108516478562 %, lr:  0.00331255104784123\n",
+      "Epoch:  15 , validation loss:  1.8716753005981446 , validation accuracy:  10.981860416463773 %, lr:  0.00331255104784123\n",
+      "Epoch:  16 , validation loss:  1.8730657577514649 , validation accuracy:  11.282323194067214 %, lr:  0.00331255104784123\n",
+      "Epoch:  17 , validation loss:  1.870351791381836 , validation accuracy:  11.51064604907679 %, lr:  0.00331255104784123\n",
+      "Epoch:  18 , validation loss:  1.8701696395874023 , validation accuracy:  12.961740592052346 %, lr:  0.00331255104784123\n",
+      "Epoch:  19 , validation loss:  1.8696847915649415 , validation accuracy:  13.061293685231876 %, lr:  0.00331255104784123\n",
+      "Epoch:  20 , validation loss:  1.8739299774169922 , validation accuracy:  11.477461684683613 %, lr:  0.00331255104784123\n",
+      "Epoch:  21 , validation loss:  1.8694843292236327 , validation accuracy:  12.539361345265277 %, lr:  0.00331255104784123\n",
+      "Epoch:  22 , validation loss:  1.8715950012207032 , validation accuracy:  12.059991559629056 %, lr:  0.00331255104784123\n",
+      "Epoch:  23 , validation loss:  1.8702875137329102 , validation accuracy:  11.839604096104805 %, lr:  0.00331255104784123\n",
+      "Epoch:  24 , validation loss:  1.871748161315918 , validation accuracy:  10.453796183076696 %, lr:  0.00331255104784123\n",
+      "Epoch:  25 , validation loss:  1.8724369049072265 , validation accuracy:  11.487561273846753 %, lr:  0.00331255104784123\n",
+      "Epoch:  26 , validation loss:  1.8698192596435548 , validation accuracy:  13.055883191037335 %, lr:  0.00331255104784123\n",
+      "Epoch:  27 , validation loss:  1.874199676513672 , validation accuracy:  11.055443137509513 %, lr:  0.00331255104784123\n",
+      "Epoch:  28 , validation loss:  1.8697532653808593 , validation accuracy:  13.773675420846274 %, lr:  0.00331255104784123\n",
+      "Epoch:  29 , validation loss:  1.8747045516967773 , validation accuracy:  14.462611681617666 %, lr:  0.00331255104784123\n",
+      "Epoch:  30 , validation loss:  1.8724985122680664 , validation accuracy:  12.241784164565592 %, lr:  0.00331255104784123\n",
+      "Epoch:  31 , validation loss:  1.8701698303222656 , validation accuracy:  13.757804637875623 %, lr:  0.00331255104784123\n",
+      "Epoch:  32 , validation loss:  1.8694328308105468 , validation accuracy:  13.90605217880601 %, lr:  0.00331255104784123\n",
+      "Epoch:  33 , validation loss:  1.8822919845581054 , validation accuracy:  10.455960380754512 %, lr:  0.00331255104784123\n",
+      "Epoch:  34 , validation loss:  1.8692310333251954 , validation accuracy:  11.763496477768278 %, lr:  0.00331255104784123\n",
+      "Epoch:  35 , validation loss:  1.8702274322509767 , validation accuracy:  11.623184328323216 %, lr:  0.00331255104784123\n",
+      "Epoch:  36 , validation loss:  1.8697088241577149 , validation accuracy:  12.36838972871782 %, lr:  0.00331255104784123\n",
+      "Epoch:  37 , validation loss:  1.8702306747436523 , validation accuracy:  12.541525542943091 %, lr:  0.00331255104784123\n",
+      "Epoch:  38 , validation loss:  1.8698314666748046 , validation accuracy:  11.593967659672701 %, lr:  0.00331255104784123\n",
+      "Epoch:  39 , validation loss:  1.8700551986694336 , validation accuracy:  12.337369562002461 %, lr:  0.00331255104784123\n",
+      "Epoch:  40 , validation loss:  1.8700996398925782 , validation accuracy:  10.689693729958629 %, lr:  0.00331255104784123\n",
+      "Epoch:  41 , validation loss:  1.869683074951172 , validation accuracy:  11.292422783230354 %, lr:  0.00331255104784123\n",
+      "Epoch:  42 , validation loss:  1.868921661376953 , validation accuracy:  11.454737609066544 %, lr:  0.00331255104784123\n",
+      "Epoch:  43 , validation loss:  1.868988609313965 , validation accuracy:  12.645407031478257 %, lr:  0.00331255104784123\n",
+      "Epoch:  44 , validation loss:  1.8691446304321289 , validation accuracy:  12.386424709366286 %, lr:  0.00331255104784123\n",
+      "Epoch:  45 , validation loss:  1.8691146850585938 , validation accuracy:  12.91701384004415 %, lr:  0.00331255104784123\n",
+      "Epoch:  46 , validation loss:  1.8704069137573243 , validation accuracy:  11.951060276512324 %, lr:  0.00331255104784123\n",
+      "Epoch:  47 , validation loss:  1.8699045181274414 , validation accuracy:  12.088847528666602 %, lr:  0.00331255104784123\n",
+      "Epoch:  48 , validation loss:  1.8695255279541017 , validation accuracy:  12.592384188371767 %, lr:  0.00331255104784123\n",
+      "Epoch:  49 , validation loss:  1.8689369201660155 , validation accuracy:  13.274467156496742 %, lr:  0.00331255104784123\n",
+      "Epoch:  50 , validation loss:  1.868934440612793 , validation accuracy:  13.444356674205288 %, lr:  0.00331255104784123\n",
+      "Epoch:  51 , validation loss:  1.8686878204345703 , validation accuracy:  11.502349957978495 %, lr:  0.00331255104784123\n",
+      "Epoch:  52 , validation loss:  1.8701282501220704 , validation accuracy:  12.028610693300726 %, lr:  0.00331255104784123\n",
+      "Epoch:  53 , validation loss:  1.870278549194336 , validation accuracy:  13.777282416975966 %, lr:  0.00331255104784123\n",
+      "Epoch:  54 , validation loss:  1.8705215454101562 , validation accuracy:  12.219060088948524 %, lr:  0.00331255104784123\n",
+      "Epoch:  55 , validation loss:  1.8694734573364258 , validation accuracy:  13.70802809128586 %, lr:  0.00331255104784123\n",
+      "Epoch:  56 , validation loss:  1.872582244873047 , validation accuracy:  10.553349276256228 %, lr:  0.00331255104784123\n",
+      "Epoch:  57 , validation loss:  1.8699373245239257 , validation accuracy:  13.778364515814875 %, lr:  0.00331255104784123\n",
+      "Epoch:  58 , validation loss:  1.8687967300415038 , validation accuracy:  12.366225531040005 %, lr:  0.00331255104784123\n",
+      "Epoch:  59 , validation loss:  1.8698480606079102 , validation accuracy:  13.72786656999917 %, lr:  0.00331255104784123\n",
+      "Epoch:  60 , validation loss:  1.8682516098022461 , validation accuracy:  12.475156814156739 %, lr:  0.00331255104784123\n",
+      "Epoch:  61 , validation loss:  1.872650146484375 , validation accuracy:  10.806560404560686 %, lr:  0.00331255104784123\n",
+      "Epoch:  62 , validation loss:  1.868748092651367 , validation accuracy:  13.11792352446806 %, lr:  0.00331255104784123\n",
+      "Epoch:  63 , validation loss:  1.869330596923828 , validation accuracy:  12.149445063645446 %, lr:  0.00331255104784123\n",
+      "Epoch:  64 , validation loss:  1.868980598449707 , validation accuracy:  11.097644992226924 %, lr:  0.00331255104784123\n",
+      "Epoch:  65 , validation loss:  1.869577980041504 , validation accuracy:  11.178081005919081 %, lr:  0.00331255104784123\n",
+      "Epoch:  66 , validation loss:  1.8683965682983399 , validation accuracy:  13.011877838255078 %, lr:  0.00331255104784123\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  67 , validation loss:  1.8699874877929688 , validation accuracy:  12.682919791227064 %, lr:  0.00331255104784123\n",
+      "Epoch:  68 , validation loss:  1.8684236526489257 , validation accuracy:  12.551625132106233 %, lr:  0.00331255104784123\n",
+      "Epoch:  69 , validation loss:  1.87042293548584 , validation accuracy:  11.204051378052872 %, lr:  0.00331255104784123\n",
+      "Epoch:  70 , validation loss:  1.868545150756836 , validation accuracy:  11.93663229199355 %, lr:  0.00331255104784123\n",
+      "Epoch:  71 , validation loss:  1.8689748764038085 , validation accuracy:  12.251883753728732 %, lr:  0.00331255104784123\n",
+      "Epoch:  72 , validation loss:  1.8699264526367188 , validation accuracy:  11.745461497119813 %, lr:  0.00331255104784123\n",
+      "Epoch:  73 , validation loss:  1.8683002471923829 , validation accuracy:  12.127442387254318 %, lr:  0.00331255104784123\n",
+      "Epoch:  74 , validation loss:  1.8694063186645509 , validation accuracy:  14.143753223752793 %, lr:  0.00331255104784123\n",
+      "Epoch:  75 , validation loss:  1.8683568954467773 , validation accuracy:  12.317170383676178 %, lr:  0.00331255104784123\n",
+      "Epoch:  76 , validation loss:  1.871821403503418 , validation accuracy:  12.665606209804537 %, lr:  0.00331255104784123\n",
+      "Epoch:  77 , validation loss:  1.8687334060668945 , validation accuracy:  12.255851449471395 %, lr:  0.00331255104784123\n",
+      "Epoch:  78 , validation loss:  1.8687294006347657 , validation accuracy:  12.551625132106233 %, lr:  0.00331255104784123\n",
+      "Epoch:  79 , validation loss:  1.8694564819335937 , validation accuracy:  12.717186254459149 %, lr:  0.00331255104784123\n",
+      "Epoch:  80 , validation loss:  1.8681028366088868 , validation accuracy:  13.291420038306297 %, lr:  0.00331255104784123\n",
+      "Epoch:  81 , validation loss:  1.8690059661865235 , validation accuracy:  12.256212149084364 %, lr:  0.000993765314352369\n",
+      "Epoch:  82 , validation loss:  1.8692968368530274 , validation accuracy:  13.862407525636725 %, lr:  0.000993765314352369\n",
+      "Epoch:  83 , validation loss:  1.868107223510742 , validation accuracy:  12.656949419093275 %, lr:  0.000993765314352369\n",
+      "Epoch:  84 , validation loss:  1.8678018569946289 , validation accuracy:  12.678230696258463 %, lr:  0.000993765314352369\n",
+      "Epoch:  85 , validation loss:  1.8693119049072267 , validation accuracy:  11.74113310176418 %, lr:  0.000993765314352369\n",
+      "Epoch:  86 , validation loss:  1.8680143356323242 , validation accuracy:  13.09664224730287 %, lr:  0.000993765314352369\n",
+      "Epoch:  87 , validation loss:  1.8676862716674805 , validation accuracy:  12.792933173182705 %, lr:  0.000993765314352369\n",
+      "Epoch:  88 , validation loss:  1.8674808502197267 , validation accuracy:  12.523490562294626 %, lr:  0.000993765314352369\n",
+      "Epoch:  89 , validation loss:  1.8676340103149414 , validation accuracy:  12.439447552472776 %, lr:  0.000993765314352369\n",
+      "Epoch:  90 , validation loss:  1.8675603866577148 , validation accuracy:  13.34336078257388 %, lr:  0.000993765314352369\n",
+      "Epoch:  91 , validation loss:  1.8673301696777345 , validation accuracy:  13.065261380974539 %, lr:  0.000993765314352369\n",
+      "Epoch:  92 , validation loss:  1.8677633285522461 , validation accuracy:  13.136319204729494 %, lr:  0.000993765314352369\n",
+      "Epoch:  93 , validation loss:  1.868004035949707 , validation accuracy:  12.308152893351945 %, lr:  0.000993765314352369\n",
+      "Epoch:  94 , validation loss:  1.869160270690918 , validation accuracy:  13.409729511360236 %, lr:  0.000993765314352369\n",
+      "Epoch:  95 , validation loss:  1.867790985107422 , validation accuracy:  12.958854995148592 %, lr:  0.000993765314352369\n",
+      "Epoch:  96 , validation loss:  1.8674156188964843 , validation accuracy:  13.028830720064638 %, lr:  0.000993765314352369\n",
+      "Epoch:  97 , validation loss:  1.8671699523925782 , validation accuracy:  13.029191419677607 %, lr:  0.000993765314352369\n",
+      "Epoch:  98 , validation loss:  1.866811180114746 , validation accuracy:  12.873729886487832 %, lr:  0.000993765314352369\n",
+      "Epoch:  99 , validation loss:  1.867242431640625 , validation accuracy:  12.497520190160836 %, lr:  0.000993765314352369\n",
+      "Epoch:  100 , validation loss:  1.8675439834594727 , validation accuracy:  12.527458258037289 %, lr:  0.000993765314352369\n",
+      "Epoch:  101 , validation loss:  1.8682445526123046 , validation accuracy:  13.168060770670792 %, lr:  0.000993765314352369\n",
+      "Epoch:  102 , validation loss:  1.8670730590820312 , validation accuracy:  13.316669011214152 %, lr:  0.000993765314352369\n",
+      "Epoch:  103 , validation loss:  1.866716194152832 , validation accuracy:  12.5061769808721 %, lr:  0.000993765314352369\n",
+      "Epoch:  104 , validation loss:  1.8666818618774415 , validation accuracy:  13.1644537745411 %, lr:  0.000993765314352369\n",
+      "Epoch:  105 , validation loss:  1.8690311431884765 , validation accuracy:  12.470467719188138 %, lr:  0.000993765314352369\n",
+      "Epoch:  106 , validation loss:  1.8667095184326172 , validation accuracy:  12.543329041007938 %, lr:  0.000993765314352369\n",
+      "Epoch:  107 , validation loss:  1.866444969177246 , validation accuracy:  12.198139511396304 %, lr:  0.000993765314352369\n",
+      "Epoch:  108 , validation loss:  1.8626653671264648 , validation accuracy:  13.31197991624555 %, lr:  0.000993765314352369\n",
+      "Epoch:  109 , validation loss:  1.852446937561035 , validation accuracy:  13.192227644739738 %, lr:  0.000993765314352369\n",
+      "Epoch:  110 , validation loss:  1.8487260818481446 , validation accuracy:  13.3913338310988 %, lr:  0.000993765314352369\n",
+      "Epoch:  111 , validation loss:  1.8205499649047852 , validation accuracy:  14.358008793856564 %, lr:  0.000993765314352369\n",
+      "Epoch:  112 , validation loss:  1.8011066436767578 , validation accuracy:  14.188840675373957 %, lr:  0.000993765314352369\n",
+      "Epoch:  113 , validation loss:  1.9319509506225585 , validation accuracy:  12.303103098770375 %, lr:  0.000993765314352369\n",
+      "Epoch:  114 , validation loss:  1.766097068786621 , validation accuracy:  15.87763626329629 %, lr:  0.000993765314352369\n",
+      "Epoch:  115 , validation loss:  1.7657604217529297 , validation accuracy:  16.254567358849222 %, lr:  0.000993765314352369\n",
+      "Epoch:  116 , validation loss:  1.7315216064453125 , validation accuracy:  17.787180014355844 %, lr:  0.000993765314352369\n",
+      "Epoch:  117 , validation loss:  1.7192726135253906 , validation accuracy:  18.396040961048048 %, lr:  0.000993765314352369\n",
+      "Epoch:  118 , validation loss:  1.7632301330566407 , validation accuracy:  14.895811916793814 %, lr:  0.000993765314352369\n",
+      "Epoch:  119 , validation loss:  1.6823776245117188 , validation accuracy:  19.574446596618802 %, lr:  0.000993765314352369\n",
+      "Epoch:  120 , validation loss:  1.660214614868164 , validation accuracy:  18.481526769321775 %, lr:  0.000993765314352369\n",
+      "Epoch:  121 , validation loss:  1.660712432861328 , validation accuracy:  17.78032672170943 %, lr:  0.000993765314352369\n",
+      "Epoch:  122 , validation loss:  1.6951280593872071 , validation accuracy:  20.776658406645527 %, lr:  0.000993765314352369\n",
+      "Epoch:  123 , validation loss:  1.7055862426757813 , validation accuracy:  18.75457637633955 %, lr:  0.000993765314352369\n",
+      "Epoch:  124 , validation loss:  1.612380027770996 , validation accuracy:  21.248453500409394 %, lr:  0.000993765314352369\n",
+      "Epoch:  125 , validation loss:  1.5855119705200196 , validation accuracy:  20.9227417498981 %, lr:  0.000993765314352369\n",
+      "Epoch:  126 , validation loss:  1.7729598999023437 , validation accuracy:  19.420067162267934 %, lr:  0.000993765314352369\n",
+      "Epoch:  127 , validation loss:  1.7467927932739258 , validation accuracy:  12.340976558132153 %, lr:  0.000993765314352369\n",
+      "Epoch:  128 , validation loss:  1.6998685836791991 , validation accuracy:  16.784435090301148 %, lr:  0.000993765314352369\n",
+      "Epoch:  129 , validation loss:  1.7539676666259765 , validation accuracy:  11.670796677235165 %, lr:  0.000993765314352369\n",
+      "Epoch:  130 , validation loss:  1.569759464263916 , validation accuracy:  18.84366918074297 %, lr:  0.000993765314352369\n",
+      "Epoch:  131 , validation loss:  2.015633201599121 , validation accuracy:  21.074235587345214 %, lr:  0.000993765314352369\n",
+      "Epoch:  132 , validation loss:  1.470371150970459 , validation accuracy:  21.686342830554143 %, lr:  0.000993765314352369\n",
+      "Epoch:  133 , validation loss:  1.6732473373413086 , validation accuracy:  14.674703054043622 %, lr:  0.000993765314352369\n",
+      "Epoch:  134 , validation loss:  1.5662439346313477 , validation accuracy:  18.402533554081497 %, lr:  0.000993765314352369\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  135 , validation loss:  1.5204621315002442 , validation accuracy:  23.15799725146895 %, lr:  0.000993765314352369\n",
+      "Epoch:  136 , validation loss:  1.461225986480713 , validation accuracy:  25.668105858122413 %, lr:  0.000993765314352369\n",
+      "Epoch:  137 , validation loss:  1.7022897720336914 , validation accuracy:  21.15178600413362 %, lr:  0.000993765314352369\n",
+      "Epoch:  138 , validation loss:  1.6106029510498048 , validation accuracy:  21.990773303900248 %, lr:  0.000993765314352369\n",
+      "Epoch:  139 , validation loss:  1.5011514663696288 , validation accuracy:  24.60584549792778 %, lr:  0.000993765314352369\n",
+      "Epoch:  140 , validation loss:  1.5479843139648437 , validation accuracy:  24.160020776297706 %, lr:  0.000993765314352369\n",
+      "Epoch:  141 , validation loss:  1.4775799751281737 , validation accuracy:  20.968911300358176 %, lr:  0.000993765314352369\n",
+      "Epoch:  142 , validation loss:  1.471799945831299 , validation accuracy:  16.269716742593936 %, lr:  0.000993765314352369\n",
+      "Epoch:  143 , validation loss:  1.4868105888366698 , validation accuracy:  25.290814062956514 %, lr:  0.000993765314352369\n",
+      "Epoch:  144 , validation loss:  1.4819032669067382 , validation accuracy:  22.432991029400625 %, lr:  0.000993765314352369\n",
+      "Epoch:  145 , validation loss:  1.5382058143615722 , validation accuracy:  17.03584272054076 %, lr:  0.000993765314352369\n",
+      "Epoch:  146 , validation loss:  1.5711252212524414 , validation accuracy:  22.33091303893031 %, lr:  0.000993765314352369\n",
+      "Epoch:  147 , validation loss:  1.4734992980957031 , validation accuracy:  26.93344010041877 %, lr:  0.000993765314352369\n",
+      "Epoch:  148 , validation loss:  1.5031538963317872 , validation accuracy:  27.111986408838582 %, lr:  0.000993765314352369\n",
+      "Epoch:  149 , validation loss:  1.4686474800109863 , validation accuracy:  22.733453807004064 %, lr:  0.000993765314352369\n",
+      "Epoch:  150 , validation loss:  1.4981348991394043 , validation accuracy:  25.575766757202267 %, lr:  0.000993765314352369\n",
+      "Epoch:  151 , validation loss:  1.563105010986328 , validation accuracy:  17.77455552790192 %, lr:  0.000993765314352369\n",
+      "Epoch:  152 , validation loss:  1.4533620834350587 , validation accuracy:  24.660311139486147 %, lr:  0.000993765314352369\n",
+      "Epoch:  153 , validation loss:  1.5119709014892577 , validation accuracy:  20.895328579312434 %, lr:  0.000993765314352369\n",
+      "Epoch:  154 , validation loss:  1.4439645767211915 , validation accuracy:  23.135273175851882 %, lr:  0.000993765314352369\n",
+      "Epoch:  155 , validation loss:  1.6100240707397462 , validation accuracy:  23.053394363707845 %, lr:  0.000993765314352369\n",
+      "Epoch:  156 , validation loss:  1.4522889137268067 , validation accuracy:  24.319089305617176 %, lr:  0.000993765314352369\n",
+      "Epoch:  157 , validation loss:  1.7037908554077148 , validation accuracy:  19.077041830334114 %, lr:  0.000993765314352369\n",
+      "Epoch:  158 , validation loss:  1.4359628677368164 , validation accuracy:  21.98175581357601 %, lr:  0.000993765314352369\n",
+      "Epoch:  159 , validation loss:  1.3940927505493164 , validation accuracy:  25.787858129628226 %, lr:  0.000993765314352369\n",
+      "Epoch:  160 , validation loss:  1.4702397346496583 , validation accuracy:  26.094092101039173 %, lr:  0.000993765314352369\n",
+      "Epoch:  161 , validation loss:  1.4399585723876953 , validation accuracy:  19.331695757090454 %, lr:  0.000993765314352369\n",
+      "Epoch:  162 , validation loss:  1.5577592849731445 , validation accuracy:  20.541842958602505 %, lr:  0.000993765314352369\n",
+      "Epoch:  163 , validation loss:  1.3700648307800294 , validation accuracy:  24.399886018922302 %, lr:  0.000993765314352369\n",
+      "Epoch:  164 , validation loss:  1.4281825065612792 , validation accuracy:  24.522523887331868 %, lr:  0.000993765314352369\n",
+      "Epoch:  165 , validation loss:  1.4671483993530274 , validation accuracy:  23.113270499460754 %, lr:  0.000993765314352369\n",
+      "Epoch:  166 , validation loss:  1.8202281951904298 , validation accuracy:  24.967627209736005 %, lr:  0.000993765314352369\n",
+      "Epoch:  167 , validation loss:  1.669172477722168 , validation accuracy:  21.131586825807336 %, lr:  0.000993765314352369\n",
+      "Epoch:  168 , validation loss:  1.4692268371582031 , validation accuracy:  19.426199055688414 %, lr:  0.000993765314352369\n",
+      "Epoch:  169 , validation loss:  1.4339914321899414 , validation accuracy:  26.652815801528646 %, lr:  0.000993765314352369\n"
+     ]
+    }
+   ],
+   "source": [
+    "def train():\n",
+    "           \n",
+    "    print(\"Initialising W&B...\")\n",
+    "    wandb.init()\n",
+    "\n",
+    "    from torch_geometric.data import Data\n",
+    "    from torch_geometric.data import DataLoader\n",
+    "    from torch_scatter import scatter_add\n",
+    "    \n",
+    "    # Local imports\n",
+    "    from utils.toy_utils import load_data, make_mlp\n",
+    "\n",
+    "    class TwoHopAttNetwork(nn.Module):\n",
+    "        \"\"\"\n",
+    "        A module which computes new node features on the graph.\n",
+    "        For each node, it aggregates the neighbor node features\n",
+    "        (separately on the input and output side), and combines\n",
+    "        them with the node's previous features in a fully-connected\n",
+    "        network to compute the new features.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
+    "                     layer_norm=True):\n",
+    "            super(TwoHopAttNetwork, self).__init__()\n",
+    "            self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                    hidden_activation=hidden_activation,\n",
+    "                                    output_activation=hidden_activation,\n",
+    "                                    layer_norm=layer_norm)\n",
+    "\n",
+    "        def forward(self, x, e, edge_index):\n",
+    "            start, end = edge_index\n",
+    "            # Aggregate edge-weighted incoming/outgoing features\n",
+    "            mi = scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mi2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mo = scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            mo2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
+    "            return self.network(node_inputs)\n",
+    "\n",
+    "    class TwoHopNetwork(nn.Module):\n",
+    "        \"\"\"\n",
+    "        A module which computes new node features on the graph.\n",
+    "        For each node, it aggregates the neighbor node features\n",
+    "        (separately on the input and output side), and combines\n",
+    "        them with the node's previous features in a fully-connected\n",
+    "        network to compute the new features.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
+    "                     layer_norm=True):\n",
+    "            super(TwoHopNetwork, self).__init__()\n",
+    "            self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                    hidden_activation=hidden_activation,\n",
+    "                                    output_activation=hidden_activation,\n",
+    "                                    layer_norm=layer_norm)\n",
+    "\n",
+    "        def forward(self, x, e, edge_index):\n",
+    "            start, end = edge_index\n",
+    "            # Aggregate edge-weighted incoming/outgoing features\n",
+    "            mi = scatter_add(x[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mi2 = scatter_add(scatter_add(x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mo = scatter_add(x[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            mo2 = scatter_add(scatter_add(x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
+    "            return self.network(node_inputs)\n",
+    "\n",
+    "    class Edge_Track_Net(nn.Module):\n",
+    "        \"\"\"\n",
+    "        Segment classification graph neural network model.\n",
+    "        Consists of an input network, an edge network, and a node network.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
+    "                     output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
+    "            super(Edge_Track_Net, self).__init__()\n",
+    "            self.n_graph_iters = n_graph_iters\n",
+    "            # Setup the input network\n",
+    "            self.input_network = make_mlp(input_dim, [hidden_dim],\n",
+    "                                          hidden_activation=nn.ReLU,\n",
+    "                                          layer_norm=False)\n",
+    "            # Setup the edge network\n",
+    "            self.edge_network = EdgeNetwork(input_dim+hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation, layer_norm=layer_norm)\n",
+    "            # Setup the node layers\n",
+    "            self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation=nn.ReLU, layer_norm=False)\n",
+    "\n",
+    "    #         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
+    "    #                                         layer_norm=False)\n",
+    "            self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, output_dim],\n",
+    "                                           hidden_activation=nn.ReLU,\n",
+    "                                          output_activation=None,\n",
+    "                                          layer_norm=False)\n",
+    "\n",
+    "        def forward(self, inputs):\n",
+    "            \"\"\"Apply forward pass of the model\"\"\"\n",
+    "            # Apply input network to get hidden representation\n",
+    "            x = self.input_network(inputs.x)\n",
+    "            # Shortcut connect the inputs onto the hidden representation\n",
+    "            x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Loop over iterations of edge and node networks\n",
+    "            for i in range(self.n_graph_iters):\n",
+    "                # Apply edge network\n",
+    "                e = torch.sigmoid(self.edge_network(x, inputs.edge_index))\n",
+    "                # Apply node network\n",
+    "                x = self.node_network(x, e, inputs.edge_index)\n",
+    "                # Shortcut connect the inputs onto the hidden representation\n",
+    "                x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Apply final edge network\n",
+    "            e = self.edge_network(x, inputs.edge_index)\n",
+    "            return e, self.output_network(x)\n",
+    "\n",
+    "    class Edge_Track_Truth_Net(nn.Module):\n",
+    "        \"\"\"\n",
+    "        Segment classification graph neural network model.\n",
+    "        Consists of an input network, an edge network, and a node network.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
+    "                     output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
+    "            super(Edge_Track_Truth_Net, self).__init__()\n",
+    "            self.n_graph_iters = n_graph_iters\n",
+    "            # Setup the input network\n",
+    "            self.input_network = make_mlp(input_dim, [hidden_dim],\n",
+    "                                          hidden_activation=nn.ReLU,\n",
+    "                                          layer_norm=False)\n",
+    "            # Setup the node layers\n",
+    "            self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation=nn.ReLU, layer_norm=False)\n",
+    "\n",
+    "    #         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
+    "    #                                         layer_norm=False)\n",
+    "            self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                           hidden_activation=nn.ReLU,\n",
+    "                                          output_activation=None,\n",
+    "                                          layer_norm=False)\n",
+    "\n",
+    "        def forward(self, inputs):\n",
+    "            \"\"\"Apply forward pass of the model\"\"\"\n",
+    "            # Apply input network to get hidden representation\n",
+    "            x = self.input_network(inputs.x)\n",
+    "            # Shortcut connect the inputs onto the hidden representation\n",
+    "            x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Loop over iterations of edge and node networks\n",
+    "            for i in range(self.n_graph_iters):\n",
+    "                # Apply edge network\n",
+    "                e = inputs.y_edges\n",
+    "                # Apply node network\n",
+    "                x = self.node_network(x, e, inputs.edge_index)\n",
+    "                # Shortcut connect the inputs onto the hidden representation\n",
+    "                x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Apply final edge network\n",
+    "            return self.output_network(x)\n",
+    "\n",
+    "    def validate(model, val_loader, val_size):\n",
+    "        model = model.eval()\n",
+    "        node_correct, node_total, loss = 0, 0, 0\n",
+    "        for batch in val_loader:\n",
+    "            data = batch.to(device)\n",
+    "#             print(len(data.y_params))\n",
+    "            node_pred = model(data)\n",
+    "            node_correct += (((node_pred - data.y_params)/data.y_params)**2 < 0.1**2).sum().item()\n",
+    "            node_total += len(node_pred)\n",
+    "            loss += F.mse_loss(node_pred, data.y_params)\n",
+    "        acc = node_correct / node_total\n",
+    "        return acc, loss.item()/val_size\n",
+    "\n",
+    "    def get_lr(optimizer):\n",
+    "        for param_group in optimizer.param_groups:\n",
+    "            return param_group['lr']\n",
+    "    \n",
+    "    print(\"Loading data...\")\n",
+    "    train_dataset, val_dataset = load_data(train_size=wandb.config.get(\"train_size\",0), test_size=20)\n",
+    "    train_loader, val_loader = DataLoader(train_dataset, batch_size=2, shuffle=True), DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
+    "    \n",
+    "    print(\"config:\", dict(wandb.config.user_items()))\n",
+    "\n",
+    "    device = torch.device('cuda') # if torch.cuda.is_available() else 'cpu')\n",
+    "    print(\"Using \", device)\n",
+    "    \n",
+    "    m_dic = [\"hidden_dim\", \"n_graph_iters\"]\n",
+    "    m_configs = {k:wandb.config.get(k,0) for k in m_dic} \n",
+    "    m_configs = {'input_dim': 3, **m_configs, 'output_dim': 1}\n",
+    "        \n",
+    "    print(\"Loading model...\")\n",
+    "    print(\"Model configs: \", m_configs)\n",
+    "    model = Edge_Track_Truth_Net(**m_configs).to(device)\n",
+    "    wandb.watch(model, log='all')\n",
+    "    \n",
+    "    print(\"Loading optimiser\")\n",
+    "    o_dic = [\"lr\"]\n",
+    "    o_configs = {k:wandb.config.get(k,0) for k in o_dic} \n",
+    "    optimizer_fn = getattr(torch.optim, wandb.config.get(\"optimizer\",0))\n",
+    "#     optimizer_kwargs = {\"Adam\": {}, \"SGD\": {}}\n",
+    "    optimizer = optimizer_fn(model.parameters(), amsgrad=True, **o_configs)\n",
+    "    \n",
+    "    print(\"Loading scheduler...\")\n",
+    "#     s_dic = [\"step_size\", \"gamma\"]\n",
+    "#     s_configs = {k:wandb.config.get(k,0) for k in s_dic} \n",
+    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30)\n",
+    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.3, patience=20)\n",
+    "    \n",
+    "    model.train()\n",
+    "    \n",
+    "    print(\"Training...\")\n",
+    "    \n",
+    "    ep = 0\n",
+    "    best_acc = 0\n",
+    "    for epoch in range(wandb.config.get(\"epochs\", 0)):\n",
+    "        for batch in train_loader:\n",
+    "            optimizer.zero_grad()\n",
+    "            data = batch.to(device)\n",
+    "#             print(len(data.y_params))\n",
+    "            node_pred = model(data)\n",
+    "            loss = F.mse_loss(node_pred, data.y_params)\n",
+    "#             print(loss)\n",
+    "            loss.backward()\n",
+    "            optimizer.step()\n",
+    "        ep += 1\n",
+    "#         print(\"Evaluating...\")\n",
+    "        val_acc, val_loss = validate(model, val_loader, 20)\n",
+    "        if (val_acc > best_acc): best_acc = val_acc\n",
+    "        scheduler.step(val_loss)\n",
+    "#         scheduler.step()\n",
+    "        lr = get_lr(optimizer)\n",
+    "        print(\"Epoch: \" , ep, \", validation loss: \", val_loss, \", validation accuracy: \", val_acc*100, \"%, lr: \", lr)\n",
+    "        wandb.log({\"Validation Accuracy\": val_acc, \"Best Accuracy\": best_acc, \"Validation Loss\": val_loss, \"Learning Rate\": lr})\n",
+    "    \n",
+    "wandb.agent(sweep_id, function=train)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 6,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:11.240625, resuming normal operation.\n"
+     ]
+    },
+    {
+     "ename": "ControllerError",
+     "evalue": "Only sweeps with a local controller are currently supported.",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mControllerError\u001b[0m                           Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-6-d64628e1e9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msweep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[0;32m~/.local/lib/python3.7/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, verbose, print_status, print_actions, print_debug)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mprint_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mprint_debug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_if_not_started\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m~/.local/lib/python3.7/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36m_start_if_not_started\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mis_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sweep_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'controller'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'local'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mControllerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only sweeps with a local controller are currently supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;31m# reset controller state, we might want to parse this and decide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;31mControllerError\u001b[0m: Only sweeps with a local controller are currently supported."
+     ]
     }
    ],
    "source": [
-    "dir(tnn)"
+    "sweep = wandb.controller(sweep_id)\n",
+    "sweep.run()"
    ]
   },
   {
diff --git a/notebooks/ToyModelTrackML.ipynb b/notebooks/ToyModelTrackML.ipynb
index d3f957d..cf4a3a7 100644
--- a/notebooks/ToyModelTrackML.ipynb
+++ b/notebooks/ToyModelTrackML.ipynb
@@ -11,7 +11,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 3,
    "metadata": {
     "cell_style": "center",
     "code_folding": []
@@ -33,6 +33,9 @@
     "import matplotlib.colors\n",
     "import numpy as np\n",
     "import torch\n",
+    "import torch.multiprocessing as mp\n",
+    "import torch.nn as nn\n",
+    "# mp.set_start_method(\"forkserver\", force=True)\n",
     "from torch_geometric.data import Data\n",
     "from torch_geometric.data import DataLoader\n",
     "import seaborn as sns\n",
@@ -43,17 +46,18 @@
     "from ipywidgets import interact, interact_manual\n",
     "\n",
     "# Limit CPU usage on Jupyter\n",
-    "os.environ['OMP_NUM_THREADS'] = '4'\n",
+    "os.environ['OMP_NUM_THREADS'] = '1'\n",
     "\n",
     "# Local imports\n",
-    "from utils.toy_utils import *\n",
-    "from datasets.hitgraphs_params import *\n",
+    "from utils.toy_utils import load_data, make_mlp\n",
     "%matplotlib inline"
    ]
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "## Loading TrackML Dataset"
    ]
@@ -61,7 +65,9 @@
   {
    "cell_type": "code",
    "execution_count": 6,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -79,7 +85,9 @@
   {
    "cell_type": "code",
    "execution_count": 2,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "input_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/\"\n",
@@ -90,7 +98,9 @@
   {
    "cell_type": "code",
    "execution_count": 3,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "full_graphs = [load_graph(fi) for fi in filenames]"
@@ -99,7 +109,9 @@
   {
    "cell_type": "code",
    "execution_count": 5,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "cut_mask = [~(np.isnan(g[3]).any()) for g in full_graphs]\n",
@@ -109,7 +121,9 @@
   {
    "cell_type": "code",
    "execution_count": 4,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "cut_full_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),\n",
@@ -117,6 +131,15 @@
     "                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in full_graphs]"
    ]
   },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "metadata": {
+    "hidden": true
+   },
+   "outputs": [],
+   "source": []
+  },
   {
    "cell_type": "markdown",
    "metadata": {
@@ -1440,19 +1463,15 @@
     "## Combined Edge & Track Param Classifier"
    ]
   },
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "How to do a double scatter..."
-   ]
-  },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 4,
    "metadata": {
     "code_folding": [
-     52
+     0,
+     26,
+     52,
+     97
     ]
    },
    "outputs": [],
@@ -1598,37 +1617,43 @@
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "#### Generate data"
    ]
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "#### Load data"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
-   "metadata": {},
+   "execution_count": 3,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
-    "train_size = int(0.5 * len(cut_full_dataset))\n",
-    "test_size = int(0.1 * len(cut_full_dataset))\n",
-    "train_dataset = cut_full_dataset[:train_size]\n",
-    "test_dataset = cut_full_dataset[-test_size:]\n",
-    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
+    "train_size, test_size = 300, 50\n",
+    "train_dataset, test_dataset = load_data(train_size, test_size)\n",
+    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
     "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
     "t_configs = {'train_size': train_size, 'test_size': test_size}"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
-   "metadata": {},
+   "execution_count": 4,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -1642,7 +1667,8 @@
     "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
     "print(\"Using \", device)\n",
     "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
-    "m_configs = {'input_dim': 3, 'hidden_dim': 16, 'n_graph_iters': 3, 'output_dim': 1}\n",
+    "m_configs = {'hidden_dim': 16, 'n_graph_iters': 3}\n",
+    "m_configs = {'input_dim': 3, **m_configs, 'output_dim': 1}\n",
     "model = Edge_Track_Truth_Net(**m_configs).to(device)\n",
     "# data = dataset[0].to(device)\n",
     "o_configs = {'lr': 0.001, 'weight_decay': 1e-4}\n",
@@ -1664,7 +1690,9 @@
   {
    "cell_type": "code",
    "execution_count": 9,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "data": {
@@ -1719,66 +1747,21 @@
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": 16,
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Traceback (most recent call last):\r\n",
-      "  File \"/global/homes/d/danieltm/.local/bin/wandb\", line 6, in <module>\r\n",
-      "    from wandb.cli import cli\r\n",
-      "ModuleNotFoundError: No module named 'wandb'\r\n"
-     ]
-    }
-   ],
-   "source": [
-    "!wandb"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 47,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "[<matplotlib.lines.Line2D at 0x2aab7fcdaf60>]"
-      ]
-     },
-     "execution_count": 47,
-     "metadata": {},
-     "output_type": "execute_result"
-    },
-    {
-     "data": {
-      "image/png": "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\n",
-      "text/plain": [
-       "<Figure size 1152x288 with 2 Axes>"
-      ]
-     },
-     "metadata": {
-      "needs_background": "light"
-     },
-     "output_type": "display_data"
-    }
-   ],
+   "cell_type": "markdown",
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
-    "fig, axs = plt.subplots(1,2)\n",
-    "fig.set_size_inches(16,4)\n",
-    "axs[0].plot(np.arange(len(loss_v_node)), loss_v_node)\n",
-    "# axs[1].plot(np.arange(len(loss_v_edge)), loss_v_edge)\n",
-    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
-    "# axs[3].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
+    "### Training and Validation"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 10,
-   "metadata": {},
+   "metadata": {
+    "code_folding": [],
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stderr",
@@ -2276,7 +2259,9 @@
   {
    "cell_type": "code",
    "execution_count": 52,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -3714,16 +3699,66 @@
     "    print('Accuracy: {:.4f}%'.format(acc))"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "metadata": {
+    "heading_collapsed": true
+   },
+   "source": [
+    "### Debug"
+   ]
+  },
   {
    "cell_type": "code",
-   "execution_count": 42,
-   "metadata": {},
+   "execution_count": 47,
+   "metadata": {
+    "hidden": true
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "[<matplotlib.lines.Line2D at 0x2aab7fcdaf60>]"
+      ]
+     },
+     "execution_count": 47,
+     "metadata": {},
+     "output_type": "execute_result"
+    },
+    {
+     "data": {
+      "image/png": "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\n",
+      "text/plain": [
+       "<Figure size 1152x288 with 2 Axes>"
+      ]
+     },
+     "metadata": {
+      "needs_background": "light"
+     },
+     "output_type": "display_data"
+    }
+   ],
+   "source": [
+    "fig, axs = plt.subplots(1,2)\n",
+    "fig.set_size_inches(16,4)\n",
+    "axs[0].plot(np.arange(len(loss_v_node)), loss_v_node)\n",
+    "# axs[1].plot(np.arange(len(loss_v_edge)), loss_v_edge)\n",
+    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
+    "# axs[3].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 10,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "13.484405994415283 13.484405994415283\n"
+      "0.0 0.0\n"
      ]
     }
    ],
@@ -3736,7 +3771,9 @@
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "## Getting Weights & Bias to Work"
    ]
@@ -3744,7 +3781,9 @@
   {
    "cell_type": "code",
    "execution_count": 18,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "data": {
@@ -3852,6 +3891,2082 @@
     "model.output_network"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Sweep"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 28,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "1.013009359863071e-05"
+      ]
+     },
+     "execution_count": 28,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "import numpy as np\n",
+    "np.exp(-11.5)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 33,
+   "metadata": {
+    "code_folding": []
+   },
+   "outputs": [],
+   "source": [
+    "# System imports\n",
+    "import os\n",
+    "import sys\n",
+    "from pprint import pprint as pp\n",
+    "from time import time as tt\n",
+    "sys.path.append('..')\n",
+    "sys.path.append('/global/common/cori_cle7/software/jupyter/19-11/lib/python3.7/site-packages')\n",
+    "sys.path.append('/global/homes/d/danieltm/.local/lib/python3.7/site-packages')\n",
+    "import wandb\n",
+    "# External imports\n",
+    "import numpy as np\n",
+    "import torch\n",
+    "import torch.nn.functional as F\n",
+    "import torch.nn as nn\n",
+    "import yaml"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 37,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "{'method': 'bayes',\n",
+       " 'metric': {'goal': 'maximize', 'name': 'Best Accuracy'},\n",
+       " 'name': 'Track Param Sweep',\n",
+       " 'parameters': {'epochs': {'distribution': 'q_normal',\n",
+       "   'max': 250,\n",
+       "   'min': 50,\n",
+       "   'mu': 150,\n",
+       "   'sigma': 50},\n",
+       "  'hidden_dim': {'distribution': 'q_log_normal',\n",
+       "   'max': 4.159,\n",
+       "   'min': 1.386,\n",
+       "   'mu': 2.8,\n",
+       "   'sigma': 0.8},\n",
+       "  'lr': {'distribution': 'log_normal',\n",
+       "   'max': -2.3,\n",
+       "   'min': -11.5,\n",
+       "   'mu': -6.9,\n",
+       "   'sigma': 1.5},\n",
+       "  'n_graph_iters': {'max': 8, 'min': 1},\n",
+       "  'network': {'values': ['Edge_Track_Truth_Net']},\n",
+       "  'optimizer': {'values': ['AdamW']},\n",
+       "  'train_size': {'max': 800, 'min': 100},\n",
+       "  'weight_decay': {'distribution': 'log_uniform', 'max': -4.6, 'min': -11.5}}}"
+      ]
+     },
+     "execution_count": 37,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "with open(r'config.yaml') as file:\n",
+    "    sweep_config = yaml.load(file, Loader=yaml.FullLoader)\n",
+    "sweep_id = wandb.sweep(sweep_config, entity= \"murnanedaniel\", project= \"node_regression_sweep\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 32,
+   "metadata": {
+    "code_folding": [
+     12,
+     38,
+     64,
+     109,
+     150,
+     163
+    ]
+   },
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "wandb: Agent Starting Run: txex35gz with config:\n",
+      "\tepochs: 173\n",
+      "\thidden_dim: 36\n",
+      "\tlr: 0.002223379986022571\n",
+      "\tn_graph_iters: 5\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 292\n",
+      "\tweight_decay: 0.00021762208861989958\n",
+      "wandb: Agent Started Run: txex35gz\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/txex35gz\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/txex35gz</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 173, 'hidden_dim': 36, 'lr': 0.002223379986022571, 'n_graph_iters': 5, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 292, 'weight_decay': 0.0002176220886198996}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 36, 'n_graph_iters': 5, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.8970849990844727 , validation accuracy:  9.256994867244508 %, lr:  0.002223379986022571\n",
+      "Epoch:  2 , validation loss:  1.8765539169311523 , validation accuracy:  11.486839874620815 %, lr:  0.002223379986022571\n",
+      "Epoch:  3 , validation loss:  1.8755508422851563 , validation accuracy:  12.343501455422938 %, lr:  0.002223379986022571\n",
+      "Epoch:  4 , validation loss:  1.8715837478637696 , validation accuracy:  13.172389166026424 %, lr:  0.002223379986022571\n",
+      "Epoch:  5 , validation loss:  1.880539894104004 , validation accuracy:  10.921623581097897 %, lr:  0.002223379986022571\n",
+      "Epoch:  6 , validation loss:  1.8723861694335937 , validation accuracy:  10.33548671002276 %, lr:  0.002223379986022571\n",
+      "Epoch:  7 , validation loss:  1.8658079147338866 , validation accuracy:  11.843571791847467 %, lr:  0.002223379986022571\n",
+      "Epoch:  8 , validation loss:  1.8629955291748046 , validation accuracy:  11.67873206872049 %, lr:  0.002223379986022571\n",
+      "Epoch:  9 , validation loss:  1.8841968536376954 , validation accuracy:  10.174253983025476 %, lr:  0.002223379986022571\n",
+      "Epoch:  10 , validation loss:  1.8708663940429688 , validation accuracy:  10.274167775817975 %, lr:  0.002223379986022571\n",
+      "Epoch:  11 , validation loss:  1.8617652893066405 , validation accuracy:  12.353961744199049 %, lr:  0.002223379986022571\n",
+      "Epoch:  12 , validation loss:  1.8640022277832031 , validation accuracy:  12.503652083581315 %, lr:  0.002223379986022571\n",
+      "Epoch:  13 , validation loss:  1.8625238418579102 , validation accuracy:  11.781892158029715 %, lr:  0.002223379986022571\n",
+      "Epoch:  14 , validation loss:  1.8604522705078126 , validation accuracy:  12.916653140431182 %, lr:  0.002223379986022571\n",
+      "Epoch:  15 , validation loss:  1.8602184295654296 , validation accuracy:  12.39039240510895 %, lr:  0.002223379986022571\n",
+      "Epoch:  16 , validation loss:  1.8647550582885741 , validation accuracy:  11.884330848113 %, lr:  0.002223379986022571\n",
+      "Epoch:  17 , validation loss:  1.8623626708984375 , validation accuracy:  10.902506501610523 %, lr:  0.002223379986022571\n",
+      "Epoch:  18 , validation loss:  1.8592668533325196 , validation accuracy:  12.450629240474825 %, lr:  0.002223379986022571\n",
+      "Epoch:  19 , validation loss:  1.8605863571166992 , validation accuracy:  13.346607079090605 %, lr:  0.002223379986022571\n",
+      "Epoch:  20 , validation loss:  1.8664567947387696 , validation accuracy:  12.323662976709626 %, lr:  0.002223379986022571\n",
+      "Epoch:  21 , validation loss:  1.862752342224121 , validation accuracy:  12.27388643011986 %, lr:  0.002223379986022571\n",
+      "Epoch:  22 , validation loss:  1.8619066238403321 , validation accuracy:  12.31608828483727 %, lr:  0.002223379986022571\n",
+      "Epoch:  23 , validation loss:  1.8602188110351563 , validation accuracy:  12.46902492073626 %, lr:  0.002223379986022571\n",
+      "Epoch:  24 , validation loss:  1.8596076965332031 , validation accuracy:  13.313422714697426 %, lr:  0.002223379986022571\n",
+      "Epoch:  25 , validation loss:  1.8583532333374024 , validation accuracy:  12.8106074542182 %, lr:  0.002223379986022571\n",
+      "Epoch:  26 , validation loss:  1.8651525497436523 , validation accuracy:  13.311258517019612 %, lr:  0.002223379986022571\n",
+      "Epoch:  27 , validation loss:  1.8594324111938476 , validation accuracy:  11.739329603699336 %, lr:  0.002223379986022571\n",
+      "Epoch:  28 , validation loss:  1.8594205856323243 , validation accuracy:  11.627152024065879 %, lr:  0.002223379986022571\n",
+      "Epoch:  29 , validation loss:  1.858237075805664 , validation accuracy:  13.003581747156787 %, lr:  0.002223379986022571\n",
+      "Epoch:  30 , validation loss:  1.8592216491699218 , validation accuracy:  12.931441824562922 %, lr:  0.002223379986022571\n",
+      "Epoch:  31 , validation loss:  1.8662528991699219 , validation accuracy:  13.44796367033498 %, lr:  0.002223379986022571\n",
+      "Epoch:  32 , validation loss:  1.8596782684326172 , validation accuracy:  12.450268540861856 %, lr:  0.002223379986022571\n",
+      "Epoch:  33 , validation loss:  1.8617345809936523 , validation accuracy:  11.318032455751174 %, lr:  0.002223379986022571\n",
+      "Epoch:  34 , validation loss:  1.8593191146850585 , validation accuracy:  12.765159302984067 %, lr:  0.002223379986022571\n",
+      "Epoch:  35 , validation loss:  1.8589960098266602 , validation accuracy:  13.302962425921317 %, lr:  0.002223379986022571\n",
+      "Epoch:  36 , validation loss:  1.8606969833374023 , validation accuracy:  13.989013089788955 %, lr:  0.002223379986022571\n",
+      "Epoch:  37 , validation loss:  1.8591793060302735 , validation accuracy:  12.017068305685708 %, lr:  0.002223379986022571\n",
+      "Epoch:  38 , validation loss:  1.858823585510254 , validation accuracy:  11.772153268479544 %, lr:  0.002223379986022571\n",
+      "Epoch:  39 , validation loss:  1.863187026977539 , validation accuracy:  11.701816843950526 %, lr:  0.002223379986022571\n",
+      "Epoch:  40 , validation loss:  1.8584503173828124 , validation accuracy:  11.760250181251555 %, lr:  0.002223379986022571\n",
+      "Epoch:  41 , validation loss:  1.8572250366210938 , validation accuracy:  11.608034944578504 %, lr:  0.002223379986022571\n",
+      "Epoch:  42 , validation loss:  1.8597099304199218 , validation accuracy:  13.645266358629197 %, lr:  0.002223379986022571\n",
+      "Epoch:  43 , validation loss:  1.8602407455444336 , validation accuracy:  12.199943009461151 %, lr:  0.002223379986022571\n",
+      "Epoch:  44 , validation loss:  1.8583749771118163 , validation accuracy:  11.77936726073893 %, lr:  0.002223379986022571\n",
+      "Epoch:  45 , validation loss:  1.8586620330810546 , validation accuracy:  12.997810553349275 %, lr:  0.002223379986022571\n",
+      "Epoch:  46 , validation loss:  1.8590202331542969 , validation accuracy:  11.854392780236548 %, lr:  0.002223379986022571\n",
+      "Epoch:  47 , validation loss:  1.860488510131836 , validation accuracy:  11.239039240510895 %, lr:  0.002223379986022571\n",
+      "Epoch:  48 , validation loss:  1.8577409744262696 , validation accuracy:  12.125278189576502 %, lr:  0.002223379986022571\n",
+      "Epoch:  49 , validation loss:  1.8584442138671875 , validation accuracy:  12.946591208307634 %, lr:  0.002223379986022571\n",
+      "Epoch:  50 , validation loss:  1.859341812133789 , validation accuracy:  11.723819520341655 %, lr:  0.002223379986022571\n",
+      "Epoch:  51 , validation loss:  1.8624185562133788 , validation accuracy:  11.065903426285624 %, lr:  0.002223379986022571\n",
+      "Epoch:  52 , validation loss:  1.8546770095825196 , validation accuracy:  12.963183390504222 %, lr:  0.002223379986022571\n",
+      "Epoch:  53 , validation loss:  1.8479997634887695 , validation accuracy:  12.66849180670829 %, lr:  0.002223379986022571\n",
+      "Epoch:  54 , validation loss:  1.8570812225341797 , validation accuracy:  12.851727210096703 %, lr:  0.002223379986022571\n",
+      "Epoch:  55 , validation loss:  1.8563135147094727 , validation accuracy:  12.428987263696666 %, lr:  0.002223379986022571\n",
+      "Epoch:  56 , validation loss:  1.866143035888672 , validation accuracy:  13.687468213346607 %, lr:  0.002223379986022571\n",
+      "Epoch:  57 , validation loss:  1.8408073425292968 , validation accuracy:  14.921782288927604 %, lr:  0.002223379986022571\n",
+      "Epoch:  58 , validation loss:  1.8474803924560548 , validation accuracy:  14.013901363083836 %, lr:  0.002223379986022571\n",
+      "Epoch:  59 , validation loss:  1.790151596069336 , validation accuracy:  15.182207409491449 %, lr:  0.002223379986022571\n",
+      "Epoch:  60 , validation loss:  1.8694211959838867 , validation accuracy:  13.103856239562257 %, lr:  0.002223379986022571\n",
+      "Epoch:  61 , validation loss:  1.8789506912231446 , validation accuracy:  10.490226843986598 %, lr:  0.002223379986022571\n",
+      "Epoch:  62 , validation loss:  1.7118616104125977 , validation accuracy:  15.179682512200666 %, lr:  0.002223379986022571\n",
+      "Epoch:  63 , validation loss:  1.8365230560302734 , validation accuracy:  13.151829288087175 %, lr:  0.002223379986022571\n",
+      "Epoch:  64 , validation loss:  1.877248764038086 , validation accuracy:  10.885914319413935 %, lr:  0.002223379986022571\n",
+      "Epoch:  65 , validation loss:  1.8241140365600585 , validation accuracy:  13.788824804590986 %, lr:  0.002223379986022571\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  66 , validation loss:  1.8681299209594726 , validation accuracy:  11.758446683186708 %, lr:  0.002223379986022571\n",
+      "Epoch:  67 , validation loss:  1.8448713302612305 , validation accuracy:  12.312841988320548 %, lr:  0.002223379986022571\n",
+      "Epoch:  68 , validation loss:  1.8441734313964844 , validation accuracy:  12.971840181215486 %, lr:  0.002223379986022571\n",
+      "Epoch:  69 , validation loss:  1.8767066955566407 , validation accuracy:  11.958634968384679 %, lr:  0.002223379986022571\n",
+      "Epoch:  70 , validation loss:  1.8767049789428711 , validation accuracy:  12.160987451260464 %, lr:  0.002223379986022571\n",
+      "Epoch:  71 , validation loss:  1.8770126342773437 , validation accuracy:  12.74820642117451 %, lr:  0.002223379986022571\n",
+      "Epoch:  72 , validation loss:  1.8766077041625977 , validation accuracy:  11.86341027056078 %, lr:  0.002223379986022571\n",
+      "Epoch:  73 , validation loss:  1.87622127532959 , validation accuracy:  12.381735614397686 %, lr:  0.002223379986022571\n",
+      "Epoch:  74 , validation loss:  1.8771820068359375 , validation accuracy:  12.423216069889156 %, lr:  0.002223379986022571\n",
+      "Epoch:  75 , validation loss:  1.876499557495117 , validation accuracy:  11.558619097601708 %, lr:  0.002223379986022571\n",
+      "Epoch:  76 , validation loss:  1.8788997650146484 , validation accuracy:  11.540944816566212 %, lr:  0.002223379986022571\n",
+      "Epoch:  77 , validation loss:  1.8763755798339843 , validation accuracy:  12.33231976742089 %, lr:  0.002223379986022571\n",
+      "Epoch:  78 , validation loss:  1.8767751693725585 , validation accuracy:  12.643603533413408 %, lr:  0.002223379986022571\n",
+      "Epoch:  79 , validation loss:  1.8763322830200195 , validation accuracy:  11.54707670998669 %, lr:  0.002223379986022571\n",
+      "Epoch:  80 , validation loss:  1.8761566162109375 , validation accuracy:  12.898257460169745 %, lr:  0.002223379986022571\n",
+      "Epoch:  81 , validation loss:  1.876511573791504 , validation accuracy:  12.280379023153309 %, lr:  0.002223379986022571\n",
+      "Epoch:  82 , validation loss:  1.876321029663086 , validation accuracy:  12.589498591468013 %, lr:  0.002223379986022571\n",
+      "Epoch:  83 , validation loss:  1.8762216567993164 , validation accuracy:  12.73161423897792 %, lr:  0.0005558449965056428\n",
+      "Epoch:  84 , validation loss:  1.8761550903320312 , validation accuracy:  12.799065066603182 %, lr:  0.0005558449965056428\n",
+      "Epoch:  85 , validation loss:  1.8765811920166016 , validation accuracy:  12.93829511720934 %, lr:  0.0005558449965056428\n",
+      "Epoch:  86 , validation loss:  1.8763256072998047 , validation accuracy:  12.610779868633202 %, lr:  0.0005558449965056428\n",
+      "Epoch:  87 , validation loss:  1.8761892318725586 , validation accuracy:  12.224831282756034 %, lr:  0.0005558449965056428\n",
+      "Epoch:  88 , validation loss:  1.8761983871459962 , validation accuracy:  12.762634405693282 %, lr:  0.0005558449965056428\n",
+      "Epoch:  89 , validation loss:  1.8763145446777343 , validation accuracy:  12.755059713820927 %, lr:  0.0005558449965056428\n",
+      "Epoch:  90 , validation loss:  1.876220703125 , validation accuracy:  12.926752729594321 %, lr:  0.0005558449965056428\n",
+      "Epoch:  91 , validation loss:  1.8764003753662108 , validation accuracy:  12.697347775745838 %, lr:  0.0005558449965056428\n",
+      "Epoch:  92 , validation loss:  1.876371192932129 , validation accuracy:  12.122031893059779 %, lr:  0.0005558449965056428\n",
+      "Epoch:  93 , validation loss:  1.8763574600219726 , validation accuracy:  13.021256028192282 %, lr:  0.0005558449965056428\n",
+      "Epoch:  94 , validation loss:  1.8761648178100585 , validation accuracy:  12.946230508694665 %, lr:  0.0005558449965056428\n",
+      "Epoch:  95 , validation loss:  1.8764421463012695 , validation accuracy:  12.286510916573787 %, lr:  0.0005558449965056428\n",
+      "Epoch:  96 , validation loss:  1.8762435913085938 , validation accuracy:  12.665606209804537 %, lr:  0.0005558449965056428\n",
+      "Epoch:  97 , validation loss:  1.876566505432129 , validation accuracy:  12.2475553583731 %, lr:  0.0005558449965056428\n",
+      "Epoch:  98 , validation loss:  1.8765600204467774 , validation accuracy:  12.561364021656404 %, lr:  0.0005558449965056428\n",
+      "Epoch:  99 , validation loss:  1.8763154983520507 , validation accuracy:  12.79545807047349 %, lr:  0.0005558449965056428\n",
+      "Epoch:  100 , validation loss:  1.8762617111206055 , validation accuracy:  12.558117725139681 %, lr:  0.0005558449965056428\n",
+      "Epoch:  101 , validation loss:  1.8763967514038087 , validation accuracy:  12.592384188371767 %, lr:  0.0005558449965056428\n",
+      "Epoch:  102 , validation loss:  1.8762929916381836 , validation accuracy:  12.308513592964914 %, lr:  0.0005558449965056428\n",
+      "Epoch:  103 , validation loss:  1.8767515182495118 , validation accuracy:  12.062516456919841 %, lr:  0.0005558449965056428\n",
+      "Epoch:  104 , validation loss:  1.8762924194335937 , validation accuracy:  12.869401491132201 %, lr:  0.0001389612491264107\n",
+      "Epoch:  105 , validation loss:  1.8763742446899414 , validation accuracy:  12.636389541154022 %, lr:  0.0001389612491264107\n",
+      "Epoch:  106 , validation loss:  1.8764339447021485 , validation accuracy:  12.460007430412027 %, lr:  0.0001389612491264107\n",
+      "Epoch:  107 , validation loss:  1.876433753967285 , validation accuracy:  12.484174304480971 %, lr:  0.0001389612491264107\n",
+      "Epoch:  108 , validation loss:  1.8763843536376954 , validation accuracy:  12.587334393790195 %, lr:  0.0001389612491264107\n",
+      "Epoch:  109 , validation loss:  1.8764102935791016 , validation accuracy:  12.668131107095324 %, lr:  0.0001389612491264107\n",
+      "Epoch:  110 , validation loss:  1.876405906677246 , validation accuracy:  12.557035626300772 %, lr:  0.0001389612491264107\n",
+      "Epoch:  111 , validation loss:  1.8763925552368164 , validation accuracy:  12.741353128528093 %, lr:  0.0001389612491264107\n",
+      "Epoch:  112 , validation loss:  1.8763799667358398 , validation accuracy:  12.593826986823641 %, lr:  0.0001389612491264107\n",
+      "Epoch:  113 , validation loss:  1.876495933532715 , validation accuracy:  12.608254971342417 %, lr:  0.0001389612491264107\n",
+      "Epoch:  114 , validation loss:  1.8763177871704102 , validation accuracy:  12.778144489050963 %, lr:  0.0001389612491264107\n",
+      "Epoch:  115 , validation loss:  1.8763595581054688 , validation accuracy:  12.512669573905546 %, lr:  0.0001389612491264107\n",
+      "Epoch:  116 , validation loss:  1.8763587951660157 , validation accuracy:  12.643964233026377 %, lr:  0.0001389612491264107\n",
+      "Epoch:  117 , validation loss:  1.8764371871948242 , validation accuracy:  12.44774364357107 %, lr:  0.0001389612491264107\n",
+      "Epoch:  118 , validation loss:  1.8763462066650392 , validation accuracy:  12.51699796926118 %, lr:  0.0001389612491264107\n",
+      "Epoch:  119 , validation loss:  1.8763656616210938 , validation accuracy:  12.571824310432515 %, lr:  0.0001389612491264107\n",
+      "Epoch:  120 , validation loss:  1.8763971328735352 , validation accuracy:  12.511226775453672 %, lr:  0.0001389612491264107\n",
+      "Epoch:  121 , validation loss:  1.876434898376465 , validation accuracy:  12.625568552764943 %, lr:  0.0001389612491264107\n",
+      "Epoch:  122 , validation loss:  1.8764446258544922 , validation accuracy:  12.4473829439581 %, lr:  0.0001389612491264107\n",
+      "Epoch:  123 , validation loss:  1.8763849258422851 , validation accuracy:  12.471910517640014 %, lr:  0.0001389612491264107\n",
+      "Epoch:  124 , validation loss:  1.8763708114624023 , validation accuracy:  12.563528219334222 %, lr:  0.0001389612491264107\n",
+      "Epoch:  125 , validation loss:  1.8763998031616211 , validation accuracy:  12.646128430704193 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  126 , validation loss:  1.8763870239257812 , validation accuracy:  12.577595504240024 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  127 , validation loss:  1.8763935089111328 , validation accuracy:  12.529983155328075 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  128 , validation loss:  1.8764078140258789 , validation accuracy:  12.496438091321927 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  129 , validation loss:  1.8763925552368164 , validation accuracy:  12.544771839459818 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  130 , validation loss:  1.8763916015625 , validation accuracy:  12.542607641782 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  131 , validation loss:  1.8763910293579102 , validation accuracy:  12.51627657003524 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  132 , validation loss:  1.8764053344726563 , validation accuracy:  12.53286875223183 %, lr:  3.474031228160267e-05\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  133 , validation loss:  1.8764049530029296 , validation accuracy:  12.549100234815446 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  134 , validation loss:  1.876380157470703 , validation accuracy:  12.514473071970395 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  135 , validation loss:  1.876397705078125 , validation accuracy:  12.537918546813398 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  136 , validation loss:  1.8763849258422851 , validation accuracy:  12.536836447974492 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  137 , validation loss:  1.8763813018798827 , validation accuracy:  12.560642622430466 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  138 , validation loss:  1.8763824462890626 , validation accuracy:  12.554871428622958 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  139 , validation loss:  1.8763835906982422 , validation accuracy:  12.554510729009987 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  140 , validation loss:  1.8763805389404298 , validation accuracy:  12.563888918947189 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  141 , validation loss:  1.876375389099121 , validation accuracy:  12.591662789145827 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  142 , validation loss:  1.8763677597045898 , validation accuracy:  12.550903732880295 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  143 , validation loss:  1.8763885498046875 , validation accuracy:  12.50076648667756 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  144 , validation loss:  1.8763818740844727 , validation accuracy:  12.541164843330124 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  145 , validation loss:  1.8763734817504882 , validation accuracy:  12.542607641782 %, lr:  3.474031228160267e-05\n",
+      "Epoch:  146 , validation loss:  1.8763751983642578 , validation accuracy:  12.554871428622958 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  147 , validation loss:  1.8763765335083007 , validation accuracy:  12.555953527461867 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  148 , validation loss:  1.8763792037963867 , validation accuracy:  12.554871428622958 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  149 , validation loss:  1.8763742446899414 , validation accuracy:  12.563167519721253 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  150 , validation loss:  1.8763763427734375 , validation accuracy:  12.548018135976541 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  151 , validation loss:  1.876378059387207 , validation accuracy:  12.563167519721253 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  152 , validation loss:  1.876378631591797 , validation accuracy:  12.561724721269375 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  153 , validation loss:  1.8763772964477539 , validation accuracy:  12.561003322043435 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  154 , validation loss:  1.8763750076293946 , validation accuracy:  12.560281922817495 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  155 , validation loss:  1.8763805389404298 , validation accuracy:  12.550543033267324 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  156 , validation loss:  1.87637939453125 , validation accuracy:  12.551264432493264 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  157 , validation loss:  1.87637939453125 , validation accuracy:  12.55270723094514 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  158 , validation loss:  1.8763750076293946 , validation accuracy:  12.551264432493264 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  159 , validation loss:  1.8763818740844727 , validation accuracy:  12.54188624255606 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  160 , validation loss:  1.876377487182617 , validation accuracy:  12.565331717399067 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  161 , validation loss:  1.876378059387207 , validation accuracy:  12.55306793055811 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  162 , validation loss:  1.8763788223266602 , validation accuracy:  12.551625132106233 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  163 , validation loss:  1.8763744354248046 , validation accuracy:  12.557757025526712 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  164 , validation loss:  1.8763814926147462 , validation accuracy:  12.534311550683706 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  165 , validation loss:  1.8763776779174806 , validation accuracy:  12.556314227074836 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  166 , validation loss:  1.8763805389404298 , validation accuracy:  12.539722044878246 %, lr:  8.685078070400668e-06\n",
+      "Epoch:  167 , validation loss:  1.876375389099121 , validation accuracy:  12.549100234815446 %, lr:  2.171269517600167e-06\n",
+      "wandb: Agent Finished Run: txex35gz \n",
+      "\n",
+      "wandb: Agent Starting Run: pjgen773 with config:\n",
+      "\tepochs: 157\n",
+      "\thidden_dim: 17\n",
+      "\tlr: 0.001166754679869392\n",
+      "\tn_graph_iters: 3\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 365\n",
+      "\tweight_decay: 3.582884498686503e-05\n",
+      "wandb: Agent Started Run: pjgen773\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/pjgen773\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/pjgen773</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 157, 'hidden_dim': 17, 'lr': 0.001166754679869392, 'n_graph_iters': 3, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 365, 'weight_decay': 3.582884498686503e-05}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 17, 'n_graph_iters': 3, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.8794410705566407 , validation accuracy:  11.07888861235252 %, lr:  0.001166754679869392\n",
+      "Epoch:  2 , validation loss:  1.8830406188964843 , validation accuracy:  10.013381955641162 %, lr:  0.001166754679869392\n",
+      "Epoch:  3 , validation loss:  1.885198211669922 , validation accuracy:  9.734921854428851 %, lr:  0.001166754679869392\n",
+      "Epoch:  4 , validation loss:  1.8883790969848633 , validation accuracy:  9.53004447426228 %, lr:  0.001166754679869392\n",
+      "Epoch:  5 , validation loss:  1.8760457992553712 , validation accuracy:  10.700875417960678 %, lr:  0.001166754679869392\n",
+      "Epoch:  6 , validation loss:  1.8749399185180664 , validation accuracy:  10.8628295441839 %, lr:  0.001166754679869392\n",
+      "Epoch:  7 , validation loss:  1.8749055862426758 , validation accuracy:  10.690415129184567 %, lr:  0.001166754679869392\n",
+      "Epoch:  8 , validation loss:  1.8751474380493165 , validation accuracy:  11.20477277727881 %, lr:  0.001166754679869392\n",
+      "Epoch:  9 , validation loss:  1.8737136840820312 , validation accuracy:  10.915130988064451 %, lr:  0.001166754679869392\n",
+      "Epoch:  10 , validation loss:  1.8743400573730469 , validation accuracy:  11.360234310468584 %, lr:  0.001166754679869392\n",
+      "Epoch:  11 , validation loss:  1.8722763061523438 , validation accuracy:  10.725763691255558 %, lr:  0.001166754679869392\n",
+      "Epoch:  12 , validation loss:  1.8897653579711915 , validation accuracy:  9.476300231929851 %, lr:  0.001166754679869392\n",
+      "Epoch:  13 , validation loss:  1.868301010131836 , validation accuracy:  10.508622524248032 %, lr:  0.001166754679869392\n",
+      "Epoch:  14 , validation loss:  1.8319957733154297 , validation accuracy:  14.91889669202385 %, lr:  0.001166754679869392\n",
+      "Epoch:  15 , validation loss:  1.8397998809814453 , validation accuracy:  12.140427573321213 %, lr:  0.001166754679869392\n",
+      "Epoch:  16 , validation loss:  2.3843544006347654 , validation accuracy:  13.07968936549331 %, lr:  0.001166754679869392\n",
+      "Epoch:  17 , validation loss:  1.8890148162841798 , validation accuracy:  10.576073351873294 %, lr:  0.001166754679869392\n",
+      "Epoch:  18 , validation loss:  1.8863887786865234 , validation accuracy:  10.915491687677418 %, lr:  0.001166754679869392\n",
+      "Epoch:  19 , validation loss:  1.8845123291015624 , validation accuracy:  10.936051565616669 %, lr:  0.001166754679869392\n",
+      "Epoch:  20 , validation loss:  1.8829648971557618 , validation accuracy:  10.649656072919033 %, lr:  0.001166754679869392\n",
+      "Epoch:  21 , validation loss:  1.8805782318115234 , validation accuracy:  10.473995361402977 %, lr:  0.001166754679869392\n",
+      "Epoch:  22 , validation loss:  1.8647689819335938 , validation accuracy:  10.794296617719729 %, lr:  0.001166754679869392\n",
+      "Epoch:  23 , validation loss:  1.930759811401367 , validation accuracy:  14.36558348572892 %, lr:  0.001166754679869392\n",
+      "Epoch:  24 , validation loss:  1.8893049240112305 , validation accuracy:  10.642442080659647 %, lr:  0.001166754679869392\n",
+      "Epoch:  25 , validation loss:  1.8889991760253906 , validation accuracy:  10.66805175318047 %, lr:  0.001166754679869392\n",
+      "Epoch:  26 , validation loss:  1.888579750061035 , validation accuracy:  10.735141881192762 %, lr:  0.001166754679869392\n",
+      "Epoch:  27 , validation loss:  1.8894996643066406 , validation accuracy:  10.488784045534718 %, lr:  0.001166754679869392\n",
+      "Epoch:  28 , validation loss:  1.8888017654418945 , validation accuracy:  10.597715328651452 %, lr:  0.001166754679869392\n",
+      "Epoch:  29 , validation loss:  1.8904382705688476 , validation accuracy:  10.281742467690332 %, lr:  0.001166754679869392\n",
+      "Epoch:  30 , validation loss:  1.887472915649414 , validation accuracy:  10.710975007123817 %, lr:  0.001166754679869392\n",
+      "Epoch:  31 , validation loss:  1.8880855560302734 , validation accuracy:  10.332601113119006 %, lr:  0.001166754679869392\n",
+      "Epoch:  32 , validation loss:  1.8847158432006836 , validation accuracy:  10.721435295899928 %, lr:  0.001166754679869392\n",
+      "Epoch:  33 , validation loss:  1.8817474365234375 , validation accuracy:  10.686447433441904 %, lr:  0.001166754679869392\n",
+      "Epoch:  34 , validation loss:  1.869094467163086 , validation accuracy:  10.909359794256941 %, lr:  0.001166754679869392\n",
+      "Epoch:  35 , validation loss:  1.5720709800720214 , validation accuracy:  15.577534185305819 %, lr:  0.001166754679869392\n",
+      "Epoch:  36 , validation loss:  1.2997472763061524 , validation accuracy:  21.056561306309717 %, lr:  0.001166754679869392\n",
+      "Epoch:  37 , validation loss:  1.5900188446044923 , validation accuracy:  19.389046995552576 %, lr:  0.001166754679869392\n",
+      "Epoch:  38 , validation loss:  1.5435911178588868 , validation accuracy:  15.219720169240258 %, lr:  0.001166754679869392\n",
+      "Epoch:  39 , validation loss:  1.4026803016662597 , validation accuracy:  20.232362690674833 %, lr:  0.001166754679869392\n",
+      "Epoch:  40 , validation loss:  1.268997573852539 , validation accuracy:  20.994881672491967 %, lr:  0.001166754679869392\n",
+      "Epoch:  41 , validation loss:  1.1036632537841797 , validation accuracy:  21.948932148795805 %, lr:  0.001166754679869392\n",
+      "Epoch:  42 , validation loss:  1.1882102012634277 , validation accuracy:  20.7863972961957 %, lr:  0.001166754679869392\n",
+      "Epoch:  43 , validation loss:  1.1513134002685548 , validation accuracy:  23.37982751344508 %, lr:  0.001166754679869392\n",
+      "Epoch:  44 , validation loss:  1.573976707458496 , validation accuracy:  16.73574064255029 %, lr:  0.001166754679869392\n",
+      "Epoch:  45 , validation loss:  1.2360441207885742 , validation accuracy:  19.48607519144132 %, lr:  0.001166754679869392\n",
+      "Epoch:  46 , validation loss:  1.249138641357422 , validation accuracy:  17.175794170372853 %, lr:  0.001166754679869392\n",
+      "Epoch:  47 , validation loss:  1.1136408805847169 , validation accuracy:  22.50404885315558 %, lr:  0.001166754679869392\n",
+      "Epoch:  48 , validation loss:  1.0428122520446776 , validation accuracy:  23.576769502126325 %, lr:  0.001166754679869392\n",
+      "Epoch:  49 , validation loss:  1.1198001861572267 , validation accuracy:  22.692334051125563 %, lr:  0.001166754679869392\n",
+      "Epoch:  50 , validation loss:  1.4801968574523925 , validation accuracy:  22.596748653688696 %, lr:  0.001166754679869392\n",
+      "Epoch:  51 , validation loss:  1.7135295867919922 , validation accuracy:  20.33299788269327 %, lr:  0.001166754679869392\n",
+      "Epoch:  52 , validation loss:  1.4383548736572265 , validation accuracy:  20.314962902044805 %, lr:  0.001166754679869392\n",
+      "Epoch:  53 , validation loss:  1.183948802947998 , validation accuracy:  22.997485923697603 %, lr:  0.001166754679869392\n",
+      "Epoch:  54 , validation loss:  1.0849857330322266 , validation accuracy:  22.231720645363747 %, lr:  0.001166754679869392\n",
+      "Epoch:  55 , validation loss:  1.2415063858032227 , validation accuracy:  24.419003098409675 %, lr:  0.001166754679869392\n",
+      "Epoch:  56 , validation loss:  1.0399466514587403 , validation accuracy:  26.486533279949793 %, lr:  0.001166754679869392\n",
+      "Epoch:  57 , validation loss:  1.0533711433410644 , validation accuracy:  24.21160082095232 %, lr:  0.001166754679869392\n",
+      "Epoch:  58 , validation loss:  1.1398504257202149 , validation accuracy:  24.951756426765353 %, lr:  0.001166754679869392\n",
+      "Epoch:  59 , validation loss:  1.198128890991211 , validation accuracy:  23.15222605766144 %, lr:  0.001166754679869392\n",
+      "Epoch:  60 , validation loss:  1.1332330703735352 , validation accuracy:  19.25919513488362 %, lr:  0.001166754679869392\n",
+      "Epoch:  61 , validation loss:  1.042642879486084 , validation accuracy:  22.05173153849206 %, lr:  0.001166754679869392\n",
+      "Epoch:  62 , validation loss:  1.1737432479858398 , validation accuracy:  22.755456483395193 %, lr:  0.001166754679869392\n",
+      "Epoch:  63 , validation loss:  0.9737550735473632 , validation accuracy:  23.66333740923896 %, lr:  0.001166754679869392\n",
+      "Epoch:  64 , validation loss:  1.2218246459960938 , validation accuracy:  25.493527245445264 %, lr:  0.001166754679869392\n",
+      "Epoch:  65 , validation loss:  1.200306224822998 , validation accuracy:  25.7564772632999 %, lr:  0.001166754679869392\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  66 , validation loss:  1.380025291442871 , validation accuracy:  12.0794693387294 %, lr:  0.001166754679869392\n",
+      "Epoch:  67 , validation loss:  1.3084972381591797 , validation accuracy:  24.209436623274502 %, lr:  0.001166754679869392\n",
+      "Epoch:  68 , validation loss:  1.136939239501953 , validation accuracy:  24.62640537586703 %, lr:  0.001166754679869392\n",
+      "Epoch:  69 , validation loss:  1.1580348014831543 , validation accuracy:  23.27883162181367 %, lr:  0.001166754679869392\n",
+      "Epoch:  70 , validation loss:  1.349592399597168 , validation accuracy:  20.41920509019294 %, lr:  0.001166754679869392\n",
+      "Epoch:  71 , validation loss:  1.581709384918213 , validation accuracy:  19.662818001796285 %, lr:  0.001166754679869392\n",
+      "Epoch:  72 , validation loss:  1.21463623046875 , validation accuracy:  23.463509823653958 %, lr:  0.001166754679869392\n",
+      "Epoch:  73 , validation loss:  1.6271135330200195 , validation accuracy:  22.11016487579309 %, lr:  0.001166754679869392\n",
+      "Epoch:  74 , validation loss:  1.0561957359313965 , validation accuracy:  28.053773098301466 %, lr:  0.001166754679869392\n",
+      "Epoch:  75 , validation loss:  1.1585793495178223 , validation accuracy:  21.12329073470904 %, lr:  0.001166754679869392\n",
+      "Epoch:  76 , validation loss:  0.9940083503723145 , validation accuracy:  25.661613265088967 %, lr:  0.001166754679869392\n",
+      "Epoch:  77 , validation loss:  1.465658950805664 , validation accuracy:  23.76252980280552 %, lr:  0.001166754679869392\n",
+      "Epoch:  78 , validation loss:  1.1490548133850098 , validation accuracy:  13.811909579821021 %, lr:  0.001166754679869392\n",
+      "Epoch:  79 , validation loss:  1.1334520339965821 , validation accuracy:  22.3839358820368 %, lr:  0.001166754679869392\n",
+      "Epoch:  80 , validation loss:  2.231058692932129 , validation accuracy:  20.24498717712876 %, lr:  0.001166754679869392\n",
+      "Epoch:  81 , validation loss:  0.9076107025146485 , validation accuracy:  27.847813619295987 %, lr:  0.001166754679869392\n",
+      "Epoch:  82 , validation loss:  1.0692813873291016 , validation accuracy:  17.054238400802195 %, lr:  0.001166754679869392\n",
+      "Epoch:  83 , validation loss:  1.3333798408508302 , validation accuracy:  22.375279091325535 %, lr:  0.001166754679869392\n",
+      "Epoch:  84 , validation loss:  1.5192298889160156 , validation accuracy:  22.294482378020408 %, lr:  0.001166754679869392\n",
+      "Epoch:  85 , validation loss:  1.3978574752807618 , validation accuracy:  23.48370900198024 %, lr:  0.001166754679869392\n",
+      "Epoch:  86 , validation loss:  1.1527766227722167 , validation accuracy:  22.387542878166492 %, lr:  0.001166754679869392\n",
+      "Epoch:  87 , validation loss:  1.2625709533691407 , validation accuracy:  20.637789055652345 %, lr:  0.001166754679869392\n",
+      "Epoch:  88 , validation loss:  1.0098834037780762 , validation accuracy:  25.31245603973467 %, lr:  0.001166754679869392\n",
+      "Epoch:  89 , validation loss:  1.2164962768554688 , validation accuracy:  16.540241452320924 %, lr:  0.001166754679869392\n",
+      "Epoch:  90 , validation loss:  1.2189621925354004 , validation accuracy:  23.276306724522886 %, lr:  0.001166754679869392\n",
+      "Epoch:  91 , validation loss:  1.3480238914489746 , validation accuracy:  23.488037397335873 %, lr:  0.001166754679869392\n",
+      "Epoch:  92 , validation loss:  1.2280844688415526 , validation accuracy:  23.938190514321576 %, lr:  0.001166754679869392\n",
+      "Epoch:  93 , validation loss:  1.4816596984863282 , validation accuracy:  22.242541633752825 %, lr:  0.001166754679869392\n",
+      "Epoch:  94 , validation loss:  1.0602256774902343 , validation accuracy:  20.33335858230624 %, lr:  0.001166754679869392\n",
+      "Epoch:  95 , validation loss:  1.2432995796203614 , validation accuracy:  23.98904915975025 %, lr:  0.001166754679869392\n",
+      "Epoch:  96 , validation loss:  1.3603510856628418 , validation accuracy:  15.674562381194566 %, lr:  0.001166754679869392\n",
+      "Epoch:  97 , validation loss:  1.794692611694336 , validation accuracy:  23.839358820367988 %, lr:  0.001166754679869392\n",
+      "Epoch:  98 , validation loss:  1.0328154563903809 , validation accuracy:  26.105995188267162 %, lr:  0.001166754679869392\n",
+      "Epoch:  99 , validation loss:  1.2894248962402344 , validation accuracy:  14.49218904988115 %, lr:  0.001166754679869392\n",
+      "Epoch:  100 , validation loss:  1.1716888427734375 , validation accuracy:  13.122973319049628 %, lr:  0.001166754679869392\n",
+      "Epoch:  101 , validation loss:  1.0450764656066895 , validation accuracy:  23.65251642084988 %, lr:  0.001166754679869392\n",
+      "Epoch:  102 , validation loss:  1.2992178916931152 , validation accuracy:  24.149199787908625 %, lr:  0.000291688669967348\n",
+      "Epoch:  103 , validation loss:  0.8997855186462402 , validation accuracy:  29.781524244424485 %, lr:  0.000291688669967348\n",
+      "Epoch:  104 , validation loss:  0.8542816162109375 , validation accuracy:  30.56965289876244 %, lr:  0.000291688669967348\n",
+      "Epoch:  105 , validation loss:  0.8903159141540528 , validation accuracy:  29.0572394215821 %, lr:  0.000291688669967348\n",
+      "Epoch:  106 , validation loss:  1.6363748550415038 , validation accuracy:  24.84967843629504 %, lr:  0.000291688669967348\n",
+      "Epoch:  107 , validation loss:  0.8036284446716309 , validation accuracy:  30.73954241647099 %, lr:  0.000291688669967348\n",
+      "Epoch:  108 , validation loss:  0.8329010009765625 , validation accuracy:  30.522040549850487 %, lr:  0.000291688669967348\n",
+      "Epoch:  109 , validation loss:  0.8416542053222656 , validation accuracy:  31.064532767756344 %, lr:  0.000291688669967348\n",
+      "Epoch:  110 , validation loss:  1.221745491027832 , validation accuracy:  28.128798617799085 %, lr:  0.000291688669967348\n",
+      "Epoch:  111 , validation loss:  0.8572187423706055 , validation accuracy:  30.793286658803414 %, lr:  0.000291688669967348\n",
+      "Epoch:  112 , validation loss:  0.9431818008422852 , validation accuracy:  30.836931311972705 %, lr:  0.000291688669967348\n",
+      "Epoch:  113 , validation loss:  0.8779728889465332 , validation accuracy:  29.772506754100252 %, lr:  0.000291688669967348\n",
+      "Epoch:  114 , validation loss:  1.0826800346374512 , validation accuracy:  27.344998358816763 %, lr:  0.000291688669967348\n",
+      "Epoch:  115 , validation loss:  0.8022812843322754 , validation accuracy:  33.068579817413855 %, lr:  0.000291688669967348\n",
+      "Epoch:  116 , validation loss:  1.2317794799804687 , validation accuracy:  21.53412759388109 %, lr:  0.000291688669967348\n",
+      "Epoch:  117 , validation loss:  0.8375868797302246 , validation accuracy:  32.81753288678721 %, lr:  0.000291688669967348\n",
+      "Epoch:  118 , validation loss:  1.9711797714233399 , validation accuracy:  21.064135998182074 %, lr:  0.000291688669967348\n",
+      "Epoch:  119 , validation loss:  0.9030830383300781 , validation accuracy:  30.835127813907853 %, lr:  0.000291688669967348\n",
+      "Epoch:  120 , validation loss:  0.8192254066467285 , validation accuracy:  31.802524175891563 %, lr:  0.000291688669967348\n",
+      "Epoch:  121 , validation loss:  0.9917502403259277 , validation accuracy:  29.318025241758917 %, lr:  0.000291688669967348\n",
+      "Epoch:  122 , validation loss:  0.9201807022094727 , validation accuracy:  32.88786931131623 %, lr:  0.000291688669967348\n",
+      "Epoch:  123 , validation loss:  0.8803923606872559 , validation accuracy:  32.68299193114966 %, lr:  0.000291688669967348\n",
+      "Epoch:  124 , validation loss:  0.8053635597229004 , validation accuracy:  32.74431086535444 %, lr:  0.000291688669967348\n",
+      "Epoch:  125 , validation loss:  0.8129973411560059 , validation accuracy:  31.67519721251339 %, lr:  0.000291688669967348\n",
+      "Epoch:  126 , validation loss:  1.4542930603027344 , validation accuracy:  27.733832541597682 %, lr:  0.000291688669967348\n",
+      "Epoch:  127 , validation loss:  0.8048851013183593 , validation accuracy:  32.77100263671417 %, lr:  0.000291688669967348\n",
+      "Epoch:  128 , validation loss:  0.9672592163085938 , validation accuracy:  30.783547769253243 %, lr:  0.000291688669967348\n",
+      "Epoch:  129 , validation loss:  1.112614917755127 , validation accuracy:  30.961733378060085 %, lr:  0.000291688669967348\n",
+      "Epoch:  130 , validation loss:  1.0413976669311524 , validation accuracy:  26.07461432193883 %, lr:  0.000291688669967348\n",
+      "Epoch:  131 , validation loss:  1.3952496528625489 , validation accuracy:  27.02469710250001 %, lr:  0.000291688669967348\n",
+      "Epoch:  132 , validation loss:  1.369748592376709 , validation accuracy:  24.83633255061517 %, lr:  0.000291688669967348\n",
+      "Epoch:  133 , validation loss:  0.8187275886535644 , validation accuracy:  30.959569180382267 %, lr:  0.000291688669967348\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  134 , validation loss:  0.9458410263061523 , validation accuracy:  23.383795209187742 %, lr:  0.000291688669967348\n",
+      "Epoch:  135 , validation loss:  0.8861897468566895 , validation accuracy:  28.575344738655094 %, lr:  0.000291688669967348\n",
+      "Epoch:  136 , validation loss:  0.9067770957946777 , validation accuracy:  32.399121335742805 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  137 , validation loss:  0.7916918754577636 , validation accuracy:  33.64425639971289 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  138 , validation loss:  0.7788257598876953 , validation accuracy:  33.91622390789175 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  139 , validation loss:  0.7676527500152588 , validation accuracy:  34.424088962952546 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  140 , validation loss:  0.7918067932128906 , validation accuracy:  34.22173648007676 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  141 , validation loss:  0.808712387084961 , validation accuracy:  33.72902080876067 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  142 , validation loss:  0.7838750839233398 , validation accuracy:  33.60097244615656 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  143 , validation loss:  0.7906850337982178 , validation accuracy:  33.57500207402278 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  144 , validation loss:  0.7942712306976318 , validation accuracy:  34.16077824548494 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  145 , validation loss:  0.814669418334961 , validation accuracy:  33.6922294482378 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  146 , validation loss:  0.7898048877716064 , validation accuracy:  33.83542719458662 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  147 , validation loss:  0.828010368347168 , validation accuracy:  33.26948950183776 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  148 , validation loss:  0.7990206241607666 , validation accuracy:  33.79286464025624 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  149 , validation loss:  0.7737254619598388 , validation accuracy:  34.01613770068425 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  150 , validation loss:  0.8741440773010254 , validation accuracy:  33.33802242830193 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  151 , validation loss:  0.7726516723632812 , validation accuracy:  34.14238256522351 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  152 , validation loss:  0.7940683841705323 , validation accuracy:  33.81053892129174 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  153 , validation loss:  0.7685935020446777 , validation accuracy:  34.18133812342419 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  154 , validation loss:  0.7822577476501464 , validation accuracy:  34.20117660213751 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  155 , validation loss:  0.8065115928649902 , validation accuracy:  32.498674428922335 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  156 , validation loss:  0.7645637512207031 , validation accuracy:  34.51642806387269 %, lr:  7.2922167491837e-05\n",
+      "Epoch:  157 , validation loss:  0.8005198478698731 , validation accuracy:  33.94832617344601 %, lr:  7.2922167491837e-05\n",
+      "wandb: Agent Finished Run: pjgen773 \n",
+      "\n",
+      "wandb: Agent Starting Run: r0u1b0z1 with config:\n",
+      "\tepochs: 180\n",
+      "\thidden_dim: 19\n",
+      "\tlr: 0.0008020155923685281\n",
+      "\tn_graph_iters: 2\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 363\n",
+      "\tweight_decay: 0.00015770158871663577\n",
+      "wandb: Agent Started Run: r0u1b0z1\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/r0u1b0z1\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/r0u1b0z1</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 180, 'hidden_dim': 19, 'lr': 0.0008020155923685281, 'n_graph_iters': 2, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 363, 'weight_decay': 0.00015770158871663577}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 19, 'n_graph_iters': 2, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.8813880920410155 , validation accuracy:  10.781311431652833 %, lr:  0.0008020155923685281\n",
+      "Epoch:  2 , validation loss:  1.879414939880371 , validation accuracy:  10.966350333106092 %, lr:  0.0008020155923685281\n",
+      "Epoch:  3 , validation loss:  1.8776962280273437 , validation accuracy:  10.761833652552491 %, lr:  0.0008020155923685281\n",
+      "Epoch:  4 , validation loss:  1.875347900390625 , validation accuracy:  11.569800785603757 %, lr:  0.0008020155923685281\n",
+      "Epoch:  5 , validation loss:  1.8758623123168945 , validation accuracy:  11.42047114583446 %, lr:  0.0008020155923685281\n",
+      "Epoch:  6 , validation loss:  1.8746952056884765 , validation accuracy:  12.826478237188851 %, lr:  0.0008020155923685281\n",
+      "Epoch:  7 , validation loss:  1.8728702545166016 , validation accuracy:  12.286150216960817 %, lr:  0.0008020155923685281\n",
+      "Epoch:  8 , validation loss:  1.8725797653198242 , validation accuracy:  11.938075090445428 %, lr:  0.0008020155923685281\n",
+      "Epoch:  9 , validation loss:  1.871828269958496 , validation accuracy:  12.741713828141062 %, lr:  0.0008020155923685281\n",
+      "Epoch:  10 , validation loss:  1.8723827362060548 , validation accuracy:  11.902005129148495 %, lr:  0.0008020155923685281\n",
+      "Epoch:  11 , validation loss:  1.8702669143676758 , validation accuracy:  13.186095751319261 %, lr:  0.0008020155923685281\n",
+      "Epoch:  12 , validation loss:  1.8686391830444335 , validation accuracy:  12.66416341135266 %, lr:  0.0008020155923685281\n",
+      "Epoch:  13 , validation loss:  1.8661577224731445 , validation accuracy:  12.768405599500793 %, lr:  0.0008020155923685281\n",
+      "Epoch:  14 , validation loss:  1.890913200378418 , validation accuracy:  9.558900443299825 %, lr:  0.0008020155923685281\n",
+      "Epoch:  15 , validation loss:  1.872749137878418 , validation accuracy:  12.197778811783335 %, lr:  0.0008020155923685281\n",
+      "Epoch:  16 , validation loss:  1.6975906372070313 , validation accuracy:  15.62442513499183 %, lr:  0.0008020155923685281\n",
+      "Epoch:  17 , validation loss:  1.6338253021240234 , validation accuracy:  14.844231872139202 %, lr:  0.0008020155923685281\n",
+      "Epoch:  18 , validation loss:  1.5562023162841796 , validation accuracy:  17.51557320578995 %, lr:  0.0008020155923685281\n",
+      "Epoch:  19 , validation loss:  1.8931898117065429 , validation accuracy:  11.611641940708198 %, lr:  0.0008020155923685281\n",
+      "Epoch:  20 , validation loss:  1.868027687072754 , validation accuracy:  10.79790361384942 %, lr:  0.0008020155923685281\n",
+      "Epoch:  21 , validation loss:  1.8417713165283203 , validation accuracy:  10.642442080659647 %, lr:  0.0008020155923685281\n",
+      "Epoch:  22 , validation loss:  1.717660140991211 , validation accuracy:  15.71892843358979 %, lr:  0.0008020155923685281\n",
+      "Epoch:  23 , validation loss:  1.5213638305664063 , validation accuracy:  21.744415468242202 %, lr:  0.0008020155923685281\n",
+      "Epoch:  24 , validation loss:  1.778910255432129 , validation accuracy:  11.113876474810542 %, lr:  0.0008020155923685281\n",
+      "Epoch:  25 , validation loss:  1.8064430236816407 , validation accuracy:  16.852607317152348 %, lr:  0.0008020155923685281\n",
+      "Epoch:  26 , validation loss:  1.3043251037597656 , validation accuracy:  19.788341467109603 %, lr:  0.0008020155923685281\n",
+      "Epoch:  27 , validation loss:  1.3337764739990234 , validation accuracy:  17.612240702065726 %, lr:  0.0008020155923685281\n",
+      "Epoch:  28 , validation loss:  1.2736388206481934 , validation accuracy:  18.850161773776417 %, lr:  0.0008020155923685281\n",
+      "Epoch:  29 , validation loss:  1.291592502593994 , validation accuracy:  19.84352850789391 %, lr:  0.0008020155923685281\n",
+      "Epoch:  30 , validation loss:  1.234402847290039 , validation accuracy:  17.221963720832928 %, lr:  0.0008020155923685281\n",
+      "Epoch:  31 , validation loss:  1.3444416046142578 , validation accuracy:  18.88514963623444 %, lr:  0.0008020155923685281\n",
+      "Epoch:  32 , validation loss:  1.3410743713378905 , validation accuracy:  17.427562500225438 %, lr:  0.0008020155923685281\n",
+      "Epoch:  33 , validation loss:  1.1770970344543457 , validation accuracy:  20.526332875244822 %, lr:  0.0008020155923685281\n",
+      "Epoch:  34 , validation loss:  1.4160242080688477 , validation accuracy:  16.192527025418503 %, lr:  0.0008020155923685281\n",
+      "Epoch:  35 , validation loss:  1.461897087097168 , validation accuracy:  14.40742464083336 %, lr:  0.0008020155923685281\n",
+      "Epoch:  36 , validation loss:  1.513101291656494 , validation accuracy:  15.770147778631433 %, lr:  0.0008020155923685281\n",
+      "Epoch:  37 , validation loss:  1.3058067321777345 , validation accuracy:  18.81697740938324 %, lr:  0.0008020155923685281\n",
+      "Epoch:  38 , validation loss:  1.1402990341186523 , validation accuracy:  18.54753479849516 %, lr:  0.0008020155923685281\n",
+      "Epoch:  39 , validation loss:  1.0552688598632813 , validation accuracy:  20.658348933591594 %, lr:  0.0008020155923685281\n",
+      "Epoch:  40 , validation loss:  1.3593310356140136 , validation accuracy:  18.744476787176406 %, lr:  0.0008020155923685281\n",
+      "Epoch:  41 , validation loss:  1.2303820610046388 , validation accuracy:  21.579575745115225 %, lr:  0.0008020155923685281\n",
+      "Epoch:  42 , validation loss:  1.4101480484008788 , validation accuracy:  17.9357882548992 %, lr:  0.0008020155923685281\n",
+      "Epoch:  43 , validation loss:  1.3602951049804688 , validation accuracy:  19.07451693304333 %, lr:  0.0008020155923685281\n",
+      "Epoch:  44 , validation loss:  1.3639586448669434 , validation accuracy:  12.88527227410285 %, lr:  0.0008020155923685281\n",
+      "Epoch:  45 , validation loss:  1.7440269470214844 , validation accuracy:  16.22066159523011 %, lr:  0.0008020155923685281\n",
+      "Epoch:  46 , validation loss:  1.5929553031921386 , validation accuracy:  17.79511540584117 %, lr:  0.0008020155923685281\n",
+      "Epoch:  47 , validation loss:  1.1050966262817383 , validation accuracy:  21.09732036257525 %, lr:  0.0008020155923685281\n",
+      "Epoch:  48 , validation loss:  1.3854284286499023 , validation accuracy:  16.53194536122263 %, lr:  0.0008020155923685281\n",
+      "Epoch:  49 , validation loss:  0.9920208930969239 , validation accuracy:  22.66852787666959 %, lr:  0.0008020155923685281\n",
+      "Epoch:  50 , validation loss:  1.0532361030578614 , validation accuracy:  22.56789268465115 %, lr:  0.0008020155923685281\n",
+      "Epoch:  51 , validation loss:  1.0249624252319336 , validation accuracy:  23.208855896897624 %, lr:  0.0008020155923685281\n",
+      "Epoch:  52 , validation loss:  1.3387636184692382 , validation accuracy:  17.739928365056866 %, lr:  0.0008020155923685281\n",
+      "Epoch:  53 , validation loss:  1.172872257232666 , validation accuracy:  13.516496596799152 %, lr:  0.0008020155923685281\n",
+      "Epoch:  54 , validation loss:  1.8857461929321289 , validation accuracy:  19.99682584340587 %, lr:  0.0008020155923685281\n",
+      "Epoch:  55 , validation loss:  1.0712093353271483 , validation accuracy:  21.858757245553477 %, lr:  0.0008020155923685281\n",
+      "Epoch:  56 , validation loss:  1.2835704803466796 , validation accuracy:  20.101068031554 %, lr:  0.0008020155923685281\n",
+      "Epoch:  57 , validation loss:  1.0998748779296874 , validation accuracy:  21.66253665609817 %, lr:  0.0008020155923685281\n",
+      "Epoch:  58 , validation loss:  1.261256504058838 , validation accuracy:  13.14894369118342 %, lr:  0.0008020155923685281\n",
+      "Epoch:  59 , validation loss:  1.3864546775817872 , validation accuracy:  17.44631888009984 %, lr:  0.0008020155923685281\n",
+      "Epoch:  60 , validation loss:  1.2266440391540527 , validation accuracy:  16.776499698815822 %, lr:  0.0008020155923685281\n",
+      "Epoch:  61 , validation loss:  1.109868621826172 , validation accuracy:  22.66203528363614 %, lr:  0.0008020155923685281\n",
+      "Epoch:  62 , validation loss:  1.1967796325683593 , validation accuracy:  21.496614834132284 %, lr:  0.0008020155923685281\n",
+      "Epoch:  63 , validation loss:  1.0824108123779297 , validation accuracy:  22.304942666796517 %, lr:  0.0008020155923685281\n",
+      "Epoch:  64 , validation loss:  1.1852971076965333 , validation accuracy:  19.549558323323918 %, lr:  0.0008020155923685281\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  65 , validation loss:  1.1968267440795899 , validation accuracy:  22.238573938010163 %, lr:  0.0008020155923685281\n",
+      "Epoch:  66 , validation loss:  1.1850406646728515 , validation accuracy:  23.523385959406866 %, lr:  0.0008020155923685281\n",
+      "Epoch:  67 , validation loss:  1.2862966537475586 , validation accuracy:  23.97822817136117 %, lr:  0.0008020155923685281\n",
+      "Epoch:  68 , validation loss:  1.0739420890808105 , validation accuracy:  22.30566406602246 %, lr:  0.0008020155923685281\n",
+      "Epoch:  69 , validation loss:  2.408732223510742 , validation accuracy:  19.762731794588785 %, lr:  0.0008020155923685281\n",
+      "Epoch:  70 , validation loss:  1.028159236907959 , validation accuracy:  20.687204902629137 %, lr:  0.00020050389809213204\n",
+      "Epoch:  71 , validation loss:  0.9536089897155762 , validation accuracy:  25.12344944253875 %, lr:  0.00020050389809213204\n",
+      "Epoch:  72 , validation loss:  1.091306781768799 , validation accuracy:  23.934944217804855 %, lr:  0.00020050389809213204\n",
+      "Epoch:  73 , validation loss:  1.2239054679870605 , validation accuracy:  23.340511255631423 %, lr:  0.00020050389809213204\n",
+      "Epoch:  74 , validation loss:  0.9314729690551757 , validation accuracy:  26.265063717586628 %, lr:  0.00020050389809213204\n",
+      "Epoch:  75 , validation loss:  0.9466351509094239 , validation accuracy:  25.112989153762637 %, lr:  0.00020050389809213204\n",
+      "Epoch:  76 , validation loss:  0.9251284599304199 , validation accuracy:  26.42377154729313 %, lr:  0.00020050389809213204\n",
+      "Epoch:  77 , validation loss:  0.9340061187744141 , validation accuracy:  24.791605798606977 %, lr:  0.00020050389809213204\n",
+      "Epoch:  78 , validation loss:  0.8739388465881348 , validation accuracy:  26.653176501141612 %, lr:  0.00020050389809213204\n",
+      "Epoch:  79 , validation loss:  0.9260313987731934 , validation accuracy:  26.281655899783217 %, lr:  0.00020050389809213204\n",
+      "Epoch:  80 , validation loss:  0.942111873626709 , validation accuracy:  25.436897406209084 %, lr:  0.00020050389809213204\n",
+      "Epoch:  81 , validation loss:  1.061767578125 , validation accuracy:  23.29037400942869 %, lr:  0.00020050389809213204\n",
+      "Epoch:  82 , validation loss:  0.9220597267150878 , validation accuracy:  26.62432053210407 %, lr:  0.00020050389809213204\n",
+      "Epoch:  83 , validation loss:  1.2154945373535155 , validation accuracy:  24.77068522105476 %, lr:  0.00020050389809213204\n",
+      "Epoch:  84 , validation loss:  1.0125413894653321 , validation accuracy:  24.83669325022814 %, lr:  0.00020050389809213204\n",
+      "Epoch:  85 , validation loss:  0.9111343383789062 , validation accuracy:  26.879335158473378 %, lr:  0.00020050389809213204\n",
+      "Epoch:  86 , validation loss:  1.216498851776123 , validation accuracy:  24.38473663517759 %, lr:  0.00020050389809213204\n",
+      "Epoch:  87 , validation loss:  0.8894895553588867 , validation accuracy:  26.064154033162723 %, lr:  0.00020050389809213204\n",
+      "Epoch:  88 , validation loss:  1.1024544715881348 , validation accuracy:  25.25294060359473 %, lr:  0.00020050389809213204\n",
+      "Epoch:  89 , validation loss:  0.9919034004211426 , validation accuracy:  25.204246155843872 %, lr:  0.00020050389809213204\n",
+      "Epoch:  90 , validation loss:  0.8849070549011231 , validation accuracy:  27.19278312214371 %, lr:  0.00020050389809213204\n",
+      "Epoch:  91 , validation loss:  1.250246810913086 , validation accuracy:  23.616807159165916 %, lr:  0.00020050389809213204\n",
+      "Epoch:  92 , validation loss:  0.8652881622314453 , validation accuracy:  26.767878978065855 %, lr:  0.00020050389809213204\n",
+      "Epoch:  93 , validation loss:  1.3846283912658692 , validation accuracy:  23.18360692398977 %, lr:  0.00020050389809213204\n",
+      "Epoch:  94 , validation loss:  0.9762701034545899 , validation accuracy:  26.115734077817333 %, lr:  0.00020050389809213204\n",
+      "Epoch:  95 , validation loss:  1.0722857475280763 , validation accuracy:  23.148258361918778 %, lr:  0.00020050389809213204\n",
+      "Epoch:  96 , validation loss:  1.0479215621948241 , validation accuracy:  26.607006950681544 %, lr:  0.00020050389809213204\n",
+      "Epoch:  97 , validation loss:  0.8785940170288086 , validation accuracy:  27.279711728869316 %, lr:  0.00020050389809213204\n",
+      "Epoch:  98 , validation loss:  1.109819507598877 , validation accuracy:  25.125613640216564 %, lr:  0.00020050389809213204\n",
+      "Epoch:  99 , validation loss:  0.9219995498657226 , validation accuracy:  25.64538178250535 %, lr:  0.00020050389809213204\n",
+      "Epoch:  100 , validation loss:  1.0222323417663575 , validation accuracy:  25.33554081496471 %, lr:  0.00020050389809213204\n",
+      "Epoch:  101 , validation loss:  0.8971223831176758 , validation accuracy:  26.882581454990103 %, lr:  0.00020050389809213204\n",
+      "Epoch:  102 , validation loss:  0.9589913368225098 , validation accuracy:  25.500380538091683 %, lr:  0.00020050389809213204\n",
+      "Epoch:  103 , validation loss:  1.081144428253174 , validation accuracy:  25.702011621741526 %, lr:  0.00020050389809213204\n",
+      "Epoch:  104 , validation loss:  0.870908260345459 , validation accuracy:  28.10066404798748 %, lr:  0.00020050389809213204\n",
+      "Epoch:  105 , validation loss:  0.9331453323364258 , validation accuracy:  26.12799786465829 %, lr:  0.00020050389809213204\n",
+      "Epoch:  106 , validation loss:  1.0480691909790039 , validation accuracy:  23.233022770966567 %, lr:  0.00020050389809213204\n",
+      "Epoch:  107 , validation loss:  0.8680705070495606 , validation accuracy:  27.01459751333687 %, lr:  0.00020050389809213204\n",
+      "Epoch:  108 , validation loss:  0.8766464233398438 , validation accuracy:  27.35581934720584 %, lr:  0.00020050389809213204\n",
+      "Epoch:  109 , validation loss:  0.8976217269897461 , validation accuracy:  28.095974953018874 %, lr:  0.00020050389809213204\n",
+      "Epoch:  110 , validation loss:  0.8540549278259277 , validation accuracy:  28.021670832747198 %, lr:  0.00020050389809213204\n",
+      "Epoch:  111 , validation loss:  0.9294508934020996 , validation accuracy:  27.21947489350344 %, lr:  0.00020050389809213204\n",
+      "Epoch:  112 , validation loss:  0.8586661338806152 , validation accuracy:  28.19011755200387 %, lr:  0.00020050389809213204\n",
+      "Epoch:  113 , validation loss:  0.8747140884399414 , validation accuracy:  26.89376314299215 %, lr:  0.00020050389809213204\n",
+      "Epoch:  114 , validation loss:  1.020540142059326 , validation accuracy:  26.36822380689586 %, lr:  0.00020050389809213204\n",
+      "Epoch:  115 , validation loss:  0.8640363693237305 , validation accuracy:  28.33692229448238 %, lr:  0.00020050389809213204\n",
+      "Epoch:  116 , validation loss:  1.4627189636230469 , validation accuracy:  21.517535411684502 %, lr:  0.00020050389809213204\n",
+      "Epoch:  117 , validation loss:  0.9023487091064453 , validation accuracy:  26.900616435638565 %, lr:  0.00020050389809213204\n",
+      "Epoch:  118 , validation loss:  0.8628451347351074 , validation accuracy:  28.297966736281694 %, lr:  0.00020050389809213204\n",
+      "Epoch:  119 , validation loss:  0.9093761444091797 , validation accuracy:  26.943178989968942 %, lr:  0.00020050389809213204\n",
+      "Epoch:  120 , validation loss:  1.6675180435180663 , validation accuracy:  23.976424673296325 %, lr:  0.00020050389809213204\n",
+      "Epoch:  121 , validation loss:  0.9063900947570801 , validation accuracy:  26.172724616666486 %, lr:  0.00020050389809213204\n",
+      "Epoch:  122 , validation loss:  0.9777487754821778 , validation accuracy:  26.389505084061042 %, lr:  0.00020050389809213204\n",
+      "Epoch:  123 , validation loss:  1.16453218460083 , validation accuracy:  25.98119312217978 %, lr:  0.00020050389809213204\n",
+      "Epoch:  124 , validation loss:  1.057822036743164 , validation accuracy:  26.605924851842634 %, lr:  0.00020050389809213204\n",
+      "Epoch:  125 , validation loss:  0.9473642349243164 , validation accuracy:  26.48581188072385 %, lr:  0.00020050389809213204\n",
+      "Epoch:  126 , validation loss:  1.0643866539001465 , validation accuracy:  26.259653223392093 %, lr:  0.00020050389809213204\n",
+      "Epoch:  127 , validation loss:  0.8752276420593261 , validation accuracy:  27.767377605603826 %, lr:  0.00020050389809213204\n",
+      "Epoch:  128 , validation loss:  0.9787263870239258 , validation accuracy:  26.286344994751822 %, lr:  0.00020050389809213204\n",
+      "Epoch:  129 , validation loss:  0.8718699455261231 , validation accuracy:  27.84564942161817 %, lr:  0.00020050389809213204\n",
+      "Epoch:  130 , validation loss:  1.2192983627319336 , validation accuracy:  23.749905316351597 %, lr:  0.00020050389809213204\n",
+      "Epoch:  131 , validation loss:  0.8708565711975098 , validation accuracy:  27.88965477440043 %, lr:  5.012597452303301e-05\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  132 , validation loss:  0.8659470558166504 , validation accuracy:  28.278488957181345 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  133 , validation loss:  0.8327462196350097 , validation accuracy:  28.84623014799505 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  134 , validation loss:  0.8385174751281739 , validation accuracy:  28.661551946154763 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  135 , validation loss:  0.8581607818603516 , validation accuracy:  28.452706870245525 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  136 , validation loss:  0.8476727485656739 , validation accuracy:  28.4307041938544 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  137 , validation loss:  0.8656230926513672 , validation accuracy:  28.438639585339725 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  138 , validation loss:  0.8672338485717773 , validation accuracy:  28.042952109912385 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  139 , validation loss:  0.8496648788452148 , validation accuracy:  28.363614065842107 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  140 , validation loss:  0.8407341003417969 , validation accuracy:  28.624039186405952 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  141 , validation loss:  0.8398469924926758 , validation accuracy:  28.612496798790936 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  142 , validation loss:  0.8646501541137696 , validation accuracy:  28.28281735253698 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  143 , validation loss:  0.8314034461975097 , validation accuracy:  28.72611717687627 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  144 , validation loss:  0.8627188682556153 , validation accuracy:  28.189396152777928 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  145 , validation loss:  0.8477380752563477 , validation accuracy:  28.45018197295474 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  146 , validation loss:  0.8553605079650879 , validation accuracy:  28.040427212621598 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  147 , validation loss:  0.8854970932006836 , validation accuracy:  28.27307846298681 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  148 , validation loss:  0.846497917175293 , validation accuracy:  28.108599439472805 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  149 , validation loss:  0.8325001716613769 , validation accuracy:  28.876528915484474 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  150 , validation loss:  0.8532512664794922 , validation accuracy:  28.642434866667386 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  151 , validation loss:  0.8604220390319824 , validation accuracy:  28.18795335432605 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  152 , validation loss:  0.9817575454711914 , validation accuracy:  27.380346920887753 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  153 , validation loss:  0.8377297401428223 , validation accuracy:  28.771565328110405 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  154 , validation loss:  0.839276123046875 , validation accuracy:  28.502844116448262 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  155 , validation loss:  0.8440298080444336 , validation accuracy:  28.486612633864645 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  156 , validation loss:  0.8229964256286622 , validation accuracy:  28.955161431111787 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  157 , validation loss:  0.8208683013916016 , validation accuracy:  29.049664729709747 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  158 , validation loss:  0.8559879302978516 , validation accuracy:  28.691490014031213 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  159 , validation loss:  0.8247974395751954 , validation accuracy:  28.82206327392611 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  160 , validation loss:  0.855403995513916 , validation accuracy:  28.348103982484428 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  161 , validation loss:  0.8375555038452148 , validation accuracy:  28.823866771990954 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  162 , validation loss:  0.9314363479614258 , validation accuracy:  27.96612309234992 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  163 , validation loss:  0.8277857780456543 , validation accuracy:  28.877611014323385 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  164 , validation loss:  0.8479404449462891 , validation accuracy:  29.144889427533645 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  165 , validation loss:  0.8501813888549805 , validation accuracy:  28.81917767702235 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  166 , validation loss:  0.8334155082702637 , validation accuracy:  28.995559787764346 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  167 , validation loss:  0.8790533065795898 , validation accuracy:  28.643156265893328 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  168 , validation loss:  0.8190205574035645 , validation accuracy:  29.14164313101692 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  169 , validation loss:  0.8276859283447265 , validation accuracy:  28.96742521795274 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  170 , validation loss:  0.8241167068481445 , validation accuracy:  29.197912270640135 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  171 , validation loss:  0.8477712631225586 , validation accuracy:  28.605643506144517 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  172 , validation loss:  0.8226022720336914 , validation accuracy:  28.77877932036979 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  173 , validation loss:  0.8159697532653809 , validation accuracy:  29.132264941079715 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  174 , validation loss:  0.9160764694213868 , validation accuracy:  28.137094708897376 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  175 , validation loss:  0.8279041290283203 , validation accuracy:  29.230375235807372 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  176 , validation loss:  0.8398367881774902 , validation accuracy:  29.26283820097461 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  177 , validation loss:  0.8980484008789062 , validation accuracy:  28.88013591161417 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  178 , validation loss:  0.8576035499572754 , validation accuracy:  28.126634420121267 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  179 , validation loss:  0.8385269165039062 , validation accuracy:  28.748119853267397 %, lr:  5.012597452303301e-05\n",
+      "Epoch:  180 , validation loss:  0.8480135917663574 , validation accuracy:  29.179155890765728 %, lr:  5.012597452303301e-05\n",
+      "wandb: Agent Finished Run: r0u1b0z1 \n",
+      "\n",
+      "wandb: Agent Starting Run: 9wv3f7w6 with config:\n",
+      "\tepochs: 172\n",
+      "\thidden_dim: 34\n",
+      "\tlr: 0.0008700796900365365\n",
+      "\tn_graph_iters: 4\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 146\n",
+      "\tweight_decay: 0.00016358100599050222\n",
+      "wandb: Agent Started Run: 9wv3f7w6\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/9wv3f7w6\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/9wv3f7w6</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 172, 'hidden_dim': 34, 'lr': 0.0008700796900365365, 'n_graph_iters': 4, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 146, 'weight_decay': 0.00016358100599050222}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 34, 'n_graph_iters': 4, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.9091020584106446 , validation accuracy:  14.68768824011052 %, lr:  0.0008700796900365365\n",
+      "Epoch:  2 , validation loss:  1.8828346252441406 , validation accuracy:  11.820126317004462 %, lr:  0.0008700796900365365\n",
+      "Epoch:  3 , validation loss:  1.8781972885131837 , validation accuracy:  10.52449330721868 %, lr:  0.0008700796900365365\n",
+      "Epoch:  4 , validation loss:  1.878797721862793 , validation accuracy:  10.185435671027525 %, lr:  0.0008700796900365365\n",
+      "Epoch:  5 , validation loss:  1.8755914688110351 , validation accuracy:  11.070953220867194 %, lr:  0.0008700796900365365\n",
+      "Epoch:  6 , validation loss:  1.874929428100586 , validation accuracy:  11.211265370312258 %, lr:  0.0008700796900365365\n",
+      "Epoch:  7 , validation loss:  1.8787546157836914 , validation accuracy:  9.9776726939572 %, lr:  0.0008700796900365365\n",
+      "Epoch:  8 , validation loss:  1.873971939086914 , validation accuracy:  11.122893965134775 %, lr:  0.0008700796900365365\n",
+      "Epoch:  9 , validation loss:  1.8713409423828125 , validation accuracy:  12.834774328287146 %, lr:  0.0008700796900365365\n",
+      "Epoch:  10 , validation loss:  1.871236801147461 , validation accuracy:  12.979775572700811 %, lr:  0.0008700796900365365\n",
+      "Epoch:  11 , validation loss:  1.8720191955566405 , validation accuracy:  12.623404355087128 %, lr:  0.0008700796900365365\n",
+      "Epoch:  12 , validation loss:  1.87054443359375 , validation accuracy:  11.270420106839225 %, lr:  0.0008700796900365365\n",
+      "Epoch:  13 , validation loss:  1.8748615264892579 , validation accuracy:  10.416644122940856 %, lr:  0.0008700796900365365\n",
+      "Epoch:  14 , validation loss:  1.8672977447509767 , validation accuracy:  11.803173435194903 %, lr:  0.0008700796900365365\n",
+      "Epoch:  15 , validation loss:  1.8674930572509765 , validation accuracy:  12.164955147003127 %, lr:  0.0008700796900365365\n",
+      "Epoch:  16 , validation loss:  1.8677070617675782 , validation accuracy:  11.097284292613955 %, lr:  0.0008700796900365365\n",
+      "Epoch:  17 , validation loss:  1.8665931701660157 , validation accuracy:  11.86846006514235 %, lr:  0.0008700796900365365\n",
+      "Epoch:  18 , validation loss:  1.8662399291992187 , validation accuracy:  10.745602169968873 %, lr:  0.0008700796900365365\n",
+      "Epoch:  19 , validation loss:  1.8653430938720703 , validation accuracy:  11.680896266398307 %, lr:  0.0008700796900365365\n",
+      "Epoch:  20 , validation loss:  1.8633066177368165 , validation accuracy:  11.042097251829649 %, lr:  0.0008700796900365365\n",
+      "Epoch:  21 , validation loss:  1.8655145645141602 , validation accuracy:  11.628955522130726 %, lr:  0.0008700796900365365\n",
+      "Epoch:  22 , validation loss:  1.8602149963378907 , validation accuracy:  11.119647668618052 %, lr:  0.0008700796900365365\n",
+      "Epoch:  23 , validation loss:  1.8637565612792968 , validation accuracy:  11.90020163108365 %, lr:  0.0008700796900365365\n",
+      "Epoch:  24 , validation loss:  1.8670286178588866 , validation accuracy:  11.609117043417411 %, lr:  0.0008700796900365365\n",
+      "Epoch:  25 , validation loss:  1.861711311340332 , validation accuracy:  11.702538243176464 %, lr:  0.0008700796900365365\n",
+      "Epoch:  26 , validation loss:  1.864016342163086 , validation accuracy:  12.371996724847515 %, lr:  0.0008700796900365365\n",
+      "Epoch:  27 , validation loss:  1.8580778121948243 , validation accuracy:  11.567275888312972 %, lr:  0.0008700796900365365\n",
+      "Epoch:  28 , validation loss:  1.8646917343139648 , validation accuracy:  13.237315096360902 %, lr:  0.0008700796900365365\n",
+      "Epoch:  29 , validation loss:  1.8161035537719727 , validation accuracy:  11.21595446528086 %, lr:  0.0008700796900365365\n",
+      "Epoch:  30 , validation loss:  1.7410322189331056 , validation accuracy:  19.261359332561437 %, lr:  0.0008700796900365365\n",
+      "Epoch:  31 , validation loss:  1.8659385681152343 , validation accuracy:  11.368891101179848 %, lr:  0.0008700796900365365\n",
+      "Epoch:  32 , validation loss:  1.8962068557739258 , validation accuracy:  11.192508990437853 %, lr:  0.0008700796900365365\n",
+      "Epoch:  33 , validation loss:  1.880035972595215 , validation accuracy:  10.939658561746363 %, lr:  0.0008700796900365365\n",
+      "Epoch:  34 , validation loss:  1.8759328842163085 , validation accuracy:  10.703761014864432 %, lr:  0.0008700796900365365\n",
+      "Epoch:  35 , validation loss:  1.8734626770019531 , validation accuracy:  11.22064356024946 %, lr:  0.0008700796900365365\n",
+      "Epoch:  36 , validation loss:  1.8701082229614259 , validation accuracy:  11.303604471232402 %, lr:  0.0008700796900365365\n",
+      "Epoch:  37 , validation loss:  1.8684453964233398 , validation accuracy:  11.764217876994218 %, lr:  0.0008700796900365365\n",
+      "Epoch:  38 , validation loss:  1.8554546356201171 , validation accuracy:  11.374662294987358 %, lr:  0.0008700796900365365\n",
+      "Epoch:  39 , validation loss:  1.7743034362792969 , validation accuracy:  12.60500867482569 %, lr:  0.0008700796900365365\n",
+      "Epoch:  40 , validation loss:  1.537874412536621 , validation accuracy:  19.062253146202373 %, lr:  0.0008700796900365365\n",
+      "Epoch:  41 , validation loss:  1.855858612060547 , validation accuracy:  11.724540919567593 %, lr:  0.0008700796900365365\n",
+      "Epoch:  42 , validation loss:  1.612173080444336 , validation accuracy:  20.35463985947143 %, lr:  0.0008700796900365365\n",
+      "Epoch:  43 , validation loss:  1.5371548652648925 , validation accuracy:  19.03772557252046 %, lr:  0.0008700796900365365\n",
+      "Epoch:  44 , validation loss:  1.5401498794555664 , validation accuracy:  19.957148885979244 %, lr:  0.0008700796900365365\n",
+      "Epoch:  45 , validation loss:  1.5458714485168457 , validation accuracy:  21.013277352753402 %, lr:  0.0008700796900365365\n",
+      "Epoch:  46 , validation loss:  1.4173523902893066 , validation accuracy:  21.943882354214235 %, lr:  0.0008700796900365365\n",
+      "Epoch:  47 , validation loss:  1.318661594390869 , validation accuracy:  15.67672657887238 %, lr:  0.0008700796900365365\n",
+      "Epoch:  48 , validation loss:  1.2798543930053712 , validation accuracy:  23.55729172302598 %, lr:  0.0008700796900365365\n",
+      "Epoch:  49 , validation loss:  1.1925409317016602 , validation accuracy:  23.49561208920823 %, lr:  0.0008700796900365365\n",
+      "Epoch:  50 , validation loss:  1.7558570861816407 , validation accuracy:  16.386944116808962 %, lr:  0.0008700796900365365\n",
+      "Epoch:  51 , validation loss:  1.1730181694030761 , validation accuracy:  24.65742554258239 %, lr:  0.0008700796900365365\n",
+      "Epoch:  52 , validation loss:  1.8743942260742188 , validation accuracy:  10.246393905619339 %, lr:  0.0008700796900365365\n",
+      "Epoch:  53 , validation loss:  1.3083318710327148 , validation accuracy:  24.24334238689362 %, lr:  0.0008700796900365365\n",
+      "Epoch:  54 , validation loss:  1.1964189529418945 , validation accuracy:  24.19392653991682 %, lr:  0.0008700796900365365\n",
+      "Epoch:  55 , validation loss:  1.6691991806030273 , validation accuracy:  13.34336078257388 %, lr:  0.0008700796900365365\n",
+      "Epoch:  56 , validation loss:  1.453813362121582 , validation accuracy:  21.510682119038087 %, lr:  0.0008700796900365365\n",
+      "Epoch:  57 , validation loss:  1.216287612915039 , validation accuracy:  20.288631830298044 %, lr:  0.0008700796900365365\n",
+      "Epoch:  58 , validation loss:  1.8511173248291015 , validation accuracy:  11.88938064269457 %, lr:  0.0008700796900365365\n",
+      "Epoch:  59 , validation loss:  1.784700584411621 , validation accuracy:  14.651978978426555 %, lr:  0.0008700796900365365\n",
+      "Epoch:  60 , validation loss:  1.3472758293151856 , validation accuracy:  23.86316499482396 %, lr:  0.0008700796900365365\n",
+      "Epoch:  61 , validation loss:  1.1223159790039063 , validation accuracy:  25.81671409866577 %, lr:  0.0008700796900365365\n",
+      "Epoch:  62 , validation loss:  1.136856746673584 , validation accuracy:  25.89787151158387 %, lr:  0.0008700796900365365\n",
+      "Epoch:  63 , validation loss:  1.0784418106079101 , validation accuracy:  22.244705831430643 %, lr:  0.0008700796900365365\n",
+      "Epoch:  64 , validation loss:  1.7639089584350587 , validation accuracy:  26.279852401718372 %, lr:  0.0008700796900365365\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  65 , validation loss:  1.6932043075561523 , validation accuracy:  21.44070639412204 %, lr:  0.0008700796900365365\n",
+      "Epoch:  66 , validation loss:  1.2593038558959961 , validation accuracy:  25.01199326213123 %, lr:  0.0008700796900365365\n",
+      "Epoch:  67 , validation loss:  1.6258859634399414 , validation accuracy:  24.519998990041085 %, lr:  0.0008700796900365365\n",
+      "Epoch:  68 , validation loss:  1.2179710388183593 , validation accuracy:  26.45984150859006 %, lr:  0.0008700796900365365\n",
+      "Epoch:  69 , validation loss:  1.5390396118164062 , validation accuracy:  13.65500524817937 %, lr:  0.0008700796900365365\n",
+      "Epoch:  70 , validation loss:  1.7202926635742188 , validation accuracy:  12.805196960023663 %, lr:  0.0008700796900365365\n",
+      "Epoch:  71 , validation loss:  2.1845218658447267 , validation accuracy:  21.404997132438076 %, lr:  0.0008700796900365365\n",
+      "Epoch:  72 , validation loss:  1.9830757141113282 , validation accuracy:  18.94177947547062 %, lr:  0.0008700796900365365\n",
+      "Epoch:  73 , validation loss:  1.0595307350158691 , validation accuracy:  23.050148067191124 %, lr:  0.0008700796900365365\n",
+      "Epoch:  74 , validation loss:  1.9067169189453126 , validation accuracy:  21.59905352421557 %, lr:  0.0008700796900365365\n",
+      "Epoch:  75 , validation loss:  1.383343505859375 , validation accuracy:  26.34044993669722 %, lr:  0.0008700796900365365\n",
+      "Epoch:  76 , validation loss:  1.0287103652954102 , validation accuracy:  24.4997998117148 %, lr:  0.0008700796900365365\n",
+      "Epoch:  77 , validation loss:  1.7320590972900392 , validation accuracy:  13.17022496834861 %, lr:  0.0008700796900365365\n",
+      "Epoch:  78 , validation loss:  1.0700763702392577 , validation accuracy:  26.47066249697914 %, lr:  0.0008700796900365365\n",
+      "Epoch:  79 , validation loss:  1.3808688163757323 , validation accuracy:  24.570496935856788 %, lr:  0.0008700796900365365\n",
+      "Epoch:  80 , validation loss:  1.0555846214294433 , validation accuracy:  25.689026435674634 %, lr:  0.0008700796900365365\n",
+      "Epoch:  81 , validation loss:  1.3167749404907227 , validation accuracy:  24.444973470543466 %, lr:  0.0008700796900365365\n",
+      "Epoch:  82 , validation loss:  1.138130283355713 , validation accuracy:  26.979970350491815 %, lr:  0.0008700796900365365\n",
+      "Epoch:  83 , validation loss:  1.0336505889892578 , validation accuracy:  32.0265186355455 %, lr:  0.0008700796900365365\n",
+      "Epoch:  84 , validation loss:  1.5250054359436036 , validation accuracy:  22.485292473281177 %, lr:  0.0008700796900365365\n",
+      "Epoch:  85 , validation loss:  0.9738507270812988 , validation accuracy:  30.38497469692215 %, lr:  0.0008700796900365365\n",
+      "Epoch:  86 , validation loss:  1.2661834716796876 , validation accuracy:  26.601235756874033 %, lr:  0.0008700796900365365\n",
+      "Epoch:  87 , validation loss:  1.1661727905273438 , validation accuracy:  24.245506584571437 %, lr:  0.0008700796900365365\n",
+      "Epoch:  88 , validation loss:  1.8942483901977538 , validation accuracy:  14.519602220466817 %, lr:  0.0008700796900365365\n",
+      "Epoch:  89 , validation loss:  1.5688469886779786 , validation accuracy:  15.371214006687369 %, lr:  0.0008700796900365365\n",
+      "Epoch:  90 , validation loss:  1.7916484832763673 , validation accuracy:  17.360111672600176 %, lr:  0.0008700796900365365\n",
+      "Epoch:  91 , validation loss:  1.0151030540466308 , validation accuracy:  28.029606224232523 %, lr:  0.0008700796900365365\n",
+      "Epoch:  92 , validation loss:  1.338762092590332 , validation accuracy:  16.785156489527086 %, lr:  0.0008700796900365365\n",
+      "Epoch:  93 , validation loss:  1.5106770515441894 , validation accuracy:  14.871284343111899 %, lr:  0.0008700796900365365\n",
+      "Epoch:  94 , validation loss:  1.0265830993652343 , validation accuracy:  25.586948445204317 %, lr:  0.0008700796900365365\n",
+      "Epoch:  95 , validation loss:  1.7462806701660156 , validation accuracy:  20.516233286081683 %, lr:  0.0008700796900365365\n",
+      "Epoch:  96 , validation loss:  1.4238821983337402 , validation accuracy:  22.927510198781555 %, lr:  0.0008700796900365365\n",
+      "Epoch:  97 , validation loss:  2.007895278930664 , validation accuracy:  19.50122457518603 %, lr:  0.0008700796900365365\n",
+      "Epoch:  98 , validation loss:  1.8319753646850585 , validation accuracy:  11.950699576899353 %, lr:  0.0008700796900365365\n",
+      "Epoch:  99 , validation loss:  1.716162872314453 , validation accuracy:  14.9935615119085 %, lr:  0.0008700796900365365\n",
+      "Epoch:  100 , validation loss:  1.555234718322754 , validation accuracy:  18.481887468934747 %, lr:  0.0008700796900365365\n",
+      "Epoch:  101 , validation loss:  1.3176687240600586 , validation accuracy:  22.56176079123067 %, lr:  0.0008700796900365365\n",
+      "Epoch:  102 , validation loss:  1.3892216682434082 , validation accuracy:  17.54587197327937 %, lr:  0.0008700796900365365\n",
+      "Epoch:  103 , validation loss:  1.449809455871582 , validation accuracy:  19.574085897005833 %, lr:  0.0008700796900365365\n",
+      "Epoch:  104 , validation loss:  1.339412021636963 , validation accuracy:  15.453453518444373 %, lr:  0.0008700796900365365\n",
+      "Epoch:  105 , validation loss:  1.0522964477539063 , validation accuracy:  27.152384765491146 %, lr:  0.0008700796900365365\n",
+      "Epoch:  106 , validation loss:  1.0426014900207519 , validation accuracy:  27.088540933995574 %, lr:  0.00021751992250913413\n",
+      "Epoch:  107 , validation loss:  1.0932597160339355 , validation accuracy:  31.214944506364546 %, lr:  0.00021751992250913413\n",
+      "Epoch:  108 , validation loss:  0.947214412689209 , validation accuracy:  22.28366138963133 %, lr:  0.00021751992250913413\n",
+      "Epoch:  109 , validation loss:  0.9468029022216797 , validation accuracy:  34.172681332712926 %, lr:  0.00021751992250913413\n",
+      "Epoch:  110 , validation loss:  0.8535520553588867 , validation accuracy:  35.94443783161821 %, lr:  0.00021751992250913413\n",
+      "Epoch:  111 , validation loss:  0.8654616355895997 , validation accuracy:  36.53742799533976 %, lr:  0.00021751992250913413\n",
+      "Epoch:  112 , validation loss:  1.439758014678955 , validation accuracy:  22.35003011841768 %, lr:  0.00021751992250913413\n",
+      "Epoch:  113 , validation loss:  0.8719218254089356 , validation accuracy:  36.24562200844758 %, lr:  0.00021751992250913413\n",
+      "Epoch:  114 , validation loss:  0.9124546051025391 , validation accuracy:  35.601412499684386 %, lr:  0.00021751992250913413\n",
+      "Epoch:  115 , validation loss:  0.8706149101257324 , validation accuracy:  36.46853436926262 %, lr:  0.00021751992250913413\n",
+      "Epoch:  116 , validation loss:  0.9688322067260742 , validation accuracy:  37.0965123954422 %, lr:  0.00021751992250913413\n",
+      "Epoch:  117 , validation loss:  0.9642034530639648 , validation accuracy:  31.75058343162398 %, lr:  0.00021751992250913413\n",
+      "Epoch:  118 , validation loss:  0.9446479797363281 , validation accuracy:  30.19993579546889 %, lr:  0.00021751992250913413\n",
+      "Epoch:  119 , validation loss:  0.9206454277038574 , validation accuracy:  24.5903354145701 %, lr:  0.00021751992250913413\n",
+      "Epoch:  120 , validation loss:  0.9856614112854004 , validation accuracy:  30.81709283325939 %, lr:  0.00021751992250913413\n",
+      "Epoch:  121 , validation loss:  0.8510397911071778 , validation accuracy:  35.52386208289599 %, lr:  0.00021751992250913413\n",
+      "Epoch:  122 , validation loss:  1.0360285758972168 , validation accuracy:  28.686079519836678 %, lr:  0.00021751992250913413\n",
+      "Epoch:  123 , validation loss:  1.1119613647460938 , validation accuracy:  31.970610195535258 %, lr:  0.00021751992250913413\n",
+      "Epoch:  124 , validation loss:  0.8385290145874024 , validation accuracy:  38.35932174044777 %, lr:  0.00021751992250913413\n",
+      "Epoch:  125 , validation loss:  1.0371879577636718 , validation accuracy:  35.27173305343043 %, lr:  0.00021751992250913413\n",
+      "Epoch:  126 , validation loss:  0.7970840454101562 , validation accuracy:  33.16669011214151 %, lr:  0.00021751992250913413\n",
+      "Epoch:  127 , validation loss:  0.8473675727844239 , validation accuracy:  27.84564942161817 %, lr:  0.00021751992250913413\n",
+      "Epoch:  128 , validation loss:  0.8718366622924805 , validation accuracy:  38.30088840314674 %, lr:  0.00021751992250913413\n",
+      "Epoch:  129 , validation loss:  1.0377089500427246 , validation accuracy:  30.861458885654613 %, lr:  0.00021751992250913413\n",
+      "Epoch:  130 , validation loss:  0.7974385261535645 , validation accuracy:  38.92778433048741 %, lr:  0.00021751992250913413\n",
+      "Epoch:  131 , validation loss:  1.3939054489135743 , validation accuracy:  19.050350058974384 %, lr:  0.00021751992250913413\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  132 , validation loss:  0.8495532035827636 , validation accuracy:  30.44412943344912 %, lr:  0.00021751992250913413\n",
+      "Epoch:  133 , validation loss:  0.9021702766418457 , validation accuracy:  38.13027748621226 %, lr:  0.00021751992250913413\n",
+      "Epoch:  134 , validation loss:  1.1213175773620605 , validation accuracy:  32.93439956138927 %, lr:  0.00021751992250913413\n",
+      "Epoch:  135 , validation loss:  0.95166015625 , validation accuracy:  38.00980381548051 %, lr:  0.00021751992250913413\n",
+      "Epoch:  136 , validation loss:  0.9642169952392579 , validation accuracy:  33.76004097547604 %, lr:  0.00021751992250913413\n",
+      "Epoch:  137 , validation loss:  0.8909928321838378 , validation accuracy:  36.02162754879364 %, lr:  0.00021751992250913413\n",
+      "Epoch:  138 , validation loss:  0.962371826171875 , validation accuracy:  33.47797387813402 %, lr:  0.00021751992250913413\n",
+      "Epoch:  139 , validation loss:  0.8349101066589355 , validation accuracy:  40.10474716760629 %, lr:  0.00021751992250913413\n",
+      "Epoch:  140 , validation loss:  3.6241119384765623 , validation accuracy:  27.694876983397 %, lr:  0.00021751992250913413\n",
+      "Epoch:  141 , validation loss:  0.8459962844848633 , validation accuracy:  38.99451375888673 %, lr:  0.00021751992250913413\n",
+      "Epoch:  142 , validation loss:  0.8373771667480469 , validation accuracy:  37.232135449918665 %, lr:  0.00021751992250913413\n",
+      "Epoch:  143 , validation loss:  0.8586843490600586 , validation accuracy:  40.05713481869434 %, lr:  0.00021751992250913413\n",
+      "Epoch:  144 , validation loss:  0.7716686725616455 , validation accuracy:  39.42879609290179 %, lr:  0.00021751992250913413\n",
+      "Epoch:  145 , validation loss:  0.8137798309326172 , validation accuracy:  37.040243255818986 %, lr:  0.00021751992250913413\n",
+      "Epoch:  146 , validation loss:  1.7415000915527343 , validation accuracy:  28.853444140254435 %, lr:  0.00021751992250913413\n",
+      "Epoch:  147 , validation loss:  1.0251032829284668 , validation accuracy:  36.679904342462635 %, lr:  0.00021751992250913413\n",
+      "Epoch:  148 , validation loss:  0.843055534362793 , validation accuracy:  40.62343321105617 %, lr:  0.00021751992250913413\n",
+      "Epoch:  149 , validation loss:  0.7347175121307373 , validation accuracy:  39.9528926305462 %, lr:  0.00021751992250913413\n",
+      "Epoch:  150 , validation loss:  0.8593297958374023 , validation accuracy:  36.22181583399161 %, lr:  0.00021751992250913413\n",
+      "Epoch:  151 , validation loss:  1.2638029098510741 , validation accuracy:  29.56474377702993 %, lr:  0.00021751992250913413\n",
+      "Epoch:  152 , validation loss:  0.9223179817199707 , validation accuracy:  30.781383571575425 %, lr:  0.00021751992250913413\n",
+      "Epoch:  153 , validation loss:  1.2662925720214844 , validation accuracy:  36.19981315760048 %, lr:  0.00021751992250913413\n",
+      "Epoch:  154 , validation loss:  1.7762203216552734 , validation accuracy:  29.26428099942649 %, lr:  0.00021751992250913413\n",
+      "Epoch:  155 , validation loss:  0.7612086772918701 , validation accuracy:  38.93427692352086 %, lr:  0.00021751992250913413\n",
+      "Epoch:  156 , validation loss:  1.3173569679260253 , validation accuracy:  31.88043529229293 %, lr:  0.00021751992250913413\n",
+      "Epoch:  157 , validation loss:  0.9008918762207031 , validation accuracy:  17.52819769224388 %, lr:  0.00021751992250913413\n",
+      "Epoch:  158 , validation loss:  1.1305258750915528 , validation accuracy:  33.12701315471489 %, lr:  0.00021751992250913413\n",
+      "Epoch:  159 , validation loss:  0.6899665355682373 , validation accuracy:  41.39605178203644 %, lr:  0.00021751992250913413\n",
+      "Epoch:  160 , validation loss:  0.8177039146423339 , validation accuracy:  34.66575770364199 %, lr:  0.00021751992250913413\n",
+      "Epoch:  161 , validation loss:  0.8420660018920898 , validation accuracy:  29.65347588182038 %, lr:  0.00021751992250913413\n",
+      "Epoch:  162 , validation loss:  0.8792328834533691 , validation accuracy:  38.08338653652625 %, lr:  0.00021751992250913413\n",
+      "Epoch:  163 , validation loss:  0.8341251373291015 , validation accuracy:  38.81199975472426 %, lr:  0.00021751992250913413\n",
+      "Epoch:  164 , validation loss:  0.7425952434539795 , validation accuracy:  42.54488004934371 %, lr:  0.00021751992250913413\n",
+      "Epoch:  165 , validation loss:  1.2195145606994628 , validation accuracy:  25.43401180930533 %, lr:  0.00021751992250913413\n",
+      "Epoch:  166 , validation loss:  0.8244542121887207 , validation accuracy:  36.39603374705579 %, lr:  0.00021751992250913413\n",
+      "Epoch:  167 , validation loss:  0.7377734661102295 , validation accuracy:  38.200974610354244 %, lr:  0.00021751992250913413\n",
+      "Epoch:  168 , validation loss:  0.9013158798217773 , validation accuracy:  37.57011098727091 %, lr:  0.00021751992250913413\n",
+      "Epoch:  169 , validation loss:  0.7860296249389649 , validation accuracy:  27.886047778270733 %, lr:  0.00021751992250913413\n",
+      "Epoch:  170 , validation loss:  0.7998441696166992 , validation accuracy:  40.04198543494963 %, lr:  0.00021751992250913413\n",
+      "Epoch:  171 , validation loss:  0.7374943733215332 , validation accuracy:  37.82909330938288 %, lr:  0.00021751992250913413\n",
+      "Epoch:  172 , validation loss:  1.053414249420166 , validation accuracy:  25.17430808796742 %, lr:  0.00021751992250913413\n",
+      "wandb: Agent Finished Run: 9wv3f7w6 \n",
+      "\n",
+      "wandb: Agent Starting Run: fles6abx with config:\n",
+      "\tepochs: 211\n",
+      "\thidden_dim: 46\n",
+      "\tlr: 0.0009623351230037094\n",
+      "\tn_graph_iters: 2\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 413\n",
+      "\tweight_decay: 2.0068652397108902e-05\n",
+      "wandb: Agent Started Run: fles6abx\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fles6abx\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fles6abx</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 211, 'hidden_dim': 46, 'lr': 0.0009623351230037094, 'n_graph_iters': 2, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 413, 'weight_decay': 2.0068652397108905e-05}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 46, 'n_graph_iters': 2, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.878549575805664 , validation accuracy:  10.806921104173655 %, lr:  0.0009623351230037094\n",
+      "Epoch:  2 , validation loss:  1.8768560409545898 , validation accuracy:  10.813052997594133 %, lr:  0.0009623351230037094\n",
+      "Epoch:  3 , validation loss:  1.8763357162475587 , validation accuracy:  10.39896984190536 %, lr:  0.0009623351230037094\n",
+      "Epoch:  4 , validation loss:  1.8820119857788087 , validation accuracy:  9.786862598696432 %, lr:  0.0009623351230037094\n",
+      "Epoch:  5 , validation loss:  1.8735223770141602 , validation accuracy:  10.906834896966156 %, lr:  0.0009623351230037094\n",
+      "Epoch:  6 , validation loss:  1.8740242004394532 , validation accuracy:  10.737306078870578 %, lr:  0.0009623351230037094\n",
+      "Epoch:  7 , validation loss:  1.8778112411499024 , validation accuracy:  10.084079079783146 %, lr:  0.0009623351230037094\n",
+      "Epoch:  8 , validation loss:  1.871331787109375 , validation accuracy:  12.686887486969725 %, lr:  0.0009623351230037094\n",
+      "Epoch:  9 , validation loss:  1.8749990463256836 , validation accuracy:  13.559419850742499 %, lr:  0.0009623351230037094\n",
+      "Epoch:  10 , validation loss:  1.8678085327148437 , validation accuracy:  12.457121833508273 %, lr:  0.0009623351230037094\n",
+      "Epoch:  11 , validation loss:  1.868357276916504 , validation accuracy:  11.507399752560065 %, lr:  0.0009623351230037094\n",
+      "Epoch:  12 , validation loss:  1.8668481826782226 , validation accuracy:  12.017068305685708 %, lr:  0.0009623351230037094\n",
+      "Epoch:  13 , validation loss:  1.8658418655395508 , validation accuracy:  11.938435790058398 %, lr:  0.0009623351230037094\n",
+      "Epoch:  14 , validation loss:  1.8653430938720703 , validation accuracy:  12.662359913287812 %, lr:  0.0009623351230037094\n",
+      "Epoch:  15 , validation loss:  1.8647773742675782 , validation accuracy:  12.984464667669412 %, lr:  0.0009623351230037094\n",
+      "Epoch:  16 , validation loss:  1.8660457611083985 , validation accuracy:  13.271581559592988 %, lr:  0.0009623351230037094\n",
+      "Epoch:  17 , validation loss:  1.876143455505371 , validation accuracy:  11.668993179170318 %, lr:  0.0009623351230037094\n",
+      "Epoch:  18 , validation loss:  1.8663200378417968 , validation accuracy:  12.69518357806802 %, lr:  0.0009623351230037094\n",
+      "Epoch:  19 , validation loss:  1.8690092086791992 , validation accuracy:  11.982080443227684 %, lr:  0.0009623351230037094\n",
+      "Epoch:  20 , validation loss:  1.8649164199829102 , validation accuracy:  13.437142681945902 %, lr:  0.0009623351230037094\n",
+      "Epoch:  21 , validation loss:  1.8641124725341798 , validation accuracy:  12.511948174679608 %, lr:  0.0009623351230037094\n",
+      "Epoch:  22 , validation loss:  1.8614019393920898 , validation accuracy:  13.188620648610044 %, lr:  0.0009623351230037094\n",
+      "Epoch:  23 , validation loss:  1.8124277114868164 , validation accuracy:  15.217555971562444 %, lr:  0.0009623351230037094\n",
+      "Epoch:  24 , validation loss:  1.8086629867553712 , validation accuracy:  13.0374875107759 %, lr:  0.0009623351230037094\n",
+      "Epoch:  25 , validation loss:  1.3741058349609374 , validation accuracy:  22.897572130905104 %, lr:  0.0009623351230037094\n",
+      "Epoch:  26 , validation loss:  1.778122329711914 , validation accuracy:  10.121952539144925 %, lr:  0.0009623351230037094\n",
+      "Epoch:  27 , validation loss:  1.5936247825622558 , validation accuracy:  18.081150198925837 %, lr:  0.0009623351230037094\n",
+      "Epoch:  28 , validation loss:  1.2334193229675292 , validation accuracy:  19.27686941591912 %, lr:  0.0009623351230037094\n",
+      "Epoch:  29 , validation loss:  1.2050050735473632 , validation accuracy:  23.618610657230764 %, lr:  0.0009623351230037094\n",
+      "Epoch:  30 , validation loss:  1.2857711791992188 , validation accuracy:  16.44104905875436 %, lr:  0.0009623351230037094\n",
+      "Epoch:  31 , validation loss:  1.7269590377807618 , validation accuracy:  20.860340716854413 %, lr:  0.0009623351230037094\n",
+      "Epoch:  32 , validation loss:  1.2796895980834961 , validation accuracy:  24.313318111809664 %, lr:  0.0009623351230037094\n",
+      "Epoch:  33 , validation loss:  1.6405042648315429 , validation accuracy:  16.605888781881337 %, lr:  0.0009623351230037094\n",
+      "Epoch:  34 , validation loss:  1.2176339149475097 , validation accuracy:  22.61478363433716 %, lr:  0.0009623351230037094\n",
+      "Epoch:  35 , validation loss:  1.406186008453369 , validation accuracy:  17.769866432933316 %, lr:  0.0009623351230037094\n",
+      "Epoch:  36 , validation loss:  1.5232032775878905 , validation accuracy:  17.377785953635673 %, lr:  0.0009623351230037094\n",
+      "Epoch:  37 , validation loss:  2.26080322265625 , validation accuracy:  21.090467069928835 %, lr:  0.0009623351230037094\n",
+      "Epoch:  38 , validation loss:  1.0945672988891602 , validation accuracy:  33.27670349409715 %, lr:  0.0009623351230037094\n",
+      "Epoch:  39 , validation loss:  1.3072185516357422 , validation accuracy:  31.87827109461512 %, lr:  0.0009623351230037094\n",
+      "Epoch:  40 , validation loss:  1.7738916397094726 , validation accuracy:  12.931802524175891 %, lr:  0.0009623351230037094\n",
+      "Epoch:  41 , validation loss:  1.3055990219116211 , validation accuracy:  19.029429481422167 %, lr:  0.0009623351230037094\n",
+      "Epoch:  42 , validation loss:  1.5328802108764648 , validation accuracy:  19.677967385540995 %, lr:  0.0009623351230037094\n",
+      "Epoch:  43 , validation loss:  1.1573363304138184 , validation accuracy:  31.542820454553656 %, lr:  0.0009623351230037094\n",
+      "Epoch:  44 , validation loss:  1.1984390258789062 , validation accuracy:  32.094330162783734 %, lr:  0.0009623351230037094\n",
+      "Epoch:  45 , validation loss:  1.1493013381958008 , validation accuracy:  30.851719996104443 %, lr:  0.0009623351230037094\n",
+      "Epoch:  46 , validation loss:  0.9898947715759278 , validation accuracy:  35.26199416388026 %, lr:  0.0009623351230037094\n",
+      "Epoch:  47 , validation loss:  1.37811222076416 , validation accuracy:  24.513506397007635 %, lr:  0.0009623351230037094\n",
+      "Epoch:  48 , validation loss:  1.4442789077758789 , validation accuracy:  18.04147324149921 %, lr:  0.0009623351230037094\n",
+      "Epoch:  49 , validation loss:  1.3680171012878417 , validation accuracy:  31.246325372692873 %, lr:  0.0009623351230037094\n",
+      "Epoch:  50 , validation loss:  1.441175365447998 , validation accuracy:  23.594443783161818 %, lr:  0.0009623351230037094\n",
+      "Epoch:  51 , validation loss:  0.9483741760253906 , validation accuracy:  39.749458048831514 %, lr:  0.0009623351230037094\n",
+      "Epoch:  52 , validation loss:  1.134354019165039 , validation accuracy:  28.68824371751449 %, lr:  0.0009623351230037094\n",
+      "Epoch:  53 , validation loss:  1.6096343994140625 , validation accuracy:  23.016242303572007 %, lr:  0.0009623351230037094\n",
+      "Epoch:  54 , validation loss:  1.1088279724121093 , validation accuracy:  24.19464793914276 %, lr:  0.0009623351230037094\n",
+      "Epoch:  55 , validation loss:  1.3940546989440918 , validation accuracy:  24.32630329787656 %, lr:  0.0009623351230037094\n",
+      "Epoch:  56 , validation loss:  1.46423282623291 , validation accuracy:  21.885809716526175 %, lr:  0.0009623351230037094\n",
+      "Epoch:  57 , validation loss:  1.1658645629882813 , validation accuracy:  28.938569248915197 %, lr:  0.0009623351230037094\n",
+      "Epoch:  58 , validation loss:  1.0027233123779298 , validation accuracy:  30.761905792475087 %, lr:  0.0009623351230037094\n",
+      "Epoch:  59 , validation loss:  1.1047062873840332 , validation accuracy:  35.34495507486321 %, lr:  0.0009623351230037094\n",
+      "Epoch:  60 , validation loss:  1.5376065254211426 , validation accuracy:  18.42201133318184 %, lr:  0.0009623351230037094\n",
+      "Epoch:  61 , validation loss:  1.135129737854004 , validation accuracy:  28.278488957181345 %, lr:  0.0009623351230037094\n",
+      "Epoch:  62 , validation loss:  1.1635416984558105 , validation accuracy:  32.77533103206981 %, lr:  0.0009623351230037094\n",
+      "Epoch:  63 , validation loss:  1.0287334442138671 , validation accuracy:  37.19822968629954 %, lr:  0.0009623351230037094\n",
+      "Epoch:  64 , validation loss:  1.3969810485839844 , validation accuracy:  30.124910275971274 %, lr:  0.0009623351230037094\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  65 , validation loss:  1.2528239250183106 , validation accuracy:  25.814549900987956 %, lr:  0.0009623351230037094\n",
+      "Epoch:  66 , validation loss:  1.3192296981811524 , validation accuracy:  23.706260663182306 %, lr:  0.0009623351230037094\n",
+      "Epoch:  67 , validation loss:  1.0039659500122071 , validation accuracy:  35.43765487539632 %, lr:  0.0009623351230037094\n",
+      "Epoch:  68 , validation loss:  0.9390053749084473 , validation accuracy:  42.98962267213488 %, lr:  0.0009623351230037094\n",
+      "Epoch:  69 , validation loss:  1.0332667350769043 , validation accuracy:  35.511958995667996 %, lr:  0.0009623351230037094\n",
+      "Epoch:  70 , validation loss:  1.097170639038086 , validation accuracy:  30.914842428374072 %, lr:  0.0009623351230037094\n",
+      "Epoch:  71 , validation loss:  1.311798095703125 , validation accuracy:  20.679269511143815 %, lr:  0.0009623351230037094\n",
+      "Epoch:  72 , validation loss:  1.2232470512390137 , validation accuracy:  29.664657569822428 %, lr:  0.0009623351230037094\n",
+      "Epoch:  73 , validation loss:  1.252298641204834 , validation accuracy:  26.93560429809659 %, lr:  0.0009623351230037094\n",
+      "Epoch:  74 , validation loss:  1.1611184120178222 , validation accuracy:  32.31291412824314 %, lr:  0.0009623351230037094\n",
+      "Epoch:  75 , validation loss:  1.507094669342041 , validation accuracy:  25.193785867067763 %, lr:  0.0009623351230037094\n",
+      "Epoch:  76 , validation loss:  1.0153990745544434 , validation accuracy:  37.46298320221902 %, lr:  0.0009623351230037094\n",
+      "Epoch:  77 , validation loss:  1.0909978866577148 , validation accuracy:  37.49111777203063 %, lr:  0.0009623351230037094\n",
+      "Epoch:  78 , validation loss:  0.964591121673584 , validation accuracy:  36.90245600366471 %, lr:  0.0009623351230037094\n",
+      "Epoch:  79 , validation loss:  1.5997607231140136 , validation accuracy:  26.351992324312235 %, lr:  0.0009623351230037094\n",
+      "Epoch:  80 , validation loss:  0.9592877388000488 , validation accuracy:  44.75596867684561 %, lr:  0.0009623351230037094\n",
+      "Epoch:  81 , validation loss:  1.9306144714355469 , validation accuracy:  32.601473818618594 %, lr:  0.0009623351230037094\n",
+      "Epoch:  82 , validation loss:  1.129542636871338 , validation accuracy:  29.168334902376653 %, lr:  0.0009623351230037094\n",
+      "Epoch:  83 , validation loss:  0.9934643745422364 , validation accuracy:  37.202918781268146 %, lr:  0.0009623351230037094\n",
+      "Epoch:  84 , validation loss:  0.8373519897460937 , validation accuracy:  42.02222631015117 %, lr:  0.0009623351230037094\n",
+      "Epoch:  85 , validation loss:  1.6206398010253906 , validation accuracy:  19.13295027034436 %, lr:  0.0009623351230037094\n",
+      "Epoch:  86 , validation loss:  1.3931850433349608 , validation accuracy:  30.701668957109206 %, lr:  0.0009623351230037094\n",
+      "Epoch:  87 , validation loss:  0.8755559921264648 , validation accuracy:  38.53967154693243 %, lr:  0.0009623351230037094\n",
+      "Epoch:  88 , validation loss:  0.9211544990539551 , validation accuracy:  30.872279874043695 %, lr:  0.0009623351230037094\n",
+      "Epoch:  89 , validation loss:  1.4629279136657716 , validation accuracy:  17.19455055024726 %, lr:  0.0009623351230037094\n",
+      "Epoch:  90 , validation loss:  1.1096799850463868 , validation accuracy:  31.774028906466985 %, lr:  0.0009623351230037094\n",
+      "Epoch:  91 , validation loss:  1.2592382431030273 , validation accuracy:  26.390587182899957 %, lr:  0.0009623351230037094\n",
+      "Epoch:  92 , validation loss:  1.5525779724121094 , validation accuracy:  12.746042223496696 %, lr:  0.0009623351230037094\n",
+      "Epoch:  93 , validation loss:  2.839781951904297 , validation accuracy:  26.531260031957988 %, lr:  0.0009623351230037094\n",
+      "Epoch:  94 , validation loss:  1.1145710945129395 , validation accuracy:  25.44519349730738 %, lr:  0.0009623351230037094\n",
+      "Epoch:  95 , validation loss:  1.307628345489502 , validation accuracy:  18.88118194049178 %, lr:  0.0009623351230037094\n",
+      "Epoch:  96 , validation loss:  0.9778950691223145 , validation accuracy:  43.065369590858424 %, lr:  0.0009623351230037094\n",
+      "Epoch:  97 , validation loss:  1.0653388977050782 , validation accuracy:  21.777239133022412 %, lr:  0.0009623351230037094\n",
+      "Epoch:  98 , validation loss:  1.0662969589233398 , validation accuracy:  37.34503442877806 %, lr:  0.0009623351230037094\n",
+      "Epoch:  99 , validation loss:  1.0181438446044921 , validation accuracy:  26.952917879519116 %, lr:  0.0009623351230037094\n",
+      "Epoch:  100 , validation loss:  1.1278355598449707 , validation accuracy:  38.691526083992514 %, lr:  0.0009623351230037094\n",
+      "Epoch:  101 , validation loss:  1.1030046463012695 , validation accuracy:  23.277388823361793 %, lr:  0.0009623351230037094\n",
+      "Epoch:  102 , validation loss:  1.1972317695617676 , validation accuracy:  20.590898105966332 %, lr:  0.0009623351230037094\n",
+      "Epoch:  103 , validation loss:  1.1186842918395996 , validation accuracy:  31.6492268403796 %, lr:  0.0009623351230037094\n",
+      "Epoch:  104 , validation loss:  0.9857280731201172 , validation accuracy:  33.997020621196874 %, lr:  0.0009623351230037094\n",
+      "Epoch:  105 , validation loss:  1.3811622619628907 , validation accuracy:  19.400589383167592 %, lr:  0.00024058378075092734\n",
+      "Epoch:  106 , validation loss:  0.8587214469909668 , validation accuracy:  41.42418635184805 %, lr:  0.00024058378075092734\n",
+      "Epoch:  107 , validation loss:  1.4383726119995117 , validation accuracy:  35.83298165121069 %, lr:  0.00024058378075092734\n",
+      "Epoch:  108 , validation loss:  1.1109819412231445 , validation accuracy:  32.16214169002197 %, lr:  0.00024058378075092734\n",
+      "Epoch:  109 , validation loss:  0.8090746879577637 , validation accuracy:  44.032044553616196 %, lr:  0.00024058378075092734\n",
+      "Epoch:  110 , validation loss:  0.9041536331176758 , validation accuracy:  38.12594909085662 %, lr:  0.00024058378075092734\n",
+      "Epoch:  111 , validation loss:  0.8493800163269043 , validation accuracy:  46.45053545857545 %, lr:  0.00024058378075092734\n",
+      "Epoch:  112 , validation loss:  0.8541783332824707 , validation accuracy:  47.98964070711552 %, lr:  0.00024058378075092734\n",
+      "Epoch:  113 , validation loss:  1.011113739013672 , validation accuracy:  37.63972601257399 %, lr:  0.00024058378075092734\n",
+      "Epoch:  114 , validation loss:  0.8012811660766601 , validation accuracy:  46.20020992717475 %, lr:  0.00024058378075092734\n",
+      "Epoch:  115 , validation loss:  0.8084605216979981 , validation accuracy:  46.0526837854703 %, lr:  0.00024058378075092734\n",
+      "Epoch:  116 , validation loss:  0.9042512893676757 , validation accuracy:  44.20301617016365 %, lr:  0.00024058378075092734\n",
+      "Epoch:  117 , validation loss:  0.8582484245300293 , validation accuracy:  48.040860052157164 %, lr:  0.00024058378075092734\n",
+      "Epoch:  118 , validation loss:  1.2835267066955567 , validation accuracy:  34.798495161214696 %, lr:  0.00024058378075092734\n",
+      "Epoch:  119 , validation loss:  0.93409423828125 , validation accuracy:  39.218508218540684 %, lr:  0.00024058378075092734\n",
+      "Epoch:  120 , validation loss:  0.7888566970825195 , validation accuracy:  50.32408860225293 %, lr:  0.00024058378075092734\n",
+      "Epoch:  121 , validation loss:  1.0131292343139648 , validation accuracy:  44.81981250834118 %, lr:  0.00024058378075092734\n",
+      "Epoch:  122 , validation loss:  0.7705791473388672 , validation accuracy:  51.47363826878614 %, lr:  0.00024058378075092734\n",
+      "Epoch:  123 , validation loss:  0.8280835151672363 , validation accuracy:  49.778350087830354 %, lr:  0.00024058378075092734\n",
+      "Epoch:  124 , validation loss:  0.8077017784118652 , validation accuracy:  47.59034623555849 %, lr:  0.00024058378075092734\n",
+      "Epoch:  125 , validation loss:  0.7965360164642334 , validation accuracy:  51.59266914106602 %, lr:  0.00024058378075092734\n",
+      "Epoch:  126 , validation loss:  0.9946831703186035 , validation accuracy:  34.38982249972046 %, lr:  0.00024058378075092734\n",
+      "Epoch:  127 , validation loss:  0.7786267757415771 , validation accuracy:  50.466564949375815 %, lr:  0.00024058378075092734\n",
+      "Epoch:  128 , validation loss:  0.7518147468566895 , validation accuracy:  43.147248403002465 %, lr:  0.00024058378075092734\n",
+      "Epoch:  129 , validation loss:  0.8964925765991211 , validation accuracy:  41.61499644710881 %, lr:  0.00024058378075092734\n",
+      "Epoch:  130 , validation loss:  0.861816120147705 , validation accuracy:  38.721464151868965 %, lr:  0.00024058378075092734\n",
+      "Epoch:  131 , validation loss:  0.7664056777954101 , validation accuracy:  51.33152262127623 %, lr:  0.00024058378075092734\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  132 , validation loss:  0.889768123626709 , validation accuracy:  46.71240337759118 %, lr:  0.00024058378075092734\n",
+      "Epoch:  133 , validation loss:  1.0471166610717773 , validation accuracy:  50.55637915300517 %, lr:  0.00024058378075092734\n",
+      "Epoch:  134 , validation loss:  0.7649023056030273 , validation accuracy:  54.16229318385941 %, lr:  0.00024058378075092734\n",
+      "Epoch:  135 , validation loss:  0.8467382431030274 , validation accuracy:  51.91946299041621 %, lr:  0.00024058378075092734\n",
+      "Epoch:  136 , validation loss:  0.8965774536132812 , validation accuracy:  35.91449976374175 %, lr:  0.00024058378075092734\n",
+      "Epoch:  137 , validation loss:  0.963715648651123 , validation accuracy:  35.44811516417243 %, lr:  0.00024058378075092734\n",
+      "Epoch:  138 , validation loss:  0.7683077335357666 , validation accuracy:  51.123759644205904 %, lr:  0.00024058378075092734\n",
+      "Epoch:  139 , validation loss:  0.7721261024475098 , validation accuracy:  50.43482338343451 %, lr:  0.00024058378075092734\n",
+      "Epoch:  140 , validation loss:  0.7682314395904541 , validation accuracy:  53.87192999541911 %, lr:  0.00024058378075092734\n",
+      "Epoch:  141 , validation loss:  0.7540744781494141 , validation accuracy:  49.60593567283102 %, lr:  0.00024058378075092734\n",
+      "Epoch:  142 , validation loss:  0.8210134506225586 , validation accuracy:  51.90864200202713 %, lr:  0.00024058378075092734\n",
+      "Epoch:  143 , validation loss:  0.8415225982666016 , validation accuracy:  51.01338556263729 %, lr:  0.00024058378075092734\n",
+      "Epoch:  144 , validation loss:  0.8968653678894043 , validation accuracy:  41.427071948751795 %, lr:  0.00024058378075092734\n",
+      "Epoch:  145 , validation loss:  1.3684798240661622 , validation accuracy:  37.39950007033642 %, lr:  0.00024058378075092734\n",
+      "Epoch:  146 , validation loss:  0.8054887771606445 , validation accuracy:  52.16618152568723 %, lr:  0.00024058378075092734\n",
+      "Epoch:  147 , validation loss:  0.8038029670715332 , validation accuracy:  50.46331865285909 %, lr:  0.00024058378075092734\n",
+      "Epoch:  148 , validation loss:  0.7463179588317871 , validation accuracy:  57.25673516352317 %, lr:  0.00024058378075092734\n",
+      "Epoch:  149 , validation loss:  0.770248556137085 , validation accuracy:  52.089352508124755 %, lr:  0.00024058378075092734\n",
+      "Epoch:  150 , validation loss:  0.7985824584960938 , validation accuracy:  56.225855669656866 %, lr:  0.00024058378075092734\n",
+      "Epoch:  151 , validation loss:  1.0790095329284668 , validation accuracy:  39.19073434834204 %, lr:  0.00024058378075092734\n",
+      "Epoch:  152 , validation loss:  0.7767439365386963 , validation accuracy:  46.34088277623278 %, lr:  0.00024058378075092734\n",
+      "Epoch:  153 , validation loss:  0.8708792686462402 , validation accuracy:  54.011520745638244 %, lr:  0.00024058378075092734\n",
+      "Epoch:  154 , validation loss:  0.8899920463562012 , validation accuracy:  51.96130414552065 %, lr:  0.00024058378075092734\n",
+      "Epoch:  155 , validation loss:  0.8224380493164063 , validation accuracy:  52.58783937324836 %, lr:  0.00024058378075092734\n",
+      "Epoch:  156 , validation loss:  0.8086453437805176 , validation accuracy:  50.570085738298 %, lr:  0.00024058378075092734\n",
+      "Epoch:  157 , validation loss:  0.8152135848999024 , validation accuracy:  56.27743571431147 %, lr:  0.00024058378075092734\n",
+      "Epoch:  158 , validation loss:  0.7287994384765625 , validation accuracy:  56.37410321058726 %, lr:  0.00024058378075092734\n",
+      "Epoch:  159 , validation loss:  0.8556712150573731 , validation accuracy:  44.023027063291956 %, lr:  0.00024058378075092734\n",
+      "Epoch:  160 , validation loss:  0.7321031093597412 , validation accuracy:  57.75522202864677 %, lr:  0.00024058378075092734\n",
+      "Epoch:  161 , validation loss:  0.7827497482299804 , validation accuracy:  51.80584261233088 %, lr:  0.00024058378075092734\n",
+      "Epoch:  162 , validation loss:  0.7442350387573242 , validation accuracy:  45.40414588135147 %, lr:  0.00024058378075092734\n",
+      "Epoch:  163 , validation loss:  0.8465593338012696 , validation accuracy:  37.521416539520054 %, lr:  0.00024058378075092734\n",
+      "Epoch:  164 , validation loss:  0.8977270126342773 , validation accuracy:  53.15413776561017 %, lr:  0.00024058378075092734\n",
+      "Epoch:  165 , validation loss:  0.847159481048584 , validation accuracy:  44.73324460122854 %, lr:  0.00024058378075092734\n",
+      "Epoch:  166 , validation loss:  0.7785361766815185 , validation accuracy:  52.18313440749678 %, lr:  0.00024058378075092734\n",
+      "Epoch:  167 , validation loss:  1.2183941841125487 , validation accuracy:  44.68382875425175 %, lr:  0.00024058378075092734\n",
+      "Epoch:  168 , validation loss:  0.7798810958862304 , validation accuracy:  54.332543401180935 %, lr:  0.00024058378075092734\n",
+      "Epoch:  169 , validation loss:  1.0672648429870606 , validation accuracy:  40.670684860355145 %, lr:  0.00024058378075092734\n",
+      "Epoch:  170 , validation loss:  0.7633292198181152 , validation accuracy:  54.32785430621233 %, lr:  0.00024058378075092734\n",
+      "Epoch:  171 , validation loss:  1.0000286102294922 , validation accuracy:  48.968940156327214 %, lr:  0.00024058378075092734\n",
+      "Epoch:  172 , validation loss:  0.7324105739593506 , validation accuracy:  58.80774349929122 %, lr:  0.00024058378075092734\n",
+      "Epoch:  173 , validation loss:  0.7866692543029785 , validation accuracy:  54.56483395193317 %, lr:  0.00024058378075092734\n",
+      "Epoch:  174 , validation loss:  0.7520936965942383 , validation accuracy:  57.49912530343855 %, lr:  0.00024058378075092734\n",
+      "Epoch:  175 , validation loss:  1.203322696685791 , validation accuracy:  49.731819837757314 %, lr:  0.00024058378075092734\n",
+      "Epoch:  176 , validation loss:  0.7310639381408691 , validation accuracy:  55.38506487182539 %, lr:  0.00024058378075092734\n",
+      "Epoch:  177 , validation loss:  0.7446837902069092 , validation accuracy:  52.16582082607425 %, lr:  0.00024058378075092734\n",
+      "Epoch:  178 , validation loss:  0.9239301681518555 , validation accuracy:  49.28310951922349 %, lr:  0.00024058378075092734\n",
+      "Epoch:  179 , validation loss:  0.7833447933197022 , validation accuracy:  42.308261103235836 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  180 , validation loss:  0.7936612129211426 , validation accuracy:  54.584672430646485 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  181 , validation loss:  0.6986138343811035 , validation accuracy:  58.41530232038061 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  182 , validation loss:  0.6887392997741699 , validation accuracy:  57.973084594880234 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  183 , validation loss:  0.7097855567932129 , validation accuracy:  58.9595980363513 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  184 , validation loss:  0.7063705921173096 , validation accuracy:  58.000497765465894 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  185 , validation loss:  0.7158604621887207 , validation accuracy:  59.15221162967692 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  186 , validation loss:  0.6937165260314941 , validation accuracy:  59.245993529048945 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  187 , validation loss:  0.6870162010192871 , validation accuracy:  59.52842132600392 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  188 , validation loss:  0.696524715423584 , validation accuracy:  59.03570565468783 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  189 , validation loss:  0.6996571063995362 , validation accuracy:  59.34518592261551 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  190 , validation loss:  0.6979296207427979 , validation accuracy:  59.22579435072266 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  191 , validation loss:  0.7140697956085205 , validation accuracy:  59.59875775053294 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  192 , validation loss:  0.7036675930023193 , validation accuracy:  59.19910257936293 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  193 , validation loss:  0.7072044372558594 , validation accuracy:  59.600200548984816 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  194 , validation loss:  0.9661325454711914 , validation accuracy:  53.55451433600612 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  195 , validation loss:  0.7028179168701172 , validation accuracy:  59.70516413635888 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  196 , validation loss:  0.700844669342041 , validation accuracy:  59.952964770468796 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  197 , validation loss:  0.7041447639465332 , validation accuracy:  60.09724461565653 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  198 , validation loss:  0.6965395927429199 , validation accuracy:  60.12357568740329 %, lr:  6.0145945187731835e-05\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  199 , validation loss:  0.6863747119903565 , validation accuracy:  60.20076540457872 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  200 , validation loss:  0.696424150466919 , validation accuracy:  60.02402259422376 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  201 , validation loss:  0.703196382522583 , validation accuracy:  59.63518841144283 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  202 , validation loss:  0.6961596012115479 , validation accuracy:  59.97316394879508 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  203 , validation loss:  0.7115865230560303 , validation accuracy:  58.95526964099568 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  204 , validation loss:  0.6988650321960449 , validation accuracy:  59.5803620702715 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  205 , validation loss:  0.6946366786956787 , validation accuracy:  59.958375264663346 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  206 , validation loss:  0.7022865772247314 , validation accuracy:  60.122493588564375 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  207 , validation loss:  0.7042452335357666 , validation accuracy:  59.103517181926065 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  208 , validation loss:  0.7042398929595948 , validation accuracy:  60.05540346055208 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  209 , validation loss:  0.6991732120513916 , validation accuracy:  58.91487128434311 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  210 , validation loss:  0.7499145984649658 , validation accuracy:  57.76712511587475 %, lr:  6.0145945187731835e-05\n",
+      "Epoch:  211 , validation loss:  0.7040509223937989 , validation accuracy:  59.39784806610903 %, lr:  6.0145945187731835e-05\n",
+      "wandb: Agent Finished Run: fles6abx \n",
+      "\n",
+      "wandb: Agent Starting Run: ktdqi5wp with config:\n",
+      "\tepochs: 159\n",
+      "\thidden_dim: 38\n",
+      "\tlr: 0.001286366901168298\n",
+      "\tn_graph_iters: 2\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 525\n",
+      "\tweight_decay: 1.2787232891571813e-05\n",
+      "wandb: Agent Started Run: ktdqi5wp\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ktdqi5wp\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ktdqi5wp</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 159, 'hidden_dim': 38, 'lr': 0.001286366901168298, 'n_graph_iters': 2, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 525, 'weight_decay': 1.2787232891571813e-05}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 38, 'n_graph_iters': 2, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.8796390533447265 , validation accuracy:  10.25108300058794 %, lr:  0.001286366901168298\n",
+      "Epoch:  2 , validation loss:  1.876226043701172 , validation accuracy:  10.541806888641208 %, lr:  0.001286366901168298\n",
+      "Epoch:  3 , validation loss:  1.874910545349121 , validation accuracy:  11.219922161023522 %, lr:  0.001286366901168298\n",
+      "Epoch:  4 , validation loss:  1.8753677368164063 , validation accuracy:  13.43317498620324 %, lr:  0.001286366901168298\n",
+      "Epoch:  5 , validation loss:  1.8720743179321289 , validation accuracy:  11.16834211636891 %, lr:  0.001286366901168298\n",
+      "Epoch:  6 , validation loss:  1.8829517364501953 , validation accuracy:  10.079029285201576 %, lr:  0.001286366901168298\n",
+      "Epoch:  7 , validation loss:  1.8688592910766602 , validation accuracy:  11.134436352749793 %, lr:  0.001286366901168298\n",
+      "Epoch:  8 , validation loss:  1.867416763305664 , validation accuracy:  12.545132539072787 %, lr:  0.001286366901168298\n",
+      "Epoch:  9 , validation loss:  1.867936897277832 , validation accuracy:  13.6640227385036 %, lr:  0.001286366901168298\n",
+      "Epoch:  10 , validation loss:  1.8660648345947266 , validation accuracy:  12.729450041300105 %, lr:  0.001286366901168298\n",
+      "Epoch:  11 , validation loss:  1.8650169372558594 , validation accuracy:  12.53250805261886 %, lr:  0.001286366901168298\n",
+      "Epoch:  12 , validation loss:  1.8689624786376953 , validation accuracy:  14.200743762601942 %, lr:  0.001286366901168298\n",
+      "Epoch:  13 , validation loss:  1.8757347106933593 , validation accuracy:  11.049311244089036 %, lr:  0.001286366901168298\n",
+      "Epoch:  14 , validation loss:  1.8653406143188476 , validation accuracy:  13.842929746536381 %, lr:  0.001286366901168298\n",
+      "Epoch:  15 , validation loss:  1.818312644958496 , validation accuracy:  18.051212131049382 %, lr:  0.001286366901168298\n",
+      "Epoch:  16 , validation loss:  1.7921865463256836 , validation accuracy:  28.121223925926724 %, lr:  0.001286366901168298\n",
+      "Epoch:  17 , validation loss:  1.7980815887451171 , validation accuracy:  29.902719314382175 %, lr:  0.001286366901168298\n",
+      "Epoch:  18 , validation loss:  2.047748565673828 , validation accuracy:  19.95173839178471 %, lr:  0.001286366901168298\n",
+      "Epoch:  19 , validation loss:  1.6879928588867188 , validation accuracy:  18.493069156936794 %, lr:  0.001286366901168298\n",
+      "Epoch:  20 , validation loss:  1.7327634811401367 , validation accuracy:  17.923885167671216 %, lr:  0.001286366901168298\n",
+      "Epoch:  21 , validation loss:  1.4680061340332031 , validation accuracy:  25.014157459809045 %, lr:  0.001286366901168298\n",
+      "Epoch:  22 , validation loss:  1.6256830215454101 , validation accuracy:  17.399788630026798 %, lr:  0.001286366901168298\n",
+      "Epoch:  23 , validation loss:  1.8589149475097657 , validation accuracy:  12.292642809994266 %, lr:  0.001286366901168298\n",
+      "Epoch:  24 , validation loss:  1.5777531623840333 , validation accuracy:  25.314259537799515 %, lr:  0.001286366901168298\n",
+      "Epoch:  25 , validation loss:  1.411991786956787 , validation accuracy:  27.869816295687116 %, lr:  0.001286366901168298\n",
+      "Epoch:  26 , validation loss:  1.837466049194336 , validation accuracy:  15.400069975724918 %, lr:  0.001286366901168298\n",
+      "Epoch:  27 , validation loss:  1.553652286529541 , validation accuracy:  27.128217891422203 %, lr:  0.001286366901168298\n",
+      "Epoch:  28 , validation loss:  1.4198530197143555 , validation accuracy:  13.773675420846274 %, lr:  0.001286366901168298\n",
+      "Epoch:  29 , validation loss:  1.8933406829833985 , validation accuracy:  15.394659481530375 %, lr:  0.001286366901168298\n",
+      "Epoch:  30 , validation loss:  1.0308399200439453 , validation accuracy:  32.10911884691548 %, lr:  0.001286366901168298\n",
+      "Epoch:  31 , validation loss:  1.060704803466797 , validation accuracy:  37.064049430274956 %, lr:  0.001286366901168298\n",
+      "Epoch:  32 , validation loss:  1.107761764526367 , validation accuracy:  39.175584964597334 %, lr:  0.001286366901168298\n",
+      "Epoch:  33 , validation loss:  1.6797740936279297 , validation accuracy:  12.881665277973156 %, lr:  0.001286366901168298\n",
+      "Epoch:  34 , validation loss:  1.6899213790893555 , validation accuracy:  21.322396921068105 %, lr:  0.001286366901168298\n",
+      "Epoch:  35 , validation loss:  1.4418318748474122 , validation accuracy:  16.303983205826018 %, lr:  0.001286366901168298\n",
+      "Epoch:  36 , validation loss:  1.4924723625183105 , validation accuracy:  33.10356767987188 %, lr:  0.001286366901168298\n",
+      "Epoch:  37 , validation loss:  1.1635151863098145 , validation accuracy:  38.30882379463207 %, lr:  0.001286366901168298\n",
+      "Epoch:  38 , validation loss:  1.1647061347961425 , validation accuracy:  21.484351047291327 %, lr:  0.001286366901168298\n",
+      "Epoch:  39 , validation loss:  0.9129223823547363 , validation accuracy:  38.28537831978907 %, lr:  0.001286366901168298\n",
+      "Epoch:  40 , validation loss:  0.9214010238647461 , validation accuracy:  39.66721853707451 %, lr:  0.001286366901168298\n",
+      "Epoch:  41 , validation loss:  0.9558856010437011 , validation accuracy:  40.32116693538788 %, lr:  0.001286366901168298\n",
+      "Epoch:  42 , validation loss:  0.9949382781982422 , validation accuracy:  42.71008047208365 %, lr:  0.001286366901168298\n",
+      "Epoch:  43 , validation loss:  1.0569672584533691 , validation accuracy:  40.77095935276061 %, lr:  0.001286366901168298\n",
+      "Epoch:  44 , validation loss:  1.2940355300903321 , validation accuracy:  27.19891501556419 %, lr:  0.001286366901168298\n",
+      "Epoch:  45 , validation loss:  1.1537090301513673 , validation accuracy:  42.03521149621807 %, lr:  0.001286366901168298\n",
+      "Epoch:  46 , validation loss:  0.9158880233764648 , validation accuracy:  47.91245098994008 %, lr:  0.001286366901168298\n",
+      "Epoch:  47 , validation loss:  1.1874869346618653 , validation accuracy:  29.143446629081765 %, lr:  0.001286366901168298\n",
+      "Epoch:  48 , validation loss:  1.2747064590454102 , validation accuracy:  33.011949978177675 %, lr:  0.001286366901168298\n",
+      "Epoch:  49 , validation loss:  0.8824891090393067 , validation accuracy:  47.59034623555849 %, lr:  0.001286366901168298\n",
+      "Epoch:  50 , validation loss:  1.5246311187744142 , validation accuracy:  32.95604153816743 %, lr:  0.001286366901168298\n",
+      "Epoch:  51 , validation loss:  1.4054178237915038 , validation accuracy:  23.66297670962599 %, lr:  0.001286366901168298\n",
+      "Epoch:  52 , validation loss:  0.9383426666259765 , validation accuracy:  49.970242281930034 %, lr:  0.001286366901168298\n",
+      "Epoch:  53 , validation loss:  1.1494476318359375 , validation accuracy:  33.810899620904706 %, lr:  0.001286366901168298\n",
+      "Epoch:  54 , validation loss:  0.90535888671875 , validation accuracy:  46.471816735740646 %, lr:  0.001286366901168298\n",
+      "Epoch:  55 , validation loss:  1.4236634254455567 , validation accuracy:  39.55107326169839 %, lr:  0.001286366901168298\n",
+      "Epoch:  56 , validation loss:  1.379433536529541 , validation accuracy:  27.421466676766254 %, lr:  0.001286366901168298\n",
+      "Epoch:  57 , validation loss:  1.3170714378356934 , validation accuracy:  26.080746215359312 %, lr:  0.001286366901168298\n",
+      "Epoch:  58 , validation loss:  1.0160831451416015 , validation accuracy:  36.53742799533976 %, lr:  0.001286366901168298\n",
+      "Epoch:  59 , validation loss:  0.9645595550537109 , validation accuracy:  46.97932109118847 %, lr:  0.001286366901168298\n",
+      "Epoch:  60 , validation loss:  1.0415096282958984 , validation accuracy:  29.594321145293414 %, lr:  0.001286366901168298\n",
+      "Epoch:  61 , validation loss:  0.9393609046936036 , validation accuracy:  46.86534001349016 %, lr:  0.001286366901168298\n",
+      "Epoch:  62 , validation loss:  1.0913604736328124 , validation accuracy:  34.82338343450957 %, lr:  0.001286366901168298\n",
+      "Epoch:  63 , validation loss:  0.9682025909423828 , validation accuracy:  38.50396228524847 %, lr:  0.001286366901168298\n",
+      "Epoch:  64 , validation loss:  1.129267120361328 , validation accuracy:  30.46396791216243 %, lr:  0.001286366901168298\n",
+      "Epoch:  65 , validation loss:  1.356828498840332 , validation accuracy:  29.690627941956215 %, lr:  0.001286366901168298\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  66 , validation loss:  1.1080848693847656 , validation accuracy:  44.351263711094035 %, lr:  0.001286366901168298\n",
+      "Epoch:  67 , validation loss:  0.9877760887145997 , validation accuracy:  41.58505837923236 %, lr:  0.001286366901168298\n",
+      "Epoch:  68 , validation loss:  0.9201435089111328 , validation accuracy:  45.07915553006612 %, lr:  0.001286366901168298\n",
+      "Epoch:  69 , validation loss:  0.916505241394043 , validation accuracy:  47.5279452025148 %, lr:  0.001286366901168298\n",
+      "Epoch:  70 , validation loss:  0.8583855628967285 , validation accuracy:  36.75276566428244 %, lr:  0.001286366901168298\n",
+      "Epoch:  71 , validation loss:  2.004546546936035 , validation accuracy:  25.111185655697792 %, lr:  0.001286366901168298\n",
+      "Epoch:  72 , validation loss:  0.9875454902648926 , validation accuracy:  41.462781210435764 %, lr:  0.001286366901168298\n",
+      "Epoch:  73 , validation loss:  1.0909289360046386 , validation accuracy:  24.515670594685453 %, lr:  0.001286366901168298\n",
+      "Epoch:  74 , validation loss:  1.0622727394104003 , validation accuracy:  18.16916090449035 %, lr:  0.001286366901168298\n",
+      "Epoch:  75 , validation loss:  1.0740278244018555 , validation accuracy:  32.65485736133805 %, lr:  0.001286366901168298\n",
+      "Epoch:  76 , validation loss:  0.8707795143127441 , validation accuracy:  50.06727047781878 %, lr:  0.001286366901168298\n",
+      "Epoch:  77 , validation loss:  0.917882251739502 , validation accuracy:  22.645443101439554 %, lr:  0.001286366901168298\n",
+      "Epoch:  78 , validation loss:  0.8782808303833007 , validation accuracy:  46.87543960265331 %, lr:  0.001286366901168298\n",
+      "Epoch:  79 , validation loss:  1.627283477783203 , validation accuracy:  28.24602599201411 %, lr:  0.001286366901168298\n",
+      "Epoch:  80 , validation loss:  1.331174087524414 , validation accuracy:  28.54648876961755 %, lr:  0.001286366901168298\n",
+      "Epoch:  81 , validation loss:  0.9654205322265625 , validation accuracy:  33.23991213357428 %, lr:  0.001286366901168298\n",
+      "Epoch:  82 , validation loss:  0.9849920272827148 , validation accuracy:  42.65561483052529 %, lr:  0.001286366901168298\n",
+      "Epoch:  83 , validation loss:  0.8457913398742676 , validation accuracy:  48.89391463682959 %, lr:  0.001286366901168298\n",
+      "Epoch:  84 , validation loss:  1.020444965362549 , validation accuracy:  31.05876157394883 %, lr:  0.001286366901168298\n",
+      "Epoch:  85 , validation loss:  0.924379539489746 , validation accuracy:  41.40542997197364 %, lr:  0.001286366901168298\n",
+      "Epoch:  86 , validation loss:  0.804705810546875 , validation accuracy:  44.479312073698146 %, lr:  0.001286366901168298\n",
+      "Epoch:  87 , validation loss:  0.9095450401306152 , validation accuracy:  40.302410555513475 %, lr:  0.001286366901168298\n",
+      "Epoch:  88 , validation loss:  0.9186718940734864 , validation accuracy:  45.73635022489621 %, lr:  0.001286366901168298\n",
+      "Epoch:  89 , validation loss:  1.5044994354248047 , validation accuracy:  27.61408027009187 %, lr:  0.001286366901168298\n",
+      "Epoch:  90 , validation loss:  1.2503050804138183 , validation accuracy:  37.31473566128864 %, lr:  0.001286366901168298\n",
+      "Epoch:  91 , validation loss:  1.3462058067321778 , validation accuracy:  34.50632847470955 %, lr:  0.001286366901168298\n",
+      "Epoch:  92 , validation loss:  0.9699469566345215 , validation accuracy:  34.98209126421607 %, lr:  0.001286366901168298\n",
+      "Epoch:  93 , validation loss:  1.1965786933898925 , validation accuracy:  36.411543830413464 %, lr:  0.001286366901168298\n",
+      "Epoch:  94 , validation loss:  0.837041187286377 , validation accuracy:  34.18458441994092 %, lr:  0.001286366901168298\n",
+      "Epoch:  95 , validation loss:  1.0189000129699708 , validation accuracy:  40.37779677462406 %, lr:  0.001286366901168298\n",
+      "Epoch:  96 , validation loss:  1.4382244110107423 , validation accuracy:  35.71034378280112 %, lr:  0.001286366901168298\n",
+      "Epoch:  97 , validation loss:  1.778433609008789 , validation accuracy:  25.984800118309476 %, lr:  0.001286366901168298\n",
+      "Epoch:  98 , validation loss:  0.8560129165649414 , validation accuracy:  42.24946706632184 %, lr:  0.001286366901168298\n",
+      "Epoch:  99 , validation loss:  0.7604604721069336 , validation accuracy:  49.09554572047944 %, lr:  0.001286366901168298\n",
+      "Epoch:  100 , validation loss:  0.8362545013427735 , validation accuracy:  47.23649991523559 %, lr:  0.001286366901168298\n",
+      "Epoch:  101 , validation loss:  0.8103240013122559 , validation accuracy:  44.036012249358855 %, lr:  0.001286366901168298\n",
+      "Epoch:  102 , validation loss:  1.2021234512329102 , validation accuracy:  17.57797423883364 %, lr:  0.001286366901168298\n",
+      "Epoch:  103 , validation loss:  0.8755885124206543 , validation accuracy:  44.33503222851042 %, lr:  0.001286366901168298\n",
+      "Epoch:  104 , validation loss:  1.6646762847900392 , validation accuracy:  32.64331497372303 %, lr:  0.001286366901168298\n",
+      "Epoch:  105 , validation loss:  0.8640491485595703 , validation accuracy:  24.213404319017165 %, lr:  0.001286366901168298\n",
+      "Epoch:  106 , validation loss:  0.7951356410980225 , validation accuracy:  42.2029368162488 %, lr:  0.001286366901168298\n",
+      "Epoch:  107 , validation loss:  0.9918663024902343 , validation accuracy:  35.71286868009191 %, lr:  0.001286366901168298\n",
+      "Epoch:  108 , validation loss:  0.8445972442626953 , validation accuracy:  29.757357370355543 %, lr:  0.001286366901168298\n",
+      "Epoch:  109 , validation loss:  0.8270759582519531 , validation accuracy:  43.140395110356046 %, lr:  0.001286366901168298\n",
+      "Epoch:  110 , validation loss:  1.1173297882080078 , validation accuracy:  30.834767114294888 %, lr:  0.001286366901168298\n",
+      "Epoch:  111 , validation loss:  0.9155976295471191 , validation accuracy:  37.31293216322379 %, lr:  0.001286366901168298\n",
+      "Epoch:  112 , validation loss:  0.8522953033447266 , validation accuracy:  39.115708828844426 %, lr:  0.001286366901168298\n",
+      "Epoch:  113 , validation loss:  1.1282124519348145 , validation accuracy:  37.908807923849096 %, lr:  0.001286366901168298\n",
+      "Epoch:  114 , validation loss:  0.8947365760803223 , validation accuracy:  27.66169261900382 %, lr:  0.001286366901168298\n",
+      "Epoch:  115 , validation loss:  1.3633949279785156 , validation accuracy:  39.41545020722193 %, lr:  0.001286366901168298\n",
+      "Epoch:  116 , validation loss:  0.8404021263122559 , validation accuracy:  44.39887606000599 %, lr:  0.001286366901168298\n",
+      "Epoch:  117 , validation loss:  0.8109944343566895 , validation accuracy:  40.087433586183764 %, lr:  0.001286366901168298\n",
+      "Epoch:  118 , validation loss:  0.7681354522705078 , validation accuracy:  32.492181835888886 %, lr:  0.001286366901168298\n",
+      "Epoch:  119 , validation loss:  0.787183141708374 , validation accuracy:  44.67986105850908 %, lr:  0.001286366901168298\n",
+      "Epoch:  120 , validation loss:  1.0816365242004395 , validation accuracy:  30.267747322707123 %, lr:  0.0003215917252920745\n",
+      "Epoch:  121 , validation loss:  0.7618224143981933 , validation accuracy:  49.59655748289382 %, lr:  0.0003215917252920745\n",
+      "Epoch:  122 , validation loss:  0.6603634357452393 , validation accuracy:  51.26515389248988 %, lr:  0.0003215917252920745\n",
+      "Epoch:  123 , validation loss:  0.6671493530273438 , validation accuracy:  49.49195459513272 %, lr:  0.0003215917252920745\n",
+      "Epoch:  124 , validation loss:  0.6733799934387207 , validation accuracy:  52.09764859922306 %, lr:  0.0003215917252920745\n",
+      "Epoch:  125 , validation loss:  0.6722089767456054 , validation accuracy:  53.61511187098497 %, lr:  0.0003215917252920745\n",
+      "Epoch:  126 , validation loss:  0.857049560546875 , validation accuracy:  47.04749331803967 %, lr:  0.0003215917252920745\n",
+      "Epoch:  127 , validation loss:  0.6658608913421631 , validation accuracy:  54.09376025739524 %, lr:  0.0003215917252920745\n",
+      "Epoch:  128 , validation loss:  0.6739674568176269 , validation accuracy:  52.025508676629194 %, lr:  0.0003215917252920745\n",
+      "Epoch:  129 , validation loss:  0.6479688167572022 , validation accuracy:  52.785142061542565 %, lr:  0.0003215917252920745\n",
+      "Epoch:  130 , validation loss:  0.668792724609375 , validation accuracy:  51.32178373172606 %, lr:  0.0003215917252920745\n",
+      "Epoch:  131 , validation loss:  0.7336249351501465 , validation accuracy:  49.970602981543 %, lr:  0.0003215917252920745\n",
+      "Epoch:  132 , validation loss:  0.8872123718261719 , validation accuracy:  47.28591576221239 %, lr:  0.0003215917252920745\n",
+      "Epoch:  133 , validation loss:  0.7273683547973633 , validation accuracy:  45.908764639895544 %, lr:  0.0003215917252920745\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  134 , validation loss:  0.9518499374389648 , validation accuracy:  39.89590209169705 %, lr:  0.0003215917252920745\n",
+      "Epoch:  135 , validation loss:  0.7694330215454102 , validation accuracy:  53.49896659560884 %, lr:  0.0003215917252920745\n",
+      "Epoch:  136 , validation loss:  0.6389562129974365 , validation accuracy:  55.70500542852918 %, lr:  0.0003215917252920745\n",
+      "Epoch:  137 , validation loss:  0.854582691192627 , validation accuracy:  48.01525037963634 %, lr:  0.0003215917252920745\n",
+      "Epoch:  138 , validation loss:  0.625816011428833 , validation accuracy:  52.038854562309055 %, lr:  0.0003215917252920745\n",
+      "Epoch:  139 , validation loss:  0.8573714256286621 , validation accuracy:  49.06705045105487 %, lr:  0.0003215917252920745\n",
+      "Epoch:  140 , validation loss:  0.727449893951416 , validation accuracy:  52.150671442329546 %, lr:  0.0003215917252920745\n",
+      "Epoch:  141 , validation loss:  0.6487175464630127 , validation accuracy:  49.61639596160713 %, lr:  0.0003215917252920745\n",
+      "Epoch:  142 , validation loss:  0.7114501953125 , validation accuracy:  46.70555008494476 %, lr:  0.0003215917252920745\n",
+      "Epoch:  143 , validation loss:  0.722783899307251 , validation accuracy:  45.20359689654053 %, lr:  0.0003215917252920745\n",
+      "Epoch:  144 , validation loss:  0.8941027641296386 , validation accuracy:  42.736411543830414 %, lr:  0.0003215917252920745\n",
+      "Epoch:  145 , validation loss:  0.770181131362915 , validation accuracy:  46.532053571106516 %, lr:  0.0003215917252920745\n",
+      "Epoch:  146 , validation loss:  0.6546854019165039 , validation accuracy:  52.88217025743131 %, lr:  0.0003215917252920745\n",
+      "Epoch:  147 , validation loss:  0.749916410446167 , validation accuracy:  53.464339432763786 %, lr:  0.0003215917252920745\n",
+      "Epoch:  148 , validation loss:  0.71405029296875 , validation accuracy:  43.10648934673693 %, lr:  0.0003215917252920745\n",
+      "Epoch:  149 , validation loss:  0.7307813167572021 , validation accuracy:  33.417015643542214 %, lr:  0.0003215917252920745\n",
+      "Epoch:  150 , validation loss:  0.8116367340087891 , validation accuracy:  41.83754810831088 %, lr:  0.0003215917252920745\n",
+      "Epoch:  151 , validation loss:  0.7965562820434571 , validation accuracy:  48.24213043619404 %, lr:  0.0003215917252920745\n",
+      "Epoch:  152 , validation loss:  0.6198931694030761 , validation accuracy:  55.45936899209707 %, lr:  0.0003215917252920745\n",
+      "Epoch:  153 , validation loss:  0.6917325973510742 , validation accuracy:  52.85475708684565 %, lr:  0.0003215917252920745\n",
+      "Epoch:  154 , validation loss:  0.6561293125152587 , validation accuracy:  53.69049809009555 %, lr:  0.0003215917252920745\n",
+      "Epoch:  155 , validation loss:  0.6955145359039306 , validation accuracy:  54.44652447887923 %, lr:  0.0003215917252920745\n",
+      "Epoch:  156 , validation loss:  0.6651365280151367 , validation accuracy:  47.91209029032712 %, lr:  0.0003215917252920745\n",
+      "Epoch:  157 , validation loss:  0.652103042602539 , validation accuracy:  55.05863172208816 %, lr:  0.0003215917252920745\n",
+      "Epoch:  158 , validation loss:  0.7697356700897217 , validation accuracy:  45.66926009688392 %, lr:  0.0003215917252920745\n",
+      "Epoch:  159 , validation loss:  0.6443178176879882 , validation accuracy:  53.73955323745938 %, lr:  0.0003215917252920745\n",
+      "wandb: Agent Finished Run: ktdqi5wp \n",
+      "\n",
+      "wandb: Agent Starting Run: ylshjy3t with config:\n",
+      "\tepochs: 181\n",
+      "\thidden_dim: 56\n",
+      "\tlr: 0.0027652584263859483\n",
+      "\tn_graph_iters: 2\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 394\n",
+      "\tweight_decay: 0.0001876569683955251\n",
+      "wandb: Agent Started Run: ylshjy3t\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ylshjy3t\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ylshjy3t</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 181, 'hidden_dim': 56, 'lr': 0.0027652584263859483, 'n_graph_iters': 2, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 394, 'weight_decay': 0.0001876569683955251}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 56, 'n_graph_iters': 2, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.8854427337646484 , validation accuracy:  12.217617290496648 %, lr:  0.0027652584263859483\n",
+      "Epoch:  2 , validation loss:  1.8725807189941406 , validation accuracy:  11.719130425373054 %, lr:  0.0027652584263859483\n",
+      "Epoch:  3 , validation loss:  1.8863094329833985 , validation accuracy:  9.442394468310736 %, lr:  0.0027652584263859483\n",
+      "Epoch:  4 , validation loss:  1.8776731491088867 , validation accuracy:  11.467362095520471 %, lr:  0.0027652584263859483\n",
+      "Epoch:  5 , validation loss:  1.8675628662109376 , validation accuracy:  10.956250743942952 %, lr:  0.0027652584263859483\n",
+      "Epoch:  6 , validation loss:  1.8692047119140625 , validation accuracy:  12.543329041007938 %, lr:  0.0027652584263859483\n",
+      "Epoch:  7 , validation loss:  1.871173095703125 , validation accuracy:  14.49759954407569 %, lr:  0.0027652584263859483\n",
+      "Epoch:  8 , validation loss:  1.86627140045166 , validation accuracy:  11.476740285457673 %, lr:  0.0027652584263859483\n",
+      "Epoch:  9 , validation loss:  1.868490982055664 , validation accuracy:  11.038129556086988 %, lr:  0.0027652584263859483\n",
+      "Epoch:  10 , validation loss:  1.8661186218261718 , validation accuracy:  12.113735801961484 %, lr:  0.0027652584263859483\n",
+      "Epoch:  11 , validation loss:  1.8690509796142578 , validation accuracy:  10.80908530185147 %, lr:  0.0027652584263859483\n",
+      "Epoch:  12 , validation loss:  1.865870475769043 , validation accuracy:  13.081853563171128 %, lr:  0.0027652584263859483\n",
+      "Epoch:  13 , validation loss:  1.8698129653930664 , validation accuracy:  10.595190431360667 %, lr:  0.0027652584263859483\n",
+      "Epoch:  14 , validation loss:  1.8650182723999023 , validation accuracy:  11.954667272642016 %, lr:  0.0027652584263859483\n",
+      "Epoch:  15 , validation loss:  1.866790771484375 , validation accuracy:  12.102554113959435 %, lr:  0.0027652584263859483\n",
+      "Epoch:  16 , validation loss:  1.865317153930664 , validation accuracy:  11.961881264901402 %, lr:  0.0027652584263859483\n",
+      "Epoch:  17 , validation loss:  1.8651145935058593 , validation accuracy:  12.995285656058492 %, lr:  0.0027652584263859483\n",
+      "Epoch:  18 , validation loss:  1.8643335342407226 , validation accuracy:  11.944567683478875 %, lr:  0.0027652584263859483\n",
+      "Epoch:  19 , validation loss:  1.8777606964111329 , validation accuracy:  10.389230952355188 %, lr:  0.0027652584263859483\n",
+      "Epoch:  20 , validation loss:  1.8689493179321288 , validation accuracy:  11.189984093147068 %, lr:  0.0027652584263859483\n",
+      "Epoch:  21 , validation loss:  1.8657087326049804 , validation accuracy:  12.955608698631865 %, lr:  0.0027652584263859483\n",
+      "Epoch:  22 , validation loss:  1.8689748764038085 , validation accuracy:  10.582205245293771 %, lr:  0.0027652584263859483\n",
+      "Epoch:  23 , validation loss:  1.8698904037475585 , validation accuracy:  10.340175804991361 %, lr:  0.0027652584263859483\n",
+      "Epoch:  24 , validation loss:  1.8738250732421875 , validation accuracy:  11.556815599536861 %, lr:  0.0027652584263859483\n",
+      "Epoch:  25 , validation loss:  1.8673171997070312 , validation accuracy:  11.307211467362094 %, lr:  0.0027652584263859483\n",
+      "Epoch:  26 , validation loss:  1.865333366394043 , validation accuracy:  12.56929941314173 %, lr:  0.0027652584263859483\n",
+      "Epoch:  27 , validation loss:  1.865208625793457 , validation accuracy:  13.260760571203908 %, lr:  0.0027652584263859483\n",
+      "Epoch:  28 , validation loss:  1.8694639205932617 , validation accuracy:  13.742294554517942 %, lr:  0.0027652584263859483\n",
+      "Epoch:  29 , validation loss:  1.8658906936645507 , validation accuracy:  12.744960124657787 %, lr:  0.0027652584263859483\n",
+      "Epoch:  30 , validation loss:  1.8679492950439454 , validation accuracy:  12.430430062148544 %, lr:  0.0027652584263859483\n",
+      "Epoch:  31 , validation loss:  1.8662918090820313 , validation accuracy:  11.71588412885633 %, lr:  0.0027652584263859483\n",
+      "Epoch:  32 , validation loss:  1.8660186767578124 , validation accuracy:  13.10060994304553 %, lr:  0.0027652584263859483\n",
+      "Epoch:  33 , validation loss:  1.8712881088256836 , validation accuracy:  10.7358632804187 %, lr:  0.0027652584263859483\n",
+      "Epoch:  34 , validation loss:  1.8664922714233398 , validation accuracy:  13.446881571496075 %, lr:  0.0027652584263859483\n",
+      "Epoch:  35 , validation loss:  1.864325714111328 , validation accuracy:  13.602343104685849 %, lr:  0.0027652584263859483\n",
+      "Epoch:  36 , validation loss:  1.8683507919311524 , validation accuracy:  10.783475629330649 %, lr:  0.0027652584263859483\n",
+      "Epoch:  37 , validation loss:  1.8686182022094726 , validation accuracy:  11.31514685884742 %, lr:  0.0027652584263859483\n",
+      "Epoch:  38 , validation loss:  1.8675411224365235 , validation accuracy:  14.311478543783524 %, lr:  0.0027652584263859483\n",
+      "Epoch:  39 , validation loss:  1.8667526245117188 , validation accuracy:  12.327991372065258 %, lr:  0.0006913146065964871\n",
+      "Epoch:  40 , validation loss:  1.86466064453125 , validation accuracy:  13.47429474208174 %, lr:  0.0006913146065964871\n",
+      "Epoch:  41 , validation loss:  1.863321876525879 , validation accuracy:  12.060352259242025 %, lr:  0.0006913146065964871\n",
+      "Epoch:  42 , validation loss:  1.865037727355957 , validation accuracy:  11.508842551011943 %, lr:  0.0006913146065964871\n",
+      "Epoch:  43 , validation loss:  1.870180320739746 , validation accuracy:  12.978693473861902 %, lr:  0.0006913146065964871\n",
+      "Epoch:  44 , validation loss:  1.8673595428466796 , validation accuracy:  12.404820389627721 %, lr:  0.0006913146065964871\n",
+      "Epoch:  45 , validation loss:  1.8847633361816407 , validation accuracy:  12.075140943373768 %, lr:  0.0006913146065964871\n",
+      "Epoch:  46 , validation loss:  1.8753623962402344 , validation accuracy:  11.310818463491788 %, lr:  0.0006913146065964871\n",
+      "Epoch:  47 , validation loss:  1.8666194915771483 , validation accuracy:  12.440529651311683 %, lr:  0.0006913146065964871\n",
+      "Epoch:  48 , validation loss:  1.8802360534667968 , validation accuracy:  11.273666403355948 %, lr:  0.0006913146065964871\n",
+      "Epoch:  49 , validation loss:  1.6906015396118164 , validation accuracy:  17.30528533142884 %, lr:  0.0006913146065964871\n",
+      "Epoch:  50 , validation loss:  1.6605913162231445 , validation accuracy:  15.647149210608896 %, lr:  0.0006913146065964871\n",
+      "Epoch:  51 , validation loss:  1.4846080780029296 , validation accuracy:  13.241282792103565 %, lr:  0.0006913146065964871\n",
+      "Epoch:  52 , validation loss:  1.2945161819458009 , validation accuracy:  23.26404293768193 %, lr:  0.0006913146065964871\n",
+      "Epoch:  53 , validation loss:  1.3009424209594727 , validation accuracy:  21.981395113963043 %, lr:  0.0006913146065964871\n",
+      "Epoch:  54 , validation loss:  1.7897747039794922 , validation accuracy:  18.772611356988016 %, lr:  0.0006913146065964871\n",
+      "Epoch:  55 , validation loss:  1.3812335014343262 , validation accuracy:  18.424896930085595 %, lr:  0.0006913146065964871\n",
+      "Epoch:  56 , validation loss:  1.4778395652770997 , validation accuracy:  17.328370106658873 %, lr:  0.0006913146065964871\n",
+      "Epoch:  57 , validation loss:  1.8499940872192382 , validation accuracy:  20.95520471506534 %, lr:  0.0006913146065964871\n",
+      "Epoch:  58 , validation loss:  1.82171630859375 , validation accuracy:  19.890419457579924 %, lr:  0.0006913146065964871\n",
+      "Epoch:  59 , validation loss:  1.3307007789611816 , validation accuracy:  27.803086867287792 %, lr:  0.0006913146065964871\n",
+      "Epoch:  60 , validation loss:  1.2829394340515137 , validation accuracy:  28.064233387077575 %, lr:  0.0006913146065964871\n",
+      "Epoch:  61 , validation loss:  1.4482111930847168 , validation accuracy:  13.597293310104277 %, lr:  0.0006913146065964871\n",
+      "Epoch:  62 , validation loss:  1.5755845069885255 , validation accuracy:  19.9553453879144 %, lr:  0.0006913146065964871\n",
+      "Epoch:  63 , validation loss:  1.5935895919799805 , validation accuracy:  21.525470803169828 %, lr:  0.0006913146065964871\n",
+      "Epoch:  64 , validation loss:  1.4991907119750976 , validation accuracy:  27.201439912854973 %, lr:  0.0006913146065964871\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  65 , validation loss:  1.1740797996520995 , validation accuracy:  33.798275134450776 %, lr:  0.0006913146065964871\n",
+      "Epoch:  66 , validation loss:  1.2692875862121582 , validation accuracy:  26.95616417603584 %, lr:  0.0006913146065964871\n",
+      "Epoch:  67 , validation loss:  1.6141521453857421 , validation accuracy:  30.346019138721463 %, lr:  0.0006913146065964871\n",
+      "Epoch:  68 , validation loss:  1.6945066452026367 , validation accuracy:  18.81805950822215 %, lr:  0.0006913146065964871\n",
+      "Epoch:  69 , validation loss:  1.0825698852539063 , validation accuracy:  37.45576920995964 %, lr:  0.0006913146065964871\n",
+      "Epoch:  70 , validation loss:  1.290786361694336 , validation accuracy:  31.62325646824581 %, lr:  0.0006913146065964871\n",
+      "Epoch:  71 , validation loss:  1.3210551261901855 , validation accuracy:  28.03898441416972 %, lr:  0.0006913146065964871\n",
+      "Epoch:  72 , validation loss:  1.236750602722168 , validation accuracy:  31.8714178019687 %, lr:  0.0006913146065964871\n",
+      "Epoch:  73 , validation loss:  1.06967134475708 , validation accuracy:  36.496308239461264 %, lr:  0.0006913146065964871\n",
+      "Epoch:  74 , validation loss:  1.1039572715759278 , validation accuracy:  31.91145545900829 %, lr:  0.0006913146065964871\n",
+      "Epoch:  75 , validation loss:  1.3656742095947265 , validation accuracy:  31.716677668004863 %, lr:  0.0006913146065964871\n",
+      "Epoch:  76 , validation loss:  2.0483665466308594 , validation accuracy:  21.040690523339066 %, lr:  0.0006913146065964871\n",
+      "Epoch:  77 , validation loss:  1.3524271965026855 , validation accuracy:  26.021230779219373 %, lr:  0.0006913146065964871\n",
+      "Epoch:  78 , validation loss:  1.2273294448852539 , validation accuracy:  33.29365637590671 %, lr:  0.0006913146065964871\n",
+      "Epoch:  79 , validation loss:  0.9999866485595703 , validation accuracy:  36.016938453825034 %, lr:  0.0006913146065964871\n",
+      "Epoch:  80 , validation loss:  2.1350168228149413 , validation accuracy:  25.870458340998198 %, lr:  0.0006913146065964871\n",
+      "Epoch:  81 , validation loss:  1.1661058425903321 , validation accuracy:  25.828256486280793 %, lr:  0.0006913146065964871\n",
+      "Epoch:  82 , validation loss:  1.1350038528442383 , validation accuracy:  25.9526978527552 %, lr:  0.0006913146065964871\n",
+      "Epoch:  83 , validation loss:  1.4146041870117188 , validation accuracy:  31.187892035391844 %, lr:  0.0006913146065964871\n",
+      "Epoch:  84 , validation loss:  1.4467392921447755 , validation accuracy:  26.16623202363304 %, lr:  0.0006913146065964871\n",
+      "Epoch:  85 , validation loss:  1.7991790771484375 , validation accuracy:  12.440890350924654 %, lr:  0.0006913146065964871\n",
+      "Epoch:  86 , validation loss:  1.153927993774414 , validation accuracy:  29.96908804316853 %, lr:  0.0006913146065964871\n",
+      "Epoch:  87 , validation loss:  1.514892864227295 , validation accuracy:  27.443469353157386 %, lr:  0.0006913146065964871\n",
+      "Epoch:  88 , validation loss:  1.0938991546630858 , validation accuracy:  38.76546950465122 %, lr:  0.0006913146065964871\n",
+      "Epoch:  89 , validation loss:  1.243097686767578 , validation accuracy:  20.847355530787514 %, lr:  0.0006913146065964871\n",
+      "Epoch:  90 , validation loss:  2.1665231704711916 , validation accuracy:  24.650932949548945 %, lr:  0.0006913146065964871\n",
+      "Epoch:  91 , validation loss:  1.0001707077026367 , validation accuracy:  41.56774479780983 %, lr:  0.0006913146065964871\n",
+      "Epoch:  92 , validation loss:  1.175321674346924 , validation accuracy:  31.660769227994617 %, lr:  0.0006913146065964871\n",
+      "Epoch:  93 , validation loss:  1.1193004608154298 , validation accuracy:  34.85296080277306 %, lr:  0.0006913146065964871\n",
+      "Epoch:  94 , validation loss:  0.9916489601135254 , validation accuracy:  35.90800717070831 %, lr:  0.0006913146065964871\n",
+      "Epoch:  95 , validation loss:  1.4352840423583983 , validation accuracy:  26.638387817009875 %, lr:  0.0006913146065964871\n",
+      "Epoch:  96 , validation loss:  1.2639152526855468 , validation accuracy:  39.17702776304921 %, lr:  0.0006913146065964871\n",
+      "Epoch:  97 , validation loss:  1.1570500373840331 , validation accuracy:  32.773166834391986 %, lr:  0.0006913146065964871\n",
+      "Epoch:  98 , validation loss:  1.0205677986145019 , validation accuracy:  41.83682670908494 %, lr:  0.0006913146065964871\n",
+      "Epoch:  99 , validation loss:  1.3942800521850587 , validation accuracy:  20.185471740988824 %, lr:  0.0006913146065964871\n",
+      "Epoch:  100 , validation loss:  1.2310525894165039 , validation accuracy:  31.52370337506628 %, lr:  0.0006913146065964871\n",
+      "Epoch:  101 , validation loss:  1.748249626159668 , validation accuracy:  12.753256215756082 %, lr:  0.0006913146065964871\n",
+      "Epoch:  102 , validation loss:  1.2598732948303222 , validation accuracy:  31.888370683778255 %, lr:  0.0006913146065964871\n",
+      "Epoch:  103 , validation loss:  1.1075519561767577 , validation accuracy:  35.87482280631512 %, lr:  0.0006913146065964871\n",
+      "Epoch:  104 , validation loss:  1.4185041427612304 , validation accuracy:  18.782710946151155 %, lr:  0.0006913146065964871\n",
+      "Epoch:  105 , validation loss:  1.8119892120361327 , validation accuracy:  12.592744887984736 %, lr:  0.0006913146065964871\n",
+      "Epoch:  106 , validation loss:  1.471756362915039 , validation accuracy:  27.364476137917105 %, lr:  0.0006913146065964871\n",
+      "Epoch:  107 , validation loss:  1.284585189819336 , validation accuracy:  28.237369201302847 %, lr:  0.0006913146065964871\n",
+      "Epoch:  108 , validation loss:  1.430631732940674 , validation accuracy:  26.11645547704327 %, lr:  0.0006913146065964871\n",
+      "Epoch:  109 , validation loss:  1.1137072563171386 , validation accuracy:  36.3476999989179 %, lr:  0.0006913146065964871\n",
+      "Epoch:  110 , validation loss:  1.3964055061340332 , validation accuracy:  31.186449236939968 %, lr:  0.0006913146065964871\n",
+      "Epoch:  111 , validation loss:  1.1028635025024414 , validation accuracy:  37.75731408640198 %, lr:  0.0006913146065964871\n",
+      "Epoch:  112 , validation loss:  1.290597152709961 , validation accuracy:  33.15731192220431 %, lr:  0.0006913146065964871\n",
+      "Epoch:  113 , validation loss:  1.2120914459228516 , validation accuracy:  29.826611696045653 %, lr:  0.0006913146065964871\n",
+      "Epoch:  114 , validation loss:  1.343691349029541 , validation accuracy:  36.00359256814517 %, lr:  0.0006913146065964871\n",
+      "Epoch:  115 , validation loss:  0.9972082138061523 , validation accuracy:  41.12552707230945 %, lr:  0.00017282865164912177\n",
+      "Epoch:  116 , validation loss:  0.8877442359924317 , validation accuracy:  44.742262091552774 %, lr:  0.00017282865164912177\n",
+      "Epoch:  117 , validation loss:  0.8480795860290528 , validation accuracy:  46.989420680351614 %, lr:  0.00017282865164912177\n",
+      "Epoch:  118 , validation loss:  0.9067536354064941 , validation accuracy:  45.76556689354672 %, lr:  0.00017282865164912177\n",
+      "Epoch:  119 , validation loss:  1.1911712646484376 , validation accuracy:  37.912414919978794 %, lr:  0.00017282865164912177\n",
+      "Epoch:  120 , validation loss:  0.8672427177429199 , validation accuracy:  46.837566143291525 %, lr:  0.00017282865164912177\n",
+      "Epoch:  121 , validation loss:  0.9701091766357421 , validation accuracy:  42.38256522350752 %, lr:  0.00017282865164912177\n",
+      "Epoch:  122 , validation loss:  0.9504230499267579 , validation accuracy:  43.13823091267823 %, lr:  0.00017282865164912177\n",
+      "Epoch:  123 , validation loss:  0.8176285743713378 , validation accuracy:  45.17834792363268 %, lr:  0.00017282865164912177\n",
+      "Epoch:  124 , validation loss:  0.8153799057006836 , validation accuracy:  47.334970909576214 %, lr:  0.00017282865164912177\n",
+      "Epoch:  125 , validation loss:  1.655937385559082 , validation accuracy:  36.27988847167967 %, lr:  0.00017282865164912177\n",
+      "Epoch:  126 , validation loss:  0.8624917030334472 , validation accuracy:  45.58665988551394 %, lr:  0.00017282865164912177\n",
+      "Epoch:  127 , validation loss:  0.8310579299926758 , validation accuracy:  47.93337156749231 %, lr:  0.00017282865164912177\n",
+      "Epoch:  128 , validation loss:  0.9464837074279785 , validation accuracy:  40.73272519378587 %, lr:  0.00017282865164912177\n",
+      "Epoch:  129 , validation loss:  0.8660709381103515 , validation accuracy:  43.20496034107755 %, lr:  0.00017282865164912177\n",
+      "Epoch:  130 , validation loss:  0.9152312278747559 , validation accuracy:  46.916920058144775 %, lr:  0.00017282865164912177\n",
+      "Epoch:  131 , validation loss:  0.852107048034668 , validation accuracy:  47.3198215258315 %, lr:  0.00017282865164912177\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  132 , validation loss:  0.92957763671875 , validation accuracy:  46.48516262142051 %, lr:  0.00017282865164912177\n",
+      "Epoch:  133 , validation loss:  0.8168927192687988 , validation accuracy:  47.78043493159332 %, lr:  0.00017282865164912177\n",
+      "Epoch:  134 , validation loss:  0.8150508880615235 , validation accuracy:  48.31499175801384 %, lr:  0.00017282865164912177\n",
+      "Epoch:  135 , validation loss:  0.7973195552825928 , validation accuracy:  48.989139334653494 %, lr:  0.00017282865164912177\n",
+      "Epoch:  136 , validation loss:  0.8341896057128906 , validation accuracy:  47.25381349665812 %, lr:  0.00017282865164912177\n",
+      "Epoch:  137 , validation loss:  0.8310612678527832 , validation accuracy:  50.490731823444754 %, lr:  0.00017282865164912177\n",
+      "Epoch:  138 , validation loss:  0.9898387908935546 , validation accuracy:  43.14508420532464 %, lr:  0.00017282865164912177\n",
+      "Epoch:  139 , validation loss:  0.7954098224639893 , validation accuracy:  49.90748054927337 %, lr:  0.00017282865164912177\n",
+      "Epoch:  140 , validation loss:  0.8848856925964356 , validation accuracy:  48.18369709889301 %, lr:  0.00017282865164912177\n",
+      "Epoch:  141 , validation loss:  0.809971809387207 , validation accuracy:  49.25894264515454 %, lr:  0.00017282865164912177\n",
+      "Epoch:  142 , validation loss:  0.8697308540344239 , validation accuracy:  44.27299189507969 %, lr:  0.00017282865164912177\n",
+      "Epoch:  143 , validation loss:  0.8543578147888183 , validation accuracy:  48.959561966390005 %, lr:  0.00017282865164912177\n",
+      "Epoch:  144 , validation loss:  0.9388646125793457 , validation accuracy:  48.833317101850746 %, lr:  0.00017282865164912177\n",
+      "Epoch:  145 , validation loss:  0.7931929111480713 , validation accuracy:  51.216459444739016 %, lr:  0.00017282865164912177\n",
+      "Epoch:  146 , validation loss:  0.8320839881896973 , validation accuracy:  42.20365821547474 %, lr:  0.00017282865164912177\n",
+      "Epoch:  147 , validation loss:  0.7886894702911377 , validation accuracy:  50.83195365731372 %, lr:  0.00017282865164912177\n",
+      "Epoch:  148 , validation loss:  0.8959216117858887 , validation accuracy:  46.47434163303143 %, lr:  0.00017282865164912177\n",
+      "Epoch:  149 , validation loss:  0.8281922340393066 , validation accuracy:  50.796965794855694 %, lr:  0.00017282865164912177\n",
+      "Epoch:  150 , validation loss:  0.7776147365570069 , validation accuracy:  51.2377407219042 %, lr:  0.00017282865164912177\n",
+      "Epoch:  151 , validation loss:  0.7552031993865966 , validation accuracy:  51.83902697672406 %, lr:  0.00017282865164912177\n",
+      "Epoch:  152 , validation loss:  0.7634076595306396 , validation accuracy:  51.67671215088786 %, lr:  0.00017282865164912177\n",
+      "Epoch:  153 , validation loss:  0.8099335670471192 , validation accuracy:  50.0705167743355 %, lr:  0.00017282865164912177\n",
+      "Epoch:  154 , validation loss:  0.8878345489501953 , validation accuracy:  48.160612323662974 %, lr:  0.00017282865164912177\n",
+      "Epoch:  155 , validation loss:  0.8620566368103028 , validation accuracy:  48.618340132521034 %, lr:  0.00017282865164912177\n",
+      "Epoch:  156 , validation loss:  1.181729507446289 , validation accuracy:  45.421459462773996 %, lr:  0.00017282865164912177\n",
+      "Epoch:  157 , validation loss:  0.8553838729858398 , validation accuracy:  50.34681267787 %, lr:  0.00017282865164912177\n",
+      "Epoch:  158 , validation loss:  0.786921215057373 , validation accuracy:  51.76039446109675 %, lr:  0.00017282865164912177\n",
+      "Epoch:  159 , validation loss:  0.782235050201416 , validation accuracy:  51.862833151180034 %, lr:  0.00017282865164912177\n",
+      "Epoch:  160 , validation loss:  0.7482382297515869 , validation accuracy:  51.70737161799025 %, lr:  0.00017282865164912177\n",
+      "Epoch:  161 , validation loss:  0.8135046005249024 , validation accuracy:  51.0696547022605 %, lr:  0.00017282865164912177\n",
+      "Epoch:  162 , validation loss:  0.8559027671813965 , validation accuracy:  50.84926723873625 %, lr:  0.00017282865164912177\n",
+      "Epoch:  163 , validation loss:  0.792514705657959 , validation accuracy:  51.56273107318956 %, lr:  0.00017282865164912177\n",
+      "Epoch:  164 , validation loss:  0.7892641544342041 , validation accuracy:  51.295813359592266 %, lr:  0.00017282865164912177\n",
+      "Epoch:  165 , validation loss:  0.7436711311340332 , validation accuracy:  48.86073027243642 %, lr:  0.00017282865164912177\n",
+      "Epoch:  166 , validation loss:  0.8520591735839844 , validation accuracy:  49.78917107621943 %, lr:  0.00017282865164912177\n",
+      "Epoch:  167 , validation loss:  1.2555193901062012 , validation accuracy:  41.07106143075108 %, lr:  0.00017282865164912177\n",
+      "Epoch:  168 , validation loss:  0.7791379451751709 , validation accuracy:  51.484098557562255 %, lr:  0.00017282865164912177\n",
+      "Epoch:  169 , validation loss:  1.0667552947998047 , validation accuracy:  45.79117656606754 %, lr:  0.00017282865164912177\n",
+      "Epoch:  170 , validation loss:  1.07796630859375 , validation accuracy:  46.3347508828123 %, lr:  0.00017282865164912177\n",
+      "Epoch:  171 , validation loss:  0.7350554943084717 , validation accuracy:  52.82301552090435 %, lr:  0.00017282865164912177\n",
+      "Epoch:  172 , validation loss:  1.5347043037414552 , validation accuracy:  38.830034735372735 %, lr:  0.00017282865164912177\n",
+      "Epoch:  173 , validation loss:  1.1707054138183595 , validation accuracy:  42.72450845660243 %, lr:  0.00017282865164912177\n",
+      "Epoch:  174 , validation loss:  0.758837366104126 , validation accuracy:  53.706008173453235 %, lr:  0.00017282865164912177\n",
+      "Epoch:  175 , validation loss:  1.2957512855529785 , validation accuracy:  39.6250166823571 %, lr:  0.00017282865164912177\n",
+      "Epoch:  176 , validation loss:  0.7463548660278321 , validation accuracy:  53.55884273136174 %, lr:  0.00017282865164912177\n",
+      "Epoch:  177 , validation loss:  0.7517717361450196 , validation accuracy:  52.09368090348039 %, lr:  0.00017282865164912177\n",
+      "Epoch:  178 , validation loss:  0.98841552734375 , validation accuracy:  44.94028617907293 %, lr:  0.00017282865164912177\n",
+      "Epoch:  179 , validation loss:  0.8063377380371094 , validation accuracy:  49.49015109706787 %, lr:  0.00017282865164912177\n",
+      "Epoch:  180 , validation loss:  0.7806938171386719 , validation accuracy:  52.069514029411444 %, lr:  0.00017282865164912177\n",
+      "Epoch:  181 , validation loss:  0.922697639465332 , validation accuracy:  50.84133184725093 %, lr:  0.00017282865164912177\n",
+      "wandb: Agent Finished Run: ylshjy3t \n",
+      "\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Ctrl-c pressed. Waiting for runs to end. Press ctrl-c again to terminate them.\n"
+     ]
+    }
+   ],
+   "source": [
+    "def train():\n",
+    "           \n",
+    "    print(\"Initialising W&B...\")\n",
+    "    wandb.init()\n",
+    "\n",
+    "    from torch_geometric.data import Data\n",
+    "    from torch_geometric.data import DataLoader\n",
+    "    from torch_scatter import scatter_add\n",
+    "    \n",
+    "    # Local imports\n",
+    "    from utils.toy_utils import load_data, make_mlp\n",
+    "\n",
+    "    class TwoHopAttNetwork(nn.Module):\n",
+    "        \"\"\"\n",
+    "        A module which computes new node features on the graph.\n",
+    "        For each node, it aggregates the neighbor node features\n",
+    "        (separately on the input and output side), and combines\n",
+    "        them with the node's previous features in a fully-connected\n",
+    "        network to compute the new features.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
+    "                     layer_norm=True):\n",
+    "            super(TwoHopAttNetwork, self).__init__()\n",
+    "            self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                    hidden_activation=hidden_activation,\n",
+    "                                    output_activation=hidden_activation,\n",
+    "                                    layer_norm=layer_norm)\n",
+    "\n",
+    "        def forward(self, x, e, edge_index):\n",
+    "            start, end = edge_index\n",
+    "            # Aggregate edge-weighted incoming/outgoing features\n",
+    "            mi = scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mi2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mo = scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            mo2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
+    "            return self.network(node_inputs)\n",
+    "\n",
+    "    class TwoHopNetwork(nn.Module):\n",
+    "        \"\"\"\n",
+    "        A module which computes new node features on the graph.\n",
+    "        For each node, it aggregates the neighbor node features\n",
+    "        (separately on the input and output side), and combines\n",
+    "        them with the node's previous features in a fully-connected\n",
+    "        network to compute the new features.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
+    "                     layer_norm=True):\n",
+    "            super(TwoHopNetwork, self).__init__()\n",
+    "            self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                    hidden_activation=hidden_activation,\n",
+    "                                    output_activation=hidden_activation,\n",
+    "                                    layer_norm=layer_norm)\n",
+    "\n",
+    "        def forward(self, x, e, edge_index):\n",
+    "            start, end = edge_index\n",
+    "            # Aggregate edge-weighted incoming/outgoing features\n",
+    "            mi = scatter_add(x[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mi2 = scatter_add(scatter_add(x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mo = scatter_add(x[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            mo2 = scatter_add(scatter_add(x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
+    "            return self.network(node_inputs)\n",
+    "\n",
+    "    class Edge_Track_Net(nn.Module):\n",
+    "        \"\"\"\n",
+    "        Segment classification graph neural network model.\n",
+    "        Consists of an input network, an edge network, and a node network.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
+    "                     output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
+    "            super(Edge_Track_Net, self).__init__()\n",
+    "            self.n_graph_iters = n_graph_iters\n",
+    "            # Setup the input network\n",
+    "            self.input_network = make_mlp(input_dim, [hidden_dim],\n",
+    "                                          hidden_activation=nn.ReLU,\n",
+    "                                          layer_norm=False)\n",
+    "            # Setup the edge network\n",
+    "            self.edge_network = EdgeNetwork(input_dim+hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation, layer_norm=layer_norm)\n",
+    "            # Setup the node layers\n",
+    "            self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation=nn.ReLU, layer_norm=False)\n",
+    "\n",
+    "    #         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
+    "    #                                         layer_norm=False)\n",
+    "            self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, output_dim],\n",
+    "                                           hidden_activation=nn.ReLU,\n",
+    "                                          output_activation=None,\n",
+    "                                          layer_norm=False)\n",
+    "\n",
+    "        def forward(self, inputs):\n",
+    "            \"\"\"Apply forward pass of the model\"\"\"\n",
+    "            # Apply input network to get hidden representation\n",
+    "            x = self.input_network(inputs.x)\n",
+    "            # Shortcut connect the inputs onto the hidden representation\n",
+    "            x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Loop over iterations of edge and node networks\n",
+    "            for i in range(self.n_graph_iters):\n",
+    "                # Apply edge network\n",
+    "                e = torch.sigmoid(self.edge_network(x, inputs.edge_index))\n",
+    "                # Apply node network\n",
+    "                x = self.node_network(x, e, inputs.edge_index)\n",
+    "                # Shortcut connect the inputs onto the hidden representation\n",
+    "                x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Apply final edge network\n",
+    "            e = self.edge_network(x, inputs.edge_index)\n",
+    "            return e, self.output_network(x)\n",
+    "\n",
+    "    class Edge_Track_Truth_Net(nn.Module):\n",
+    "        \"\"\"\n",
+    "        Segment classification graph neural network model.\n",
+    "        Consists of an input network, an edge network, and a node network.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
+    "                     output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
+    "            super(Edge_Track_Truth_Net, self).__init__()\n",
+    "            self.n_graph_iters = n_graph_iters\n",
+    "            # Setup the input network\n",
+    "            self.input_network = make_mlp(input_dim, [hidden_dim],\n",
+    "                                          hidden_activation=nn.ReLU,\n",
+    "                                          layer_norm=False)\n",
+    "            # Setup the node layers\n",
+    "            self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation=nn.ReLU, layer_norm=False)\n",
+    "\n",
+    "    #         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
+    "    #                                         layer_norm=False)\n",
+    "            self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                           hidden_activation=nn.ReLU,\n",
+    "                                          output_activation=None,\n",
+    "                                          layer_norm=False)\n",
+    "\n",
+    "        def forward(self, inputs):\n",
+    "            \"\"\"Apply forward pass of the model\"\"\"\n",
+    "            # Apply input network to get hidden representation\n",
+    "            x = self.input_network(inputs.x)\n",
+    "            # Shortcut connect the inputs onto the hidden representation\n",
+    "            x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Loop over iterations of edge and node networks\n",
+    "            for i in range(self.n_graph_iters):\n",
+    "                # Apply edge network\n",
+    "                e = inputs.y_edges\n",
+    "                # Apply node network\n",
+    "                x = self.node_network(x, e, inputs.edge_index)\n",
+    "                # Shortcut connect the inputs onto the hidden representation\n",
+    "                x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Apply final edge network\n",
+    "            return self.output_network(x)\n",
+    "\n",
+    "    def validate(model, val_loader, val_size):\n",
+    "        model = model.eval()\n",
+    "        node_correct, node_total, loss = 0, 0, 0\n",
+    "        for batch in val_loader:\n",
+    "            data = batch.to(device)\n",
+    "#             print(len(data.y_params))\n",
+    "            node_pred = model(data)\n",
+    "            node_correct += (((node_pred - data.y_params)/data.y_params)**2 < 0.1**2).sum().item()\n",
+    "            node_total += len(node_pred)\n",
+    "            loss += F.mse_loss(node_pred, data.y_params)\n",
+    "        acc = node_correct / node_total\n",
+    "        return acc, loss.item()/val_size\n",
+    "\n",
+    "    def get_lr(optimizer):\n",
+    "        for param_group in optimizer.param_groups:\n",
+    "            return param_group['lr']\n",
+    "    \n",
+    "    print(\"Loading data...\")\n",
+    "    train_dataset, val_dataset = load_data(train_size=wandb.config.get(\"train_size\",0), test_size=20)\n",
+    "    train_loader, val_loader = DataLoader(train_dataset, batch_size=2, shuffle=True), DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
+    "    \n",
+    "    print(\"config:\", dict(wandb.config.user_items()))\n",
+    "\n",
+    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
+    "    print(\"Using \", device)\n",
+    "    \n",
+    "    m_dic = [\"hidden_dim\", \"n_graph_iters\"]\n",
+    "    m_configs = {k:wandb.config.get(k,0) for k in m_dic} \n",
+    "    m_configs = {'input_dim': 3, **m_configs, 'output_dim': 1}\n",
+    "        \n",
+    "    print(\"Loading model...\")\n",
+    "    print(\"Model configs: \", m_configs)\n",
+    "    model = Edge_Track_Truth_Net(**m_configs).to(device)\n",
+    "    wandb.watch(model, log='all')\n",
+    "    \n",
+    "    print(\"Loading optimiser\")\n",
+    "    o_dic = [\"lr\", \"weight_decay\"]\n",
+    "    o_configs = {k:wandb.config.get(k,0) for k in o_dic} \n",
+    "    optimizer_fn = getattr(torch.optim, wandb.config.get(\"optimizer\",0))\n",
+    "#     optimizer_kwargs = {\"Adam\": {}, \"SGD\": {}}\n",
+    "    optimizer = optimizer_fn(model.parameters(), amsgrad=True, **o_configs)\n",
+    "    \n",
+    "    print(\"Loading scheduler...\")\n",
+    "#     s_dic = [\"step_size\", \"gamma\"]\n",
+    "#     s_configs = {k:wandb.config.get(k,0) for k in s_dic} \n",
+    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30)\n",
+    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10)\n",
+    "    \n",
+    "    model.train()\n",
+    "    \n",
+    "    print(\"Training...\")\n",
+    "    \n",
+    "    ep = 0\n",
+    "    best_acc = 0\n",
+    "#     for epoch in range(wandb.config.get(\"epochs\", 0)):\n",
+    "    while (lr > 6e-6):\n",
+    "        for batch in train_loader:\n",
+    "            optimizer.zero_grad()\n",
+    "            data = batch.to(device)\n",
+    "            node_pred = model(data)\n",
+    "            loss = F.mse_loss(node_pred, data.y_params)\n",
+    "            loss.backward()\n",
+    "            optimizer.step()\n",
+    "        ep += 1\n",
+    "        val_acc, val_loss = validate(model, val_loader, 20)\n",
+    "        if (val_acc > best_acc): best_acc = val_acc\n",
+    "        scheduler.step(val_loss)\n",
+    "        lr = get_lr(optimizer)\n",
+    "        print(\"Epoch: \" , ep, \", validation loss: \", val_loss, \", validation accuracy: \", val_acc*100, \"%, lr: \", lr)\n",
+    "        wandb.log({\"Validation Accuracy\": val_acc, \"Best Accuracy\": best_acc, \"Validation Loss\": val_loss, \"Learning Rate\": lr, \"Epochs\": ep})\n",
+    "            \n",
+    "wandb.agent(sweep_id, function=train)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 6,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:11.240625, resuming normal operation.\n"
+     ]
+    },
+    {
+     "ename": "ControllerError",
+     "evalue": "Only sweeps with a local controller are currently supported.",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mControllerError\u001b[0m                           Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-6-d64628e1e9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msweep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[0;32m~/.local/lib/python3.7/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, verbose, print_status, print_actions, print_debug)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mprint_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mprint_debug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_if_not_started\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m~/.local/lib/python3.7/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36m_start_if_not_started\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mis_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sweep_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'controller'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'local'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mControllerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only sweeps with a local controller are currently supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;31m# reset controller state, we might want to parse this and decide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;31mControllerError\u001b[0m: Only sweeps with a local controller are currently supported."
+     ]
+    }
+   ],
+   "source": [
+    "sweep = wandb.controller(sweep_id)\n",
+    "sweep.run()"
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
diff --git a/notebooks/wandb/settings b/notebooks/wandb/settings
index 8e3b553..cc0e984 100644
--- a/notebooks/wandb/settings
+++ b/notebooks/wandb/settings
@@ -1,4 +1,4 @@
 [default]
 entity = murnanedaniel
-project = node_regression
+project = node_regression_sweep
 
diff --git a/scripts/setup_cgpu.sh b/scripts/setup_cgpu.sh
index 9565b91..7ca434b 100644
--- a/scripts/setup_cgpu.sh
+++ b/scripts/setup_cgpu.sh
@@ -5,4 +5,4 @@ module load openmpi/4.0.1-ucx-1.6
 module load pytorch/v1.2.0-gpu
 
 # Libary path fix
-export LD_LIBRARY_PATH=$(dirname $(which python))/../lib/python3.6/site-packages/torch/lib:$LD_LIBRARY_PATH
+export LD_LIBRARY_PATH=$(dirname $(which python))/../lib/python3.6/site-packages/torch/lib:/global/homes/d/danieltm/.local/lib/python3.7/site-packages:$LD_LIBRARY_PATH
diff --git a/utils/.ipynb_checkpoints/toy_utils-checkpoint.py b/utils/.ipynb_checkpoints/toy_utils-checkpoint.py
index 20e86d3..aa58cda 100644
--- a/utils/.ipynb_checkpoints/toy_utils-checkpoint.py
+++ b/utils/.ipynb_checkpoints/toy_utils-checkpoint.py
@@ -25,7 +25,24 @@ from torch_scatter import *
 
 # Locals
 from torch_geometric.data import Batch
-
+from datasets.hitgraphs_params import *
+
+
+# Data Loading
+
+def load_data(train_size=300, test_size=10):
+    input_dir = "/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/"
+    filenames = [os.path.join(input_dir, f) for f in os.listdir(input_dir)
+                         if f.endswith('.npz') and not f.endswith('_ID.npz')]
+    train_graphs = [load_graph(fi) for fi in filenames[:train_size]]
+    test_graphs = [load_graph(fi) for fi in filenames[:test_size]]
+    train_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),
+                                         edge_index=torch.from_numpy(di[1]), y_edges=torch.from_numpy(di[2]), 
+                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in train_graphs]
+    test_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),
+                                         edge_index=torch.from_numpy(di[1]), y_edges=torch.from_numpy(di[2]), 
+                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in test_graphs]
+    return train_dataset, test_dataset
 
 # Some dumb circle calculations
 def y1(x, r, a, sign):
diff --git a/utils/__pycache__/toy_utils.cpython-36.pyc b/utils/__pycache__/toy_utils.cpython-36.pyc
index a995810..28d2864 100644
Binary files a/utils/__pycache__/toy_utils.cpython-36.pyc and b/utils/__pycache__/toy_utils.cpython-36.pyc differ
diff --git a/utils/toy_utils.py b/utils/toy_utils.py
index 20e86d3..aa58cda 100644
--- a/utils/toy_utils.py
+++ b/utils/toy_utils.py
@@ -25,7 +25,24 @@ from torch_scatter import *
 
 # Locals
 from torch_geometric.data import Batch
-
+from datasets.hitgraphs_params import *
+
+
+# Data Loading
+
+def load_data(train_size=300, test_size=10):
+    input_dir = "/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/"
+    filenames = [os.path.join(input_dir, f) for f in os.listdir(input_dir)
+                         if f.endswith('.npz') and not f.endswith('_ID.npz')]
+    train_graphs = [load_graph(fi) for fi in filenames[:train_size]]
+    test_graphs = [load_graph(fi) for fi in filenames[:test_size]]
+    train_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),
+                                         edge_index=torch.from_numpy(di[1]), y_edges=torch.from_numpy(di[2]), 
+                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in train_graphs]
+    test_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),
+                                         edge_index=torch.from_numpy(di[1]), y_edges=torch.from_numpy(di[2]), 
+                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in test_graphs]
+    return train_dataset, test_dataset
 
 # Some dumb circle calculations
 def y1(x, r, a, sign):
