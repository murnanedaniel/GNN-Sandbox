{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Graph Training Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint as pp\n",
    "from time import time as tt\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "import seaborn as sns\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "# Limit CPU usage on Jupyter\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "# Pick up local packages\n",
    "sys.path.append('..')\n",
    "\n",
    "# Local imports\n",
    "from utils.toy_utils import *\n",
    "from datasets.hitgraphs_params import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading TrackML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mhitgraphs_med_000\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls $SCRATCH/ExaTrkX/node_tracker_data/\n",
    "g1 = np.load(\"/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/event000001000_g000.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/\"\n",
    "filenames = [os.path.join(input_dir, f) for f in os.listdir(input_dir)\n",
    "                         if f.endswith('.npz') and not f.endswith('_ID.npz')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graphs = [load_graph(fi) for fi in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_mask = [~(np.isnan(g[3]).any()) for g in full_graphs]\n",
    "cut_full_graphs = np.array(full_graphs)[cut_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_full_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),\n",
    "                                         edge_index=torch.from_numpy(di[1]), y_edges=torch.from_numpy(di[2]), \n",
    "                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)*200), pid=torch.from_numpy(di[4])) for di in full_graphs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2aab87910320>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(np.concatenate(np.array([di[3][:,0] for di in full_graphs]))[:10]*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Constructing PyG Datastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(1000)]\n",
    "test_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using \", device)\n",
    "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
    "model = Net(train_dataset).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Edge Classification Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , loss:  0.5512356758117676 , accuracy:  0.6864395625058761\n",
      "Epoch:  2 , loss:  0.5046652555465698 , accuracy:  0.7436710645899276\n",
      "Epoch:  3 , loss:  0.48637688159942627 , accuracy:  0.7629634272462315\n",
      "Epoch:  4 , loss:  0.47630026936531067 , accuracy:  0.7705349587890564\n",
      "Epoch:  5 , loss:  0.4798726439476013 , accuracy:  0.7736814064997336\n",
      "Epoch:  6 , loss:  0.4695682227611542 , accuracy:  0.7731611770973706\n",
      "Epoch:  7 , loss:  0.4612908959388733 , accuracy:  0.7738506377511047\n",
      "Epoch:  8 , loss:  0.44322115182876587 , accuracy:  0.7768779968034097\n",
      "Epoch:  9 , loss:  0.46184107661247253 , accuracy:  0.7758438058228087\n",
      "Epoch:  10 , loss:  0.43595728278160095 , accuracy:  0.7730358206148735\n",
      "Epoch:  11 , loss:  0.40324726700782776 , accuracy:  0.7812466702184336\n",
      "Epoch:  12 , loss:  0.3373474180698395 , accuracy:  0.7961014133943402\n",
      "Epoch:  13 , loss:  0.27982667088508606 , accuracy:  0.8321476699363816\n",
      "Epoch:  14 , loss:  0.2253979742527008 , accuracy:  0.8571813594910527\n",
      "Epoch:  15 , loss:  0.21640172600746155 , accuracy:  0.8812498041304961\n",
      "Epoch:  16 , loss:  0.1846497803926468 , accuracy:  0.9013381804506565\n",
      "Epoch:  17 , loss:  0.2350691705942154 , accuracy:  0.8991068350622081\n",
      "Epoch:  18 , loss:  0.1935807168483734 , accuracy:  0.8991256385345827\n",
      "Epoch:  19 , loss:  0.15857245028018951 , accuracy:  0.912563853458272\n",
      "Epoch:  20 , loss:  0.18233557045459747 , accuracy:  0.9181923595223918\n",
      "Epoch:  21 , loss:  0.16060705482959747 , accuracy:  0.9187752671660033\n",
      "Epoch:  22 , loss:  0.15544316172599792 , accuracy:  0.9248111817982387\n",
      "Epoch:  23 , loss:  0.12819615006446838 , accuracy:  0.9281519320567865\n",
      "Epoch:  24 , loss:  0.1715494692325592 , accuracy:  0.9166567426118023\n",
      "Epoch:  25 , loss:  0.15350672602653503 , accuracy:  0.9195086025886113\n",
      "Epoch:  26 , loss:  0.13381382822990417 , accuracy:  0.9310163276818453\n",
      "Epoch:  27 , loss:  0.16854779422283173 , accuracy:  0.9178727004920242\n",
      "Epoch:  28 , loss:  0.12585857510566711 , accuracy:  0.9288288570622708\n",
      "Epoch:  29 , loss:  0.1297493726015091 , accuracy:  0.936086997398853\n",
      "Epoch:  30 , loss:  0.13670764863491058 , accuracy:  0.9336112068695352\n",
      "Epoch:  31 , loss:  0.12563517689704895 , accuracy:  0.9378733272744367\n",
      "Epoch:  32 , loss:  0.10643548518419266 , accuracy:  0.9423736249960826\n",
      "Epoch:  33 , loss:  0.11343897879123688 , accuracy:  0.9475069729543389\n",
      "Epoch:  34 , loss:  0.10112588107585907 , accuracy:  0.9496004262120404\n",
      "Epoch:  35 , loss:  0.10293048620223999 , accuracy:  0.9479018458742048\n",
      "Epoch:  36 , loss:  0.10879960656166077 , accuracy:  0.9497132470462879\n",
      "Epoch:  37 , loss:  0.08479493856430054 , accuracy:  0.9517252185903664\n",
      "Epoch:  38 , loss:  0.08469492197036743 , accuracy:  0.9548340593562945\n",
      "Epoch:  39 , loss:  0.09417087584733963 , accuracy:  0.9555423234824031\n",
      "Epoch:  40 , loss:  0.09632786363363266 , accuracy:  0.9555172521859037\n",
      "Epoch:  41 , loss:  0.09234034270048141 , accuracy:  0.9530728007772102\n",
      "Epoch:  42 , loss:  0.07967119663953781 , accuracy:  0.9559309285781441\n",
      "Epoch:  43 , loss:  0.08349929749965668 , accuracy:  0.957924096649848\n",
      "Epoch:  44 , loss:  0.07990405708551407 , accuracy:  0.957710990629603\n",
      "Epoch:  45 , loss:  0.09039483219385147 , accuracy:  0.9594722492086872\n",
      "Epoch:  46 , loss:  0.0847826823592186 , accuracy:  0.9588266633238272\n",
      "Epoch:  47 , loss:  0.07450012862682343 , accuracy:  0.9607258140336582\n",
      "Epoch:  48 , loss:  0.08207990229129791 , accuracy:  0.9606819392647842\n",
      "Epoch:  49 , loss:  0.08625155687332153 , accuracy:  0.9572221003478643\n",
      "Epoch:  50 , loss:  0.08353188633918762 , accuracy:  0.9602118524554201\n",
      "Epoch:  51 , loss:  0.07035135477781296 , accuracy:  0.9608699739885299\n",
      "Epoch:  52 , loss:  0.07894345372915268 , accuracy:  0.9623930552508697\n",
      "Epoch:  53 , loss:  0.08261425048112869 , accuracy:  0.9617098624212604\n",
      "Epoch:  54 , loss:  0.07314658910036087 , accuracy:  0.9608449026920305\n",
      "Epoch:  55 , loss:  0.07553153485059738 , accuracy:  0.9610956156570246\n",
      "Epoch:  56 , loss:  0.08274070173501968 , accuracy:  0.9619856466827541\n",
      "Epoch:  57 , loss:  0.07393041253089905 , accuracy:  0.9628004638189852\n",
      "Epoch:  58 , loss:  0.07949676364660263 , accuracy:  0.9619104327932558\n",
      "Epoch:  59 , loss:  0.07388246804475784 , accuracy:  0.9609201165815288\n",
      "Epoch:  60 , loss:  0.07234286516904831 , accuracy:  0.9622676987683726\n",
      "Epoch:  61 , loss:  0.07553829252719879 , accuracy:  0.964154313829954\n",
      "Epoch:  62 , loss:  0.07114172726869583 , accuracy:  0.9638973330408349\n",
      "Epoch:  63 , loss:  0.07683456689119339 , accuracy:  0.9638597260960857\n",
      "Epoch:  64 , loss:  0.07580337673425674 , accuracy:  0.9636027453069667\n",
      "Epoch:  65 , loss:  0.07201939821243286 , accuracy:  0.9629508915979818\n",
      "Epoch:  66 , loss:  0.06553474068641663 , accuracy:  0.9643987589708233\n",
      "Epoch:  67 , loss:  0.0714544951915741 , accuracy:  0.9651320943934313\n",
      "Epoch:  68 , loss:  0.06275434046983719 , accuracy:  0.9649503274938105\n",
      "Epoch:  69 , loss:  0.06658802181482315 , accuracy:  0.966097339308659\n",
      "Epoch:  70 , loss:  0.0704989805817604 , accuracy:  0.9662540349117804\n",
      "Epoch:  71 , loss:  0.059061162173748016 , accuracy:  0.9654705568961734\n",
      "Epoch:  72 , loss:  0.06813564896583557 , accuracy:  0.9660597323639099\n",
      "Epoch:  73 , loss:  0.06905221194028854 , accuracy:  0.9658716976401642\n",
      "Epoch:  74 , loss:  0.0689922496676445 , accuracy:  0.9655771099062961\n",
      "Epoch:  75 , loss:  0.06837943941354752 , accuracy:  0.9663229809771537\n",
      "Epoch:  76 , loss:  0.05394389107823372 , accuracy:  0.9671127268168855\n",
      "Epoch:  77 , loss:  0.07251249998807907 , accuracy:  0.9667930677865179\n",
      "Epoch:  78 , loss:  0.07537279278039932 , accuracy:  0.9664169983390266\n",
      "Epoch:  79 , loss:  0.06626568734645844 , accuracy:  0.9660221254191608\n",
      "Epoch:  80 , loss:  0.07760695368051529 , accuracy:  0.9664734087561503\n",
      "Epoch:  81 , loss:  0.06580779701471329 , accuracy:  0.9625748221504905\n",
      "Epoch:  82 , loss:  0.05862663313746452 , accuracy:  0.9656147168510452\n",
      "Epoch:  83 , loss:  0.060530368238687515 , accuracy:  0.9675577423297502\n",
      "Epoch:  84 , loss:  0.05909406766295433 , accuracy:  0.969168573129838\n",
      "Epoch:  85 , loss:  0.06882461905479431 , accuracy:  0.9686734150239744\n",
      "Epoch:  86 , loss:  0.0680612325668335 , accuracy:  0.9690244131749663\n",
      "Epoch:  87 , loss:  0.05981859937310219 , accuracy:  0.971330972452913\n",
      "Epoch:  88 , loss:  0.05889563262462616 , accuracy:  0.9706289761509292\n",
      "Epoch:  89 , loss:  0.06496661901473999 , accuracy:  0.9716819706039048\n",
      "Epoch:  90 , loss:  0.05609319731593132 , accuracy:  0.9718637375035256\n",
      "Epoch:  91 , loss:  0.05172021687030792 , accuracy:  0.9737190134444828\n",
      "Epoch:  92 , loss:  0.061566054821014404 , accuracy:  0.972841518067003\n",
      "Epoch:  93 , loss:  0.05868617817759514 , accuracy:  0.9713121689805384\n",
      "Epoch:  94 , loss:  0.05601102486252785 , accuracy:  0.9713936506941615\n",
      "Epoch:  95 , loss:  0.0565975159406662 , accuracy:  0.972885392835877\n",
      "Epoch:  96 , loss:  0.06436861306428909 , accuracy:  0.9743332602087186\n",
      "Epoch:  97 , loss:  0.05844764783978462 , accuracy:  0.9742831176157197\n",
      "Epoch:  98 , loss:  0.04329262301325798 , accuracy:  0.972797643298129\n",
      "Epoch:  99 , loss:  0.04300661012530327 , accuracy:  0.9760318405465542\n",
      "Epoch:  100 , loss:  0.060396987944841385 , accuracy:  0.9762888213356733\n",
      "Epoch:  101 , loss:  0.050678230822086334 , accuracy:  0.9777053495878906\n",
      "Epoch:  102 , loss:  0.0520532988011837 , accuracy:  0.976345231752797\n",
      "Epoch:  103 , loss:  0.04601125046610832 , accuracy:  0.9768403898586606\n",
      "Epoch:  104 , loss:  0.05154242366552353 , accuracy:  0.9773230123162744\n",
      "Epoch:  105 , loss:  0.04324488714337349 , accuracy:  0.9760757153154282\n",
      "Epoch:  106 , loss:  0.05357293039560318 , accuracy:  0.9770597637030305\n",
      "Epoch:  107 , loss:  0.05393035709857941 , accuracy:  0.977210191482027\n",
      "Epoch:  108 , loss:  0.06744545698165894 , accuracy:  0.9722147356545175\n",
      "Epoch:  109 , loss:  0.050511591136455536 , accuracy:  0.9722084678303927\n",
      "Epoch:  110 , loss:  0.04840807616710663 , accuracy:  0.9769281393964085\n",
      "Epoch:  111 , loss:  0.04603151977062225 , accuracy:  0.9788460935786142\n",
      "Epoch:  112 , loss:  0.049852970987558365 , accuracy:  0.9779121877840108\n",
      "Epoch:  113 , loss:  0.06091667711734772 , accuracy:  0.977517314864145\n",
      "Epoch:  114 , loss:  0.045730751007795334 , accuracy:  0.9755742893854399\n",
      "Epoch:  115 , loss:  0.046588025987148285 , accuracy:  0.9791594847848569\n",
      "Epoch:  116 , loss:  0.04268786311149597 , accuracy:  0.979761195900843\n",
      "Epoch:  117 , loss:  0.05151399224996567 , accuracy:  0.9765896768936664\n",
      "Epoch:  118 , loss:  0.045346617698669434 , accuracy:  0.9789275752922373\n",
      "Epoch:  119 , loss:  0.040606942027807236 , accuracy:  0.9785201667241217\n",
      "Epoch:  120 , loss:  0.03887306526303291 , accuracy:  0.9797486602525933\n",
      "Epoch:  121 , loss:  0.043499015271663666 , accuracy:  0.9801874079413332\n",
      "Epoch:  122 , loss:  0.042412832379341125 , accuracy:  0.9791469491366073\n",
      "Epoch:  123 , loss:  0.04148733615875244 , accuracy:  0.980193675765458\n",
      "Epoch:  124 , loss:  0.03858195245265961 , accuracy:  0.9796609107148453\n",
      "Epoch:  125 , loss:  0.03824522718787193 , accuracy:  0.9811714563289354\n",
      "Epoch:  126 , loss:  0.04555254429578781 , accuracy:  0.97946034034285\n",
      "Epoch:  127 , loss:  0.04094495251774788 , accuracy:  0.977899652135761\n",
      "Epoch:  128 , loss:  0.03822688013315201 , accuracy:  0.9811401172083112\n",
      "Epoch:  129 , loss:  0.030357101932168007 , accuracy:  0.9822557899025354\n",
      "Epoch:  130 , loss:  0.03848995640873909 , accuracy:  0.9800933905794603\n",
      "Epoch:  131 , loss:  0.034991804510354996 , accuracy:  0.9812341345701839\n",
      "Epoch:  132 , loss:  0.03558206930756569 , accuracy:  0.9811965276254349\n",
      "Epoch:  133 , loss:  0.047384537756443024 , accuracy:  0.9814033658215551\n",
      "Epoch:  134 , loss:  0.03825727105140686 , accuracy:  0.9815224544799273\n",
      "Epoch:  135 , loss:  0.03913990408182144 , accuracy:  0.9816979535554232\n",
      "Epoch:  136 , loss:  0.050426892936229706 , accuracy:  0.9813344197561816\n",
      "Epoch:  137 , loss:  0.04604649543762207 , accuracy:  0.9807640477608198\n",
      "Epoch:  138 , loss:  0.04506449028849602 , accuracy:  0.9819486665204175\n",
      "Epoch:  139 , loss:  0.07405521720647812 , accuracy:  0.9720267009307719\n",
      "Epoch:  140 , loss:  0.04675091430544853 , accuracy:  0.9755868250336895\n",
      "Epoch:  141 , loss:  0.03860006853938103 , accuracy:  0.980538406092325\n",
      "Epoch:  142 , loss:  0.03254537656903267 , accuracy:  0.9821555047165377\n",
      "Epoch:  143 , loss:  0.040432099252939224 , accuracy:  0.9814973831834278\n",
      "Epoch:  144 , loss:  0.04703542962670326 , accuracy:  0.9801372653483343\n",
      "Epoch:  145 , loss:  0.03535279259085655 , accuracy:  0.9815099188316776\n",
      "Epoch:  146 , loss:  0.03875648230314255 , accuracy:  0.9833150521796359\n",
      "Epoch:  147 , loss:  0.04009599611163139 , accuracy:  0.9814033658215551\n",
      "Epoch:  148 , loss:  0.045232970267534256 , accuracy:  0.9813845623491805\n",
      "Epoch:  149 , loss:  0.03929991275072098 , accuracy:  0.9841612084364912\n",
      "Epoch:  150 , loss:  0.03452068567276001 , accuracy:  0.9841047980193676\n",
      "Epoch:  151 , loss:  0.03560980409383774 , accuracy:  0.9832962487072613\n",
      "Epoch:  152 , loss:  0.041717901825904846 , accuracy:  0.9828010906013978\n",
      "Epoch:  153 , loss:  0.057955581694841385 , accuracy:  0.9778056347738883\n",
      "Epoch:  154 , loss:  0.04936639219522476 , accuracy:  0.9731674449214955\n",
      "Epoch:  155 , loss:  0.04441019147634506 , accuracy:  0.977122441944279\n",
      "Epoch:  156 , loss:  0.03909330815076828 , accuracy:  0.981967469992792\n",
      "Epoch:  157 , loss:  0.030724773183465004 , accuracy:  0.9836660503306277\n",
      "Epoch:  158 , loss:  0.0435817688703537 , accuracy:  0.9832774452348867\n",
      "Epoch:  159 , loss:  0.033314041793346405 , accuracy:  0.9824124855056567\n",
      "Epoch:  160 , loss:  0.0374787338078022 , accuracy:  0.983264909586637\n",
      "Epoch:  161 , loss:  0.030533701181411743 , accuracy:  0.9833213200037607\n",
      "Epoch:  162 , loss:  0.035522811114788055 , accuracy:  0.9842301545018647\n",
      "Epoch:  163 , loss:  0.0327361561357975 , accuracy:  0.9842364223259895\n",
      "Epoch:  164 , loss:  0.03695467859506607 , accuracy:  0.9837914068131248\n",
      "Epoch:  165 , loss:  0.03675539046525955 , accuracy:  0.9829201792597699\n",
      "Epoch:  166 , loss:  0.039733801037073135 , accuracy:  0.9826381271741514\n",
      "Epoch:  167 , loss:  0.03238556906580925 , accuracy:  0.9838791563508728\n",
      "Epoch:  168 , loss:  0.030454277992248535 , accuracy:  0.9841925475571155\n",
      "Epoch:  169 , loss:  0.043676987290382385 , accuracy:  0.983007928797518\n",
      "Epoch:  170 , loss:  0.04005815088748932 , accuracy:  0.9820050769375411\n",
      "Epoch:  171 , loss:  0.045554470270872116 , accuracy:  0.9817418283242972\n",
      "Epoch:  172 , loss:  0.03457340970635414 , accuracy:  0.9826694662947758\n",
      "Epoch:  173 , loss:  0.033884212374687195 , accuracy:  0.9835406938481306\n",
      "Epoch:  174 , loss:  0.030815908685326576 , accuracy:  0.9840483876022439\n",
      "Epoch:  175 , loss:  0.03124821186065674 , accuracy:  0.9849258829797236\n",
      "Epoch:  176 , loss:  0.03896614909172058 , accuracy:  0.9772603340750259\n",
      "Epoch:  177 , loss:  0.034430284053087234 , accuracy:  0.9812529380425585\n",
      "Epoch:  178 , loss:  0.037297699600458145 , accuracy:  0.9817731674449215\n",
      "Epoch:  179 , loss:  0.0333557203412056 , accuracy:  0.9834090695415086\n",
      "Epoch:  180 , loss:  0.0382612943649292 , accuracy:  0.9839042276473722\n",
      "Epoch:  181 , loss:  0.03331493213772774 , accuracy:  0.9845811526528565\n",
      "Epoch:  182 , loss:  0.024810975417494774 , accuracy:  0.9847002413112288\n",
      "Epoch:  183 , loss:  0.0436268150806427 , accuracy:  0.9776990817637657\n",
      "Epoch:  184 , loss:  0.04014063626527786 , accuracy:  0.9790341283023598\n",
      "Epoch:  185 , loss:  0.037939392030239105 , accuracy:  0.9835156225516312\n",
      "Epoch:  186 , loss:  0.026451334357261658 , accuracy:  0.9848882760349744\n",
      "Epoch:  187 , loss:  0.02467665821313858 , accuracy:  0.9855338619198345\n",
      "Epoch:  188 , loss:  0.03608778864145279 , accuracy:  0.9855338619198345\n",
      "Epoch:  189 , loss:  0.02868589572608471 , accuracy:  0.9848067943213513\n",
      "Epoch:  190 , loss:  0.026818392798304558 , accuracy:  0.9853708984925883\n",
      "Epoch:  191 , loss:  0.030235012993216515 , accuracy:  0.9854649158544612\n",
      "Epoch:  192 , loss:  0.029142208397388458 , accuracy:  0.9861230373875709\n",
      "Epoch:  193 , loss:  0.02885563299059868 , accuracy:  0.9865680529004356\n",
      "Epoch:  194 , loss:  0.030767781659960747 , accuracy:  0.9868438371619292\n",
      "Epoch:  195 , loss:  0.031723205000162125 , accuracy:  0.9850136325174715\n",
      "Epoch:  196 , loss:  0.03449144959449768 , accuracy:  0.985471183678586\n",
      "Epoch:  197 , loss:  0.03040768951177597 , accuracy:  0.985991413080949\n",
      "Epoch:  198 , loss:  0.02778073027729988 , accuracy:  0.9841800119088658\n",
      "Epoch:  199 , loss:  0.031113574281334877 , accuracy:  0.984737848255978\n",
      "Epoch:  200 , loss:  0.0350588783621788 , accuracy:  0.985038703813971\n",
      "Epoch:  201 , loss:  0.03575316071510315 , accuracy:  0.9850261681657213\n",
      "Epoch:  202 , loss:  0.027306491509079933 , accuracy:  0.9857469679400797\n",
      "Epoch:  203 , loss:  0.02635180577635765 , accuracy:  0.9861669121564449\n",
      "Epoch:  204 , loss:  0.05310515686869621 , accuracy:  0.9747782757215833\n",
      "Epoch:  205 , loss:  0.04839653521776199 , accuracy:  0.9793851264533517\n",
      "Epoch:  206 , loss:  0.03698990121483803 , accuracy:  0.9839481024162462\n",
      "Epoch:  207 , loss:  0.03777533397078514 , accuracy:  0.9848255977937259\n",
      "Epoch:  208 , loss:  0.03729405999183655 , accuracy:  0.9835845686170046\n",
      "Epoch:  209 , loss:  0.031062213703989983 , accuracy:  0.9845059387633583\n",
      "Epoch:  210 , loss:  0.023279579356312752 , accuracy:  0.9856529505782068\n",
      "Epoch:  211 , loss:  0.03791983425617218 , accuracy:  0.9857657714124541\n",
      "Epoch:  212 , loss:  0.03225843608379364 , accuracy:  0.9841549406123664\n",
      "Epoch:  213 , loss:  0.035936351865530014 , accuracy:  0.9843993857532357\n",
      "Epoch:  214 , loss:  0.034864574670791626 , accuracy:  0.9852768811307154\n",
      "Epoch:  215 , loss:  0.028552347794175148 , accuracy:  0.9857908427089536\n",
      "Epoch:  216 , loss:  0.02753402292728424 , accuracy:  0.9852267385377166\n",
      "Epoch:  217 , loss:  0.031228698790073395 , accuracy:  0.9858535209502022\n",
      "Epoch:  218 , loss:  0.028560616075992584 , accuracy:  0.9865429816039362\n",
      "Epoch:  219 , loss:  0.031074870377779007 , accuracy:  0.9857156288194553\n",
      "Epoch:  220 , loss:  0.03851897269487381 , accuracy:  0.9836785859788775\n",
      "Epoch:  221 , loss:  0.039986029267311096 , accuracy:  0.983396533893259\n",
      "Epoch:  222 , loss:  0.033866241574287415 , accuracy:  0.9857281644677051\n",
      "Epoch:  223 , loss:  0.026249274611473083 , accuracy:  0.9867122128553073\n",
      "Epoch:  224 , loss:  0.0259819608181715 , accuracy:  0.9858033783572033\n",
      "Epoch:  225 , loss:  0.02425507828593254 , accuracy:  0.9853708984925883\n",
      "Epoch:  226 , loss:  0.03318915516138077 , accuracy:  0.9861105017393212\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-f515b0ae1d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/d/danieltm/ExaTrkX/eta-tracker/notebooks/toy_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_graph_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# Apply edge network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0;31m# Apply node network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/d/danieltm/ExaTrkX/eta-tracker/notebooks/toy_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0medge_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNodeNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 152\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \"\"\"\n\u001b[1;32m   1681\u001b[0m     return torch.layer_norm(input, normalized_shape, weight, bias, eps,\n\u001b[0;32m-> 1682\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_v = []\n",
    "acc_v = []\n",
    "ep = 0\n",
    "for epoch in range(500):\n",
    "    ep += 1\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in train_loader:\n",
    "#         print(batch.x)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        pred = model(data)\n",
    "        loss = F.binary_cross_entropy_with_logits(pred.float(), data.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += ((pred > 0.5) == (data.y > 0.5)).sum().item()\n",
    "#         print(correct, pred, data.y)\n",
    "        total += len(pred)\n",
    "#         print(out, data.y, )\n",
    "    acc = correct/total\n",
    "    print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", accuracy: \", acc)\n",
    "    loss_v.append(loss)\n",
    "    acc_v.append(acc)\n",
    "plt.plot(np.arange(len(loss_v)), loss_v)\n",
    "plt.plot(np.arange(len(acc_v)), acc_v)\n",
    "plt.ylim(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[5930], edge_index=[2, 14580], x=[5930, 2], y=[14580])\n",
      "Accuracy: 0.9812\n",
      "Batch(batch=[5880], edge_index=[2, 14637], x=[5880, 2], y=[14637])\n",
      "Accuracy: 0.9832\n",
      "Batch(batch=[5580], edge_index=[2, 14190], x=[5580, 2], y=[14190])\n",
      "Accuracy: 0.9862\n",
      "Batch(batch=[5710], edge_index=[2, 14652], x=[5710, 2], y=[14652])\n",
      "Accuracy: 0.9838\n",
      "Batch(batch=[5470], edge_index=[2, 12952], x=[5470, 2], y=[12952])\n",
      "Accuracy: 0.9866\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    data = batch.to(device)\n",
    "    pred = model(data)\n",
    "    correct = ((pred > 0.5) == (data.y > 0.5)).sum().item()\n",
    "    acc = correct / len(pred)\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Track Count Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(1000)]\n",
    "test_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using \", device)\n",
    "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
    "model = Net(train_dataset).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 9,  9,  7,  4,  7,  3,  5,  7,  6,  7,  4,  7,  2,  6,  5,  6,  7,  9,\n",
      "         5,  9,  6,  9,  5,  7,  8,  8,  4,  4,  7,  5,  6,  4,  4,  8, 10,  1,\n",
      "         5,  8,  8,  5,  8,  4,  9,  5,  9,  6,  2,  9,  5,  4,  7,  4,  9,  5,\n",
      "         9,  5,  5,  4,  9,  6,  5,  7,  6,  4,  7,  4, 11,  4, 11,  5,  7,  4,\n",
      "         7,  7,  9,  5,  3,  7,  3,  6,  3,  8,  3,  6,  6,  4,  6,  4,  8,  3,\n",
      "         7,  7,  8,  2,  6,  6,  3,  4,  8,  2], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 3, 10,  9,  3,  7,  7,  5,  8,  4,  6, 10,  4,  7,  5,  3,  5, 10,  7,\n",
      "         4,  6,  9,  5,  7,  4,  8,  4,  3,  6,  3,  6,  5,  4,  9,  7,  6,  8,\n",
      "         7,  8,  9,  3,  3,  7,  9,  8,  7,  4, 11,  6,  6,  4,  4,  8,  5,  7,\n",
      "         4,  5,  6,  6,  7,  4,  6,  3,  7,  5,  6,  8,  6,  8,  8,  9,  4,  8,\n",
      "         4,  7,  7,  5,  6,  7,  5,  7,  3,  7,  6,  5,  8,  5,  2,  5,  7,  5,\n",
      "         7,  3,  9,  9,  5,  9,  7,  4,  6,  7], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 8,  4,  2,  7,  7,  4,  5,  6,  9,  6,  3,  7,  7,  5,  9,  3,  5,  5,\n",
      "         4,  5,  9,  9,  7,  7,  8,  3,  7,  5,  9,  6,  7,  3,  6,  5,  9,  3,\n",
      "        10,  3,  7,  5,  9,  6,  5,  8,  4,  3,  3,  6,  4,  5,  4, 10,  7,  5,\n",
      "         5,  6,  9,  5,  6,  5,  6,  4,  7,  4,  3,  3,  6,  8,  6, 10,  7,  7,\n",
      "         8,  4,  5,  3,  8,  8,  4,  2,  5,  5,  3,  9,  5, 11,  9,  5,  3,  6,\n",
      "         9,  4,  9,  8,  7,  7,  5,  4,  6,  7], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 4,  4,  6,  7,  9,  8,  4,  8,  4,  4,  3, 11,  4,  6,  9,  6,  7,  5,\n",
      "         7,  8,  6,  5,  4,  7,  9,  9,  4,  4,  9,  9,  4,  6,  5,  4,  6,  7,\n",
      "         4,  9,  4,  4,  6,  8,  6,  2,  6,  6,  3,  7,  6,  7,  2,  7,  7,  3,\n",
      "         3,  6,  7,  7,  7,  3,  7,  7,  5,  2,  9,  7, 10,  8,  7,  7,  3,  8,\n",
      "         3,  5,  6,  7,  7,  6,  5,  6,  7, 11,  2,  8, 10,  7,  8,  7,  6,  5,\n",
      "         4, 10, 10,  4,  3,  7,  8,  6,  5,  7], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 4,  4,  7,  8,  7,  5,  2,  6,  6,  2,  7,  4,  7,  4,  6,  5,  7,  7,\n",
      "         5,  6,  2, 10,  4,  5,  7,  8,  5,  7,  5,  8, 10,  5,  8,  4,  7,  8,\n",
      "         6,  9,  5,  5,  9,  8,  9,  5,  3,  7,  7,  6, 10,  7,  6,  3,  7,  7,\n",
      "         5,  9,  4,  6,  5,  9,  5,  5,  5,  9,  9,  7,  7,  6,  6,  5,  6,  7,\n",
      "         4,  4,  6,  4,  3,  7,  3,  8,  6,  3,  5,  5,  5,  8,  6,  5,  3,  8,\n",
      "        11,  5,  3,  4,  4,  8,  5,  8,  9,  3], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 4,  8,  3,  5,  4,  4,  8,  7,  7,  7,  8,  9,  4,  9,  9,  6,  5,  7,\n",
      "         7,  7,  8,  5,  5,  9,  6,  5,  3,  8,  4,  5,  7,  5,  3, 10,  6,  5,\n",
      "         3,  6,  5,  2,  5, 11,  5,  6,  4,  6,  8,  7,  5,  7,  9,  6,  8,  3,\n",
      "         7,  8,  2,  8,  4,  4,  4,  9,  6,  4,  6,  6,  6,  5,  9,  4,  7,  8,\n",
      "         4,  5,  3,  7,  5,  7,  3,  8,  4,  8,  8,  8,  5,  6,  9,  8,  6,  5,\n",
      "         6, 10,  7,  9,  4,  7,  2,  4,  7, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 5,  3,  7,  6,  6,  7,  8,  3,  2,  6,  3,  4,  3,  8,  3,  4,  4,  4,\n",
      "         8,  5,  6,  3,  4,  8,  4,  7,  6,  9,  7,  9,  9,  9,  5,  6,  7,  4,\n",
      "         5,  8,  3,  6,  9,  3,  8,  6,  9,  5,  5,  6,  7,  1, 10,  4,  8,  6,\n",
      "         5,  6, 10,  4,  9,  8,  4,  7,  4,  5,  4,  5,  9,  5,  7,  9,  7,  6,\n",
      "         5, 10,  9,  8,  3,  6,  2,  4,  8,  6,  7,  7,  5,  3,  4,  6,  8,  9,\n",
      "         5,  8,  6,  6,  6,  5,  5,  4,  6,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 7,  7,  4,  8,  6,  6,  7,  3,  6,  5,  3,  5,  7, 10,  6,  7,  9, 10,\n",
      "         4,  4,  5,  6,  5,  7,  8,  9,  7,  3,  7,  3,  5,  8,  8,  9,  6,  5,\n",
      "         7, 10,  8,  7,  7,  5,  8,  4,  7, 10,  8,  5,  8,  7,  7,  9,  7,  7,\n",
      "         4,  8,  5,  8,  5,  6, 10,  3,  3,  7,  7, 10,  5,  8,  7,  3,  9, 10,\n",
      "         3,  4, 10,  8,  5,  5,  4, 10,  7,  6,  5, 10,  9,  6,  8,  5,  9,  5,\n",
      "         7,  3,  4,  6,  3,  6,  5,  7,  8,  8], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([10,  6,  6,  8,  9,  6,  4,  6,  9,  6,  9,  8,  7,  4,  7, 10,  9,  5,\n",
      "         4,  9,  4,  6,  4,  4,  8,  4,  5,  4,  8, 10,  2,  2,  7,  5,  5,  7,\n",
      "         6,  3, 11,  9,  7, 10,  4,  5,  3,  2,  8,  4,  5,  3,  8,  9,  4,  8,\n",
      "         5, 11,  4,  9,  6,  7,  8,  4,  5,  3,  3, 10,  9,  7,  2,  7,  9, 10,\n",
      "         5,  4,  6,  3,  9,  3,  7,  5,  7,  8,  5,  7,  4,  4,  5,  4,  8,  8,\n",
      "         6,  3,  7,  9, 10,  8, 10,  4,  6,  5], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 9,  5,  5,  8,  9,  4,  5,  8,  5,  3,  8,  6,  9,  1,  6,  6,  7,  6,\n",
      "         4,  5,  6,  4,  8,  4,  8,  7,  7,  8,  9,  6,  9, 10,  7,  8,  3,  3,\n",
      "         8,  5,  6,  5,  8,  3,  9,  7,  7,  8,  5, 10,  4,  3,  4,  7,  6,  8,\n",
      "         4,  3,  3,  1,  4,  8,  9, 10,  6,  4,  8,  2, 10,  7,  4,  2,  6,  4,\n",
      "         8, 10,  4,  8,  2, 10,  8,  8,  3,  3,  9,  4,  8,  7,  6,  3,  3,  6,\n",
      "         9,  7,  9,  7,  5, 10,  8,  7,  3,  8], device='cuda:0')\n",
      "Epoch:  1 , loss:  2.449791431427002 , accuracy:  0.14\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 6,  7,  9, 10,  6,  8,  2,  3,  4,  9,  7,  7,  5,  8,  3,  5, 10,  3,\n",
      "         4,  7,  4,  6,  5,  7,  7,  4,  4,  4,  5,  7,  7,  6,  7,  3,  5,  5,\n",
      "         5,  8,  4,  7,  4,  7,  5,  4,  6,  9,  6,  8,  4,  6,  8,  6, 10,  8,\n",
      "         4,  5,  6,  6,  5,  4,  7,  7,  6,  3,  4,  5,  5,  4,  4,  9,  5,  3,\n",
      "         9,  3,  7,  5,  5,  3,  4,  5,  7,  4,  8,  5,  7,  5,  7,  7,  6,  7,\n",
      "         5,  7,  5,  8,  8,  4,  6, 10,  6,  3], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 4, 6, 4, 6, 6, 4, 4, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 4, 4, 6, 6, 4, 4, 6, 4, 4, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 4, 4, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 4, 6, 4,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([11,  7,  2,  9,  3,  8,  8,  4,  3,  9,  6,  6,  6,  8,  5,  7,  3,  5,\n",
      "         9,  8,  8,  5,  5,  8,  7,  8,  7,  9,  6,  4,  8, 10,  3,  5,  4,  9,\n",
      "         9,  6,  3,  7,  9,  7,  9,  9,  7,  7,  5,  8,  4,  7,  7,  9,  7,  7,\n",
      "         7,  9,  9,  2,  9,  3,  4, 10,  5,  5,  5,  8,  5,  3,  6,  4,  9,  7,\n",
      "         7,  7,  8, 10,  4,  5,  2,  9,  3,  8,  4,  7,  8,  8,  8,  6,  6,  3,\n",
      "         4,  5,  8,  5,  9,  6,  8,  7,  9,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 4, 6, 4, 4, 6, 4, 4, 6, 6, 4, 4, 4, 6, 6, 4, 4, 6, 4, 4, 6, 4, 6, 4,\n",
      "        4, 6, 6, 4, 4, 6, 4, 6, 4, 4, 6, 4, 6, 4, 6, 4, 4, 4, 4, 4, 4, 4, 6, 4,\n",
      "        4, 6, 6, 4, 4, 4, 4, 6, 4, 4, 4, 4, 6, 4, 4, 6, 4, 4, 4, 4, 6, 6, 4, 4,\n",
      "        4, 4, 4, 4, 6, 4, 4, 4, 6, 6, 4, 6, 4, 4, 4, 6, 6, 4, 6, 4, 6, 4, 4, 4,\n",
      "        4, 4, 6, 6], device='cuda:0') tensor([ 4,  6,  8,  5,  4, 10,  8,  5,  6,  8,  6,  8,  6,  6,  8,  5,  4,  8,\n",
      "         6,  3,  7,  5,  9,  4,  5,  7,  5,  6,  3,  6,  3,  8,  5,  3,  9,  4,\n",
      "         8,  5, 10,  5,  9,  5,  3,  7,  6,  4,  8,  6,  7, 11,  5,  3,  5,  7,\n",
      "         9,  7,  5,  5,  3,  5,  9,  4,  3, 10,  2,  7,  8,  9, 10,  9,  6,  6,\n",
      "         6,  4,  3,  1,  7,  3,  4,  7,  8,  8,  7,  9,  6,  5,  4,  4,  9,  7,\n",
      "         7,  6,  8,  7,  5,  5,  3,  5,  9, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 5, 5, 5, 5, 4, 5, 5, 5, 4, 5, 6, 5, 5, 5, 5, 5, 6, 4, 5, 5, 6, 5, 4,\n",
      "        5, 5, 4, 5, 5, 6, 5, 5, 4, 5, 5, 6, 5, 6, 5, 4, 5, 5, 4, 5, 5, 5, 4, 6,\n",
      "        4, 4, 5, 5, 5, 5, 5, 5, 4, 4, 5, 4, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 6, 5, 4, 4,\n",
      "        5, 4, 4, 5], device='cuda:0') tensor([ 3,  5,  9,  5, 10,  4,  9,  6,  7,  5,  9,  8,  5,  8,  8,  5,  6,  5,\n",
      "         3,  8,  6,  5,  9,  2,  5,  7,  6,  7,  6,  3,  6,  7,  3, 10,  8,  7,\n",
      "        10,  3,  7,  5,  8,  7,  5,  8,  9,  7,  5,  8,  1,  4,  6,  8,  2, 11,\n",
      "         7,  8,  3,  4,  7,  3,  5,  9,  7,  4,  4,  8,  4,  9,  6,  8,  4,  5,\n",
      "         4,  5,  8,  4,  9,  5,  5,  6,  3,  4,  6,  9,  4,  7,  6,  5,  8,  4,\n",
      "         7,  4,  6, 11,  4,  4,  4,  4,  4,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 4,  7,  4,  2, 10,  7,  4,  7,  3,  7,  5,  9,  5,  8,  6,  7,  6, 10,\n",
      "         6,  6,  4,  4,  3,  6,  3, 10,  8,  7,  9,  5,  6,  7,  4,  5,  7,  8,\n",
      "         6,  3,  7,  9,  8,  5,  5,  3,  4,  5, 10,  4,  6,  4,  7,  6,  4,  5,\n",
      "         5,  1,  7,  4,  3,  8,  6,  6,  2,  5,  4,  7,  8,  7,  9,  8,  7, 10,\n",
      "         3,  7,  8,  7,  9,  9,  3, 10,  4,  6,  8,  5,  6,  7,  8,  4,  9,  4,\n",
      "         4,  2,  8,  5,  5,  9,  7,  4,  6,  6], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 8,  8,  6,  6,  7,  9,  8,  7,  7,  7,  7,  8,  5,  6,  5,  8,  6,  6,\n",
      "         6,  6,  6,  7,  7,  4,  8,  3,  5,  6,  9,  3,  4,  5,  5,  4,  2,  7,\n",
      "         6,  5,  4,  9,  8,  8,  5,  7,  8,  5,  4, 10,  5,  5,  7,  9,  4,  6,\n",
      "         7,  9,  4,  6,  5,  7,  6,  3,  4,  6,  9,  4,  5,  5,  8,  3,  5,  5,\n",
      "         8,  4,  9,  3,  6,  3,  8,  4,  7,  4,  7,  8,  9,  9,  9,  4,  9,  2,\n",
      "        10,  6,  8,  4,  3,  6, 10,  8,  4,  6], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 5,  2,  5,  8,  8,  5,  8,  4,  5,  4,  9,  9,  8,  7,  3,  4,  5,  4,\n",
      "         7,  4,  7,  4,  8,  9,  7,  3,  7,  9,  3,  8,  7,  7,  8,  8,  8,  7,\n",
      "         9,  6,  9,  6,  3,  7,  6,  8,  6,  7,  6,  5,  8, 10,  8,  6,  9,  5,\n",
      "         7,  7,  7,  9,  6,  3,  7,  6,  5,  7,  9,  7,  3,  7,  8,  6,  6,  4,\n",
      "         8,  7,  8,  3,  7,  4,  3,  3,  9,  7,  4,  6,  6,  4,  7,  4,  4,  8,\n",
      "         3,  6,  7,  3,  6,  7,  5,  6,  8, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([10,  5,  5,  4,  5,  7,  5,  8,  5,  2,  9,  3,  5,  4,  7,  2, 10,  2,\n",
      "         4,  9,  4,  3,  5,  5,  6,  7, 11,  7,  8,  7,  8,  8,  9,  3,  4,  6,\n",
      "         6,  3,  9,  4,  3, 10,  3,  6,  9,  3,  2,  8, 10,  6,  5,  9,  6,  3,\n",
      "         5,  7,  6, 11,  5,  3,  5,  7,  3,  5,  4,  4,  8,  5,  7,  4, 10,  4,\n",
      "         6,  9,  7,  9,  6,  2,  8,  5,  7,  7,  7, 11,  8,  2,  9,  5,  7,  2,\n",
      "         4,  7, 11, 11,  5,  6,  7,  4,  9,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 3,  7,  5,  9,  5,  4,  3,  2,  3,  5,  6,  7,  8,  8,  5, 10,  7,  7,\n",
      "         7,  7,  6,  7,  3,  7,  7,  5,  3,  6,  6,  7,  4,  5,  5, 10,  6,  6,\n",
      "        10,  8,  5,  4,  6,  8, 10,  3,  7,  3,  8,  7,  3,  5,  9,  9,  6,  5,\n",
      "         4, 10,  6, 10,  9,  3,  7,  7,  6,  5,  3,  7, 10,  4,  6,  9,  9,  6,\n",
      "         7,  8,  5,  5, 10,  8,  7, 11,  7,  4,  8,  6,  6,  4,  8,  8,  5,  9,\n",
      "         6,  5,  7,  6,  6,  8, 10,  6,  7,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 4,  2,  8,  3, 10,  7,  5, 10,  7,  8, 10,  5,  6,  6,  4,  7,  1,  6,\n",
      "         5, 10,  7,  2,  6,  7,  9,  9,  9,  7,  9,  4,  3,  4,  7,  9,  9, 10,\n",
      "         5,  4,  7,  5,  3,  8,  5,  3,  5,  3,  2,  6,  7,  3,  8,  5,  4,  4,\n",
      "         9,  5,  6,  3,  9,  6,  8,  5,  9,  8,  4,  7,  3,  6,  5,  7,  3,  2,\n",
      "         6,  6,  9,  4,  6,  4,  5,  6,  4,  4,  3,  2,  4,  6,  4,  4,  4,  4,\n",
      "         9,  7,  5,  4,  7,  6,  7,  8,  8,  7], device='cuda:0')\n",
      "Epoch:  2 , loss:  2.38297176361084 , accuracy:  0.141\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 8,  9,  5,  4,  7,  7,  7,  7,  7,  4,  8,  7,  5,  2,  6,  3,  7,  9,\n",
      "         6,  5,  7,  4,  4,  5,  8,  8,  4,  3,  5,  8,  7,  4,  7,  8,  9,  2,\n",
      "         3,  9,  4,  4, 11,  9,  4,  4,  3,  9,  7,  7,  3,  7,  7,  8,  6,  8,\n",
      "         4,  5,  5,  2,  7,  9,  5,  7,  6,  3,  7,  7,  8,  7,  5,  8,  6,  3,\n",
      "         4,  3,  7, 11,  7,  7,  5,  6,  7,  5,  6,  3,  6,  8,  7,  3,  7,  7,\n",
      "         6,  7, 10,  7,  6,  9,  5,  9,  7,  5], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 3,  4,  4,  7,  4,  7,  7,  5,  8,  5,  5,  8,  9,  8,  5,  4,  7,  6,\n",
      "         6,  7,  4,  7,  5,  5,  5, 11,  3,  6,  8,  8,  8,  9,  4,  7,  3,  5,\n",
      "         4,  9,  4,  6,  9, 10,  1,  5,  4, 10,  8,  3,  8,  7,  5,  9,  6,  7,\n",
      "         4,  7,  9,  8,  5,  6,  8,  8,  3,  9,  9,  2,  5,  3,  5,  7,  6,  9,\n",
      "         3,  3,  6,  7,  6,  4,  9,  4,  2,  4,  4,  7,  9,  7,  9,  3,  3,  5,\n",
      "         7,  5,  6,  6,  5,  4,  7,  7,  4,  5], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 4, 5, 5, 4, 5, 4, 4, 5, 5, 4, 4, 5, 4, 4,\n",
      "        5, 4, 5, 4, 5, 5, 5, 4, 4, 4, 4, 5, 4, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 4,\n",
      "        4, 5, 5, 5, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4, 4, 5, 5, 4, 5, 5, 5, 4, 4,\n",
      "        4, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 5, 5, 4, 5, 4, 5, 4, 5, 4,\n",
      "        5, 4, 5, 5], device='cuda:0') tensor([ 6,  4,  5, 10,  7, 10,  6,  4,  5,  6,  3,  2,  7,  6,  6,  6,  5,  5,\n",
      "         6,  6,  4,  5,  8,  6,  4,  2,  8,  6,  8,  8,  9,  4,  3,  6,  2,  6,\n",
      "         4,  6,  7,  6,  5,  4,  7,  7,  3,  9,  5,  4,  4,  8,  5, 10,  4,  4,\n",
      "         6,  4,  5,  8,  6,  5,  6,  6,  6,  6,  5,  6,  3,  6,  7,  9,  4,  4,\n",
      "         2,  7,  5,  3,  7,  6,  6,  5,  5,  9, 10,  5,  6,  3,  5,  5, 10,  6,\n",
      "         7,  7,  8,  3,  7,  6,  9,  7,  9,  8], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 5, 5, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 4, 5, 4, 5, 4, 4, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4,\n",
      "        4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4,\n",
      "        4, 4, 4, 5], device='cuda:0') tensor([ 6,  9,  9,  7,  4, 10,  8,  4,  4,  6,  4, 11,  9,  7,  2,  2,  5,  7,\n",
      "         7,  4,  5,  4,  4,  9,  7,  5,  6,  5,  7,  3,  5,  3,  3,  5,  6, 10,\n",
      "         8,  5,  5,  6,  5, 10,  4,  3,  6,  9,  4,  4,  4,  3,  3,  4,  6,  5,\n",
      "         5,  5,  5,  7,  9,  6,  9,  9,  9,  5,  4,  3,  3,  7,  7,  9,  3,  9,\n",
      "         5,  8,  6,  3,  4,  4,  3,  7,  6,  7,  3,  8,  4,  3,  6,  8,  5,  9,\n",
      "         7,  7,  2,  7,  8,  6,  4,  9,  4, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4], device='cuda:0') tensor([ 4,  4,  4,  6,  4,  4,  8,  6,  7,  6,  9,  5,  8,  7,  8, 10,  4,  9,\n",
      "         4,  7,  5,  8,  6,  5, 10,  7,  9,  3,  2,  4,  5,  5,  4, 10,  3,  4,\n",
      "         3,  8,  5,  9, 10,  8,  8,  6,  8,  5,  7,  5,  8,  5,  7,  7,  9,  5,\n",
      "         3,  5, 10,  4,  6,  6,  7,  9,  3, 10,  6,  3,  6,  7,  5,  5,  8,  8,\n",
      "        10,  6,  5,  7,  6,  6,  4,  9,  2,  8,  9,  4,  9,  7,  5,  4,  8,  4,\n",
      "         4,  5,  8,  8,  2,  7,  8,  9,  4,  9], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-31fb8df39f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_v = []\n",
    "acc_v = []\n",
    "ep = 0\n",
    "for epoch in range(500):\n",
    "    ep += 1\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in train_loader:\n",
    "#         print(batch.x)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        out = model(data)\n",
    "        _, pred = out.max(dim=1)\n",
    "        print(pred.shape, data.y.shape, pred, data.y)\n",
    "        loss = F.cross_entropy(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        correct += float(pred.eq(data.y).sum().item())\n",
    "#         print(correct, pred, data.y)\n",
    "        total += len(pred)\n",
    "#         print(out, data.y, )\n",
    "    acc = correct/total\n",
    "    print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", accuracy: \", acc)\n",
    "    loss_v.append(loss)\n",
    "    acc_v.append(acc)\n",
    "plt.plot(np.arange(len(loss_v)), loss_v)\n",
    "plt.plot(np.arange(len(acc_v)), acc_v)\n",
    "plt.ylim(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[6110], edge_index=[2, 16297], x=[6110, 2], y=[100])\n",
      "tensor([ 7,  7,  7,  4,  6,  4,  6,  9,  7,  9,  8,  2,  5,  6,  5,  6,  7,  7,\n",
      "         9,  7,  4,  7,  9,  9,  5,  8,  5,  5,  4,  9,  7,  4,  9,  3,  9,  4,\n",
      "         6,  5,  4,  6,  4,  7,  3,  5,  5,  4,  5,  5, 10,  5,  2,  7,  9,  6,\n",
      "        10,  4,  3,  9,  4,  9,  4,  8,  6,  9,  9,  5,  1,  9,  7,  9,  5,  4,\n",
      "         9,  6,  4,  9,  4,  4,  3,  7,  7,  9,  4,  4,  3,  7,  7,  4,  6,  9,\n",
      "         7,  9, 10,  7,  9,  4, 10,  5,  7,  6], device='cuda:0') tensor([ 7,  7,  8,  4,  6,  4,  5, 11,  8, 10,  8,  3,  5,  6,  4,  6,  7,  6,\n",
      "         8,  7,  4,  7,  9,  8,  5,  8,  5,  5,  2, 10,  7,  5,  9,  2,  8,  4,\n",
      "         6,  5,  4,  6,  4,  7,  3,  5,  6,  5,  5,  6, 10,  5,  2,  6,  7,  6,\n",
      "        11,  4,  3,  9,  3,  9,  4,  8,  6,  8,  6,  6,  2,  8,  7,  8,  5,  4,\n",
      "         6,  5,  3,  9,  4,  3,  3,  6,  8, 10,  5,  4,  3,  7,  9,  4,  6,  5,\n",
      "         7,  9,  9,  7, 10,  4, 11,  5,  6,  6], device='cuda:0')\n",
      "Accuracy: 0.5800\n",
      "Batch(batch=[6030], edge_index=[2, 15800], x=[6030, 2], y=[100])\n",
      "tensor([ 4,  6,  8,  3,  8,  6, 10,  6,  7,  9,  3,  6,  7,  6,  5,  8,  4,  4,\n",
      "         4,  6,  4,  6,  7,  5,  6, 10,  8,  5,  9,  2,  5,  6,  4,  9,  7,  9,\n",
      "         9,  8,  6,  9,  4,  7,  3,  4,  4,  4,  6,  4,  7,  9,  3,  4,  9,  4,\n",
      "         6,  8,  4,  7,  9,  5,  5,  8,  3,  7,  5,  7,  4,  9,  5,  3,  7,  8,\n",
      "         9,  4,  9,  8,  9,  4,  3,  2,  7,  8,  7,  6,  5,  7,  7,  5,  5,  7,\n",
      "         7,  7,  6,  4,  7,  9,  7,  7,  5,  2], device='cuda:0') tensor([ 4,  5,  8,  2,  6,  6, 10,  6,  8,  6,  2,  6,  8,  5,  6,  7,  4,  4,\n",
      "         4,  5,  4,  6,  7,  5,  6,  9,  7,  5, 10,  2,  5,  6,  3,  9,  6,  8,\n",
      "        10,  8,  6,  9,  4,  8,  3,  4,  5,  4,  5,  4,  7,  8,  3,  3,  8,  3,\n",
      "         6,  8,  4,  7,  9,  5,  5,  8,  3,  8,  6,  7,  4,  8,  4,  3,  7,  9,\n",
      "         9,  4,  9,  8,  8,  5,  4,  2,  7,  8,  6,  6,  6,  9,  7,  3,  6,  8,\n",
      "         8,  8,  6,  4,  8,  9,  6,  9,  4,  3], device='cuda:0')\n",
      "Accuracy: 0.5400\n",
      "Batch(batch=[6180], edge_index=[2, 16398], x=[6180, 2], y=[100])\n",
      "tensor([ 7,  8,  5,  4,  9,  9,  9,  4,  9,  9,  6,  7,  5,  9,  3, 10,  3,  8,\n",
      "         4,  3,  3,  1,  5,  5,  4,  7,  9,  6,  6,  9,  2,  5,  4,  5,  5,  7,\n",
      "         5,  4,  6,  7,  9,  8,  4,  7,  4,  5,  6,  5,  6,  9,  7,  2,  7,  4,\n",
      "         2,  9,  6,  9,  3,  4, 10,  9,  5,  9,  6,  5,  7,  7,  6,  9,  5,  6,\n",
      "         5,  5,  5, 10,  8,  9,  6,  6,  7, 10,  7,  9,  4,  3,  5,  7,  5,  9,\n",
      "         4,  9,  9,  9, 10,  4,  5,  5,  7,  7], device='cuda:0') tensor([ 6,  7,  5,  4,  7,  9, 10,  3,  9,  8,  6,  6,  5,  7,  3, 11,  3,  7,\n",
      "         4,  3,  3,  1,  4,  5,  4,  7,  7,  6,  6, 10,  5,  5,  4,  5,  5,  7,\n",
      "         5,  3,  5,  9,  9,  9,  4,  7,  4,  6,  6,  6,  6,  8,  6,  2,  6,  4,\n",
      "         2,  8,  5,  9,  3,  4,  8,  9,  6,  7,  7,  6,  7,  7,  6, 10,  6,  6,\n",
      "         5,  7,  5, 10,  8,  9,  6,  6,  7, 10,  7,  8,  5,  3,  5,  7,  6,  9,\n",
      "         4,  9,  8,  9,  9,  4,  4,  6,  7,  7], device='cuda:0')\n",
      "Accuracy: 0.6000\n",
      "Batch(batch=[6120], edge_index=[2, 16169], x=[6120, 2], y=[100])\n",
      "tensor([ 7,  9,  3,  4,  6,  2,  4,  9,  5,  7,  8, 10,  9,  7,  6,  6,  9,  9,\n",
      "         6,  5,  4,  5,  5,  4,  9,  9,  3,  7,  4,  4,  4,  8,  7,  9,  1,  4,\n",
      "         9, 10,  7,  9, 10,  7,  9,  5,  7,  9,  4,  4,  5,  4,  9,  7,  4,  7,\n",
      "         5,  8,  9,  9,  4,  6,  9,  7,  7,  7,  6,  9,  5,  7,  4,  7,  5,  5,\n",
      "         4,  4, 10,  5,  9,  8,  9,  9,  2,  9,  4,  5,  3,  6,  6,  9,  6,  9,\n",
      "         7,  9,  7,  6,  4,  7,  6,  5,  7,  6], device='cuda:0') tensor([ 7,  8,  2,  4,  7,  2,  4,  9,  6,  7,  7, 10,  8,  6,  6,  5,  8,  8,\n",
      "         5,  5,  4,  5,  5,  5, 10,  9,  4,  8,  4,  5,  4,  8,  6,  8,  1,  4,\n",
      "         8,  8,  6,  9, 11,  6,  8,  5,  6,  8,  3,  3,  3,  3,  9,  7,  3,  7,\n",
      "         3,  8,  8,  8,  4,  6,  9,  7,  7,  7,  6,  8,  5,  7,  4,  8,  5,  5,\n",
      "         5,  4,  8,  5,  9,  9,  8,  7,  2,  8,  3,  5,  3,  6,  6,  8,  6,  9,\n",
      "         7,  8,  6,  5,  4,  6,  6,  5,  6,  6], device='cuda:0')\n",
      "Accuracy: 0.5100\n",
      "Batch(batch=[6080], edge_index=[2, 15661], x=[6080, 2], y=[100])\n",
      "tensor([ 7,  4,  6,  7,  6,  4,  4,  7,  7,  3,  7,  4,  9,  9, 10,  6,  9,  5,\n",
      "         7,  8,  9,  9,  7, 10,  4,  7,  9,  7,  5,  6,  6,  5,  9,  9,  4,  9,\n",
      "         4, 10,  5,  5,  4,  5,  7,  6,  4,  7,  9,  7,  7,  8,  5,  5,  2,  4,\n",
      "         7,  9,  3,  6,  9,  9,  4,  3,  7,  6,  4,  4,  4,  7,  5,  4, 10,  5,\n",
      "         7,  5,  4,  5,  8,  9,  6,  5,  5, 10,  5,  7,  1,  4,  4,  7,  5,  6,\n",
      "         7,  9,  7,  5, 10,  9,  6,  9,  9,  6], device='cuda:0') tensor([ 8,  4,  5,  8,  5,  4,  3,  6,  7,  3,  7,  4,  9,  9, 10,  7,  9,  6,\n",
      "         7,  8,  8,  9,  6, 10,  4,  6,  3,  8,  5,  6,  5,  5,  8,  9,  4,  9,\n",
      "         4,  9,  5,  6,  4,  5,  6,  5,  3,  8,  9,  7,  7,  9,  5,  5,  3,  3,\n",
      "         8,  8,  2,  5,  8,  8,  4,  2,  6,  6,  3,  5,  3,  7,  5,  5,  9,  5,\n",
      "         6,  5,  4,  5,  8,  9,  7,  6,  3,  9,  5,  7,  1,  4,  5,  7,  5,  6,\n",
      "         6,  7,  6,  5, 10,  8,  6,  8,  8,  6], device='cuda:0')\n",
      "Accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    data = batch.to(device)\n",
    "    _, pred = model(data).max(dim=1)\n",
    "    print(pred, data.y)\n",
    "    correct = float(pred.eq(data.y).sum().item())\n",
    "    acc = correct / len(pred)\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combined Counter & Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = [gen_edge_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(1000)]\n",
    "test_dataset = [gen_edge_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].y_graph.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using \", device)\n",
    "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
    "model = Edge_Graph_Class_Net(input_dim=2, hidden_dim=16, n_graph_iters=4, output_dim=12).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , loss:  3.1576285362243652 , count accuracy:  0.122 , edge accuracy:  0.6513064133016627\n",
      "Epoch:  2 , loss:  3.1742045879364014 , count accuracy:  0.134 , edge accuracy:  0.6614945111382166\n",
      "Epoch:  3 , loss:  3.0324511528015137 , count accuracy:  0.134 , edge accuracy:  0.6614945111382166\n",
      "Epoch:  4 , loss:  3.011707305908203 , count accuracy:  0.158 , edge accuracy:  0.6614945111382166\n",
      "Epoch:  5 , loss:  3.0208494663238525 , count accuracy:  0.196 , edge accuracy:  0.6620851255055531\n",
      "Epoch:  6 , loss:  3.003718137741089 , count accuracy:  0.182 , edge accuracy:  0.6734865506837003\n",
      "Epoch:  7 , loss:  2.8945674896240234 , count accuracy:  0.193 , edge accuracy:  0.6919881877126532\n",
      "Epoch:  8 , loss:  2.9283816814422607 , count accuracy:  0.194 , edge accuracy:  0.7084547730628491\n",
      "Epoch:  9 , loss:  2.8948309421539307 , count accuracy:  0.204 , edge accuracy:  0.7297875072221865\n",
      "Epoch:  10 , loss:  2.914076328277588 , count accuracy:  0.208 , edge accuracy:  0.746857546382487\n",
      "Epoch:  11 , loss:  2.802792549133301 , count accuracy:  0.216 , edge accuracy:  0.7610258714771779\n",
      "Epoch:  12 , loss:  2.8270790576934814 , count accuracy:  0.247 , edge accuracy:  0.7690762020928291\n",
      "Epoch:  13 , loss:  2.7655274868011475 , count accuracy:  0.247 , edge accuracy:  0.7779418373242601\n",
      "Epoch:  14 , loss:  2.808720111846924 , count accuracy:  0.254 , edge accuracy:  0.7958464402644925\n",
      "Epoch:  15 , loss:  2.6588196754455566 , count accuracy:  0.259 , edge accuracy:  0.8237080310714515\n",
      "Epoch:  16 , loss:  2.656951427459717 , count accuracy:  0.266 , edge accuracy:  0.8548436797842973\n",
      "Epoch:  17 , loss:  2.6260929107666016 , count accuracy:  0.273 , edge accuracy:  0.8773512229569237\n",
      "Epoch:  18 , loss:  2.5608267784118652 , count accuracy:  0.272 , edge accuracy:  0.8878089490916095\n",
      "Epoch:  19 , loss:  2.58125376701355 , count accuracy:  0.273 , edge accuracy:  0.9003723438402773\n",
      "Epoch:  20 , loss:  2.567147731781006 , count accuracy:  0.273 , edge accuracy:  0.9057199717532259\n",
      "Epoch:  21 , loss:  2.507758617401123 , count accuracy:  0.276 , edge accuracy:  0.9089234127238878\n",
      "Epoch:  22 , loss:  2.519458770751953 , count accuracy:  0.291 , edge accuracy:  0.9125954933555883\n",
      "Epoch:  23 , loss:  2.466383457183838 , count accuracy:  0.287 , edge accuracy:  0.9154458496501252\n",
      "Epoch:  24 , loss:  2.516859531402588 , count accuracy:  0.307 , edge accuracy:  0.9169865827823073\n",
      "Epoch:  25 , loss:  2.4069888591766357 , count accuracy:  0.288 , edge accuracy:  0.9167233742055595\n",
      "Epoch:  26 , loss:  2.520430326461792 , count accuracy:  0.288 , edge accuracy:  0.9171534955382936\n",
      "Epoch:  27 , loss:  2.5352001190185547 , count accuracy:  0.297 , edge accuracy:  0.9195673107787122\n",
      "Epoch:  28 , loss:  2.4262051582336426 , count accuracy:  0.31 , edge accuracy:  0.9197855813057714\n",
      "Epoch:  29 , loss:  2.428661584854126 , count accuracy:  0.31 , edge accuracy:  0.9215189060794762\n",
      "Epoch:  30 , loss:  2.467913866043091 , count accuracy:  0.292 , edge accuracy:  0.9207164409064647\n",
      "Epoch:  31 , loss:  2.4559147357940674 , count accuracy:  0.291 , edge accuracy:  0.9211786608461193\n",
      "Epoch:  32 , loss:  2.435981273651123 , count accuracy:  0.323 , edge accuracy:  0.9214739680297875\n",
      "Epoch:  33 , loss:  2.349578380584717 , count accuracy:  0.324 , edge accuracy:  0.922417667073249\n",
      "Epoch:  34 , loss:  2.4482226371765137 , count accuracy:  0.319 , edge accuracy:  0.9236630930217629\n",
      "Epoch:  35 , loss:  2.389862537384033 , count accuracy:  0.335 , edge accuracy:  0.9241317326828016\n",
      "Epoch:  36 , loss:  2.457862377166748 , count accuracy:  0.353 , edge accuracy:  0.924439879309238\n",
      "Epoch:  37 , loss:  2.384885787963867 , count accuracy:  0.352 , edge accuracy:  0.9241381524041856\n",
      "Epoch:  38 , loss:  2.327662944793701 , count accuracy:  0.335 , edge accuracy:  0.923887783270206\n",
      "Epoch:  39 , loss:  2.3603055477142334 , count accuracy:  0.328 , edge accuracy:  0.9231880336393401\n",
      "Epoch:  40 , loss:  2.4143574237823486 , count accuracy:  0.323 , edge accuracy:  0.9241830904538743\n",
      "Epoch:  41 , loss:  2.3928160667419434 , count accuracy:  0.314 , edge accuracy:  0.923605315529306\n",
      "Epoch:  42 , loss:  2.3331708908081055 , count accuracy:  0.341 , edge accuracy:  0.9241959298966425\n",
      "Epoch:  43 , loss:  2.352027416229248 , count accuracy:  0.359 , edge accuracy:  0.9256467869294472\n",
      "Epoch:  44 , loss:  2.3379623889923096 , count accuracy:  0.359 , edge accuracy:  0.927444308916993\n",
      "Epoch:  45 , loss:  2.403022289276123 , count accuracy:  0.374 , edge accuracy:  0.9267573987288952\n",
      "Epoch:  46 , loss:  2.396306037902832 , count accuracy:  0.378 , edge accuracy:  0.9265583873659883\n",
      "Epoch:  47 , loss:  2.395338535308838 , count accuracy:  0.38 , edge accuracy:  0.9251460486614881\n",
      "Epoch:  48 , loss:  2.359173536300659 , count accuracy:  0.348 , edge accuracy:  0.9255376516659177\n",
      "Epoch:  49 , loss:  2.243870258331299 , count accuracy:  0.366 , edge accuracy:  0.925345060024395\n",
      "Epoch:  50 , loss:  2.382564067840576 , count accuracy:  0.378 , edge accuracy:  0.9261346857546382\n",
      "Epoch:  51 , loss:  2.3130781650543213 , count accuracy:  0.388 , edge accuracy:  0.9288181292931886\n",
      "Epoch:  52 , loss:  2.3007421493530273 , count accuracy:  0.395 , edge accuracy:  0.9275406047377543\n",
      "Epoch:  53 , loss:  2.38906192779541 , count accuracy:  0.381 , edge accuracy:  0.9281247993837067\n",
      "Epoch:  54 , loss:  2.4518377780914307 , count accuracy:  0.375 , edge accuracy:  0.9269628298131861\n",
      "Epoch:  55 , loss:  2.1836540699005127 , count accuracy:  0.387 , edge accuracy:  0.9280349232843295\n",
      "Epoch:  56 , loss:  2.303584337234497 , count accuracy:  0.393 , edge accuracy:  0.9277973935931181\n",
      "Epoch:  57 , loss:  2.3001396656036377 , count accuracy:  0.389 , edge accuracy:  0.9290235603774796\n",
      "Epoch:  58 , loss:  2.2036349773406982 , count accuracy:  0.398 , edge accuracy:  0.9304551582461321\n",
      "Epoch:  59 , loss:  2.3271288871765137 , count accuracy:  0.393 , edge accuracy:  0.9297554086152661\n",
      "Epoch:  60 , loss:  2.3661508560180664 , count accuracy:  0.376 , edge accuracy:  0.9301341721769275\n",
      "Epoch:  61 , loss:  2.4601023197174072 , count accuracy:  0.33 , edge accuracy:  0.9298838030429479\n",
      "Epoch:  62 , loss:  2.3030624389648438 , count accuracy:  0.322 , edge accuracy:  0.9283880079604545\n",
      "Epoch:  63 , loss:  2.2585561275482178 , count accuracy:  0.346 , edge accuracy:  0.9281183796623227\n",
      "Epoch:  64 , loss:  2.3640875816345215 , count accuracy:  0.367 , edge accuracy:  0.9275983822302112\n",
      "Epoch:  65 , loss:  2.283921241760254 , count accuracy:  0.363 , edge accuracy:  0.9294151633819092\n",
      "Epoch:  66 , loss:  2.2880241870880127 , count accuracy:  0.399 , edge accuracy:  0.9302433074404571\n",
      "Epoch:  67 , loss:  2.1699166297912598 , count accuracy:  0.393 , edge accuracy:  0.9289401039994865\n",
      "Epoch:  68 , loss:  2.3117504119873047 , count accuracy:  0.404 , edge accuracy:  0.9309687359568595\n",
      "Epoch:  69 , loss:  2.1328814029693604 , count accuracy:  0.402 , edge accuracy:  0.9310842909417731\n",
      "Epoch:  70 , loss:  2.395967483520508 , count accuracy:  0.407 , edge accuracy:  0.9302176285549207\n",
      "Epoch:  71 , loss:  2.3635895252227783 , count accuracy:  0.381 , edge accuracy:  0.930378121589523\n",
      "Epoch:  72 , loss:  2.29846453666687 , count accuracy:  0.371 , edge accuracy:  0.9311549078769982\n",
      "Epoch:  73 , loss:  2.1668996810913086 , count accuracy:  0.382 , edge accuracy:  0.932047249149387\n",
      "Epoch:  74 , loss:  2.2934577465057373 , count accuracy:  0.398 , edge accuracy:  0.9325800860242666\n",
      "Epoch:  75 , loss:  2.3736393451690674 , count accuracy:  0.395 , edge accuracy:  0.9321949027412211\n",
      "Epoch:  76 , loss:  2.371438980102539 , count accuracy:  0.382 , edge accuracy:  0.9291326956410092\n",
      "Epoch:  77 , loss:  2.2368662357330322 , count accuracy:  0.374 , edge accuracy:  0.9309430570713231\n",
      "Epoch:  78 , loss:  2.23089337348938 , count accuracy:  0.367 , edge accuracy:  0.931077871220389\n",
      "Epoch:  79 , loss:  2.2200896739959717 , count accuracy:  0.407 , edge accuracy:  0.930654169609039\n",
      "Epoch:  80 , loss:  2.272797107696533 , count accuracy:  0.41 , edge accuracy:  0.9314694742248186\n",
      "Epoch:  81 , loss:  2.177095651626587 , count accuracy:  0.41 , edge accuracy:  0.9321499646915324\n",
      "Epoch:  82 , loss:  2.1739630699157715 , count accuracy:  0.406 , edge accuracy:  0.9331257623419144\n",
      "Epoch:  83 , loss:  2.115454912185669 , count accuracy:  0.4 , edge accuracy:  0.9315272517172755\n",
      "Epoch:  84 , loss:  2.3608763217926025 , count accuracy:  0.397 , edge accuracy:  0.9334210695255826\n",
      "Epoch:  85 , loss:  2.078286647796631 , count accuracy:  0.402 , edge accuracy:  0.9339731655646145\n",
      "Epoch:  86 , loss:  2.271789312362671 , count accuracy:  0.407 , edge accuracy:  0.9319445336072415\n",
      "Epoch:  87 , loss:  2.3249642848968506 , count accuracy:  0.393 , edge accuracy:  0.9322270013481415\n",
      "Epoch:  88 , loss:  2.2421343326568604 , count accuracy:  0.397 , edge accuracy:  0.9326763818450279\n",
      "Epoch:  89 , loss:  2.205183744430542 , count accuracy:  0.405 , edge accuracy:  0.9325800860242666\n",
      "Epoch:  90 , loss:  2.22875714302063 , count accuracy:  0.408 , edge accuracy:  0.9313346600757527\n",
      "Epoch:  91 , loss:  2.149848699569702 , count accuracy:  0.405 , edge accuracy:  0.9319573730500096\n",
      "Epoch:  92 , loss:  2.1380088329315186 , count accuracy:  0.402 , edge accuracy:  0.9338897091866213\n",
      "Epoch:  93 , loss:  2.304644823074341 , count accuracy:  0.402 , edge accuracy:  0.9320729280349233\n",
      "Epoch:  94 , loss:  2.3695461750030518 , count accuracy:  0.408 , edge accuracy:  0.9317391025229506\n",
      "Epoch:  95 , loss:  2.2972190380096436 , count accuracy:  0.406 , edge accuracy:  0.9335623033960326\n",
      "Epoch:  96 , loss:  2.261439800262451 , count accuracy:  0.402 , edge accuracy:  0.9329524298645439\n",
      "Epoch:  97 , loss:  2.201672077178955 , count accuracy:  0.415 , edge accuracy:  0.9345830390961032\n",
      "Epoch:  98 , loss:  2.2863404750823975 , count accuracy:  0.412 , edge accuracy:  0.9342106952558259\n",
      "Epoch:  99 , loss:  2.221977710723877 , count accuracy:  0.413 , edge accuracy:  0.9334916864608076\n",
      "Epoch:  100 , loss:  2.222644329071045 , count accuracy:  0.412 , edge accuracy:  0.9339218077935417\n",
      "Epoch:  101 , loss:  2.3099451065063477 , count accuracy:  0.419 , edge accuracy:  0.9340309430570714\n",
      "Epoch:  102 , loss:  2.3079631328582764 , count accuracy:  0.409 , edge accuracy:  0.9325030493676575\n",
      "Epoch:  103 , loss:  2.1578786373138428 , count accuracy:  0.395 , edge accuracy:  0.9344161263401168\n",
      "Epoch:  104 , loss:  2.235250234603882 , count accuracy:  0.412 , edge accuracy:  0.9348205687873147\n",
      "Epoch:  105 , loss:  2.147027015686035 , count accuracy:  0.418 , edge accuracy:  0.9348783462797715\n",
      "Epoch:  106 , loss:  2.2201507091522217 , count accuracy:  0.419 , edge accuracy:  0.9355138986967966\n",
      "Epoch:  107 , loss:  2.1187169551849365 , count accuracy:  0.411 , edge accuracy:  0.9336329203312577\n",
      "Epoch:  108 , loss:  2.2093658447265625 , count accuracy:  0.411 , edge accuracy:  0.93379341336586\n",
      "Epoch:  109 , loss:  2.1756436824798584 , count accuracy:  0.405 , edge accuracy:  0.9343711882904282\n",
      "Epoch:  110 , loss:  2.1418650150299072 , count accuracy:  0.414 , edge accuracy:  0.9358413044873852\n",
      "Epoch:  111 , loss:  2.1606314182281494 , count accuracy:  0.414 , edge accuracy:  0.9356615522886307\n",
      "Epoch:  112 , loss:  2.1200220584869385 , count accuracy:  0.406 , edge accuracy:  0.934351929126276\n",
      "Epoch:  113 , loss:  2.2652487754821777 , count accuracy:  0.421 , edge accuracy:  0.935822045323233\n",
      "Epoch:  114 , loss:  2.0983119010925293 , count accuracy:  0.425 , edge accuracy:  0.9338383514155486\n",
      "Epoch:  115 , loss:  2.0581417083740234 , count accuracy:  0.429 , edge accuracy:  0.9341721769275213\n",
      "Epoch:  116 , loss:  2.2800710201263428 , count accuracy:  0.428 , edge accuracy:  0.935822045323233\n",
      "Epoch:  117 , loss:  2.1589226722717285 , count accuracy:  0.43 , edge accuracy:  0.9354689606471079\n",
      "Epoch:  118 , loss:  2.2353904247283936 , count accuracy:  0.429 , edge accuracy:  0.9372022854208127\n",
      "Epoch:  119 , loss:  2.226597547531128 , count accuracy:  0.403 , edge accuracy:  0.935828465044617\n",
      "Epoch:  120 , loss:  2.053783416748047 , count accuracy:  0.416 , edge accuracy:  0.9358156256018488\n",
      "Epoch:  121 , loss:  2.3179473876953125 , count accuracy:  0.407 , edge accuracy:  0.9352956281697374\n",
      "Epoch:  122 , loss:  2.0529134273529053 , count accuracy:  0.414 , edge accuracy:  0.9362906849842717\n",
      "Epoch:  123 , loss:  2.335205554962158 , count accuracy:  0.427 , edge accuracy:  0.9383257366630289\n",
      "Epoch:  124 , loss:  2.206385374069214 , count accuracy:  0.427 , edge accuracy:  0.9374141362264877\n",
      "Epoch:  125 , loss:  2.0820634365081787 , count accuracy:  0.429 , edge accuracy:  0.9370610515503627\n",
      "Epoch:  126 , loss:  1.9886621236801147 , count accuracy:  0.432 , edge accuracy:  0.9374012967837196\n",
      "Epoch:  127 , loss:  2.1789045333862305 , count accuracy:  0.416 , edge accuracy:  0.9378121589523015\n",
      "Epoch:  128 , loss:  2.05041766166687 , count accuracy:  0.427 , edge accuracy:  0.935269949284201\n",
      "Epoch:  129 , loss:  2.181492328643799 , count accuracy:  0.434 , edge accuracy:  0.936386980805033\n",
      "Epoch:  130 , loss:  2.1278584003448486 , count accuracy:  0.416 , edge accuracy:  0.9367079668742376\n",
      "Epoch:  131 , loss:  2.1479368209838867 , count accuracy:  0.416 , edge accuracy:  0.9355652564678693\n",
      "Epoch:  132 , loss:  2.1656486988067627 , count accuracy:  0.421 , edge accuracy:  0.9355780959106375\n",
      "Epoch:  133 , loss:  2.199862003326416 , count accuracy:  0.425 , edge accuracy:  0.9360659947358284\n",
      "Epoch:  134 , loss:  2.10709285736084 , count accuracy:  0.427 , edge accuracy:  0.9364704371830262\n",
      "Epoch:  135 , loss:  2.0422310829162598 , count accuracy:  0.434 , edge accuracy:  0.9368042626949991\n",
      "Epoch:  136 , loss:  2.1500422954559326 , count accuracy:  0.428 , edge accuracy:  0.9384605508120948\n",
      "Epoch:  137 , loss:  2.084538698196411 , count accuracy:  0.424 , edge accuracy:  0.9367143865956218\n",
      "Epoch:  138 , loss:  2.2892906665802 , count accuracy:  0.431 , edge accuracy:  0.9367850035308468\n",
      "Epoch:  139 , loss:  2.1157445907592773 , count accuracy:  0.431 , edge accuracy:  0.9348398279514669\n",
      "Epoch:  140 , loss:  2.2012758255004883 , count accuracy:  0.426 , edge accuracy:  0.9361815497207421\n",
      "Epoch:  141 , loss:  2.0916194915771484 , count accuracy:  0.435 , edge accuracy:  0.9329845284714643\n",
      "Epoch:  142 , loss:  1.9550838470458984 , count accuracy:  0.427 , edge accuracy:  0.9348398279514669\n",
      "Epoch:  143 , loss:  2.240842342376709 , count accuracy:  0.432 , edge accuracy:  0.9371124093214355\n",
      "Epoch:  144 , loss:  2.1204588413238525 , count accuracy:  0.431 , edge accuracy:  0.9379726519869037\n",
      "Epoch:  145 , loss:  2.136545419692993 , count accuracy:  0.434 , edge accuracy:  0.9362200680490467\n",
      "Epoch:  146 , loss:  2.195040702819824 , count accuracy:  0.439 , edge accuracy:  0.9365346343968671\n",
      "Epoch:  147 , loss:  2.142554759979248 , count accuracy:  0.439 , edge accuracy:  0.9371701868138923\n",
      "Epoch:  148 , loss:  2.1372339725494385 , count accuracy:  0.429 , edge accuracy:  0.9364704371830262\n",
      "Epoch:  149 , loss:  1.9903781414031982 , count accuracy:  0.431 , edge accuracy:  0.9381716633498106\n",
      "Epoch:  150 , loss:  2.008729934692383 , count accuracy:  0.429 , edge accuracy:  0.9383000577774925\n",
      "Epoch:  151 , loss:  2.160226821899414 , count accuracy:  0.436 , edge accuracy:  0.9382615394491879\n",
      "Epoch:  152 , loss:  2.074380874633789 , count accuracy:  0.445 , edge accuracy:  0.9368235218591513\n",
      "Epoch:  153 , loss:  2.027723789215088 , count accuracy:  0.436 , edge accuracy:  0.9385953649611607\n",
      "Epoch:  154 , loss:  2.1855876445770264 , count accuracy:  0.441 , edge accuracy:  0.9384220324837902\n",
      "Epoch:  155 , loss:  2.1038031578063965 , count accuracy:  0.438 , edge accuracy:  0.9373306798484946\n",
      "Epoch:  156 , loss:  2.154909610748291 , count accuracy:  0.435 , edge accuracy:  0.9362906849842717\n",
      "Epoch:  157 , loss:  2.0912325382232666 , count accuracy:  0.422 , edge accuracy:  0.9384926494190152\n",
      "Epoch:  158 , loss:  2.0611534118652344 , count accuracy:  0.432 , edge accuracy:  0.9382101816781152\n",
      "Epoch:  159 , loss:  2.0063302516937256 , count accuracy:  0.444 , edge accuracy:  0.9389548693586698\n",
      "Epoch:  160 , loss:  1.9991614818572998 , count accuracy:  0.443 , edge accuracy:  0.9373114206843423\n",
      "Epoch:  161 , loss:  1.958442211151123 , count accuracy:  0.444 , edge accuracy:  0.9383835141554856\n",
      "Epoch:  162 , loss:  2.21334171295166 , count accuracy:  0.436 , edge accuracy:  0.938691660781922\n",
      "Epoch:  163 , loss:  2.0490927696228027 , count accuracy:  0.446 , edge accuracy:  0.9391153623932721\n",
      "Epoch:  164 , loss:  2.175071954727173 , count accuracy:  0.444 , edge accuracy:  0.938897091866213\n",
      "Epoch:  165 , loss:  2.1463544368743896 , count accuracy:  0.448 , edge accuracy:  0.9385119085831675\n",
      "Epoch:  166 , loss:  2.122861623764038 , count accuracy:  0.445 , edge accuracy:  0.9366501893817808\n",
      "Epoch:  167 , loss:  2.05952525138855 , count accuracy:  0.448 , edge accuracy:  0.9378249983950696\n",
      "Epoch:  168 , loss:  2.1320407390594482 , count accuracy:  0.442 , edge accuracy:  0.9380753675290492\n",
      "Epoch:  169 , loss:  2.0140438079833984 , count accuracy:  0.445 , edge accuracy:  0.9368812993516081\n",
      "Epoch:  170 , loss:  2.022045135498047 , count accuracy:  0.446 , edge accuracy:  0.9374269756692559\n",
      "Epoch:  171 , loss:  1.9167137145996094 , count accuracy:  0.444 , edge accuracy:  0.9384220324837902\n",
      "Epoch:  172 , loss:  2.0613515377044678 , count accuracy:  0.448 , edge accuracy:  0.9379405533799833\n",
      "Epoch:  173 , loss:  2.018104076385498 , count accuracy:  0.451 , edge accuracy:  0.9382615394491879\n",
      "Epoch:  174 , loss:  1.9494966268539429 , count accuracy:  0.454 , edge accuracy:  0.9382422802850356\n",
      "Epoch:  175 , loss:  1.7587087154388428 , count accuracy:  0.446 , edge accuracy:  0.9383449958271811\n",
      "Epoch:  176 , loss:  1.8550444841384888 , count accuracy:  0.458 , edge accuracy:  0.9371830262566605\n",
      "Epoch:  177 , loss:  2.022266387939453 , count accuracy:  0.456 , edge accuracy:  0.9381716633498106\n",
      "Epoch:  178 , loss:  2.0113096237182617 , count accuracy:  0.464 , edge accuracy:  0.9381010464145856\n",
      "Epoch:  179 , loss:  1.8105573654174805 , count accuracy:  0.478 , edge accuracy:  0.9376324067535469\n",
      "Epoch:  180 , loss:  1.9163634777069092 , count accuracy:  0.488 , edge accuracy:  0.9385568466328561\n",
      "Epoch:  181 , loss:  1.863350510597229 , count accuracy:  0.501 , edge accuracy:  0.9364704371830262\n",
      "Epoch:  182 , loss:  1.6614629030227661 , count accuracy:  0.498 , edge accuracy:  0.938685241060538\n",
      "Epoch:  183 , loss:  1.807140588760376 , count accuracy:  0.493 , edge accuracy:  0.9379533928227515\n",
      "Epoch:  184 , loss:  1.8507134914398193 , count accuracy:  0.503 , edge accuracy:  0.9382936380561083\n",
      "Epoch:  185 , loss:  1.717226266860962 , count accuracy:  0.507 , edge accuracy:  0.9382807986133401\n",
      "Epoch:  186 , loss:  1.9944990873336792 , count accuracy:  0.489 , edge accuracy:  0.9387365988316108\n",
      "Epoch:  187 , loss:  1.9143891334533691 , count accuracy:  0.51 , edge accuracy:  0.9357257495024716\n",
      "Epoch:  188 , loss:  1.8687174320220947 , count accuracy:  0.491 , edge accuracy:  0.9355973550747898\n",
      "Epoch:  189 , loss:  1.9194934368133545 , count accuracy:  0.492 , edge accuracy:  0.9359632791936829\n",
      "Epoch:  190 , loss:  2.0154356956481934 , count accuracy:  0.51 , edge accuracy:  0.9353469859408101\n",
      "Epoch:  191 , loss:  1.9457921981811523 , count accuracy:  0.496 , edge accuracy:  0.9377543814598447\n",
      "Epoch:  192 , loss:  1.8166245222091675 , count accuracy:  0.526 , edge accuracy:  0.9372472234705014\n",
      "Epoch:  193 , loss:  1.979361891746521 , count accuracy:  0.516 , edge accuracy:  0.9381010464145856\n",
      "Epoch:  194 , loss:  1.8314417600631714 , count accuracy:  0.52 , edge accuracy:  0.9396738781536881\n",
      "Epoch:  195 , loss:  1.827699899673462 , count accuracy:  0.521 , edge accuracy:  0.9390447454580472\n",
      "Epoch:  196 , loss:  1.8227808475494385 , count accuracy:  0.518 , edge accuracy:  0.9363163638698081\n",
      "Epoch:  197 , loss:  1.7523926496505737 , count accuracy:  0.521 , edge accuracy:  0.935475380368492\n",
      "Epoch:  198 , loss:  1.9599902629852295 , count accuracy:  0.495 , edge accuracy:  0.937080310714515\n",
      "Epoch:  199 , loss:  2.0010786056518555 , count accuracy:  0.469 , edge accuracy:  0.9353213070552738\n",
      "Epoch:  200 , loss:  1.863943099975586 , count accuracy:  0.514 , edge accuracy:  0.9339731655646145\n",
      "Epoch:  201 , loss:  1.879685640335083 , count accuracy:  0.504 , edge accuracy:  0.9360788341785966\n",
      "Epoch:  202 , loss:  1.9052863121032715 , count accuracy:  0.519 , edge accuracy:  0.9384862296976311\n",
      "Epoch:  203 , loss:  1.8513412475585938 , count accuracy:  0.52 , edge accuracy:  0.9362457469345831\n",
      "Epoch:  204 , loss:  2.059642791748047 , count accuracy:  0.537 , edge accuracy:  0.9356487128458625\n",
      "Epoch:  205 , loss:  1.7278437614440918 , count accuracy:  0.514 , edge accuracy:  0.9382487000064197\n",
      "Epoch:  206 , loss:  1.863663673400879 , count accuracy:  0.507 , edge accuracy:  0.9374911728830969\n",
      "Epoch:  207 , loss:  1.857136607170105 , count accuracy:  0.471 , edge accuracy:  0.9354625409257238\n",
      "Epoch:  208 , loss:  2.0660808086395264 , count accuracy:  0.498 , edge accuracy:  0.9337227964306349\n",
      "Epoch:  209 , loss:  1.7690074443817139 , count accuracy:  0.519 , edge accuracy:  0.935545997303717\n",
      "Epoch:  210 , loss:  1.7688298225402832 , count accuracy:  0.516 , edge accuracy:  0.9378763561661424\n",
      "Epoch:  211 , loss:  1.742173433303833 , count accuracy:  0.543 , edge accuracy:  0.9393914104127881\n",
      "Epoch:  212 , loss:  1.870680570602417 , count accuracy:  0.531 , edge accuracy:  0.9386595621750016\n",
      "Epoch:  213 , loss:  1.8515676259994507 , count accuracy:  0.518 , edge accuracy:  0.9384605508120948\n",
      "Epoch:  214 , loss:  1.7366515398025513 , count accuracy:  0.542 , edge accuracy:  0.9385311677473198\n",
      "Epoch:  215 , loss:  1.8430802822113037 , count accuracy:  0.533 , edge accuracy:  0.9387879566026834\n",
      "Epoch:  216 , loss:  1.6865381002426147 , count accuracy:  0.54 , edge accuracy:  0.9396353598253836\n",
      "Epoch:  217 , loss:  1.8010212182998657 , count accuracy:  0.539 , edge accuracy:  0.9392244976568017\n",
      "Epoch:  218 , loss:  1.9431835412979126 , count accuracy:  0.551 , edge accuracy:  0.939314373756179\n",
      "Epoch:  219 , loss:  1.7670519351959229 , count accuracy:  0.544 , edge accuracy:  0.9393785709700199\n",
      "Epoch:  220 , loss:  1.75729238986969 , count accuracy:  0.535 , edge accuracy:  0.938126725300122\n",
      "Epoch:  221 , loss:  1.857451319694519 , count accuracy:  0.503 , edge accuracy:  0.9373884573409514\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-16cb4621fbe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcount_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0medge_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#         print(batch.x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(data_list)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             collate_fn=lambda data_list: Batch.from_data_list(\n\u001b[0;32m---> 32\u001b[0;31m                 data_list, follow_batch),\n\u001b[0m\u001b[1;32m     33\u001b[0m             **kwargs)\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(data_list, follow_batch)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0mcumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_v = []\n",
    "acc_v_count = []\n",
    "acc_v_edge = []\n",
    "ep = 0\n",
    "for epoch in range(500):\n",
    "    ep += 1\n",
    "    count_correct = 0\n",
    "    edge_correct = 0\n",
    "    count_total = 0\n",
    "    edge_total = 0 \n",
    "    for batch in train_loader:\n",
    "#         print(batch.x)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        edge_pred, graph_pred = model(data)\n",
    "        _, graph_pred_max = graph_pred.max(dim=1)\n",
    "        losses = [F.binary_cross_entropy_with_logits(edge_pred.float(), data.y.float()), F.cross_entropy(graph_pred, data.y_graph)]\n",
    "#         print(losses[0].item(), losses[1].item())\n",
    "        loss = sum(losses)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        edge_correct += ((edge_pred > 0.5) == (data.y > 0.5)).sum().item()\n",
    "        count_correct += float(graph_pred_max.eq(data.y_graph).sum().item())\n",
    "#         print(correct, pred, data.y)\n",
    "        count_total += len(graph_pred_max)\n",
    "        edge_total += len(edge_pred)\n",
    "#         print(out, data.y, )\n",
    "    count_acc = count_correct/count_total\n",
    "    edge_acc = edge_correct / edge_total\n",
    "    print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", count accuracy: \", count_acc, \", edge accuracy: \", edge_acc)\n",
    "    loss_v.append(loss)\n",
    "    acc_v_count.append(count_acc)\n",
    "    acc_v_edge.append(edge_acc)\n",
    "plt.plot(np.arange(len(loss_v)), loss_v)\n",
    "plt.plot(np.arange(len(acc_v_count)), acc_v_count)\n",
    "plt.plot(np.arange(len(acc_v_edge)), acc_v_edge)\n",
    "plt.ylim(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[5910], edge_index=[2, 14768], x=[5910, 2], y=[14768], y_graph=[100])\n",
      "Accuracy: 0.6900\n",
      "Batch(batch=[6130], edge_index=[2, 15735], x=[6130, 2], y=[15735], y_graph=[100])\n",
      "Accuracy: 0.7000\n",
      "Batch(batch=[6460], edge_index=[2, 17175], x=[6460, 2], y=[17175], y_graph=[100])\n",
      "Accuracy: 0.6700\n",
      "Batch(batch=[6180], edge_index=[2, 15944], x=[6180, 2], y=[15944], y_graph=[100])\n",
      "Accuracy: 0.6800\n",
      "Batch(batch=[6110], edge_index=[2, 15557], x=[6110, 2], y=[15557], y_graph=[100])\n",
      "Accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    data = batch.to(device)\n",
    "    edge_pred, graph_pred = model(data)\n",
    "    _, graph_pred_max = graph_pred.max(dim=1)\n",
    "    correct = float(graph_pred_max.eq(data.y_graph).sum().item())\n",
    "    acc = correct / len(graph_pred_max)\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Edge & Track Param Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Edge_Track_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Segment classification graph neural network model.\n",
    "    Consists of an input network, an edge network, and a node network.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
    "                 output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
    "        super(Edge_Track_Net, self).__init__()\n",
    "        self.n_graph_iters = n_graph_iters\n",
    "        # Setup the input network\n",
    "        self.input_network = make_mlp(input_dim, [hidden_dim],\n",
    "                                      output_activation=nn.Tanh,\n",
    "                                      layer_norm=True)\n",
    "        # Setup the edge network\n",
    "        self.edge_network = EdgeNetwork(input_dim+hidden_dim, hidden_dim,\n",
    "                                        hidden_activation, layer_norm=layer_norm)\n",
    "        # Setup the node layers\n",
    "        self.node_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
    "                                        layer_norm=True)\n",
    "        \n",
    "        self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
    "                                        layer_norm=False)\n",
    "#         make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
    "                                       hidden_activation=nn.ReLU,\n",
    "                                      output_activation=nn.ReLU,\n",
    "                                      layer_norm=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Apply forward pass of the model\"\"\"\n",
    "        # Apply input network to get hidden representation\n",
    "        x = self.input_network(inputs.x)\n",
    "        # Shortcut connect the inputs onto the hidden representation\n",
    "        x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Loop over iterations of edge and node networks\n",
    "        for i in range(self.n_graph_iters):\n",
    "            # Apply edge network\n",
    "            e = torch.sigmoid(self.edge_network(x, inputs.edge_index))\n",
    "            # Apply node network\n",
    "            x = self.node_network(x, e, inputs.edge_index)\n",
    "            # Shortcut connect the inputs onto the hidden representation\n",
    "            x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Apply final edge network\n",
    "        e = self.edge_network(x, inputs.edge_index)\n",
    "        return e, self.output_network(x, e, inputs.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = cut_full_dataset[:int(0.2 * len(cut_full_dataset))]\n",
    "test_dataset = cut_full_dataset[int(0.9 * len(cut_full_dataset)):]\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using \", device)\n",
    "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
    "model = Edge_Track_Net(input_dim=3, hidden_dim=32, n_graph_iters=4, output_dim=1).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "learning_rate=0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aab83484da0>]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,3)\n",
    "fig.set_size_inches(16,4)\n",
    "axs[0].plot(np.arange(len(loss_v)-10), loss_v[10:])\n",
    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
    "axs[2].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , loss:  0.5599503517150879 , node accuracy:  0.038111395897190876 , edge accuracy:  0.7874483127827399  lr:  [0.001]\n",
      "Epoch:  2 , loss:  0.6682133674621582 , node accuracy:  0.015668295751018683 , edge accuracy:  0.8321150353814678  lr:  [0.001]\n",
      "Epoch:  3 , loss:  0.5618876814842224 , node accuracy:  0.02112377126953855 , edge accuracy:  0.8355207652216219  lr:  [0.001]\n",
      "Epoch:  4 , loss:  0.734445333480835 , node accuracy:  0.02421896405351819 , edge accuracy:  0.8363695120549128  lr:  [0.001]\n",
      "Epoch:  5 , loss:  0.5602551698684692 , node accuracy:  0.02242825347850675 , edge accuracy:  0.8370234732655845  lr:  [0.001]\n",
      "Epoch:  6 , loss:  0.5669384002685547 , node accuracy:  0.02287129153861416 , edge accuracy:  0.8376109374701751  lr:  [0.001]\n",
      "Epoch:  7 , loss:  0.4889724850654602 , node accuracy:  0.020894660193519564 , edge accuracy:  0.8485200864904985  lr:  [0.001]\n",
      "Epoch:  8 , loss:  0.38022947311401367 , node accuracy:  0.022190369371594545 , edge accuracy:  0.8846958782953861  lr:  [0.001]\n",
      "Epoch:  9 , loss:  0.35603076219558716 , node accuracy:  0.022660063948646725 , edge accuracy:  0.9033561456240042  lr:  [0.001]\n",
      "Epoch:  10 , loss:  0.43030795454978943 , node accuracy:  0.023864331150873188 , edge accuracy:  0.912043992785652  lr:  [0.0009000000000000001]\n",
      "Epoch:  11 , loss:  0.42047613859176636 , node accuracy:  0.024040804041532877 , edge accuracy:  0.922484200302477  lr:  [0.0009000000000000001]\n",
      "Epoch:  12 , loss:  0.3376671075820923 , node accuracy:  0.024999088954484164 , edge accuracy:  0.9305282072930968  lr:  [0.0009000000000000001]\n",
      "Epoch:  13 , loss:  0.30888134241104126 , node accuracy:  0.026108877362475993 , edge accuracy:  0.9328315428415174  lr:  [0.0009000000000000001]\n",
      "Epoch:  14 , loss:  0.22948771715164185 , node accuracy:  0.026934554539233668 , edge accuracy:  0.9337742200251872  lr:  [0.0009000000000000001]\n",
      "Epoch:  15 , loss:  0.27933305501937866 , node accuracy:  0.02833149099684576 , edge accuracy:  0.9368628239565009  lr:  [0.0009000000000000001]\n",
      "Epoch:  16 , loss:  0.27099600434303284 , node accuracy:  0.02917336453832937 , edge accuracy:  0.93955031510614  lr:  [0.0009000000000000001]\n",
      "Epoch:  17 , loss:  0.2604626417160034 , node accuracy:  0.02991974701278298 , edge accuracy:  0.9412265013208401  lr:  [0.0009000000000000001]\n",
      "Epoch:  18 , loss:  0.37988629937171936 , node accuracy:  0.031116253456911595 , edge accuracy:  0.9422398482199178  lr:  [0.0009000000000000001]\n",
      "Epoch:  19 , loss:  0.22471609711647034 , node accuracy:  0.031251560587226196 , edge accuracy:  0.9433266170469381  lr:  [0.0009000000000000001]\n",
      "Epoch:  20 , loss:  0.3343443274497986 , node accuracy:  0.031403064082266736 , edge accuracy:  0.9442486082460727  lr:  [0.0008100000000000001]\n",
      "Epoch:  21 , loss:  0.25551119446754456 , node accuracy:  0.031596745610447736 , edge accuracy:  0.946011622327191  lr:  [0.0008100000000000001]\n",
      "Epoch:  22 , loss:  0.3524739742279053 , node accuracy:  0.03200131730433104 , edge accuracy:  0.9466308701475052  lr:  [0.0008100000000000001]\n",
      "Epoch:  23 , loss:  0.21147102117538452 , node accuracy:  0.03289549160690883 , edge accuracy:  0.9472581082622752  lr:  [0.0008100000000000001]\n",
      "Epoch:  24 , loss:  0.38444021344184875 , node accuracy:  0.032404201876888736 , edge accuracy:  0.9486311071929074  lr:  [0.0008100000000000001]\n",
      "Epoch:  25 , loss:  0.36394181847572327 , node accuracy:  0.03299705631071106 , edge accuracy:  0.948075160260892  lr:  [0.0008100000000000001]\n",
      "Epoch:  26 , loss:  0.401293009519577 , node accuracy:  0.0334519042200978 , edge accuracy:  0.9492716624651035  lr:  [0.0008100000000000001]\n",
      "Epoch:  27 , loss:  0.3061547577381134 , node accuracy:  0.033214357537450716 , edge accuracy:  0.949970902011024  lr:  [0.0008100000000000001]\n",
      "Epoch:  28 , loss:  0.23824721574783325 , node accuracy:  0.034131476690056915 , edge accuracy:  0.951233102191871  lr:  [0.0008100000000000001]\n",
      "Epoch:  29 , loss:  0.2962646186351776 , node accuracy:  0.033924973039801215 , edge accuracy:  0.9511691798362256  lr:  [0.0008100000000000001]\n",
      "Epoch:  30 , loss:  0.3002249300479889 , node accuracy:  0.03414699820625261 , edge accuracy:  0.9513690259786668  lr:  [0.0007290000000000002]\n",
      "Epoch:  31 , loss:  0.21453049778938293 , node accuracy:  0.03389021834049347 , edge accuracy:  0.952017127640071  lr:  [0.0007290000000000002]\n",
      "Epoch:  32 , loss:  0.3410756289958954 , node accuracy:  0.035327645709920405 , edge accuracy:  0.9529358339403737  lr:  [0.0007290000000000002]\n",
      "Epoch:  33 , loss:  0.38386762142181396 , node accuracy:  0.03475706127759624 , edge accuracy:  0.9531690617574298  lr:  [0.0007290000000000002]\n",
      "Epoch:  34 , loss:  0.3646724224090576 , node accuracy:  0.034717245214311646 , edge accuracy:  0.9528793691928871  lr:  [0.0007290000000000002]\n",
      "Epoch:  35 , loss:  0.32825997471809387 , node accuracy:  0.03493285931972569 , edge accuracy:  0.9531853086894896  lr:  [0.0007290000000000002]\n",
      "Epoch:  36 , loss:  0.5765171051025391 , node accuracy:  0.03487077325494293 , edge accuracy:  0.9542378968124496  lr:  [0.0007290000000000002]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-f7037618432f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0medge_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_v = []\n",
    "acc_v_node = []\n",
    "acc_v_edge = []\n",
    "ep = 0\n",
    "for epoch in range(100):\n",
    "    ep += 1\n",
    "    node_correct = 0\n",
    "    edge_correct = 0\n",
    "    node_total = 0\n",
    "    edge_total = 0 \n",
    "    for batch in train_loader:\n",
    "#         print(batch)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        edge_pred, node_pred = model(data)\n",
    "#         print(edge_pred.shape, data.y_edges.shape, node_pred.shape, data.y_params.shape)\n",
    "#         print(edge_pred, data.y_edges, node_pred, data.y_params)\n",
    "        losses = [F.binary_cross_entropy_with_logits(edge_pred.float(), data.y_edges.float()), 0.001*F.mse_loss(node_pred.float(), data.y_params.float())]\n",
    "#         print(node_pred, data.y_nodes)\n",
    "#         print(\"Losses: \", losses[0].item(), losses[1].item())\n",
    "#         loss = F.mse_loss(node_pred, data.y_params.float())\n",
    "        loss = sum(losses)\n",
    "        loss_v.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        edge_pred = torch.sigmoid(edge_pred)\n",
    "        edge_correct += ((edge_pred > 0.5) == (data.y_edges > 0.5)).sum().item()\n",
    "        # A \"correct\" track parameter is one where the pred. is within 5% of the truth\n",
    "#         print(node_pred, data.y_nodes)\n",
    "#         print((((node_pred - data.y_nodes)/data.y_nodes)**2 < 0.05**2).sum().item())\n",
    "        node_correct += (((node_pred - data.y_params)/data.y_params)**2 < 0.1**2).sum().item()\n",
    "        node_total += len(node_pred)\n",
    "        edge_total += len(edge_pred)\n",
    "#         print(out, data.y, )\n",
    "    node_acc = node_correct/node_total\n",
    "    edge_acc = edge_correct / edge_total\n",
    "    scheduler.step()\n",
    "    print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", node accuracy: \", node_acc, \", edge accuracy: \", edge_acc, \" lr: \", scheduler.get_lr())\n",
    "    acc_v_node.append(node_acc)\n",
    "    acc_v_edge.append(edge_acc)\n",
    "\n",
    "#     if node_acc > 0.5:\n",
    "#         break\n",
    "fig, axs = plt.subplots(1,3)\n",
    "fig.set_size_inches(16,4)\n",
    "axs[0].plot(np.arange(len(loss_v)-10), loss_v[10:])\n",
    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
    "axs[2].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.484405994415283 13.484405994415283\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()\n",
    "print(torch.cuda.memory_allocated(0)/1024**3, torch.cuda.max_memory_allocated(0)/1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.3371e-01, 1.2481e-04, 9.6756e-05,  ..., 9.9400e-01, 9.9787e-01,\n",
      "        8.2649e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 1., 1.], device='cuda:0') tensor([[ 1.5715],\n",
      "        [ 0.5701],\n",
      "        [13.6160],\n",
      "        ...,\n",
      "        [ 1.3305],\n",
      "        [ 7.2867],\n",
      "        [ 6.9683]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[63.3021],\n",
      "        [63.3021],\n",
      "        [63.3021],\n",
      "        ...,\n",
      "        [ 0.3630],\n",
      "        [ 0.3630],\n",
      "        [ 0.3630]], device='cuda:0')\n",
      "Accuracy: 0.0375\n",
      "tensor([9.9742e-01, 1.4877e-04, 3.3513e-04,  ..., 8.9183e-01, 7.1162e-01,\n",
      "        7.0020e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[ 0.7292],\n",
      "        [ 0.5435],\n",
      "        [ 0.9654],\n",
      "        ...,\n",
      "        [14.1774],\n",
      "        [13.7110],\n",
      "        [13.0482]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.4460],\n",
      "        [0.4460],\n",
      "        [0.4460],\n",
      "        ...,\n",
      "        [1.8646],\n",
      "        [1.8646],\n",
      "        [1.8646]], device='cuda:0')\n",
      "Accuracy: 0.0337\n",
      "tensor([9.7150e-01, 1.0385e-04, 1.2531e-03,  ..., 2.0462e-03, 2.8011e-01,\n",
      "        6.7641e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 1.], device='cuda:0') tensor([[1.1098],\n",
      "        [0.5423],\n",
      "        [0.5456],\n",
      "        ...,\n",
      "        [0.9280],\n",
      "        [0.8626],\n",
      "        [1.1622]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.0569],\n",
      "        [0.0569],\n",
      "        [0.0569],\n",
      "        ...,\n",
      "        [8.0154],\n",
      "        [8.0154],\n",
      "        [8.0154]], device='cuda:0')\n",
      "Accuracy: 0.0363\n",
      "tensor([2.4325e-01, 1.1887e-04, 5.5876e-04,  ..., 9.6752e-01, 2.1461e-01,\n",
      "        7.7381e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.6849],\n",
      "        [0.5458],\n",
      "        [0.9192],\n",
      "        ...,\n",
      "        [0.6772],\n",
      "        [7.2738],\n",
      "        [6.1074]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[2.1139],\n",
      "        [2.1139],\n",
      "        [2.1139],\n",
      "        ...,\n",
      "        [3.9318],\n",
      "        [3.9318],\n",
      "        [3.9318]], device='cuda:0')\n",
      "Accuracy: 0.0361\n",
      "tensor([9.9032e-01, 1.2744e-01, 1.6800e-04,  ..., 9.8953e-01, 8.3447e-01,\n",
      "        1.5724e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 1., 0.], device='cuda:0') tensor([[0.7098],\n",
      "        [0.5436],\n",
      "        [0.5460],\n",
      "        ...,\n",
      "        [1.0879],\n",
      "        [2.7611],\n",
      "        [8.4110]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[2.5095],\n",
      "        [2.5095],\n",
      "        [2.5095],\n",
      "        ...,\n",
      "        [5.1271],\n",
      "        [5.1271],\n",
      "        [5.1271]], device='cuda:0')\n",
      "Accuracy: 0.0325\n",
      "tensor([8.6973e-01, 1.6951e-04, 1.6392e-04,  ..., 9.6008e-02, 9.9416e-01,\n",
      "        8.2875e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 1., 1.], device='cuda:0') tensor([[ 0.8158],\n",
      "        [ 0.5432],\n",
      "        [ 0.6423],\n",
      "        ...,\n",
      "        [ 3.0944],\n",
      "        [10.2323],\n",
      "        [ 0.9616]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.5287],\n",
      "        [0.5287],\n",
      "        [0.5287],\n",
      "        ...,\n",
      "        [6.7962],\n",
      "        [6.7962],\n",
      "        [6.7962]], device='cuda:0')\n",
      "Accuracy: 0.0351\n",
      "tensor([9.9511e-01, 1.3140e-04, 1.4977e-04,  ..., 1.9575e-04, 9.9504e-01,\n",
      "        9.8382e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 1., 1.], device='cuda:0') tensor([[0.6525],\n",
      "        [0.5424],\n",
      "        [0.8683],\n",
      "        ...,\n",
      "        [1.4378],\n",
      "        [2.9625],\n",
      "        [2.0328]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[3.4463],\n",
      "        [3.4463],\n",
      "        [3.4463],\n",
      "        ...,\n",
      "        [0.5728],\n",
      "        [0.5728],\n",
      "        [0.5728]], device='cuda:0')\n",
      "Accuracy: 0.0354\n",
      "tensor([7.8903e-01, 2.8118e-03, 5.7416e-04,  ..., 4.6416e-01, 1.1951e-04,\n",
      "        9.4196e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[3.9413],\n",
      "        [0.9036],\n",
      "        [9.4332],\n",
      "        ...,\n",
      "        [0.8195],\n",
      "        [1.9732],\n",
      "        [3.7097]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.0314],\n",
      "        [0.0314],\n",
      "        [0.0314],\n",
      "        ...,\n",
      "        [0.0686],\n",
      "        [0.0686],\n",
      "        [0.0686]], device='cuda:0')\n",
      "Accuracy: 0.0342\n",
      "tensor([8.7638e-01, 1.0924e-04, 1.0771e-04,  ..., 1.2790e-02, 2.9906e-02,\n",
      "        1.3434e-02], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') tensor([[0.7203],\n",
      "        [0.5467],\n",
      "        [1.0233],\n",
      "        ...,\n",
      "        [0.5462],\n",
      "        [0.5487],\n",
      "        [3.3905]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.2186],\n",
      "        [0.2186],\n",
      "        [0.2186],\n",
      "        ...,\n",
      "        [0.0403],\n",
      "        [0.0403],\n",
      "        [0.0403]], device='cuda:0')\n",
      "Accuracy: 0.0349\n",
      "tensor([9.8768e-01, 9.7742e-05, 2.7992e-02,  ..., 1.7775e-01, 1.6944e-01,\n",
      "        2.2894e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 1.], device='cuda:0') tensor([[0.7063],\n",
      "        [0.5915],\n",
      "        [1.0360],\n",
      "        ...,\n",
      "        [3.9350],\n",
      "        [1.1334],\n",
      "        [1.5988]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[ 0.0349],\n",
      "        [ 0.0349],\n",
      "        [ 0.0349],\n",
      "        ...,\n",
      "        [32.7402],\n",
      "        [32.7402],\n",
      "        [32.7402]], device='cuda:0')\n",
      "Accuracy: 0.0358\n",
      "tensor([9.8840e-01, 1.9351e-04, 2.5222e-04,  ..., 4.7956e-03, 1.0587e-03,\n",
      "        9.4449e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') tensor([[0.9140],\n",
      "        [0.5431],\n",
      "        [0.5767],\n",
      "        ...,\n",
      "        [0.5397],\n",
      "        [0.7263],\n",
      "        [8.6720]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.3607],\n",
      "        [0.3607],\n",
      "        [0.3607],\n",
      "        ...,\n",
      "        [0.1135],\n",
      "        [0.1135],\n",
      "        [0.1135]], device='cuda:0')\n",
      "Accuracy: 0.0335\n",
      "tensor([8.6358e-02, 1.4355e-01, 1.9970e-04,  ..., 9.9696e-01, 8.0943e-04,\n",
      "        9.7098e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 1., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[7.1680],\n",
      "        [0.5435],\n",
      "        [0.9238],\n",
      "        ...,\n",
      "        [0.6047],\n",
      "        [2.3098],\n",
      "        [5.3418]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[4.3154],\n",
      "        [4.3154],\n",
      "        [4.3154],\n",
      "        ...,\n",
      "        [0.2060],\n",
      "        [0.2060],\n",
      "        [0.2060]], device='cuda:0')\n",
      "Accuracy: 0.0345\n",
      "tensor([4.3749e-01, 1.7056e-04, 1.1816e-04,  ..., 9.6023e-01, 9.9551e-01,\n",
      "        1.8150e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 1., 0.], device='cuda:0') tensor([[ 0.7187],\n",
      "        [ 0.5534],\n",
      "        [ 0.8164],\n",
      "        ...,\n",
      "        [15.4443],\n",
      "        [ 6.8037],\n",
      "        [ 5.4404]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[2.2738],\n",
      "        [2.2738],\n",
      "        [2.2738],\n",
      "        ...,\n",
      "        [0.0978],\n",
      "        [0.0978],\n",
      "        [0.0978]], device='cuda:0')\n",
      "Accuracy: 0.0350\n",
      "tensor([9.2696e-05, 8.7801e-05, 9.5737e-05,  ..., 8.8211e-01, 1.6481e-03,\n",
      "        9.2225e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([0., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.7574],\n",
      "        [0.9120],\n",
      "        [7.5483],\n",
      "        ...,\n",
      "        [0.5395],\n",
      "        [0.8428],\n",
      "        [6.1476]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[30.9913],\n",
      "        [30.9913],\n",
      "        [30.9913],\n",
      "        ...,\n",
      "        [ 0.3478],\n",
      "        [ 0.3478],\n",
      "        [ 0.3478]], device='cuda:0')\n",
      "Accuracy: 0.0341\n",
      "tensor([4.6446e-01, 1.5978e-04, 1.7472e-01,  ..., 5.8727e-01, 5.0097e-01,\n",
      "        5.0055e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.6067],\n",
      "        [0.5435],\n",
      "        [1.0965],\n",
      "        ...,\n",
      "        [0.9453],\n",
      "        [0.8330],\n",
      "        [1.0036]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.2520],\n",
      "        [0.2520],\n",
      "        [0.2520],\n",
      "        ...,\n",
      "        [0.3966],\n",
      "        [0.3966],\n",
      "        [0.3966]], device='cuda:0')\n",
      "Accuracy: 0.0348\n",
      "tensor([7.9539e-01, 1.2997e-01, 1.9766e-04,  ..., 9.3179e-01, 1.4623e-02,\n",
      "        9.8409e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.5707],\n",
      "        [0.6216],\n",
      "        [0.8513],\n",
      "        ...,\n",
      "        [0.6348],\n",
      "        [0.6736],\n",
      "        [0.8960]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.0417],\n",
      "        [0.0417],\n",
      "        [0.0417],\n",
      "        ...,\n",
      "        [0.2276],\n",
      "        [0.2276],\n",
      "        [0.2276]], device='cuda:0')\n",
      "Accuracy: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.9341e-01, 2.5245e-04, 1.8199e-04,  ..., 9.0931e-02, 8.6608e-01,\n",
      "        1.8489e-03], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0') tensor([[0.5448],\n",
      "        [0.5467],\n",
      "        [0.8112],\n",
      "        ...,\n",
      "        [1.7237],\n",
      "        [1.7570],\n",
      "        [5.0801]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.1209],\n",
      "        [0.1209],\n",
      "        [0.1209],\n",
      "        ...,\n",
      "        [2.2227],\n",
      "        [2.2227],\n",
      "        [2.2227]], device='cuda:0')\n",
      "Accuracy: 0.0350\n",
      "tensor([3.5646e-01, 1.3433e-04, 2.6260e-04,  ..., 5.4933e-04, 5.9468e-04,\n",
      "        9.8144e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 1.], device='cuda:0') tensor([[0.7382],\n",
      "        [0.5465],\n",
      "        [0.6196],\n",
      "        ...,\n",
      "        [1.1391],\n",
      "        [1.2705],\n",
      "        [1.7194]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.0023],\n",
      "        [0.0023],\n",
      "        [0.0023],\n",
      "        ...,\n",
      "        [0.1175],\n",
      "        [0.1175],\n",
      "        [0.1175]], device='cuda:0')\n",
      "Accuracy: 0.0338\n",
      "tensor([3.0108e-02, 1.3733e-03, 8.1862e-05,  ..., 1.4494e-03, 6.4844e-01,\n",
      "        1.0903e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([0., 0., 0.,  ..., 0., 0., 1.], device='cuda:0') tensor([[7.9655],\n",
      "        [1.5169],\n",
      "        [0.7510],\n",
      "        ...,\n",
      "        [1.3972],\n",
      "        [3.3405],\n",
      "        [1.0085]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[51.9062],\n",
      "        [51.9062],\n",
      "        [51.9062],\n",
      "        ...,\n",
      "        [ 0.2006],\n",
      "        [ 0.2006],\n",
      "        [ 0.2006]], device='cuda:0')\n",
      "Accuracy: 0.0340\n",
      "tensor([4.4391e-01, 1.0845e-04, 9.7740e-05,  ..., 9.9425e-01, 2.3081e-04,\n",
      "        9.7540e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.7346],\n",
      "        [0.5472],\n",
      "        [0.5459],\n",
      "        ...,\n",
      "        [0.5880],\n",
      "        [0.8285],\n",
      "        [2.3015]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.0423],\n",
      "        [0.0423],\n",
      "        [0.0423],\n",
      "        ...,\n",
      "        [0.3633],\n",
      "        [0.3633],\n",
      "        [0.3633]], device='cuda:0')\n",
      "Accuracy: 0.0356\n",
      "tensor([8.6055e-01, 1.6129e-04, 1.2192e-04,  ..., 1.9832e-01, 1.3138e-01,\n",
      "        3.0419e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 1.], device='cuda:0') tensor([[3.3039],\n",
      "        [0.6548],\n",
      "        [0.6124],\n",
      "        ...,\n",
      "        [0.9618],\n",
      "        [1.2512],\n",
      "        [2.3853]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[ 0.1545],\n",
      "        [ 0.1545],\n",
      "        [ 0.1545],\n",
      "        ...,\n",
      "        [18.5391],\n",
      "        [18.5391],\n",
      "        [18.5391]], device='cuda:0')\n",
      "Accuracy: 0.0352\n",
      "tensor([0.4641, 0.4169, 0.7636,  ..., 0.9914, 0.9883, 0.9748], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>) tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0') tensor([[ 9.2842],\n",
      "        [10.4451],\n",
      "        [ 7.8896],\n",
      "        ...,\n",
      "        [ 1.4973],\n",
      "        [ 1.1776],\n",
      "        [ 1.7480]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[83.8616],\n",
      "        [83.8616],\n",
      "        [83.8616],\n",
      "        ...,\n",
      "        [ 0.0908],\n",
      "        [ 0.0908],\n",
      "        [ 0.0908]], device='cuda:0')\n",
      "Accuracy: 0.0336\n",
      "tensor([8.6679e-01, 2.9149e-03, 1.2847e-04,  ..., 9.8813e-01, 9.9544e-01,\n",
      "        9.9051e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 1., 1.], device='cuda:0') tensor([[0.8661],\n",
      "        [0.5415],\n",
      "        [0.5461],\n",
      "        ...,\n",
      "        [0.7583],\n",
      "        [1.5500],\n",
      "        [1.8687]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[2.6424],\n",
      "        [2.6424],\n",
      "        [2.6424],\n",
      "        ...,\n",
      "        [0.4221],\n",
      "        [0.4221],\n",
      "        [0.4221]], device='cuda:0')\n",
      "Accuracy: 0.0348\n",
      "tensor([5.3342e-01, 1.5163e-04, 1.2795e-04,  ..., 4.2354e-02, 3.2658e-04,\n",
      "        9.8938e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.9908],\n",
      "        [0.5889],\n",
      "        [0.8017],\n",
      "        ...,\n",
      "        [1.0144],\n",
      "        [1.4240],\n",
      "        [4.2202]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[3.3233],\n",
      "        [3.3233],\n",
      "        [3.3233],\n",
      "        ...,\n",
      "        [0.6371],\n",
      "        [0.6371],\n",
      "        [0.6371]], device='cuda:0')\n",
      "Accuracy: 0.0381\n",
      "tensor([9.6733e-01, 2.6323e-04, 2.2965e-04,  ..., 9.3327e-01, 3.5791e-03,\n",
      "        9.8144e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.6911],\n",
      "        [0.5462],\n",
      "        [0.5439],\n",
      "        ...,\n",
      "        [0.9134],\n",
      "        [7.5918],\n",
      "        [1.0038]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[10.6444],\n",
      "        [10.6444],\n",
      "        [10.6444],\n",
      "        ...,\n",
      "        [ 0.2166],\n",
      "        [ 0.2166],\n",
      "        [ 0.2166]], device='cuda:0')\n",
      "Accuracy: 0.0332\n",
      "tensor([9.8665e-01, 1.0347e-04, 8.7657e-05,  ..., 3.9000e-03, 9.8597e-01,\n",
      "        4.2907e-03], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 1., 0.], device='cuda:0') tensor([[0.7773],\n",
      "        [0.5452],\n",
      "        [3.0912],\n",
      "        ...,\n",
      "        [1.2596],\n",
      "        [1.2275],\n",
      "        [1.6707]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.4743],\n",
      "        [0.4743],\n",
      "        [0.4743],\n",
      "        ...,\n",
      "        [0.1173],\n",
      "        [0.1173],\n",
      "        [0.1173]], device='cuda:0')\n",
      "Accuracy: 0.0351\n",
      "tensor([7.3535e-01, 1.3217e-04, 1.1330e-04,  ..., 2.4735e-04, 2.8507e-03,\n",
      "        8.7266e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 1.], device='cuda:0') tensor([[0.8854],\n",
      "        [0.5451],\n",
      "        [0.6782],\n",
      "        ...,\n",
      "        [0.6149],\n",
      "        [0.9327],\n",
      "        [0.9552]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[1.6060],\n",
      "        [1.6060],\n",
      "        [1.6060],\n",
      "        ...,\n",
      "        [0.0386],\n",
      "        [0.0386],\n",
      "        [0.0386]], device='cuda:0')\n",
      "Accuracy: 0.0348\n",
      "tensor([9.7652e-01, 8.5466e-05, 2.7331e-04,  ..., 1.6046e-01, 5.7225e-04,\n",
      "        9.8357e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.7516],\n",
      "        [0.5424],\n",
      "        [0.5460],\n",
      "        ...,\n",
      "        [0.9380],\n",
      "        [1.7524],\n",
      "        [4.1151]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.0254],\n",
      "        [0.0254],\n",
      "        [0.0254],\n",
      "        ...,\n",
      "        [0.1382],\n",
      "        [0.1382],\n",
      "        [0.1382]], device='cuda:0')\n",
      "Accuracy: 0.0359\n",
      "tensor([4.6875e-01, 2.8193e-01, 1.7245e-04,  ..., 1.4696e-02, 3.4589e-02,\n",
      "        8.3899e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 1.], device='cuda:0') tensor([[0.8937],\n",
      "        [0.6325],\n",
      "        [0.8045],\n",
      "        ...,\n",
      "        [1.8717],\n",
      "        [2.4681],\n",
      "        [5.7391]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.0755],\n",
      "        [0.0755],\n",
      "        [0.0755],\n",
      "        ...,\n",
      "        [8.9241],\n",
      "        [8.9241],\n",
      "        [8.9241]], device='cuda:0')\n",
      "Accuracy: 0.0348\n",
      "tensor([5.7931e-01, 1.9722e-01, 5.3190e-04,  ..., 1.7703e-03, 1.9580e-04,\n",
      "        2.2929e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 1.], device='cuda:0') tensor([[0.5925],\n",
      "        [0.7365],\n",
      "        [0.6088],\n",
      "        ...,\n",
      "        [0.5674],\n",
      "        [0.6823],\n",
      "        [1.2497]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.5226],\n",
      "        [0.5226],\n",
      "        [0.5226],\n",
      "        ...,\n",
      "        [0.0704],\n",
      "        [0.0704],\n",
      "        [0.0704]], device='cuda:0')\n",
      "Accuracy: 0.0352\n",
      "tensor([7.6390e-01, 4.5444e-03, 1.1119e-04,  ..., 9.8995e-01, 5.4751e-01,\n",
      "        3.9858e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.6109],\n",
      "        [0.5443],\n",
      "        [0.5476],\n",
      "        ...,\n",
      "        [6.4189],\n",
      "        [0.8579],\n",
      "        [7.5937]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.1732],\n",
      "        [0.1732],\n",
      "        [0.1732],\n",
      "        ...,\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081]], device='cuda:0')\n",
      "Accuracy: 0.0370\n",
      "tensor([9.8327e-01, 1.3564e-04, 1.3634e-04,  ..., 7.9088e-01, 5.0286e-01,\n",
      "        5.7304e-02], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0') tensor([[0.7074],\n",
      "        [0.5430],\n",
      "        [1.2764],\n",
      "        ...,\n",
      "        [6.5383],\n",
      "        [1.2499],\n",
      "        [1.2671]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[1.0848],\n",
      "        [1.0848],\n",
      "        [1.0848],\n",
      "        ...,\n",
      "        [1.2075],\n",
      "        [1.2075],\n",
      "        [1.2075]], device='cuda:0')\n",
      "Accuracy: 0.0368\n",
      "tensor([4.7669e-02, 5.2056e-04, 6.5352e-02,  ..., 9.8914e-01, 9.3796e-02,\n",
      "        8.5225e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.8733],\n",
      "        [0.9494],\n",
      "        [0.8729],\n",
      "        ...,\n",
      "        [1.3489],\n",
      "        [1.8896],\n",
      "        [1.8478]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[1.1149],\n",
      "        [1.1149],\n",
      "        [1.1149],\n",
      "        ...,\n",
      "        [0.3781],\n",
      "        [0.3781],\n",
      "        [0.3781]], device='cuda:0')\n",
      "Accuracy: 0.0349\n",
      "tensor([8.4347e-01, 1.4776e-04, 4.5167e-04,  ..., 1.6111e-04, 9.9050e-01,\n",
      "        9.9732e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 1., 1.], device='cuda:0') tensor([[0.5422],\n",
      "        [0.7242],\n",
      "        [0.5855],\n",
      "        ...,\n",
      "        [8.0421],\n",
      "        [3.3055],\n",
      "        [8.1637]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[1.0212e-01],\n",
      "        [1.0212e-01],\n",
      "        [1.0212e-01],\n",
      "        ...,\n",
      "        [1.3067e+02],\n",
      "        [1.3067e+02],\n",
      "        [1.3067e+02]], device='cuda:0')\n",
      "Accuracy: 0.0357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9595e-01, 4.9849e-01, 9.5157e-05,  ..., 8.5482e-01, 4.3373e-01,\n",
      "        8.3115e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[ 0.7067],\n",
      "        [ 3.8614],\n",
      "        [10.1679],\n",
      "        ...,\n",
      "        [ 0.8682],\n",
      "        [ 0.5501],\n",
      "        [ 1.4535]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[1.3448e+02],\n",
      "        [1.3448e+02],\n",
      "        [1.3448e+02],\n",
      "        ...,\n",
      "        [6.0341e-02],\n",
      "        [6.0341e-02],\n",
      "        [6.0341e-02]], device='cuda:0')\n",
      "Accuracy: 0.0353\n",
      "tensor([0.3161, 0.1951, 0.2565,  ..., 0.0008, 0.4652, 0.3716], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 1.], device='cuda:0') tensor([[1.5366],\n",
      "        [0.5426],\n",
      "        [0.5455],\n",
      "        ...,\n",
      "        [1.0948],\n",
      "        [1.4515],\n",
      "        [4.6992]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.0791],\n",
      "        [0.0791],\n",
      "        [0.0791],\n",
      "        ...,\n",
      "        [0.4389],\n",
      "        [0.4389],\n",
      "        [0.4389]], device='cuda:0')\n",
      "Accuracy: 0.0350\n",
      "tensor([6.1782e-01, 9.1888e-04, 1.2533e-04,  ..., 9.7308e-01, 1.7723e-04,\n",
      "        9.8832e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[1.1526],\n",
      "        [0.9570],\n",
      "        [0.6574],\n",
      "        ...,\n",
      "        [3.2503],\n",
      "        [1.7889],\n",
      "        [1.2714]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.2002],\n",
      "        [0.2002],\n",
      "        [0.2002],\n",
      "        ...,\n",
      "        [0.7439],\n",
      "        [0.7439],\n",
      "        [0.7439]], device='cuda:0')\n",
      "Accuracy: 0.0351\n",
      "tensor([0.5141, 0.1407, 0.5748,  ..., 0.9726, 0.0903, 0.7708], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.6482],\n",
      "        [0.5417],\n",
      "        [1.0431],\n",
      "        ...,\n",
      "        [0.5490],\n",
      "        [0.7944],\n",
      "        [6.8744]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.0854],\n",
      "        [0.0854],\n",
      "        [0.0854],\n",
      "        ...,\n",
      "        [0.3277],\n",
      "        [0.3277],\n",
      "        [0.3277]], device='cuda:0')\n",
      "Accuracy: 0.0344\n",
      "tensor([9.4967e-01, 1.9661e-04, 1.2988e-04,  ..., 8.0945e-01, 9.2410e-02,\n",
      "        9.7857e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[1.0679],\n",
      "        [0.5420],\n",
      "        [0.5454],\n",
      "        ...,\n",
      "        [3.0806],\n",
      "        [1.5062],\n",
      "        [7.9585]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.2910],\n",
      "        [0.2910],\n",
      "        [0.2910],\n",
      "        ...,\n",
      "        [0.1204],\n",
      "        [0.1204],\n",
      "        [0.1204]], device='cuda:0')\n",
      "Accuracy: 0.0367\n",
      "tensor([5.0405e-01, 1.1651e-04, 1.2058e-01,  ..., 5.6051e-03, 9.4491e-01,\n",
      "        9.7349e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 1., 1.], device='cuda:0') tensor([[0.6300],\n",
      "        [0.7620],\n",
      "        [0.6761],\n",
      "        ...,\n",
      "        [0.5419],\n",
      "        [0.9048],\n",
      "        [4.7914]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.5109],\n",
      "        [0.5109],\n",
      "        [0.5109],\n",
      "        ...,\n",
      "        [0.1410],\n",
      "        [0.1410],\n",
      "        [0.1410]], device='cuda:0')\n",
      "Accuracy: 0.0372\n",
      "tensor([0.3892, 0.0886, 0.0253,  ..., 0.1251, 0.0016, 0.7245], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 1.], device='cuda:0') tensor([[ 2.6081],\n",
      "        [ 0.5434],\n",
      "        [ 0.5428],\n",
      "        ...,\n",
      "        [ 2.4864],\n",
      "        [ 2.4090],\n",
      "        [15.0986]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[1.0438],\n",
      "        [1.0438],\n",
      "        [1.0438],\n",
      "        ...,\n",
      "        [1.8620],\n",
      "        [1.8620],\n",
      "        [1.8620]], device='cuda:0')\n",
      "Accuracy: 0.0347\n",
      "tensor([8.3795e-01, 1.0678e-04, 1.7930e-04,  ..., 9.8179e-01, 4.2272e-01,\n",
      "        4.1965e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[1.7973],\n",
      "        [0.5431],\n",
      "        [0.6561],\n",
      "        ...,\n",
      "        [0.5996],\n",
      "        [0.5500],\n",
      "        [2.7891]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[1.9852],\n",
      "        [1.9852],\n",
      "        [1.9852],\n",
      "        ...,\n",
      "        [0.0100],\n",
      "        [0.0100],\n",
      "        [0.0100]], device='cuda:0')\n",
      "Accuracy: 0.0356\n",
      "tensor([4.4137e-01, 7.3130e-04, 1.2012e-04,  ..., 9.3023e-01, 1.3134e-01,\n",
      "        8.5316e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[0.8385],\n",
      "        [0.5448],\n",
      "        [0.5467],\n",
      "        ...,\n",
      "        [0.6612],\n",
      "        [1.0554],\n",
      "        [5.1643]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.7683],\n",
      "        [0.7683],\n",
      "        [0.7683],\n",
      "        ...,\n",
      "        [0.0732],\n",
      "        [0.0732],\n",
      "        [0.0732]], device='cuda:0')\n",
      "Accuracy: 0.0355\n",
      "tensor([1.9255e-01, 1.3474e-04, 1.1974e-03,  ..., 8.4294e-01, 6.4017e-04,\n",
      "        9.7782e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[1.2746],\n",
      "        [0.6322],\n",
      "        [0.9034],\n",
      "        ...,\n",
      "        [1.1458],\n",
      "        [1.3878],\n",
      "        [1.7722]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[4.5390],\n",
      "        [4.5390],\n",
      "        [4.5390],\n",
      "        ...,\n",
      "        [0.7533],\n",
      "        [0.7533],\n",
      "        [0.7533]], device='cuda:0')\n",
      "Accuracy: 0.0364\n",
      "tensor([8.0751e-04, 8.8880e-05, 1.2780e-04,  ..., 2.1240e-03, 9.8284e-01,\n",
      "        9.9026e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([0., 0., 0.,  ..., 0., 1., 1.], device='cuda:0') tensor([[3.3026],\n",
      "        [3.1837],\n",
      "        [0.8561],\n",
      "        ...,\n",
      "        [0.5356],\n",
      "        [0.8326],\n",
      "        [6.9366]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[14.8994],\n",
      "        [14.8994],\n",
      "        [14.8994],\n",
      "        ...,\n",
      "        [ 0.2008],\n",
      "        [ 0.2008],\n",
      "        [ 0.2008]], device='cuda:0')\n",
      "Accuracy: 0.0342\n",
      "tensor([9.9185e-01, 1.0765e-04, 9.1675e-05,  ..., 2.4229e-02, 9.7195e-01,\n",
      "        9.0920e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 1., 1.], device='cuda:0') tensor([[0.7104],\n",
      "        [0.5441],\n",
      "        [0.5452],\n",
      "        ...,\n",
      "        [1.2240],\n",
      "        [1.1488],\n",
      "        [0.9144]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[1.5634],\n",
      "        [1.5634],\n",
      "        [1.5634],\n",
      "        ...,\n",
      "        [1.9763],\n",
      "        [1.9763],\n",
      "        [1.9763]], device='cuda:0')\n",
      "Accuracy: 0.0341\n",
      "tensor([9.8652e-01, 1.3592e-04, 2.0944e-04,  ..., 8.6725e-01, 1.3076e-02,\n",
      "        9.9441e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 1., 1.], device='cuda:0') tensor([[0.7453],\n",
      "        [0.5453],\n",
      "        [0.5456],\n",
      "        ...,\n",
      "        [0.5436],\n",
      "        [0.9128],\n",
      "        [0.9530]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[10.9352],\n",
      "        [10.9352],\n",
      "        [10.9352],\n",
      "        ...,\n",
      "        [ 0.2870],\n",
      "        [ 0.2870],\n",
      "        [ 0.2870]], device='cuda:0')\n",
      "Accuracy: 0.0357\n",
      "tensor([2.5748e-01, 8.3904e-05, 4.6140e-01,  ..., 9.9685e-01, 1.1448e-02,\n",
      "        7.5961e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0') tensor([[1.0213],\n",
      "        [0.5444],\n",
      "        [0.7075],\n",
      "        ...,\n",
      "        [0.7741],\n",
      "        [3.9515],\n",
      "        [2.3138]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.0163],\n",
      "        [0.0163],\n",
      "        [0.0163],\n",
      "        ...,\n",
      "        [6.3676],\n",
      "        [6.3676],\n",
      "        [6.3676]], device='cuda:0')\n",
      "Accuracy: 0.0344\n",
      "tensor([4.4654e-01, 1.7093e-04, 8.6026e-05,  ..., 2.3539e-01, 4.6134e-03,\n",
      "        8.4370e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 1.], device='cuda:0') tensor([[0.9188],\n",
      "        [0.6421],\n",
      "        [0.5606],\n",
      "        ...,\n",
      "        [1.3088],\n",
      "        [1.6571],\n",
      "        [2.0567]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.2370],\n",
      "        [0.2370],\n",
      "        [0.2370],\n",
      "        ...,\n",
      "        [0.1704],\n",
      "        [0.1704],\n",
      "        [0.1704]], device='cuda:0')\n",
      "Accuracy: 0.0341\n",
      "tensor([2.2003e-01, 5.1669e-01, 3.2341e-04,  ..., 5.6173e-02, 3.2754e-03,\n",
      "        8.9267e-01], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([1., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') tensor([[0.8634],\n",
      "        [0.5831],\n",
      "        [0.7467],\n",
      "        ...,\n",
      "        [1.3825],\n",
      "        [1.5989],\n",
      "        [2.9171]], device='cuda:0', grad_fn=<ReluBackward0>) tensor([[0.2142],\n",
      "        [0.2142],\n",
      "        [0.2142],\n",
      "        ...,\n",
      "        [0.3064],\n",
      "        [0.3064],\n",
      "        [0.3064]], device='cuda:0')\n",
      "Accuracy: 0.0325\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "#     print(batch)\n",
    "    data = batch.to(device)\n",
    "    edge_pred, node_pred = model(data)\n",
    "    edge_pred = torch.sigmoid(edge_pred)\n",
    "    print(edge_pred, data.y_edges, node_pred, data.y_params)\n",
    "    correct = (((node_pred - data.y_params)/data.y_params)**2 < 0.1**2).sum().item()\n",
    "    acc = correct / (len(node_pred))\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True False\n",
      "True False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False True\n",
      "False True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "False True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True False\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "False True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "False True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False True\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "False True\n",
      "False False\n",
      "False True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True False\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True False\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "True True\n",
      "True False\n",
      "True True\n",
      "False True\n",
      "False False\n",
      "True False\n"
     ]
    }
   ],
   "source": [
    "for pred, dat in zip(edge_pred, data.y):\n",
    "    print(pred.item() < 0.5, dat.item() < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8922e+01, 3.6313e+00, 3.0467e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
      "tensor([ 46.2187, -35.0857,   0.6955], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
      "tensor([ 1.8613e+01,  3.5876e+00, -1.0034e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
      "tensor([ 1.8996e+01,  2.9768e+00, -4.8119e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
      "tensor([25.8152, 16.9260, -1.2471], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
      "tensor([25.4800, 16.8262, -1.2453], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
      "tensor([24.8583, 16.6111, -1.2062], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
      "tensor([21.5880, -2.6879,  0.8381], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
      "tensor([16.9862,  3.8774,  0.1122], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
      "tensor([ 41.1885, -32.8211,   1.0185], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
      "tensor([ 40.7710, -30.7252,   1.2782], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
      "tensor([25.7639, 18.2869, -1.1607], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
      "tensor([16.9630,  2.1817,  0.0223], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
      "tensor([24.5119, -4.3527,  0.6603], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
      "tensor([ 44.5465, -35.2413,   1.0523], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
      "tensor([ 45.1856, -40.0252,   1.1841], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
      "tensor([24.6620, 16.4957, -1.1209], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
      "tensor([1.7948e+01, 5.2398e-01, 7.7200e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
      "tensor([ 45.7709, -35.0205,   1.2817], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
      "tensor([ 44.2098, -33.7250,   1.2481], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
      "tensor([22.9125, -3.6225,  0.6602], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
      "tensor([16.7419,  3.0845,  0.0594], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
      "tensor([26.6395, 17.5330, -0.8474], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
      "tensor([23.7234, -3.3299,  1.1437], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
      "tensor([27.5753, 17.9557, -0.5238], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
      "tensor([21.8177, -2.6738,  1.0679], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
      "tensor([ 44.8839, -32.5191,   1.1000], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
      "tensor([21.9020, -3.5113,  1.1277], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
      "tensor([1.8384e+01, 6.1529e-01, 3.2547e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
      "tensor([25.4626, 16.8129, -1.2414], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
      "tensor([25.4351, 17.4593, -1.2281], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
      "tensor([16.8515,  3.8994,  0.0608], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
      "tensor([23.3092, -1.9636,  0.5303], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
      "tensor([25.9646, 17.7169, -1.2468], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
      "tensor([ 46.9991, -33.8223,   0.1652], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
      "tensor([21.1459, -2.2798,  0.9505], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
      "tensor([23.1696, -3.5011,  1.1510], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
      "tensor([21.5713, -3.3363,  1.0770], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
      "tensor([ 46.2006, -35.3662,   1.1758], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
      "tensor([1.7263e+01, 1.0393e+00, 1.6066e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
      "tensor([27.7684, 17.3738,  0.4669], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
      "tensor([45.3506, 18.0112,  0.9953], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
      "tensor([50.5027, 18.5959,  1.0513], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
      "tensor([37.3744, -5.8386,  0.6888], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
      "tensor([ 46.2743, -27.2447,   0.5555], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
      "tensor([ 51.6387, -31.0397,   0.8468], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
      "tensor([24.5524, 19.4569,  0.9050], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
      "tensor([24.2394, 18.8239,  0.8832], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
      "tensor([45.0087, 16.7298,  0.2292], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
      "tensor([44.5156, 15.5085,  1.1685], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
      "tensor([ 1.7541e+01,  2.0131e+00, -4.8630e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
      "tensor([48.6423, 16.9927,  1.0624], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
      "tensor([27.6775, 16.9265,  1.0528], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
      "tensor([23.6196, 18.5726,  0.9916], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
      "tensor([1.7953e+01, 9.1990e-03, 5.6586e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
      "tensor([28.0753, 17.4585,  1.0053], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
      "tensor([20.5719, 12.1217, -1.0629], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
      "tensor([21.2473, 11.5207, -0.8434], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
      "tensor([34.1981, -3.6442,  0.7675], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
      "tensor([35.5160, -5.8147,  0.7135], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
      "tensor([17.7641,  0.0203,  0.2386], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
      "tensor([26.3771, 16.5180,  1.0986], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
      "tensor([23.0741,  8.3208, -0.6991], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
      "tensor([21.7606, 12.2207, -1.2206], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
      "tensor([ 51.5355, -31.3089,   0.8295], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
      "tensor([47.0115, 18.1877,  0.6074], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
      "tensor([38.1979, -4.7878,  1.0353], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
      "tensor([24.2371, 19.3842,  0.5825], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
      "tensor([24.3078, 19.6725,  1.0566], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
      "tensor([37.0417, -5.9561,  0.7059], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
      "tensor([ 1.7006e+01,  1.8718e+00, -3.3896e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
      "tensor([ 47.2504, -27.9689,   1.1573], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
      "tensor([20.9418, 12.1344, -1.0992], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
      "tensor([45.6598, 17.6850,  0.9116], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
      "tensor([22.2479, 12.4092, -1.2084], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
      "tensor([47.0971, 18.5995,  1.0467], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
      "tensor([ 48.1816, -27.8349,   1.0276], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
      "tensor([26.3400, 16.4928,  1.0442], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
      "tensor([27.0130, 16.4426,  1.0671], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
      "tensor([36.6436, -5.3281,  0.9428], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
      "tensor([ 49.8435, -29.2734,   0.8564], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
      "tensor([27.7259, 17.4203,  1.0643], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
      "tensor([ 4.2559e+01,  1.6479e+01, -7.1920e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
      "tensor([24.3839, 18.9240,  0.9832], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
      "tensor([1.8226e+01, 6.0504e-01, 6.6561e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
      "tensor([ 47.6424, -27.5069,   1.3200], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
      "tensor([18.5114,  0.3200,  0.0315], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
      "tensor([27.6347, 17.0694,  1.0836], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
      "tensor([17.6981,  0.1550,  0.0968], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
      "tensor([ 45.3533, -26.1198,   0.2132], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
      "tensor([28.8183, 17.7870,  0.8339], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
      "tensor([20.1620, 11.9863, -1.1321], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
      "tensor([48.3909, 18.0284,  0.7943], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
      "tensor([37.8586, -5.2764,  0.7718], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
      "tensor([ 46.1128, -26.8198,   1.3595], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
      "tensor([36.0578, -6.1242,  0.8403], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
      "tensor([38.0319, -5.8003,  1.1152], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
      "tensor([1.7983e+01, 1.5616e-02, 4.1088e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
      "tensor([20.5953, 12.0102, -1.1903], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
      "tensor([ 1.7714e+01,  8.4727e-01, -1.6490e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
      "tensor([27.2588, 16.8424,  1.0697], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
      "tensor([24.0996, 19.1311,  1.1166], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
      "tensor([25.2157, 19.9593,  0.5026], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
      "tensor([37.2529, -6.4199,  0.9335], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
      "tensor([21.1143, 11.9102, -0.9114], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
      "tensor([24.5080, 18.7854,  0.8182], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
      "tensor([ 1.7304e+01,  1.5815e+00, -2.6718e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
      "tensor([ 52.6274, -29.6235,   0.7102], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
      "tensor([21.7299, 12.2777, -1.1904], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
      "tensor([24.5432, 19.5908,  1.0037], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
      "tensor([ 48.1639, -28.5145,  -1.3257], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
      "tensor([32.0019, 26.6397, -1.1649], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
      "tensor([32.1165, 12.5905,  0.0456], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
      "tensor([28.7304, 14.3607,  0.9624], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
      "tensor([2.0859e+01, 8.6323e+00, 3.1196e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
      "tensor([47.7461, -8.3849,  1.1690], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
      "tensor([25.8597, 20.8922, -0.9945], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
      "tensor([46.4431, -6.8762,  0.9621], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
      "tensor([18.2406,  5.1905,  0.0713], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
      "tensor([ 54.1077, -30.4465,  -1.2699], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
      "tensor([17.1021,  3.1857,  0.1222], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
      "tensor([17.2286, 13.7583, -1.1431], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
      "tensor([4.6069e+01, 4.6449e+00, 1.8598e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
      "tensor([24.2882, 11.2915,  1.0395], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
      "tensor([24.4959, 11.5860,  0.8428], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
      "tensor([43.2275,  4.4356, -0.1100], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
      "tensor([ 46.4589, -29.3233,  -1.2642], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
      "tensor([29.5395, 13.9458,  1.0556], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
      "tensor([1.5784e+01, 1.2392e+01, 4.4193e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
      "tensor([32.3649, 12.6060,  0.7098], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
      "tensor([ 42.0881, -26.7149,  -0.8660], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
      "tensor([31.0216, 26.6414, -1.1206], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
      "tensor([23.7804, 11.2889,  0.9542], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
      "tensor([ 42.3342, -26.9702,  -1.2818], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
      "tensor([31.6662, 26.6305, -1.1397], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
      "tensor([ 41.3861, -26.5129,  -1.1880], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
      "tensor([30.7623, 25.6517, -0.5856], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
      "tensor([ 46.0461, -10.6148,   1.0503], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
      "tensor([ 30.8343, -17.1875,  -1.1948], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
      "tensor([1.8842e+01, 4.8756e+00, 1.1441e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
      "tensor([1.7010e+01, 1.0998e+00, 6.0374e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
      "tensor([ 41.6420, -26.5655,  -1.1666], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
      "tensor([27.8856, 23.0059, -0.4784], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
      "tensor([ 4.6144e+01,  4.0165e+00, -1.2932e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
      "tensor([15.9573, 12.7325, -0.0453], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
      "tensor([30.1603, 25.6759, -1.1075], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
      "tensor([33.0890, 28.8386, -0.8282], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
      "tensor([44.9079, -7.6834,  1.2577], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
      "tensor([ 48.7111, -25.7130,  -1.4429], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
      "tensor([ 41.6861, -26.8061,  -1.3106], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
      "tensor([1.7741e+01, 3.0308e-01, 9.8991e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
      "tensor([17.5335,  4.3753,  0.2962], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
      "tensor([33.2634, 12.2586,  0.3365], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
      "tensor([24.2539, 11.3417,  0.9970], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
      "tensor([29.9662, 26.8041, -1.0218], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
      "tensor([49.1592, -7.7543,  1.1602], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
      "tensor([42.5250, -7.2680,  1.1907], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
      "tensor([45.2285, -9.9877,  1.1006], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
      "tensor([ 4.4435e+01,  6.0937e+00, -3.4538e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
      "tensor([24.4202, 11.0299,  1.0440], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
      "tensor([29.6907, 24.8335, -1.1392], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
      "tensor([2.8395e+01, 9.9921e+00, 1.9658e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
      "tensor([ 4.5632e+01,  4.1621e+00, -3.9749e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
      "tensor([31.0132, 26.7924, -1.1592], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
      "tensor([24.7528, 11.4088,  1.0851], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
      "tensor([46.1363, -8.4528,  1.1295], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
      "tensor([ 41.6044, -27.0621,  -1.0020], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
      "tensor([ 40.1575, -25.1728,  -1.2345], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
      "tensor([ 4.7806e+01,  5.0180e+00, -1.6837e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
      "tensor([4.1045e+01, 6.2937e+00, 1.2046e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
      "tensor([29.7276, 14.2327,  0.9999], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
      "tensor([28.7566, 14.1472,  1.1039], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
      "tensor([1.7636e+01, 1.1737e+01, 2.9489e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
      "tensor([17.8668, 15.0071, -1.1991], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
      "tensor([28.8045, 14.2918,  1.0584], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
      "tensor([3.8797e+01, 6.2271e+00, 3.3374e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
      "tensor([29.5629, 14.0177,  1.0133], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
      "tensor([ 47.2604, -29.8391,  -1.1907], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
      "tensor([1.6598e+01, 1.2691e+01, 2.2851e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
      "tensor([ 39.0897, -25.0488,  -1.1440], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
      "tensor([46.1941, -9.5500,  1.0726], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
      "tensor([4.0250e+01, 6.5744e+00, 1.9062e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
      "tensor([17.0370,  1.2464,  0.0194], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
      "tensor([23.4191, 10.2125,  0.8028], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
      "tensor([ 52.5991, -30.6360,  -1.1983], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
      "tensor([22.7708, 11.3404,  0.5429], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
      "tensor([32.0703, 26.3512, -1.1672], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
      "tensor([ 4.8828e+01,  6.4398e+00, -7.5582e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
      "tensor([16.4979,  2.3589,  0.0554], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
      "tensor([28.8272, 13.8015,  1.0916], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
      "tensor([ 37.9628, -24.4737,  -0.9050], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
      "tensor([ 43.8031, -28.4171,  -1.2870], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
      "tensor([1.7140e+01, 6.3404e-05, 6.3291e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
      "tensor([23.0901, 18.6425, -1.1632], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
      "tensor([22.5966, 11.1689,  0.8177], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
      "tensor([49.2041, -8.4592,  1.0448], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
      "tensor([ 46.2717, -30.4173,  -1.0776], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
      "tensor([ 41.9591, -26.0762,  -0.9106], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
      "tensor([ 43.6489, -29.1443,  -1.1057], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
      "tensor([ 4.4414e+01,  4.0448e+00, -8.6032e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
      "tensor([20.4732,  7.7521, -0.8678], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
      "tensor([ 3.0361e+01, -9.0684e-01,  1.4020e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
      "tensor([2.3867e+01, 1.5737e+00, 6.2276e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
      "tensor([2.8793e+01, 1.6137e-02, 1.9421e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
      "tensor([18.1009,  7.2010, -0.5217], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
      "tensor([20.4995,  6.1244, -0.3843], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
      "tensor([ 2.4375e+01,  5.3006e-01, -2.2653e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
      "tensor([ 2.9346e+01, -2.1110e+00,  6.9283e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
      "tensor([ 1.9825e+01,  2.6374e+00, -5.3469e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
      "tensor([ 2.2607e+01,  2.6042e+00, -5.4687e-06], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
      "tensor([2.2622e+01, 1.7777e-01, 8.2684e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
      "tensor([19.3176,  7.6769, -0.7170], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
      "tensor([2.3651e+01, 3.5793e-01, 6.9781e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
      "tensor([2.3212e+01, 2.8957e-01, 1.6484e-07], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
      "tensor([20.5678,  6.4029, -0.9347], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
      "tensor([20.6440,  7.0543, -0.5203], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
      "tensor([19.4577,  6.7390, -0.8307], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
      "tensor([25.7861, -2.1049, -0.9565], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
      "tensor([26.9044, -2.0418, -0.9875], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
      "tensor([32.0293, -2.8769,  0.0618], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
      "tensor([ 3.4346e+01, -4.0661e-01,  6.4398e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
      "tensor([25.9423, -1.9959, -0.4250], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
      "tensor([26.4303, -2.0085, -0.1088], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
      "tensor([ 2.1563e+01,  2.6869e+00, -2.6040e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
      "tensor([26.0292, -1.0818, -0.6359], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
      "tensor([20.7453,  6.8437, -0.9572], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
      "tensor([18.3152,  6.8623, -0.6716], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
      "tensor([28.0052, -2.1346, -0.9193], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
      "tensor([18.1486,  7.7711, -0.3882], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
      "tensor([26.0147, -2.3663, -0.7187], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
      "tensor([37.6316, 17.6384,  0.6327], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
      "tensor([38.4320, -5.6872,  1.0864], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
      "tensor([39.4602, 29.9535, -1.1194], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
      "tensor([37.6067, 28.3178, -0.9100], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
      "tensor([41.1823, -6.8072,  0.9684], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
      "tensor([ 30.2778, -12.4251,  -1.1322], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
      "tensor([37.0519, 18.6641,  1.0256], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
      "tensor([ 30.2364, -11.8132,  -1.0391], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
      "tensor([ 4.4481e+01, -6.5600e-01, -5.0757e-08], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
      "tensor([ 30.7749, -12.7462,  -1.1717], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
      "tensor([38.3575, 19.1815,  1.0025], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
      "tensor([41.0319, -3.1314, -0.6708], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
      "tensor([36.5603, 18.9082,  0.9219], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
      "tensor([ 29.2684, -12.0046,  -0.7118], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
      "tensor([40.8006, -8.1951,  0.8819], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
      "tensor([ 4.8053e+01, -2.9964e+00,  2.2435e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
      "tensor([23.6557,  5.3420,  0.4148], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
      "tensor([20.6691,  5.0161,  0.4992], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
      "tensor([27.3522,  2.0463,  0.0655], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
      "tensor([39.3495, 30.9496, -1.0776], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
      "tensor([ 28.3781, -12.0150,  -1.0010], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
      "tensor([37.1208, 18.8004,  1.1111], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
      "tensor([ 2.9178e+01, -1.0264e+01, -3.6540e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
      "tensor([24.6353,  4.4781,  0.1336], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
      "tensor([39.0446, 18.4038,  1.1690], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
      "tensor([ 29.7751, -11.9870,  -1.0337], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
      "tensor([39.1089, -7.1186,  1.3860], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
      "tensor([39.6200, 29.3303, -0.4647], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
      "tensor([39.4916, 30.8150, -1.0854], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
      "tensor([39.6167, -8.1484,  1.0453], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
      "tensor([43.2562, -3.6169, -0.9345], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
      "tensor([40.7500, -7.5464,  0.9650], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
      "tensor([41.2075, -1.7224, -0.2210], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
      "tensor([41.8914, -6.7456,  1.1842], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
      "tensor([22.6407,  4.9817,  0.0567], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
      "tensor([41.0046, -2.9481, -0.6774], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
      "tensor([37.8384, 29.9754, -1.1338], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
      "tensor([41.1329, 19.6691,  0.1152], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
      "tensor([41.6940, -3.3429,  0.1971], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
      "tensor([ 4.5591e+01, -2.7471e+00,  3.4420e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
      "tensor([40.9958, -6.8056,  0.9397], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
      "tensor([40.8906, -7.7229,  0.9011], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
      "tensor([39.2874, 31.5213, -1.0686], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
      "tensor([ 30.1761, -11.8717,  -1.0767], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
      "tensor([25.5830,  4.6412,  0.3656], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
      "tensor([ 30.0866, -11.9596,  -1.0088], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
      "tensor([24.0881,  5.5311,  0.3139], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
      "tensor([43.6374, -3.3421, -0.7984], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
      "tensor([38.3118, 17.2446,  0.8301], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
      "tensor([39.1915, 29.7655, -1.1314], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
      "tensor([36.4061, 18.3137,  1.0203], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
      "tensor([39.7809, -8.1087,  1.0083], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
      "tensor([ 2.1692e+01,  3.9961e+00, -1.3708e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
      "tensor([38.3595, 19.1461,  1.0342], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
      "tensor([37.6707, 29.5908, -1.0714], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
      "tensor([40.0692, 32.2023, -1.0258], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
      "tensor([2.2357e+01, 4.9793e+00, 2.5894e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
      "tensor([ 30.3413, -12.3630,  -1.1304], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
      "tensor([22.5654,  6.4018,  0.1331], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
      "tensor([ 4.8627e+01, -1.5483e+00,  1.0832e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
      "tensor([25.0635, 20.6621,  0.9118], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
      "tensor([ 32.3412, -21.4295,  -0.4783], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
      "tensor([24.8563, 20.7228,  0.9519], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
      "tensor([ 30.5998, -21.6088,  -0.9220], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
      "tensor([ 38.3277, -27.7195,  -1.0626], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
      "tensor([24.3583, 21.3949,  1.1643], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
      "tensor([24.7492, 20.6866,  1.0289], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
      "tensor([ 36.1638, -25.0830,  -1.0250], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
      "tensor([25.0523, 21.1409,  0.4789], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
      "tensor([23.5665, 20.8937,  0.5312], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
      "tensor([ 32.5937, -21.2133,  -1.0758], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
      "tensor([23.3976, 20.0892,  0.9583], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
      "tensor([24.1440, 20.5512,  1.0356], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
      "tensor([ 33.6129, -23.0956,  -0.9738], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
      "tensor([ 30.0960, -15.5063,  -1.1366], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
      "tensor([ 38.0785, -29.6126,  -1.0845], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
      "tensor([24.8373, 21.4133,  1.1694], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
      "tensor([23.4217, 19.6150,  0.9108], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
      "tensor([ 30.4280, -20.8386,  -0.9225], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
      "tensor([ 32.3170, -22.2782,  -1.0892], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
      "tensor([27.2292,  7.9937, -0.8391], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
      "tensor([ 31.8698, -18.5931,   1.4277], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
      "tensor([ 48.1254, -30.4452,  -0.8618], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
      "tensor([ 32.5653, -19.2922,  -1.1136], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
      "tensor([ 33.5700, -20.4197,   1.2511], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
      "tensor([ 39.1715, -22.6338,   1.1657], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
      "tensor([ 33.3085, -20.2111,   1.0551], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
      "tensor([ 42.2549, -26.4990,  -1.3056], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
      "tensor([24.7784,  8.8442, -0.4713], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
      "tensor([27.0000,  8.2584, -0.2980], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
      "tensor([ 44.0308, -23.1981,   0.7422], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
      "tensor([ 42.6640, -24.9193,   1.0270], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
      "tensor([ 48.1079, -32.5155,  -0.8624], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
      "tensor([ 43.0763, -25.1173,  -1.0208], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
      "tensor([ 32.7897, -18.1567,  -1.2757], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
      "tensor([ 32.2616, -19.1610,   0.9457], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
      "tensor([ 50.7671, -27.0119,  -1.0360], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
      "tensor([ 31.1080, -17.7125,   0.6052], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
      "tensor([ 39.6060, -23.2370,  -1.2991], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
      "tensor([26.9951,  8.1046, -0.8100], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
      "tensor([ 29.6949, -16.4559,   1.0694], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
      "tensor([ 36.1768, -20.4686,   0.6178], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
      "tensor([ 45.3915, -21.4775,   0.9351], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
      "tensor([ 29.9549, -18.3827,   1.1334], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
      "tensor([ 36.7118, -21.7746,   0.8704], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
      "tensor([ 51.9191, -35.4677,  -1.1198], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
      "tensor([ 46.7065, -30.8349,  -1.2729], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
      "tensor([ 45.9194, -26.0154,  -1.3024], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
      "tensor([ 27.8645, -16.0591,   1.1560], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
      "tensor([25.9221,  9.7349, -0.3596], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
      "tensor([ 40.1617, -22.3173,  -1.3455], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
      "tensor([ 33.0416, -20.6618,   1.0726], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
      "tensor([25.0358,  7.8745, -0.6312], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
      "tensor([ 35.2067, -17.9522,   1.1347], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
      "tensor([26.5732,  8.0706, -0.7725], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
      "tensor([ 35.0165, -15.6279,   0.7247], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
      "tensor([ 48.9671, -30.7986,  -1.3131], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
      "tensor([ 41.9918, -24.1578,  -1.2832], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
      "tensor([ 46.2006, -30.1672,  -0.8878], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
      "tensor([ 43.5084, -25.8403,  -1.3615], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
      "tensor([ 48.5722, -31.7141,  -1.0249], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
      "tensor([25.8978,  7.6763, -0.7499], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
      "tensor([24.7793,  7.4680, -0.6518], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
      "tensor([24.9587,  6.3740, -0.5758], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
      "tensor([ 48.6529, -26.0149,  -0.9965], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
      "tensor([ 46.3356, -30.3369,  -0.7518], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
      "tensor([ 50.1795, -34.1627,  -1.0129], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
      "tensor([ 29.1484, -15.9217,   1.3702], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
      "tensor([ 44.0147, -25.0389,   1.0110], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
      "tensor([ 38.0040, -21.0520,   0.8675], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
      "tensor([19.1694, -8.4264,  0.9726], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
      "tensor([19.3052, 14.7226, -1.2652], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
      "tensor([19.9093, 14.4648, -1.2532], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
      "tensor([43.7420, -9.4681, -0.9711], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
      "tensor([24.6558, -1.0284, -0.7798], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
      "tensor([40.4085, 23.6050, -1.1083], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
      "tensor([ 45.7367, -11.8549,   1.2197], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
      "tensor([15.9912,  1.8245,  0.0539], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
      "tensor([20.4814, 14.6420, -1.1478], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
      "tensor([ 1.7310e+01,  1.3532e+01, -2.5872e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
      "tensor([ 45.8967, -11.2985,   1.1787], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
      "tensor([19.1737,  6.5416,  0.4160], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
      "tensor([17.7633,  4.8228,  0.3674], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
      "tensor([ 2.0003e+01,  1.8229e-02, -5.8753e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
      "tensor([45.6128, -9.8662, -1.0718], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
      "tensor([39.9717, -9.6078, -0.5851], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
      "tensor([ 28.3255, -17.3660,  -0.9996], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
      "tensor([ 50.5374, -10.9733,   1.1294], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
      "tensor([2.2874e+01, 3.3643e-04, 2.0508e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
      "tensor([1.7383e+01, 5.4251e-01, 2.2851e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
      "tensor([41.7526, -9.6131,  1.1053], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
      "tensor([38.8679, 22.0989, -1.0209], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
      "tensor([42.2459, 24.2224, -1.1425], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
      "tensor([23.0029, -0.4130, -0.5072], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
      "tensor([37.1308, 20.9270, -0.6662], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
      "tensor([24.6513, -1.0274, -0.7799], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
      "tensor([36.7437, 21.7721, -0.5055], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
      "tensor([38.8172, 22.1275, -1.0668], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
      "tensor([32.5541, -7.1424, -0.4088], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
      "tensor([ 21.7859, -10.9481,   0.9601], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
      "tensor([ 27.7086, -17.2293,  -1.0346], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
      "tensor([ 32.4475, -15.1250,   1.1521], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
      "tensor([ 29.3695, -17.8955,  -1.0002], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
      "tensor([17.9851, -7.8031,  1.0950], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
      "tensor([ 4.4604e+01, -9.2402e+00, -2.2697e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
      "tensor([ 34.6389, -22.0240,   1.0612], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
      "tensor([2.1917e+01, 3.7318e-04, 1.0870e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
      "tensor([45.7130, -9.6971, -1.1591], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
      "tensor([ 48.5334, -11.1791,   1.1318], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
      "tensor([20.6993, 13.5720, -0.8054], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
      "tensor([ 2.2089e+01, -3.6863e-02, -1.7284e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
      "tensor([ 27.2232, -16.6841,  -1.0463], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
      "tensor([ 28.3570, -17.2013,  -1.0628], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
      "tensor([18.6096, -8.1778,  1.0952], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
      "tensor([ 41.1040, -10.5154,  -0.4078], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
      "tensor([2.2622e+01, 4.7181e-05, 9.8465e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
      "tensor([ 46.9590, -10.0802,   1.0000], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
      "tensor([ 31.0548, -19.3935,  -0.9932], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
      "tensor([ 32.7773, -15.3948,   0.4964], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
      "tensor([ 33.4972, -22.4312,  -1.0192], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
      "tensor([ 46.2448, -12.3461,   1.2108], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
      "tensor([17.7250,  3.3450,  0.0559], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
      "tensor([ 45.7980, -10.8379,  -1.0088], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
      "tensor([ 47.2279, -11.1517,   1.1422], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
      "tensor([18.1354,  0.1791, -0.6717], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
      "tensor([ 28.9363, -17.8795,  -1.1328], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
      "tensor([21.1007, -9.8037,  1.0609], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
      "tensor([ 2.0315e+01,  1.5277e+01, -5.1279e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
      "tensor([22.0932, -0.3574, -0.8531], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
      "tensor([17.2614, 13.4807, -0.1066], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
      "tensor([45.1314, -9.8459,  1.3050], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
      "tensor([39.3175, 22.6438, -1.1115], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
      "tensor([45.1563, -9.9030, -1.3124], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
      "tensor([23.0284, -0.3491, -0.1983], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
      "tensor([17.9584, 13.7529, -0.9381], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
      "tensor([40.2954, 23.0237, -1.1225], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
      "tensor([39.6436, 22.8016, -1.1094], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
      "tensor([16.3021,  4.4033,  0.4693], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
      "tensor([49.8576, -9.7559,  1.2227], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
      "tensor([45.7060, -9.8630, -1.2551], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
      "tensor([ 1.8570e+01,  1.4343e+01, -5.7742e-08], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
      "tensor([36.4904, 20.6650, -0.9052], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
      "tensor([ 43.3137, -10.5829,   0.0456], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
      "tensor([16.3764,  2.3267,  0.0347], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
      "tensor([ 26.4741, -15.8986,  -0.2672], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
      "tensor([ 30.3962, -15.5043,   0.7691], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
      "tensor([ 1.9314e+01, -3.2709e-01,  8.9996e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
      "tensor([20.2633, 14.9293, -1.2018], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
      "tensor([19.7943, -8.5712,  1.0701], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
      "tensor([ 27.5721, -16.4542,  -1.0861], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
      "tensor([ 36.8004, -14.0253,  -0.1525], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
      "tensor([ 37.6987, -12.7500,  -0.9818], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
      "tensor([ 36.8323, -13.1476,  -0.8427], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
      "tensor([ 37.0691, -13.0756,  -1.2426], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
      "tensor([ 37.7271, -12.7907,  -1.1204], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
      "tensor([ 4.7225e+01,  3.1429e+00, -5.7094e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
      "tensor([4.8059e+01, 4.4811e-01, 1.0074e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
      "tensor([5.0588e+01, 5.3723e-01, 1.1402e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
      "tensor([4.5107e+01, 1.1715e+00, 3.5800e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
      "tensor([ 4.4905e+01,  2.2869e+00, -3.3138e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
      "tensor([ 35.8117, -13.7389,  -0.5532], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
      "tensor([ 4.6455e+01,  3.2318e+00, -2.4588e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
      "tensor([ 37.7274, -12.8226,  -1.1574], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
      "tensor([ 37.3657, -12.9295,  -1.1164], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
      "tensor([42.8013,  3.1678, -0.0764], device='cuda:0', grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
      "tensor([ 37.8884, -13.3035,  -1.2201], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
      "tensor([ 4.4989e+01,  3.4468e+00, -2.9004e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
      "tensor([ 36.7744, -12.8364,  -1.1663], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
      "tensor([ 4.5628e+01,  3.1252e+00, -8.4812e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
      "tensor([ 4.8861e+01,  1.6628e+00, -6.3367e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
      "tensor([21.1452, 14.2958,  1.0402], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
      "tensor([ 34.3848, -21.0683,   0.4999], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
      "tensor([ 36.1567, -22.2870,   0.9020], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
      "tensor([20.7149, -8.4735, -0.9143], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
      "tensor([22.1994, 14.6790,  0.9295], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
      "tensor([ 31.6820, -19.2839,   1.0733], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
      "tensor([43.4429, -9.6276, -0.5950], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
      "tensor([ 45.2725, -13.6588,   1.2365], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
      "tensor([ 47.2706, -11.9890,   1.1404], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
      "tensor([37.7684,  9.9255, -0.3758], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
      "tensor([21.2967, -9.2416, -0.7403], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
      "tensor([46.9732, -9.0880, -1.1894], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
      "tensor([ 41.1978, -11.2936,  -1.3125], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
      "tensor([45.6473, -8.7864, -1.0961], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
      "tensor([ 33.3934, -13.4733,  -0.0717], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
      "tensor([ 46.2767, -13.3457,   1.3039], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
      "tensor([ 35.7915, -23.1989,   1.4267], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
      "tensor([24.5251, -8.3163, -1.0842], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
      "tensor([19.2190, -8.1142, -0.0356], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
      "tensor([23.9683, -9.7375, -1.1503], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
      "tensor([21.8635, -9.6428, -1.1142], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
      "tensor([ 47.6516, -11.7902,   1.0446], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
      "tensor([28.3642, -9.4880, -1.0699], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
      "tensor([45.1132, -8.6117, -0.9859], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
      "tensor([34.4113,  8.6637, -0.7571], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
      "tensor([ 4.4134e+01, -8.3850e+00,  1.2796e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
      "tensor([22.0105, 14.7682,  0.4353], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
      "tensor([ 42.1805, -14.1110,  -1.3199], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
      "tensor([ 33.1469, -12.6442,  -0.5486], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
      "tensor([22.9424, 13.8233,  0.7787], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
      "tensor([ 39.9691, -30.4766,   1.3957], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
      "tensor([ 46.1071, -32.6982,   0.8277], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
      "tensor([ 36.9858, -22.7988,   0.9687], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
      "tensor([ 47.4768, -12.7926,   0.9172], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
      "tensor([43.5278, -8.5838, -0.9152], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
      "tensor([ 37.6509, -23.5464,   1.0267], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
      "tensor([36.0453,  9.8700, -0.2599], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
      "tensor([ 37.4979, -26.4122,   1.0523], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
      "tensor([22.5580, 15.2765,  0.9946], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
      "tensor([ 39.3663, -27.1656,   1.0368], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
      "tensor([20.3253, -8.3980, -1.0026], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
      "tensor([34.1808, -8.9038, -1.1762], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
      "tensor([35.4480,  9.0929, -0.6705], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
      "tensor([36.7542,  9.2998, -0.5362], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
      "tensor([ 35.5665, -14.0888,  -0.1037], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
      "tensor([ 43.2548, -30.9784,   0.8108], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
      "tensor([ 43.7007, -11.5399,   1.3480], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
      "tensor([ 40.7450, -11.0795,   0.8547], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
      "tensor([ 36.3603, -22.9301,   0.9941], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
      "tensor([25.3835, -8.7454, -1.0970], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
      "tensor([ 43.7655, -32.5143,   1.4511], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
      "tensor([21.9805, 14.6549,  0.9896], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
      "tensor([ 42.7131, -14.0731,  -1.2423], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
      "tensor([36.3246,  9.1050, -0.6384], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
      "tensor([22.2379, 15.5507,  0.3626], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
      "tensor([41.2401, -9.1022,  0.0708], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
      "tensor([ 47.5700, -32.0633,   0.7148], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
      "tensor([ 44.4812, -29.9610,   0.1999], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
      "tensor([21.5474, -9.3747, -0.6336], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
      "tensor([22.3830, -9.6972, -1.0111], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
      "tensor([44.0308, -9.5210, -0.1934], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
      "tensor([ 24.7156, -11.5502,  -1.0125], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
      "tensor([ 46.2647, -12.7126,   1.1559], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
      "tensor([21.9339, 13.5515,  0.6462], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
      "tensor([22.3797, 15.6557,  0.4092], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
      "tensor([44.3779, -9.2008, -0.8399], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
      "tensor([39.1298,  8.9210, -0.5924], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
      "tensor([39.6513,  9.4132, -0.8297], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
      "tensor([ 22.2594, -10.0362,  -1.0848], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
      "tensor([ 39.1314, -27.1075,   1.1799], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
      "tensor([ 48.3564, -12.1008,   1.0983], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
      "tensor([28.6191, -9.6940, -0.8227], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
      "tensor([ 43.2633, -15.0926,  -1.2950], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
      "tensor([24.7170, -8.7339, -1.1214], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
      "tensor([29.0598,  3.9818,  0.2646], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
      "tensor([21.7672, 14.6257,  0.9070], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
      "tensor([34.6777,  9.0611, -0.7263], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
      "tensor([25.9458, -8.9930, -1.1087], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
      "tensor([36.9219,  8.8780, -0.7726], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
      "tensor([ 36.9911, -23.7474,   1.3183], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
      "tensor([34.7247, -9.9405, -0.9778], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
      "tensor([ 34.3366, -22.1937,   0.8130], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
      "tensor([21.8759, 14.8030,  1.0215], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
      "tensor([46.1893, -9.2882, -1.2502], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
      "tensor([ 46.0888, -12.8163,   1.2269], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
      "tensor([ 30.9451, -11.3676,  -0.3238], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
      "tensor([ 46.2089, -33.2701,   1.1292], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
      "tensor([26.8774, -9.5045, -1.0295], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
      "tensor([ 37.6442, -23.3092,   0.8890], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
      "tensor([ 36.6121, -12.8179,  -0.8288], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for pred, dat in zip(node_pred, data.y_nodes):\n",
    "    print(pred, dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGNNConv',\n",
       " 'APPNP',\n",
       " 'ARGA',\n",
       " 'ARGVA',\n",
       " 'ARMAConv',\n",
       " 'ChebConv',\n",
       " 'DNAConv',\n",
       " 'DataParallel',\n",
       " 'DeepGraphInfomax',\n",
       " 'DenseGCNConv',\n",
       " 'DenseGINConv',\n",
       " 'DenseSAGEConv',\n",
       " 'DynamicEdgeConv',\n",
       " 'ECConv',\n",
       " 'EdgeConv',\n",
       " 'FeaStConv',\n",
       " 'GAE',\n",
       " 'GATConv',\n",
       " 'GCNConv',\n",
       " 'GINConv',\n",
       " 'GMMConv',\n",
       " 'GatedGraphConv',\n",
       " 'GlobalAttention',\n",
       " 'GraphConv',\n",
       " 'HypergraphConv',\n",
       " 'InnerProductDecoder',\n",
       " 'JumpingKnowledge',\n",
       " 'MessagePassing',\n",
       " 'MetaLayer',\n",
       " 'NNConv',\n",
       " 'PPFConv',\n",
       " 'PointConv',\n",
       " 'RENet',\n",
       " 'RGCNConv',\n",
       " 'Reshape',\n",
       " 'SAGEConv',\n",
       " 'SAGPooling',\n",
       " 'SGConv',\n",
       " 'Set2Set',\n",
       " 'SignedConv',\n",
       " 'SignedGCN',\n",
       " 'SplineConv',\n",
       " 'TopKPooling',\n",
       " 'VGAE',\n",
       " 'XConv',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'avg_pool',\n",
       " 'avg_pool_x',\n",
       " 'conv',\n",
       " 'data_parallel',\n",
       " 'dense',\n",
       " 'dense_diff_pool',\n",
       " 'fps',\n",
       " 'glob',\n",
       " 'global_add_pool',\n",
       " 'global_max_pool',\n",
       " 'global_mean_pool',\n",
       " 'global_sort_pool',\n",
       " 'graclus',\n",
       " 'inits',\n",
       " 'knn',\n",
       " 'knn_graph',\n",
       " 'knn_interpolate',\n",
       " 'max_pool',\n",
       " 'max_pool_x',\n",
       " 'meta',\n",
       " 'models',\n",
       " 'nearest',\n",
       " 'pool',\n",
       " 'radius',\n",
       " 'radius_graph',\n",
       " 'reshape',\n",
       " 'unpool',\n",
       " 'voxel_grid']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-v1.2.0-gpu [conda env:root] *",
   "language": "python",
   "name": "conda-root-pytorch-v1.2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
