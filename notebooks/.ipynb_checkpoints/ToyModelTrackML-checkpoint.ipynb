{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Graph Training Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint as pp\n",
    "from time import time as tt\n",
    "sys.path.append('..')\n",
    "\n",
    "sys.path.append('/global/common/cori_cle7/software/jupyter/19-11/lib/python3.7/site-packages')\n",
    "sys.path.append('/global/homes/d/danieltm/.local/lib/python3.7/site-packages')\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "# mp.set_start_method(\"forkserver\", force=True)\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_scatter import scatter_add\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "# os.environ['WANDB_MODE'] = 'dryrun'\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "# Limit CPU usage on Jupyter\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "# Local imports\n",
    "from utils.toy_utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loading TrackML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mhitgraphs_med_000\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls $SCRATCH/ExaTrkX/node_tracker_data/\n",
    "g1 = np.load(\"/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/event000001000_g000.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/\"\n",
    "filenames = [os.path.join(input_dir, f) for f in os.listdir(input_dir)\n",
    "                         if f.endswith('.npz') and not f.endswith('_ID.npz')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "full_graphs = [load_graph(fi) for fi in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cut_mask = [~(np.isnan(g[3]).any()) for g in full_graphs]\n",
    "cut_full_graphs = np.array(full_graphs)[cut_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cut_full_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),\n",
    "                                         edge_index=torch.from_numpy(di[1]), y_edges=torch.from_numpy(di[2]), \n",
    "                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in full_graphs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2aab7fd80cf8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(np.concatenate(np.array([di[3][:,0] for di in full_graphs]))[:100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Constructing PyG Datastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(1000)]\n",
    "test_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using \", device)\n",
    "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
    "model = Net(train_dataset).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Edge Classification Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , loss:  0.5512356758117676 , accuracy:  0.6864395625058761\n",
      "Epoch:  2 , loss:  0.5046652555465698 , accuracy:  0.7436710645899276\n",
      "Epoch:  3 , loss:  0.48637688159942627 , accuracy:  0.7629634272462315\n",
      "Epoch:  4 , loss:  0.47630026936531067 , accuracy:  0.7705349587890564\n",
      "Epoch:  5 , loss:  0.4798726439476013 , accuracy:  0.7736814064997336\n",
      "Epoch:  6 , loss:  0.4695682227611542 , accuracy:  0.7731611770973706\n",
      "Epoch:  7 , loss:  0.4612908959388733 , accuracy:  0.7738506377511047\n",
      "Epoch:  8 , loss:  0.44322115182876587 , accuracy:  0.7768779968034097\n",
      "Epoch:  9 , loss:  0.46184107661247253 , accuracy:  0.7758438058228087\n",
      "Epoch:  10 , loss:  0.43595728278160095 , accuracy:  0.7730358206148735\n",
      "Epoch:  11 , loss:  0.40324726700782776 , accuracy:  0.7812466702184336\n",
      "Epoch:  12 , loss:  0.3373474180698395 , accuracy:  0.7961014133943402\n",
      "Epoch:  13 , loss:  0.27982667088508606 , accuracy:  0.8321476699363816\n",
      "Epoch:  14 , loss:  0.2253979742527008 , accuracy:  0.8571813594910527\n",
      "Epoch:  15 , loss:  0.21640172600746155 , accuracy:  0.8812498041304961\n",
      "Epoch:  16 , loss:  0.1846497803926468 , accuracy:  0.9013381804506565\n",
      "Epoch:  17 , loss:  0.2350691705942154 , accuracy:  0.8991068350622081\n",
      "Epoch:  18 , loss:  0.1935807168483734 , accuracy:  0.8991256385345827\n",
      "Epoch:  19 , loss:  0.15857245028018951 , accuracy:  0.912563853458272\n",
      "Epoch:  20 , loss:  0.18233557045459747 , accuracy:  0.9181923595223918\n",
      "Epoch:  21 , loss:  0.16060705482959747 , accuracy:  0.9187752671660033\n",
      "Epoch:  22 , loss:  0.15544316172599792 , accuracy:  0.9248111817982387\n",
      "Epoch:  23 , loss:  0.12819615006446838 , accuracy:  0.9281519320567865\n",
      "Epoch:  24 , loss:  0.1715494692325592 , accuracy:  0.9166567426118023\n",
      "Epoch:  25 , loss:  0.15350672602653503 , accuracy:  0.9195086025886113\n",
      "Epoch:  26 , loss:  0.13381382822990417 , accuracy:  0.9310163276818453\n",
      "Epoch:  27 , loss:  0.16854779422283173 , accuracy:  0.9178727004920242\n",
      "Epoch:  28 , loss:  0.12585857510566711 , accuracy:  0.9288288570622708\n",
      "Epoch:  29 , loss:  0.1297493726015091 , accuracy:  0.936086997398853\n",
      "Epoch:  30 , loss:  0.13670764863491058 , accuracy:  0.9336112068695352\n",
      "Epoch:  31 , loss:  0.12563517689704895 , accuracy:  0.9378733272744367\n",
      "Epoch:  32 , loss:  0.10643548518419266 , accuracy:  0.9423736249960826\n",
      "Epoch:  33 , loss:  0.11343897879123688 , accuracy:  0.9475069729543389\n",
      "Epoch:  34 , loss:  0.10112588107585907 , accuracy:  0.9496004262120404\n",
      "Epoch:  35 , loss:  0.10293048620223999 , accuracy:  0.9479018458742048\n",
      "Epoch:  36 , loss:  0.10879960656166077 , accuracy:  0.9497132470462879\n",
      "Epoch:  37 , loss:  0.08479493856430054 , accuracy:  0.9517252185903664\n",
      "Epoch:  38 , loss:  0.08469492197036743 , accuracy:  0.9548340593562945\n",
      "Epoch:  39 , loss:  0.09417087584733963 , accuracy:  0.9555423234824031\n",
      "Epoch:  40 , loss:  0.09632786363363266 , accuracy:  0.9555172521859037\n",
      "Epoch:  41 , loss:  0.09234034270048141 , accuracy:  0.9530728007772102\n",
      "Epoch:  42 , loss:  0.07967119663953781 , accuracy:  0.9559309285781441\n",
      "Epoch:  43 , loss:  0.08349929749965668 , accuracy:  0.957924096649848\n",
      "Epoch:  44 , loss:  0.07990405708551407 , accuracy:  0.957710990629603\n",
      "Epoch:  45 , loss:  0.09039483219385147 , accuracy:  0.9594722492086872\n",
      "Epoch:  46 , loss:  0.0847826823592186 , accuracy:  0.9588266633238272\n",
      "Epoch:  47 , loss:  0.07450012862682343 , accuracy:  0.9607258140336582\n",
      "Epoch:  48 , loss:  0.08207990229129791 , accuracy:  0.9606819392647842\n",
      "Epoch:  49 , loss:  0.08625155687332153 , accuracy:  0.9572221003478643\n",
      "Epoch:  50 , loss:  0.08353188633918762 , accuracy:  0.9602118524554201\n",
      "Epoch:  51 , loss:  0.07035135477781296 , accuracy:  0.9608699739885299\n",
      "Epoch:  52 , loss:  0.07894345372915268 , accuracy:  0.9623930552508697\n",
      "Epoch:  53 , loss:  0.08261425048112869 , accuracy:  0.9617098624212604\n",
      "Epoch:  54 , loss:  0.07314658910036087 , accuracy:  0.9608449026920305\n",
      "Epoch:  55 , loss:  0.07553153485059738 , accuracy:  0.9610956156570246\n",
      "Epoch:  56 , loss:  0.08274070173501968 , accuracy:  0.9619856466827541\n",
      "Epoch:  57 , loss:  0.07393041253089905 , accuracy:  0.9628004638189852\n",
      "Epoch:  58 , loss:  0.07949676364660263 , accuracy:  0.9619104327932558\n",
      "Epoch:  59 , loss:  0.07388246804475784 , accuracy:  0.9609201165815288\n",
      "Epoch:  60 , loss:  0.07234286516904831 , accuracy:  0.9622676987683726\n",
      "Epoch:  61 , loss:  0.07553829252719879 , accuracy:  0.964154313829954\n",
      "Epoch:  62 , loss:  0.07114172726869583 , accuracy:  0.9638973330408349\n",
      "Epoch:  63 , loss:  0.07683456689119339 , accuracy:  0.9638597260960857\n",
      "Epoch:  64 , loss:  0.07580337673425674 , accuracy:  0.9636027453069667\n",
      "Epoch:  65 , loss:  0.07201939821243286 , accuracy:  0.9629508915979818\n",
      "Epoch:  66 , loss:  0.06553474068641663 , accuracy:  0.9643987589708233\n",
      "Epoch:  67 , loss:  0.0714544951915741 , accuracy:  0.9651320943934313\n",
      "Epoch:  68 , loss:  0.06275434046983719 , accuracy:  0.9649503274938105\n",
      "Epoch:  69 , loss:  0.06658802181482315 , accuracy:  0.966097339308659\n",
      "Epoch:  70 , loss:  0.0704989805817604 , accuracy:  0.9662540349117804\n",
      "Epoch:  71 , loss:  0.059061162173748016 , accuracy:  0.9654705568961734\n",
      "Epoch:  72 , loss:  0.06813564896583557 , accuracy:  0.9660597323639099\n",
      "Epoch:  73 , loss:  0.06905221194028854 , accuracy:  0.9658716976401642\n",
      "Epoch:  74 , loss:  0.0689922496676445 , accuracy:  0.9655771099062961\n",
      "Epoch:  75 , loss:  0.06837943941354752 , accuracy:  0.9663229809771537\n",
      "Epoch:  76 , loss:  0.05394389107823372 , accuracy:  0.9671127268168855\n",
      "Epoch:  77 , loss:  0.07251249998807907 , accuracy:  0.9667930677865179\n",
      "Epoch:  78 , loss:  0.07537279278039932 , accuracy:  0.9664169983390266\n",
      "Epoch:  79 , loss:  0.06626568734645844 , accuracy:  0.9660221254191608\n",
      "Epoch:  80 , loss:  0.07760695368051529 , accuracy:  0.9664734087561503\n",
      "Epoch:  81 , loss:  0.06580779701471329 , accuracy:  0.9625748221504905\n",
      "Epoch:  82 , loss:  0.05862663313746452 , accuracy:  0.9656147168510452\n",
      "Epoch:  83 , loss:  0.060530368238687515 , accuracy:  0.9675577423297502\n",
      "Epoch:  84 , loss:  0.05909406766295433 , accuracy:  0.969168573129838\n",
      "Epoch:  85 , loss:  0.06882461905479431 , accuracy:  0.9686734150239744\n",
      "Epoch:  86 , loss:  0.0680612325668335 , accuracy:  0.9690244131749663\n",
      "Epoch:  87 , loss:  0.05981859937310219 , accuracy:  0.971330972452913\n",
      "Epoch:  88 , loss:  0.05889563262462616 , accuracy:  0.9706289761509292\n",
      "Epoch:  89 , loss:  0.06496661901473999 , accuracy:  0.9716819706039048\n",
      "Epoch:  90 , loss:  0.05609319731593132 , accuracy:  0.9718637375035256\n",
      "Epoch:  91 , loss:  0.05172021687030792 , accuracy:  0.9737190134444828\n",
      "Epoch:  92 , loss:  0.061566054821014404 , accuracy:  0.972841518067003\n",
      "Epoch:  93 , loss:  0.05868617817759514 , accuracy:  0.9713121689805384\n",
      "Epoch:  94 , loss:  0.05601102486252785 , accuracy:  0.9713936506941615\n",
      "Epoch:  95 , loss:  0.0565975159406662 , accuracy:  0.972885392835877\n",
      "Epoch:  96 , loss:  0.06436861306428909 , accuracy:  0.9743332602087186\n",
      "Epoch:  97 , loss:  0.05844764783978462 , accuracy:  0.9742831176157197\n",
      "Epoch:  98 , loss:  0.04329262301325798 , accuracy:  0.972797643298129\n",
      "Epoch:  99 , loss:  0.04300661012530327 , accuracy:  0.9760318405465542\n",
      "Epoch:  100 , loss:  0.060396987944841385 , accuracy:  0.9762888213356733\n",
      "Epoch:  101 , loss:  0.050678230822086334 , accuracy:  0.9777053495878906\n",
      "Epoch:  102 , loss:  0.0520532988011837 , accuracy:  0.976345231752797\n",
      "Epoch:  103 , loss:  0.04601125046610832 , accuracy:  0.9768403898586606\n",
      "Epoch:  104 , loss:  0.05154242366552353 , accuracy:  0.9773230123162744\n",
      "Epoch:  105 , loss:  0.04324488714337349 , accuracy:  0.9760757153154282\n",
      "Epoch:  106 , loss:  0.05357293039560318 , accuracy:  0.9770597637030305\n",
      "Epoch:  107 , loss:  0.05393035709857941 , accuracy:  0.977210191482027\n",
      "Epoch:  108 , loss:  0.06744545698165894 , accuracy:  0.9722147356545175\n",
      "Epoch:  109 , loss:  0.050511591136455536 , accuracy:  0.9722084678303927\n",
      "Epoch:  110 , loss:  0.04840807616710663 , accuracy:  0.9769281393964085\n",
      "Epoch:  111 , loss:  0.04603151977062225 , accuracy:  0.9788460935786142\n",
      "Epoch:  112 , loss:  0.049852970987558365 , accuracy:  0.9779121877840108\n",
      "Epoch:  113 , loss:  0.06091667711734772 , accuracy:  0.977517314864145\n",
      "Epoch:  114 , loss:  0.045730751007795334 , accuracy:  0.9755742893854399\n",
      "Epoch:  115 , loss:  0.046588025987148285 , accuracy:  0.9791594847848569\n",
      "Epoch:  116 , loss:  0.04268786311149597 , accuracy:  0.979761195900843\n",
      "Epoch:  117 , loss:  0.05151399224996567 , accuracy:  0.9765896768936664\n",
      "Epoch:  118 , loss:  0.045346617698669434 , accuracy:  0.9789275752922373\n",
      "Epoch:  119 , loss:  0.040606942027807236 , accuracy:  0.9785201667241217\n",
      "Epoch:  120 , loss:  0.03887306526303291 , accuracy:  0.9797486602525933\n",
      "Epoch:  121 , loss:  0.043499015271663666 , accuracy:  0.9801874079413332\n",
      "Epoch:  122 , loss:  0.042412832379341125 , accuracy:  0.9791469491366073\n",
      "Epoch:  123 , loss:  0.04148733615875244 , accuracy:  0.980193675765458\n",
      "Epoch:  124 , loss:  0.03858195245265961 , accuracy:  0.9796609107148453\n",
      "Epoch:  125 , loss:  0.03824522718787193 , accuracy:  0.9811714563289354\n",
      "Epoch:  126 , loss:  0.04555254429578781 , accuracy:  0.97946034034285\n",
      "Epoch:  127 , loss:  0.04094495251774788 , accuracy:  0.977899652135761\n",
      "Epoch:  128 , loss:  0.03822688013315201 , accuracy:  0.9811401172083112\n",
      "Epoch:  129 , loss:  0.030357101932168007 , accuracy:  0.9822557899025354\n",
      "Epoch:  130 , loss:  0.03848995640873909 , accuracy:  0.9800933905794603\n",
      "Epoch:  131 , loss:  0.034991804510354996 , accuracy:  0.9812341345701839\n",
      "Epoch:  132 , loss:  0.03558206930756569 , accuracy:  0.9811965276254349\n",
      "Epoch:  133 , loss:  0.047384537756443024 , accuracy:  0.9814033658215551\n",
      "Epoch:  134 , loss:  0.03825727105140686 , accuracy:  0.9815224544799273\n",
      "Epoch:  135 , loss:  0.03913990408182144 , accuracy:  0.9816979535554232\n",
      "Epoch:  136 , loss:  0.050426892936229706 , accuracy:  0.9813344197561816\n",
      "Epoch:  137 , loss:  0.04604649543762207 , accuracy:  0.9807640477608198\n",
      "Epoch:  138 , loss:  0.04506449028849602 , accuracy:  0.9819486665204175\n",
      "Epoch:  139 , loss:  0.07405521720647812 , accuracy:  0.9720267009307719\n",
      "Epoch:  140 , loss:  0.04675091430544853 , accuracy:  0.9755868250336895\n",
      "Epoch:  141 , loss:  0.03860006853938103 , accuracy:  0.980538406092325\n",
      "Epoch:  142 , loss:  0.03254537656903267 , accuracy:  0.9821555047165377\n",
      "Epoch:  143 , loss:  0.040432099252939224 , accuracy:  0.9814973831834278\n",
      "Epoch:  144 , loss:  0.04703542962670326 , accuracy:  0.9801372653483343\n",
      "Epoch:  145 , loss:  0.03535279259085655 , accuracy:  0.9815099188316776\n",
      "Epoch:  146 , loss:  0.03875648230314255 , accuracy:  0.9833150521796359\n",
      "Epoch:  147 , loss:  0.04009599611163139 , accuracy:  0.9814033658215551\n",
      "Epoch:  148 , loss:  0.045232970267534256 , accuracy:  0.9813845623491805\n",
      "Epoch:  149 , loss:  0.03929991275072098 , accuracy:  0.9841612084364912\n",
      "Epoch:  150 , loss:  0.03452068567276001 , accuracy:  0.9841047980193676\n",
      "Epoch:  151 , loss:  0.03560980409383774 , accuracy:  0.9832962487072613\n",
      "Epoch:  152 , loss:  0.041717901825904846 , accuracy:  0.9828010906013978\n",
      "Epoch:  153 , loss:  0.057955581694841385 , accuracy:  0.9778056347738883\n",
      "Epoch:  154 , loss:  0.04936639219522476 , accuracy:  0.9731674449214955\n",
      "Epoch:  155 , loss:  0.04441019147634506 , accuracy:  0.977122441944279\n",
      "Epoch:  156 , loss:  0.03909330815076828 , accuracy:  0.981967469992792\n",
      "Epoch:  157 , loss:  0.030724773183465004 , accuracy:  0.9836660503306277\n",
      "Epoch:  158 , loss:  0.0435817688703537 , accuracy:  0.9832774452348867\n",
      "Epoch:  159 , loss:  0.033314041793346405 , accuracy:  0.9824124855056567\n",
      "Epoch:  160 , loss:  0.0374787338078022 , accuracy:  0.983264909586637\n",
      "Epoch:  161 , loss:  0.030533701181411743 , accuracy:  0.9833213200037607\n",
      "Epoch:  162 , loss:  0.035522811114788055 , accuracy:  0.9842301545018647\n",
      "Epoch:  163 , loss:  0.0327361561357975 , accuracy:  0.9842364223259895\n",
      "Epoch:  164 , loss:  0.03695467859506607 , accuracy:  0.9837914068131248\n",
      "Epoch:  165 , loss:  0.03675539046525955 , accuracy:  0.9829201792597699\n",
      "Epoch:  166 , loss:  0.039733801037073135 , accuracy:  0.9826381271741514\n",
      "Epoch:  167 , loss:  0.03238556906580925 , accuracy:  0.9838791563508728\n",
      "Epoch:  168 , loss:  0.030454277992248535 , accuracy:  0.9841925475571155\n",
      "Epoch:  169 , loss:  0.043676987290382385 , accuracy:  0.983007928797518\n",
      "Epoch:  170 , loss:  0.04005815088748932 , accuracy:  0.9820050769375411\n",
      "Epoch:  171 , loss:  0.045554470270872116 , accuracy:  0.9817418283242972\n",
      "Epoch:  172 , loss:  0.03457340970635414 , accuracy:  0.9826694662947758\n",
      "Epoch:  173 , loss:  0.033884212374687195 , accuracy:  0.9835406938481306\n",
      "Epoch:  174 , loss:  0.030815908685326576 , accuracy:  0.9840483876022439\n",
      "Epoch:  175 , loss:  0.03124821186065674 , accuracy:  0.9849258829797236\n",
      "Epoch:  176 , loss:  0.03896614909172058 , accuracy:  0.9772603340750259\n",
      "Epoch:  177 , loss:  0.034430284053087234 , accuracy:  0.9812529380425585\n",
      "Epoch:  178 , loss:  0.037297699600458145 , accuracy:  0.9817731674449215\n",
      "Epoch:  179 , loss:  0.0333557203412056 , accuracy:  0.9834090695415086\n",
      "Epoch:  180 , loss:  0.0382612943649292 , accuracy:  0.9839042276473722\n",
      "Epoch:  181 , loss:  0.03331493213772774 , accuracy:  0.9845811526528565\n",
      "Epoch:  182 , loss:  0.024810975417494774 , accuracy:  0.9847002413112288\n",
      "Epoch:  183 , loss:  0.0436268150806427 , accuracy:  0.9776990817637657\n",
      "Epoch:  184 , loss:  0.04014063626527786 , accuracy:  0.9790341283023598\n",
      "Epoch:  185 , loss:  0.037939392030239105 , accuracy:  0.9835156225516312\n",
      "Epoch:  186 , loss:  0.026451334357261658 , accuracy:  0.9848882760349744\n",
      "Epoch:  187 , loss:  0.02467665821313858 , accuracy:  0.9855338619198345\n",
      "Epoch:  188 , loss:  0.03608778864145279 , accuracy:  0.9855338619198345\n",
      "Epoch:  189 , loss:  0.02868589572608471 , accuracy:  0.9848067943213513\n",
      "Epoch:  190 , loss:  0.026818392798304558 , accuracy:  0.9853708984925883\n",
      "Epoch:  191 , loss:  0.030235012993216515 , accuracy:  0.9854649158544612\n",
      "Epoch:  192 , loss:  0.029142208397388458 , accuracy:  0.9861230373875709\n",
      "Epoch:  193 , loss:  0.02885563299059868 , accuracy:  0.9865680529004356\n",
      "Epoch:  194 , loss:  0.030767781659960747 , accuracy:  0.9868438371619292\n",
      "Epoch:  195 , loss:  0.031723205000162125 , accuracy:  0.9850136325174715\n",
      "Epoch:  196 , loss:  0.03449144959449768 , accuracy:  0.985471183678586\n",
      "Epoch:  197 , loss:  0.03040768951177597 , accuracy:  0.985991413080949\n",
      "Epoch:  198 , loss:  0.02778073027729988 , accuracy:  0.9841800119088658\n",
      "Epoch:  199 , loss:  0.031113574281334877 , accuracy:  0.984737848255978\n",
      "Epoch:  200 , loss:  0.0350588783621788 , accuracy:  0.985038703813971\n",
      "Epoch:  201 , loss:  0.03575316071510315 , accuracy:  0.9850261681657213\n",
      "Epoch:  202 , loss:  0.027306491509079933 , accuracy:  0.9857469679400797\n",
      "Epoch:  203 , loss:  0.02635180577635765 , accuracy:  0.9861669121564449\n",
      "Epoch:  204 , loss:  0.05310515686869621 , accuracy:  0.9747782757215833\n",
      "Epoch:  205 , loss:  0.04839653521776199 , accuracy:  0.9793851264533517\n",
      "Epoch:  206 , loss:  0.03698990121483803 , accuracy:  0.9839481024162462\n",
      "Epoch:  207 , loss:  0.03777533397078514 , accuracy:  0.9848255977937259\n",
      "Epoch:  208 , loss:  0.03729405999183655 , accuracy:  0.9835845686170046\n",
      "Epoch:  209 , loss:  0.031062213703989983 , accuracy:  0.9845059387633583\n",
      "Epoch:  210 , loss:  0.023279579356312752 , accuracy:  0.9856529505782068\n",
      "Epoch:  211 , loss:  0.03791983425617218 , accuracy:  0.9857657714124541\n",
      "Epoch:  212 , loss:  0.03225843608379364 , accuracy:  0.9841549406123664\n",
      "Epoch:  213 , loss:  0.035936351865530014 , accuracy:  0.9843993857532357\n",
      "Epoch:  214 , loss:  0.034864574670791626 , accuracy:  0.9852768811307154\n",
      "Epoch:  215 , loss:  0.028552347794175148 , accuracy:  0.9857908427089536\n",
      "Epoch:  216 , loss:  0.02753402292728424 , accuracy:  0.9852267385377166\n",
      "Epoch:  217 , loss:  0.031228698790073395 , accuracy:  0.9858535209502022\n",
      "Epoch:  218 , loss:  0.028560616075992584 , accuracy:  0.9865429816039362\n",
      "Epoch:  219 , loss:  0.031074870377779007 , accuracy:  0.9857156288194553\n",
      "Epoch:  220 , loss:  0.03851897269487381 , accuracy:  0.9836785859788775\n",
      "Epoch:  221 , loss:  0.039986029267311096 , accuracy:  0.983396533893259\n",
      "Epoch:  222 , loss:  0.033866241574287415 , accuracy:  0.9857281644677051\n",
      "Epoch:  223 , loss:  0.026249274611473083 , accuracy:  0.9867122128553073\n",
      "Epoch:  224 , loss:  0.0259819608181715 , accuracy:  0.9858033783572033\n",
      "Epoch:  225 , loss:  0.02425507828593254 , accuracy:  0.9853708984925883\n",
      "Epoch:  226 , loss:  0.03318915516138077 , accuracy:  0.9861105017393212\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-f515b0ae1d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/d/danieltm/ExaTrkX/eta-tracker/notebooks/toy_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_graph_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# Apply edge network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0;31m# Apply node network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/d/danieltm/ExaTrkX/eta-tracker/notebooks/toy_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0medge_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNodeNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 152\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \"\"\"\n\u001b[1;32m   1681\u001b[0m     return torch.layer_norm(input, normalized_shape, weight, bias, eps,\n\u001b[0;32m-> 1682\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_v = []\n",
    "acc_v = []\n",
    "ep = 0\n",
    "for epoch in range(500):\n",
    "    ep += 1\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in train_loader:\n",
    "#         print(batch.x)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        pred = model(data)\n",
    "        loss = F.binary_cross_entropy_with_logits(pred.float(), data.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += ((pred > 0.5) == (data.y > 0.5)).sum().item()\n",
    "#         print(correct, pred, data.y)\n",
    "        total += len(pred)\n",
    "#         print(out, data.y, )\n",
    "    acc = correct/total\n",
    "    print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", accuracy: \", acc)\n",
    "    loss_v.append(loss)\n",
    "    acc_v.append(acc)\n",
    "plt.plot(np.arange(len(loss_v)), loss_v)\n",
    "plt.plot(np.arange(len(acc_v)), acc_v)\n",
    "plt.ylim(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[5930], edge_index=[2, 14580], x=[5930, 2], y=[14580])\n",
      "Accuracy: 0.9812\n",
      "Batch(batch=[5880], edge_index=[2, 14637], x=[5880, 2], y=[14637])\n",
      "Accuracy: 0.9832\n",
      "Batch(batch=[5580], edge_index=[2, 14190], x=[5580, 2], y=[14190])\n",
      "Accuracy: 0.9862\n",
      "Batch(batch=[5710], edge_index=[2, 14652], x=[5710, 2], y=[14652])\n",
      "Accuracy: 0.9838\n",
      "Batch(batch=[5470], edge_index=[2, 12952], x=[5470, 2], y=[12952])\n",
      "Accuracy: 0.9866\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    data = batch.to(device)\n",
    "    pred = model(data)\n",
    "    correct = ((pred > 0.5) == (data.y > 0.5)).sum().item()\n",
    "    acc = correct / len(pred)\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Track Count Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(1000)]\n",
    "test_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using \", device)\n",
    "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
    "model = Net(train_dataset).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 9,  9,  7,  4,  7,  3,  5,  7,  6,  7,  4,  7,  2,  6,  5,  6,  7,  9,\n",
      "         5,  9,  6,  9,  5,  7,  8,  8,  4,  4,  7,  5,  6,  4,  4,  8, 10,  1,\n",
      "         5,  8,  8,  5,  8,  4,  9,  5,  9,  6,  2,  9,  5,  4,  7,  4,  9,  5,\n",
      "         9,  5,  5,  4,  9,  6,  5,  7,  6,  4,  7,  4, 11,  4, 11,  5,  7,  4,\n",
      "         7,  7,  9,  5,  3,  7,  3,  6,  3,  8,  3,  6,  6,  4,  6,  4,  8,  3,\n",
      "         7,  7,  8,  2,  6,  6,  3,  4,  8,  2], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 3, 10,  9,  3,  7,  7,  5,  8,  4,  6, 10,  4,  7,  5,  3,  5, 10,  7,\n",
      "         4,  6,  9,  5,  7,  4,  8,  4,  3,  6,  3,  6,  5,  4,  9,  7,  6,  8,\n",
      "         7,  8,  9,  3,  3,  7,  9,  8,  7,  4, 11,  6,  6,  4,  4,  8,  5,  7,\n",
      "         4,  5,  6,  6,  7,  4,  6,  3,  7,  5,  6,  8,  6,  8,  8,  9,  4,  8,\n",
      "         4,  7,  7,  5,  6,  7,  5,  7,  3,  7,  6,  5,  8,  5,  2,  5,  7,  5,\n",
      "         7,  3,  9,  9,  5,  9,  7,  4,  6,  7], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 8,  4,  2,  7,  7,  4,  5,  6,  9,  6,  3,  7,  7,  5,  9,  3,  5,  5,\n",
      "         4,  5,  9,  9,  7,  7,  8,  3,  7,  5,  9,  6,  7,  3,  6,  5,  9,  3,\n",
      "        10,  3,  7,  5,  9,  6,  5,  8,  4,  3,  3,  6,  4,  5,  4, 10,  7,  5,\n",
      "         5,  6,  9,  5,  6,  5,  6,  4,  7,  4,  3,  3,  6,  8,  6, 10,  7,  7,\n",
      "         8,  4,  5,  3,  8,  8,  4,  2,  5,  5,  3,  9,  5, 11,  9,  5,  3,  6,\n",
      "         9,  4,  9,  8,  7,  7,  5,  4,  6,  7], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 4,  4,  6,  7,  9,  8,  4,  8,  4,  4,  3, 11,  4,  6,  9,  6,  7,  5,\n",
      "         7,  8,  6,  5,  4,  7,  9,  9,  4,  4,  9,  9,  4,  6,  5,  4,  6,  7,\n",
      "         4,  9,  4,  4,  6,  8,  6,  2,  6,  6,  3,  7,  6,  7,  2,  7,  7,  3,\n",
      "         3,  6,  7,  7,  7,  3,  7,  7,  5,  2,  9,  7, 10,  8,  7,  7,  3,  8,\n",
      "         3,  5,  6,  7,  7,  6,  5,  6,  7, 11,  2,  8, 10,  7,  8,  7,  6,  5,\n",
      "         4, 10, 10,  4,  3,  7,  8,  6,  5,  7], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 4,  4,  7,  8,  7,  5,  2,  6,  6,  2,  7,  4,  7,  4,  6,  5,  7,  7,\n",
      "         5,  6,  2, 10,  4,  5,  7,  8,  5,  7,  5,  8, 10,  5,  8,  4,  7,  8,\n",
      "         6,  9,  5,  5,  9,  8,  9,  5,  3,  7,  7,  6, 10,  7,  6,  3,  7,  7,\n",
      "         5,  9,  4,  6,  5,  9,  5,  5,  5,  9,  9,  7,  7,  6,  6,  5,  6,  7,\n",
      "         4,  4,  6,  4,  3,  7,  3,  8,  6,  3,  5,  5,  5,  8,  6,  5,  3,  8,\n",
      "        11,  5,  3,  4,  4,  8,  5,  8,  9,  3], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 4,  8,  3,  5,  4,  4,  8,  7,  7,  7,  8,  9,  4,  9,  9,  6,  5,  7,\n",
      "         7,  7,  8,  5,  5,  9,  6,  5,  3,  8,  4,  5,  7,  5,  3, 10,  6,  5,\n",
      "         3,  6,  5,  2,  5, 11,  5,  6,  4,  6,  8,  7,  5,  7,  9,  6,  8,  3,\n",
      "         7,  8,  2,  8,  4,  4,  4,  9,  6,  4,  6,  6,  6,  5,  9,  4,  7,  8,\n",
      "         4,  5,  3,  7,  5,  7,  3,  8,  4,  8,  8,  8,  5,  6,  9,  8,  6,  5,\n",
      "         6, 10,  7,  9,  4,  7,  2,  4,  7, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 5,  3,  7,  6,  6,  7,  8,  3,  2,  6,  3,  4,  3,  8,  3,  4,  4,  4,\n",
      "         8,  5,  6,  3,  4,  8,  4,  7,  6,  9,  7,  9,  9,  9,  5,  6,  7,  4,\n",
      "         5,  8,  3,  6,  9,  3,  8,  6,  9,  5,  5,  6,  7,  1, 10,  4,  8,  6,\n",
      "         5,  6, 10,  4,  9,  8,  4,  7,  4,  5,  4,  5,  9,  5,  7,  9,  7,  6,\n",
      "         5, 10,  9,  8,  3,  6,  2,  4,  8,  6,  7,  7,  5,  3,  4,  6,  8,  9,\n",
      "         5,  8,  6,  6,  6,  5,  5,  4,  6,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 7,  7,  4,  8,  6,  6,  7,  3,  6,  5,  3,  5,  7, 10,  6,  7,  9, 10,\n",
      "         4,  4,  5,  6,  5,  7,  8,  9,  7,  3,  7,  3,  5,  8,  8,  9,  6,  5,\n",
      "         7, 10,  8,  7,  7,  5,  8,  4,  7, 10,  8,  5,  8,  7,  7,  9,  7,  7,\n",
      "         4,  8,  5,  8,  5,  6, 10,  3,  3,  7,  7, 10,  5,  8,  7,  3,  9, 10,\n",
      "         3,  4, 10,  8,  5,  5,  4, 10,  7,  6,  5, 10,  9,  6,  8,  5,  9,  5,\n",
      "         7,  3,  4,  6,  3,  6,  5,  7,  8,  8], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([10,  6,  6,  8,  9,  6,  4,  6,  9,  6,  9,  8,  7,  4,  7, 10,  9,  5,\n",
      "         4,  9,  4,  6,  4,  4,  8,  4,  5,  4,  8, 10,  2,  2,  7,  5,  5,  7,\n",
      "         6,  3, 11,  9,  7, 10,  4,  5,  3,  2,  8,  4,  5,  3,  8,  9,  4,  8,\n",
      "         5, 11,  4,  9,  6,  7,  8,  4,  5,  3,  3, 10,  9,  7,  2,  7,  9, 10,\n",
      "         5,  4,  6,  3,  9,  3,  7,  5,  7,  8,  5,  7,  4,  4,  5,  4,  8,  8,\n",
      "         6,  3,  7,  9, 10,  8, 10,  4,  6,  5], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 9,  5,  5,  8,  9,  4,  5,  8,  5,  3,  8,  6,  9,  1,  6,  6,  7,  6,\n",
      "         4,  5,  6,  4,  8,  4,  8,  7,  7,  8,  9,  6,  9, 10,  7,  8,  3,  3,\n",
      "         8,  5,  6,  5,  8,  3,  9,  7,  7,  8,  5, 10,  4,  3,  4,  7,  6,  8,\n",
      "         4,  3,  3,  1,  4,  8,  9, 10,  6,  4,  8,  2, 10,  7,  4,  2,  6,  4,\n",
      "         8, 10,  4,  8,  2, 10,  8,  8,  3,  3,  9,  4,  8,  7,  6,  3,  3,  6,\n",
      "         9,  7,  9,  7,  5, 10,  8,  7,  3,  8], device='cuda:0')\n",
      "Epoch:  1 , loss:  2.449791431427002 , accuracy:  0.14\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 6,  7,  9, 10,  6,  8,  2,  3,  4,  9,  7,  7,  5,  8,  3,  5, 10,  3,\n",
      "         4,  7,  4,  6,  5,  7,  7,  4,  4,  4,  5,  7,  7,  6,  7,  3,  5,  5,\n",
      "         5,  8,  4,  7,  4,  7,  5,  4,  6,  9,  6,  8,  4,  6,  8,  6, 10,  8,\n",
      "         4,  5,  6,  6,  5,  4,  7,  7,  6,  3,  4,  5,  5,  4,  4,  9,  5,  3,\n",
      "         9,  3,  7,  5,  5,  3,  4,  5,  7,  4,  8,  5,  7,  5,  7,  7,  6,  7,\n",
      "         5,  7,  5,  8,  8,  4,  6, 10,  6,  3], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 4, 6, 4, 6, 6, 4, 4, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 4, 4, 6, 6, 4, 4, 6, 4, 4, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 4, 4, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 4, 6, 4,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([11,  7,  2,  9,  3,  8,  8,  4,  3,  9,  6,  6,  6,  8,  5,  7,  3,  5,\n",
      "         9,  8,  8,  5,  5,  8,  7,  8,  7,  9,  6,  4,  8, 10,  3,  5,  4,  9,\n",
      "         9,  6,  3,  7,  9,  7,  9,  9,  7,  7,  5,  8,  4,  7,  7,  9,  7,  7,\n",
      "         7,  9,  9,  2,  9,  3,  4, 10,  5,  5,  5,  8,  5,  3,  6,  4,  9,  7,\n",
      "         7,  7,  8, 10,  4,  5,  2,  9,  3,  8,  4,  7,  8,  8,  8,  6,  6,  3,\n",
      "         4,  5,  8,  5,  9,  6,  8,  7,  9,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 4, 6, 4, 4, 6, 4, 4, 6, 6, 4, 4, 4, 6, 6, 4, 4, 6, 4, 4, 6, 4, 6, 4,\n",
      "        4, 6, 6, 4, 4, 6, 4, 6, 4, 4, 6, 4, 6, 4, 6, 4, 4, 4, 4, 4, 4, 4, 6, 4,\n",
      "        4, 6, 6, 4, 4, 4, 4, 6, 4, 4, 4, 4, 6, 4, 4, 6, 4, 4, 4, 4, 6, 6, 4, 4,\n",
      "        4, 4, 4, 4, 6, 4, 4, 4, 6, 6, 4, 6, 4, 4, 4, 6, 6, 4, 6, 4, 6, 4, 4, 4,\n",
      "        4, 4, 6, 6], device='cuda:0') tensor([ 4,  6,  8,  5,  4, 10,  8,  5,  6,  8,  6,  8,  6,  6,  8,  5,  4,  8,\n",
      "         6,  3,  7,  5,  9,  4,  5,  7,  5,  6,  3,  6,  3,  8,  5,  3,  9,  4,\n",
      "         8,  5, 10,  5,  9,  5,  3,  7,  6,  4,  8,  6,  7, 11,  5,  3,  5,  7,\n",
      "         9,  7,  5,  5,  3,  5,  9,  4,  3, 10,  2,  7,  8,  9, 10,  9,  6,  6,\n",
      "         6,  4,  3,  1,  7,  3,  4,  7,  8,  8,  7,  9,  6,  5,  4,  4,  9,  7,\n",
      "         7,  6,  8,  7,  5,  5,  3,  5,  9, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 5, 5, 5, 5, 4, 5, 5, 5, 4, 5, 6, 5, 5, 5, 5, 5, 6, 4, 5, 5, 6, 5, 4,\n",
      "        5, 5, 4, 5, 5, 6, 5, 5, 4, 5, 5, 6, 5, 6, 5, 4, 5, 5, 4, 5, 5, 5, 4, 6,\n",
      "        4, 4, 5, 5, 5, 5, 5, 5, 4, 4, 5, 4, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 6, 5, 4, 4,\n",
      "        5, 4, 4, 5], device='cuda:0') tensor([ 3,  5,  9,  5, 10,  4,  9,  6,  7,  5,  9,  8,  5,  8,  8,  5,  6,  5,\n",
      "         3,  8,  6,  5,  9,  2,  5,  7,  6,  7,  6,  3,  6,  7,  3, 10,  8,  7,\n",
      "        10,  3,  7,  5,  8,  7,  5,  8,  9,  7,  5,  8,  1,  4,  6,  8,  2, 11,\n",
      "         7,  8,  3,  4,  7,  3,  5,  9,  7,  4,  4,  8,  4,  9,  6,  8,  4,  5,\n",
      "         4,  5,  8,  4,  9,  5,  5,  6,  3,  4,  6,  9,  4,  7,  6,  5,  8,  4,\n",
      "         7,  4,  6, 11,  4,  4,  4,  4,  4,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 4,  7,  4,  2, 10,  7,  4,  7,  3,  7,  5,  9,  5,  8,  6,  7,  6, 10,\n",
      "         6,  6,  4,  4,  3,  6,  3, 10,  8,  7,  9,  5,  6,  7,  4,  5,  7,  8,\n",
      "         6,  3,  7,  9,  8,  5,  5,  3,  4,  5, 10,  4,  6,  4,  7,  6,  4,  5,\n",
      "         5,  1,  7,  4,  3,  8,  6,  6,  2,  5,  4,  7,  8,  7,  9,  8,  7, 10,\n",
      "         3,  7,  8,  7,  9,  9,  3, 10,  4,  6,  8,  5,  6,  7,  8,  4,  9,  4,\n",
      "         4,  2,  8,  5,  5,  9,  7,  4,  6,  6], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 8,  8,  6,  6,  7,  9,  8,  7,  7,  7,  7,  8,  5,  6,  5,  8,  6,  6,\n",
      "         6,  6,  6,  7,  7,  4,  8,  3,  5,  6,  9,  3,  4,  5,  5,  4,  2,  7,\n",
      "         6,  5,  4,  9,  8,  8,  5,  7,  8,  5,  4, 10,  5,  5,  7,  9,  4,  6,\n",
      "         7,  9,  4,  6,  5,  7,  6,  3,  4,  6,  9,  4,  5,  5,  8,  3,  5,  5,\n",
      "         8,  4,  9,  3,  6,  3,  8,  4,  7,  4,  7,  8,  9,  9,  9,  4,  9,  2,\n",
      "        10,  6,  8,  4,  3,  6, 10,  8,  4,  6], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 5,  2,  5,  8,  8,  5,  8,  4,  5,  4,  9,  9,  8,  7,  3,  4,  5,  4,\n",
      "         7,  4,  7,  4,  8,  9,  7,  3,  7,  9,  3,  8,  7,  7,  8,  8,  8,  7,\n",
      "         9,  6,  9,  6,  3,  7,  6,  8,  6,  7,  6,  5,  8, 10,  8,  6,  9,  5,\n",
      "         7,  7,  7,  9,  6,  3,  7,  6,  5,  7,  9,  7,  3,  7,  8,  6,  6,  4,\n",
      "         8,  7,  8,  3,  7,  4,  3,  3,  9,  7,  4,  6,  6,  4,  7,  4,  4,  8,\n",
      "         3,  6,  7,  3,  6,  7,  5,  6,  8, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([10,  5,  5,  4,  5,  7,  5,  8,  5,  2,  9,  3,  5,  4,  7,  2, 10,  2,\n",
      "         4,  9,  4,  3,  5,  5,  6,  7, 11,  7,  8,  7,  8,  8,  9,  3,  4,  6,\n",
      "         6,  3,  9,  4,  3, 10,  3,  6,  9,  3,  2,  8, 10,  6,  5,  9,  6,  3,\n",
      "         5,  7,  6, 11,  5,  3,  5,  7,  3,  5,  4,  4,  8,  5,  7,  4, 10,  4,\n",
      "         6,  9,  7,  9,  6,  2,  8,  5,  7,  7,  7, 11,  8,  2,  9,  5,  7,  2,\n",
      "         4,  7, 11, 11,  5,  6,  7,  4,  9,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 3,  7,  5,  9,  5,  4,  3,  2,  3,  5,  6,  7,  8,  8,  5, 10,  7,  7,\n",
      "         7,  7,  6,  7,  3,  7,  7,  5,  3,  6,  6,  7,  4,  5,  5, 10,  6,  6,\n",
      "        10,  8,  5,  4,  6,  8, 10,  3,  7,  3,  8,  7,  3,  5,  9,  9,  6,  5,\n",
      "         4, 10,  6, 10,  9,  3,  7,  7,  6,  5,  3,  7, 10,  4,  6,  9,  9,  6,\n",
      "         7,  8,  5,  5, 10,  8,  7, 11,  7,  4,  8,  6,  6,  4,  8,  8,  5,  9,\n",
      "         6,  5,  7,  6,  6,  8, 10,  6,  7,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 4,  2,  8,  3, 10,  7,  5, 10,  7,  8, 10,  5,  6,  6,  4,  7,  1,  6,\n",
      "         5, 10,  7,  2,  6,  7,  9,  9,  9,  7,  9,  4,  3,  4,  7,  9,  9, 10,\n",
      "         5,  4,  7,  5,  3,  8,  5,  3,  5,  3,  2,  6,  7,  3,  8,  5,  4,  4,\n",
      "         9,  5,  6,  3,  9,  6,  8,  5,  9,  8,  4,  7,  3,  6,  5,  7,  3,  2,\n",
      "         6,  6,  9,  4,  6,  4,  5,  6,  4,  4,  3,  2,  4,  6,  4,  4,  4,  4,\n",
      "         9,  7,  5,  4,  7,  6,  7,  8,  8,  7], device='cuda:0')\n",
      "Epoch:  2 , loss:  2.38297176361084 , accuracy:  0.141\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 8,  9,  5,  4,  7,  7,  7,  7,  7,  4,  8,  7,  5,  2,  6,  3,  7,  9,\n",
      "         6,  5,  7,  4,  4,  5,  8,  8,  4,  3,  5,  8,  7,  4,  7,  8,  9,  2,\n",
      "         3,  9,  4,  4, 11,  9,  4,  4,  3,  9,  7,  7,  3,  7,  7,  8,  6,  8,\n",
      "         4,  5,  5,  2,  7,  9,  5,  7,  6,  3,  7,  7,  8,  7,  5,  8,  6,  3,\n",
      "         4,  3,  7, 11,  7,  7,  5,  6,  7,  5,  6,  3,  6,  8,  7,  3,  7,  7,\n",
      "         6,  7, 10,  7,  6,  9,  5,  9,  7,  5], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 3,  4,  4,  7,  4,  7,  7,  5,  8,  5,  5,  8,  9,  8,  5,  4,  7,  6,\n",
      "         6,  7,  4,  7,  5,  5,  5, 11,  3,  6,  8,  8,  8,  9,  4,  7,  3,  5,\n",
      "         4,  9,  4,  6,  9, 10,  1,  5,  4, 10,  8,  3,  8,  7,  5,  9,  6,  7,\n",
      "         4,  7,  9,  8,  5,  6,  8,  8,  3,  9,  9,  2,  5,  3,  5,  7,  6,  9,\n",
      "         3,  3,  6,  7,  6,  4,  9,  4,  2,  4,  4,  7,  9,  7,  9,  3,  3,  5,\n",
      "         7,  5,  6,  6,  5,  4,  7,  7,  4,  5], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 4, 5, 5, 4, 5, 4, 4, 5, 5, 4, 4, 5, 4, 4,\n",
      "        5, 4, 5, 4, 5, 5, 5, 4, 4, 4, 4, 5, 4, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 4,\n",
      "        4, 5, 5, 5, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4, 4, 5, 5, 4, 5, 5, 5, 4, 4,\n",
      "        4, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 5, 5, 4, 5, 4, 5, 4, 5, 4,\n",
      "        5, 4, 5, 5], device='cuda:0') tensor([ 6,  4,  5, 10,  7, 10,  6,  4,  5,  6,  3,  2,  7,  6,  6,  6,  5,  5,\n",
      "         6,  6,  4,  5,  8,  6,  4,  2,  8,  6,  8,  8,  9,  4,  3,  6,  2,  6,\n",
      "         4,  6,  7,  6,  5,  4,  7,  7,  3,  9,  5,  4,  4,  8,  5, 10,  4,  4,\n",
      "         6,  4,  5,  8,  6,  5,  6,  6,  6,  6,  5,  6,  3,  6,  7,  9,  4,  4,\n",
      "         2,  7,  5,  3,  7,  6,  6,  5,  5,  9, 10,  5,  6,  3,  5,  5, 10,  6,\n",
      "         7,  7,  8,  3,  7,  6,  9,  7,  9,  8], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 5, 5, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 4, 5, 4, 5, 4, 4, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4,\n",
      "        4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4,\n",
      "        4, 4, 4, 5], device='cuda:0') tensor([ 6,  9,  9,  7,  4, 10,  8,  4,  4,  6,  4, 11,  9,  7,  2,  2,  5,  7,\n",
      "         7,  4,  5,  4,  4,  9,  7,  5,  6,  5,  7,  3,  5,  3,  3,  5,  6, 10,\n",
      "         8,  5,  5,  6,  5, 10,  4,  3,  6,  9,  4,  4,  4,  3,  3,  4,  6,  5,\n",
      "         5,  5,  5,  7,  9,  6,  9,  9,  9,  5,  4,  3,  3,  7,  7,  9,  3,  9,\n",
      "         5,  8,  6,  3,  4,  4,  3,  7,  6,  7,  3,  8,  4,  3,  6,  8,  5,  9,\n",
      "         7,  7,  2,  7,  8,  6,  4,  9,  4, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4], device='cuda:0') tensor([ 4,  4,  4,  6,  4,  4,  8,  6,  7,  6,  9,  5,  8,  7,  8, 10,  4,  9,\n",
      "         4,  7,  5,  8,  6,  5, 10,  7,  9,  3,  2,  4,  5,  5,  4, 10,  3,  4,\n",
      "         3,  8,  5,  9, 10,  8,  8,  6,  8,  5,  7,  5,  8,  5,  7,  7,  9,  5,\n",
      "         3,  5, 10,  4,  6,  6,  7,  9,  3, 10,  6,  3,  6,  7,  5,  5,  8,  8,\n",
      "        10,  6,  5,  7,  6,  6,  4,  9,  2,  8,  9,  4,  9,  7,  5,  4,  8,  4,\n",
      "         4,  5,  8,  8,  2,  7,  8,  9,  4,  9], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-31fb8df39f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_v = []\n",
    "acc_v = []\n",
    "ep = 0\n",
    "for epoch in range(500):\n",
    "    ep += 1\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in train_loader:\n",
    "#         print(batch.x)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        out = model(data)\n",
    "        _, pred = out.max(dim=1)\n",
    "        print(pred.shape, data.y.shape, pred, data.y)\n",
    "        loss = F.cross_entropy(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        correct += float(pred.eq(data.y).sum().item())\n",
    "#         print(correct, pred, data.y)\n",
    "        total += len(pred)\n",
    "#         print(out, data.y, )\n",
    "    acc = correct/total\n",
    "    print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", accuracy: \", acc)\n",
    "    loss_v.append(loss)\n",
    "    acc_v.append(acc)\n",
    "plt.plot(np.arange(len(loss_v)), loss_v)\n",
    "plt.plot(np.arange(len(acc_v)), acc_v)\n",
    "plt.ylim(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[6110], edge_index=[2, 16297], x=[6110, 2], y=[100])\n",
      "tensor([ 7,  7,  7,  4,  6,  4,  6,  9,  7,  9,  8,  2,  5,  6,  5,  6,  7,  7,\n",
      "         9,  7,  4,  7,  9,  9,  5,  8,  5,  5,  4,  9,  7,  4,  9,  3,  9,  4,\n",
      "         6,  5,  4,  6,  4,  7,  3,  5,  5,  4,  5,  5, 10,  5,  2,  7,  9,  6,\n",
      "        10,  4,  3,  9,  4,  9,  4,  8,  6,  9,  9,  5,  1,  9,  7,  9,  5,  4,\n",
      "         9,  6,  4,  9,  4,  4,  3,  7,  7,  9,  4,  4,  3,  7,  7,  4,  6,  9,\n",
      "         7,  9, 10,  7,  9,  4, 10,  5,  7,  6], device='cuda:0') tensor([ 7,  7,  8,  4,  6,  4,  5, 11,  8, 10,  8,  3,  5,  6,  4,  6,  7,  6,\n",
      "         8,  7,  4,  7,  9,  8,  5,  8,  5,  5,  2, 10,  7,  5,  9,  2,  8,  4,\n",
      "         6,  5,  4,  6,  4,  7,  3,  5,  6,  5,  5,  6, 10,  5,  2,  6,  7,  6,\n",
      "        11,  4,  3,  9,  3,  9,  4,  8,  6,  8,  6,  6,  2,  8,  7,  8,  5,  4,\n",
      "         6,  5,  3,  9,  4,  3,  3,  6,  8, 10,  5,  4,  3,  7,  9,  4,  6,  5,\n",
      "         7,  9,  9,  7, 10,  4, 11,  5,  6,  6], device='cuda:0')\n",
      "Accuracy: 0.5800\n",
      "Batch(batch=[6030], edge_index=[2, 15800], x=[6030, 2], y=[100])\n",
      "tensor([ 4,  6,  8,  3,  8,  6, 10,  6,  7,  9,  3,  6,  7,  6,  5,  8,  4,  4,\n",
      "         4,  6,  4,  6,  7,  5,  6, 10,  8,  5,  9,  2,  5,  6,  4,  9,  7,  9,\n",
      "         9,  8,  6,  9,  4,  7,  3,  4,  4,  4,  6,  4,  7,  9,  3,  4,  9,  4,\n",
      "         6,  8,  4,  7,  9,  5,  5,  8,  3,  7,  5,  7,  4,  9,  5,  3,  7,  8,\n",
      "         9,  4,  9,  8,  9,  4,  3,  2,  7,  8,  7,  6,  5,  7,  7,  5,  5,  7,\n",
      "         7,  7,  6,  4,  7,  9,  7,  7,  5,  2], device='cuda:0') tensor([ 4,  5,  8,  2,  6,  6, 10,  6,  8,  6,  2,  6,  8,  5,  6,  7,  4,  4,\n",
      "         4,  5,  4,  6,  7,  5,  6,  9,  7,  5, 10,  2,  5,  6,  3,  9,  6,  8,\n",
      "        10,  8,  6,  9,  4,  8,  3,  4,  5,  4,  5,  4,  7,  8,  3,  3,  8,  3,\n",
      "         6,  8,  4,  7,  9,  5,  5,  8,  3,  8,  6,  7,  4,  8,  4,  3,  7,  9,\n",
      "         9,  4,  9,  8,  8,  5,  4,  2,  7,  8,  6,  6,  6,  9,  7,  3,  6,  8,\n",
      "         8,  8,  6,  4,  8,  9,  6,  9,  4,  3], device='cuda:0')\n",
      "Accuracy: 0.5400\n",
      "Batch(batch=[6180], edge_index=[2, 16398], x=[6180, 2], y=[100])\n",
      "tensor([ 7,  8,  5,  4,  9,  9,  9,  4,  9,  9,  6,  7,  5,  9,  3, 10,  3,  8,\n",
      "         4,  3,  3,  1,  5,  5,  4,  7,  9,  6,  6,  9,  2,  5,  4,  5,  5,  7,\n",
      "         5,  4,  6,  7,  9,  8,  4,  7,  4,  5,  6,  5,  6,  9,  7,  2,  7,  4,\n",
      "         2,  9,  6,  9,  3,  4, 10,  9,  5,  9,  6,  5,  7,  7,  6,  9,  5,  6,\n",
      "         5,  5,  5, 10,  8,  9,  6,  6,  7, 10,  7,  9,  4,  3,  5,  7,  5,  9,\n",
      "         4,  9,  9,  9, 10,  4,  5,  5,  7,  7], device='cuda:0') tensor([ 6,  7,  5,  4,  7,  9, 10,  3,  9,  8,  6,  6,  5,  7,  3, 11,  3,  7,\n",
      "         4,  3,  3,  1,  4,  5,  4,  7,  7,  6,  6, 10,  5,  5,  4,  5,  5,  7,\n",
      "         5,  3,  5,  9,  9,  9,  4,  7,  4,  6,  6,  6,  6,  8,  6,  2,  6,  4,\n",
      "         2,  8,  5,  9,  3,  4,  8,  9,  6,  7,  7,  6,  7,  7,  6, 10,  6,  6,\n",
      "         5,  7,  5, 10,  8,  9,  6,  6,  7, 10,  7,  8,  5,  3,  5,  7,  6,  9,\n",
      "         4,  9,  8,  9,  9,  4,  4,  6,  7,  7], device='cuda:0')\n",
      "Accuracy: 0.6000\n",
      "Batch(batch=[6120], edge_index=[2, 16169], x=[6120, 2], y=[100])\n",
      "tensor([ 7,  9,  3,  4,  6,  2,  4,  9,  5,  7,  8, 10,  9,  7,  6,  6,  9,  9,\n",
      "         6,  5,  4,  5,  5,  4,  9,  9,  3,  7,  4,  4,  4,  8,  7,  9,  1,  4,\n",
      "         9, 10,  7,  9, 10,  7,  9,  5,  7,  9,  4,  4,  5,  4,  9,  7,  4,  7,\n",
      "         5,  8,  9,  9,  4,  6,  9,  7,  7,  7,  6,  9,  5,  7,  4,  7,  5,  5,\n",
      "         4,  4, 10,  5,  9,  8,  9,  9,  2,  9,  4,  5,  3,  6,  6,  9,  6,  9,\n",
      "         7,  9,  7,  6,  4,  7,  6,  5,  7,  6], device='cuda:0') tensor([ 7,  8,  2,  4,  7,  2,  4,  9,  6,  7,  7, 10,  8,  6,  6,  5,  8,  8,\n",
      "         5,  5,  4,  5,  5,  5, 10,  9,  4,  8,  4,  5,  4,  8,  6,  8,  1,  4,\n",
      "         8,  8,  6,  9, 11,  6,  8,  5,  6,  8,  3,  3,  3,  3,  9,  7,  3,  7,\n",
      "         3,  8,  8,  8,  4,  6,  9,  7,  7,  7,  6,  8,  5,  7,  4,  8,  5,  5,\n",
      "         5,  4,  8,  5,  9,  9,  8,  7,  2,  8,  3,  5,  3,  6,  6,  8,  6,  9,\n",
      "         7,  8,  6,  5,  4,  6,  6,  5,  6,  6], device='cuda:0')\n",
      "Accuracy: 0.5100\n",
      "Batch(batch=[6080], edge_index=[2, 15661], x=[6080, 2], y=[100])\n",
      "tensor([ 7,  4,  6,  7,  6,  4,  4,  7,  7,  3,  7,  4,  9,  9, 10,  6,  9,  5,\n",
      "         7,  8,  9,  9,  7, 10,  4,  7,  9,  7,  5,  6,  6,  5,  9,  9,  4,  9,\n",
      "         4, 10,  5,  5,  4,  5,  7,  6,  4,  7,  9,  7,  7,  8,  5,  5,  2,  4,\n",
      "         7,  9,  3,  6,  9,  9,  4,  3,  7,  6,  4,  4,  4,  7,  5,  4, 10,  5,\n",
      "         7,  5,  4,  5,  8,  9,  6,  5,  5, 10,  5,  7,  1,  4,  4,  7,  5,  6,\n",
      "         7,  9,  7,  5, 10,  9,  6,  9,  9,  6], device='cuda:0') tensor([ 8,  4,  5,  8,  5,  4,  3,  6,  7,  3,  7,  4,  9,  9, 10,  7,  9,  6,\n",
      "         7,  8,  8,  9,  6, 10,  4,  6,  3,  8,  5,  6,  5,  5,  8,  9,  4,  9,\n",
      "         4,  9,  5,  6,  4,  5,  6,  5,  3,  8,  9,  7,  7,  9,  5,  5,  3,  3,\n",
      "         8,  8,  2,  5,  8,  8,  4,  2,  6,  6,  3,  5,  3,  7,  5,  5,  9,  5,\n",
      "         6,  5,  4,  5,  8,  9,  7,  6,  3,  9,  5,  7,  1,  4,  5,  7,  5,  6,\n",
      "         6,  7,  6,  5, 10,  8,  6,  8,  8,  6], device='cuda:0')\n",
      "Accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    data = batch.to(device)\n",
    "    _, pred = model(data).max(dim=1)\n",
    "    print(pred, data.y)\n",
    "    correct = float(pred.eq(data.y).sum().item())\n",
    "    acc = correct / len(pred)\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combined Counter & Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = [gen_edge_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(1000)]\n",
    "test_dataset = [gen_edge_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].y_graph.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using \", device)\n",
    "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
    "model = Edge_Graph_Class_Net(input_dim=2, hidden_dim=16, n_graph_iters=4, output_dim=12).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , loss:  3.1576285362243652 , count accuracy:  0.122 , edge accuracy:  0.6513064133016627\n",
      "Epoch:  2 , loss:  3.1742045879364014 , count accuracy:  0.134 , edge accuracy:  0.6614945111382166\n",
      "Epoch:  3 , loss:  3.0324511528015137 , count accuracy:  0.134 , edge accuracy:  0.6614945111382166\n",
      "Epoch:  4 , loss:  3.011707305908203 , count accuracy:  0.158 , edge accuracy:  0.6614945111382166\n",
      "Epoch:  5 , loss:  3.0208494663238525 , count accuracy:  0.196 , edge accuracy:  0.6620851255055531\n",
      "Epoch:  6 , loss:  3.003718137741089 , count accuracy:  0.182 , edge accuracy:  0.6734865506837003\n",
      "Epoch:  7 , loss:  2.8945674896240234 , count accuracy:  0.193 , edge accuracy:  0.6919881877126532\n",
      "Epoch:  8 , loss:  2.9283816814422607 , count accuracy:  0.194 , edge accuracy:  0.7084547730628491\n",
      "Epoch:  9 , loss:  2.8948309421539307 , count accuracy:  0.204 , edge accuracy:  0.7297875072221865\n",
      "Epoch:  10 , loss:  2.914076328277588 , count accuracy:  0.208 , edge accuracy:  0.746857546382487\n",
      "Epoch:  11 , loss:  2.802792549133301 , count accuracy:  0.216 , edge accuracy:  0.7610258714771779\n",
      "Epoch:  12 , loss:  2.8270790576934814 , count accuracy:  0.247 , edge accuracy:  0.7690762020928291\n",
      "Epoch:  13 , loss:  2.7655274868011475 , count accuracy:  0.247 , edge accuracy:  0.7779418373242601\n",
      "Epoch:  14 , loss:  2.808720111846924 , count accuracy:  0.254 , edge accuracy:  0.7958464402644925\n",
      "Epoch:  15 , loss:  2.6588196754455566 , count accuracy:  0.259 , edge accuracy:  0.8237080310714515\n",
      "Epoch:  16 , loss:  2.656951427459717 , count accuracy:  0.266 , edge accuracy:  0.8548436797842973\n",
      "Epoch:  17 , loss:  2.6260929107666016 , count accuracy:  0.273 , edge accuracy:  0.8773512229569237\n",
      "Epoch:  18 , loss:  2.5608267784118652 , count accuracy:  0.272 , edge accuracy:  0.8878089490916095\n",
      "Epoch:  19 , loss:  2.58125376701355 , count accuracy:  0.273 , edge accuracy:  0.9003723438402773\n",
      "Epoch:  20 , loss:  2.567147731781006 , count accuracy:  0.273 , edge accuracy:  0.9057199717532259\n",
      "Epoch:  21 , loss:  2.507758617401123 , count accuracy:  0.276 , edge accuracy:  0.9089234127238878\n",
      "Epoch:  22 , loss:  2.519458770751953 , count accuracy:  0.291 , edge accuracy:  0.9125954933555883\n",
      "Epoch:  23 , loss:  2.466383457183838 , count accuracy:  0.287 , edge accuracy:  0.9154458496501252\n",
      "Epoch:  24 , loss:  2.516859531402588 , count accuracy:  0.307 , edge accuracy:  0.9169865827823073\n",
      "Epoch:  25 , loss:  2.4069888591766357 , count accuracy:  0.288 , edge accuracy:  0.9167233742055595\n",
      "Epoch:  26 , loss:  2.520430326461792 , count accuracy:  0.288 , edge accuracy:  0.9171534955382936\n",
      "Epoch:  27 , loss:  2.5352001190185547 , count accuracy:  0.297 , edge accuracy:  0.9195673107787122\n",
      "Epoch:  28 , loss:  2.4262051582336426 , count accuracy:  0.31 , edge accuracy:  0.9197855813057714\n",
      "Epoch:  29 , loss:  2.428661584854126 , count accuracy:  0.31 , edge accuracy:  0.9215189060794762\n",
      "Epoch:  30 , loss:  2.467913866043091 , count accuracy:  0.292 , edge accuracy:  0.9207164409064647\n",
      "Epoch:  31 , loss:  2.4559147357940674 , count accuracy:  0.291 , edge accuracy:  0.9211786608461193\n",
      "Epoch:  32 , loss:  2.435981273651123 , count accuracy:  0.323 , edge accuracy:  0.9214739680297875\n",
      "Epoch:  33 , loss:  2.349578380584717 , count accuracy:  0.324 , edge accuracy:  0.922417667073249\n",
      "Epoch:  34 , loss:  2.4482226371765137 , count accuracy:  0.319 , edge accuracy:  0.9236630930217629\n",
      "Epoch:  35 , loss:  2.389862537384033 , count accuracy:  0.335 , edge accuracy:  0.9241317326828016\n",
      "Epoch:  36 , loss:  2.457862377166748 , count accuracy:  0.353 , edge accuracy:  0.924439879309238\n",
      "Epoch:  37 , loss:  2.384885787963867 , count accuracy:  0.352 , edge accuracy:  0.9241381524041856\n",
      "Epoch:  38 , loss:  2.327662944793701 , count accuracy:  0.335 , edge accuracy:  0.923887783270206\n",
      "Epoch:  39 , loss:  2.3603055477142334 , count accuracy:  0.328 , edge accuracy:  0.9231880336393401\n",
      "Epoch:  40 , loss:  2.4143574237823486 , count accuracy:  0.323 , edge accuracy:  0.9241830904538743\n",
      "Epoch:  41 , loss:  2.3928160667419434 , count accuracy:  0.314 , edge accuracy:  0.923605315529306\n",
      "Epoch:  42 , loss:  2.3331708908081055 , count accuracy:  0.341 , edge accuracy:  0.9241959298966425\n",
      "Epoch:  43 , loss:  2.352027416229248 , count accuracy:  0.359 , edge accuracy:  0.9256467869294472\n",
      "Epoch:  44 , loss:  2.3379623889923096 , count accuracy:  0.359 , edge accuracy:  0.927444308916993\n",
      "Epoch:  45 , loss:  2.403022289276123 , count accuracy:  0.374 , edge accuracy:  0.9267573987288952\n",
      "Epoch:  46 , loss:  2.396306037902832 , count accuracy:  0.378 , edge accuracy:  0.9265583873659883\n",
      "Epoch:  47 , loss:  2.395338535308838 , count accuracy:  0.38 , edge accuracy:  0.9251460486614881\n",
      "Epoch:  48 , loss:  2.359173536300659 , count accuracy:  0.348 , edge accuracy:  0.9255376516659177\n",
      "Epoch:  49 , loss:  2.243870258331299 , count accuracy:  0.366 , edge accuracy:  0.925345060024395\n",
      "Epoch:  50 , loss:  2.382564067840576 , count accuracy:  0.378 , edge accuracy:  0.9261346857546382\n",
      "Epoch:  51 , loss:  2.3130781650543213 , count accuracy:  0.388 , edge accuracy:  0.9288181292931886\n",
      "Epoch:  52 , loss:  2.3007421493530273 , count accuracy:  0.395 , edge accuracy:  0.9275406047377543\n",
      "Epoch:  53 , loss:  2.38906192779541 , count accuracy:  0.381 , edge accuracy:  0.9281247993837067\n",
      "Epoch:  54 , loss:  2.4518377780914307 , count accuracy:  0.375 , edge accuracy:  0.9269628298131861\n",
      "Epoch:  55 , loss:  2.1836540699005127 , count accuracy:  0.387 , edge accuracy:  0.9280349232843295\n",
      "Epoch:  56 , loss:  2.303584337234497 , count accuracy:  0.393 , edge accuracy:  0.9277973935931181\n",
      "Epoch:  57 , loss:  2.3001396656036377 , count accuracy:  0.389 , edge accuracy:  0.9290235603774796\n",
      "Epoch:  58 , loss:  2.2036349773406982 , count accuracy:  0.398 , edge accuracy:  0.9304551582461321\n",
      "Epoch:  59 , loss:  2.3271288871765137 , count accuracy:  0.393 , edge accuracy:  0.9297554086152661\n",
      "Epoch:  60 , loss:  2.3661508560180664 , count accuracy:  0.376 , edge accuracy:  0.9301341721769275\n",
      "Epoch:  61 , loss:  2.4601023197174072 , count accuracy:  0.33 , edge accuracy:  0.9298838030429479\n",
      "Epoch:  62 , loss:  2.3030624389648438 , count accuracy:  0.322 , edge accuracy:  0.9283880079604545\n",
      "Epoch:  63 , loss:  2.2585561275482178 , count accuracy:  0.346 , edge accuracy:  0.9281183796623227\n",
      "Epoch:  64 , loss:  2.3640875816345215 , count accuracy:  0.367 , edge accuracy:  0.9275983822302112\n",
      "Epoch:  65 , loss:  2.283921241760254 , count accuracy:  0.363 , edge accuracy:  0.9294151633819092\n",
      "Epoch:  66 , loss:  2.2880241870880127 , count accuracy:  0.399 , edge accuracy:  0.9302433074404571\n",
      "Epoch:  67 , loss:  2.1699166297912598 , count accuracy:  0.393 , edge accuracy:  0.9289401039994865\n",
      "Epoch:  68 , loss:  2.3117504119873047 , count accuracy:  0.404 , edge accuracy:  0.9309687359568595\n",
      "Epoch:  69 , loss:  2.1328814029693604 , count accuracy:  0.402 , edge accuracy:  0.9310842909417731\n",
      "Epoch:  70 , loss:  2.395967483520508 , count accuracy:  0.407 , edge accuracy:  0.9302176285549207\n",
      "Epoch:  71 , loss:  2.3635895252227783 , count accuracy:  0.381 , edge accuracy:  0.930378121589523\n",
      "Epoch:  72 , loss:  2.29846453666687 , count accuracy:  0.371 , edge accuracy:  0.9311549078769982\n",
      "Epoch:  73 , loss:  2.1668996810913086 , count accuracy:  0.382 , edge accuracy:  0.932047249149387\n",
      "Epoch:  74 , loss:  2.2934577465057373 , count accuracy:  0.398 , edge accuracy:  0.9325800860242666\n",
      "Epoch:  75 , loss:  2.3736393451690674 , count accuracy:  0.395 , edge accuracy:  0.9321949027412211\n",
      "Epoch:  76 , loss:  2.371438980102539 , count accuracy:  0.382 , edge accuracy:  0.9291326956410092\n",
      "Epoch:  77 , loss:  2.2368662357330322 , count accuracy:  0.374 , edge accuracy:  0.9309430570713231\n",
      "Epoch:  78 , loss:  2.23089337348938 , count accuracy:  0.367 , edge accuracy:  0.931077871220389\n",
      "Epoch:  79 , loss:  2.2200896739959717 , count accuracy:  0.407 , edge accuracy:  0.930654169609039\n",
      "Epoch:  80 , loss:  2.272797107696533 , count accuracy:  0.41 , edge accuracy:  0.9314694742248186\n",
      "Epoch:  81 , loss:  2.177095651626587 , count accuracy:  0.41 , edge accuracy:  0.9321499646915324\n",
      "Epoch:  82 , loss:  2.1739630699157715 , count accuracy:  0.406 , edge accuracy:  0.9331257623419144\n",
      "Epoch:  83 , loss:  2.115454912185669 , count accuracy:  0.4 , edge accuracy:  0.9315272517172755\n",
      "Epoch:  84 , loss:  2.3608763217926025 , count accuracy:  0.397 , edge accuracy:  0.9334210695255826\n",
      "Epoch:  85 , loss:  2.078286647796631 , count accuracy:  0.402 , edge accuracy:  0.9339731655646145\n",
      "Epoch:  86 , loss:  2.271789312362671 , count accuracy:  0.407 , edge accuracy:  0.9319445336072415\n",
      "Epoch:  87 , loss:  2.3249642848968506 , count accuracy:  0.393 , edge accuracy:  0.9322270013481415\n",
      "Epoch:  88 , loss:  2.2421343326568604 , count accuracy:  0.397 , edge accuracy:  0.9326763818450279\n",
      "Epoch:  89 , loss:  2.205183744430542 , count accuracy:  0.405 , edge accuracy:  0.9325800860242666\n",
      "Epoch:  90 , loss:  2.22875714302063 , count accuracy:  0.408 , edge accuracy:  0.9313346600757527\n",
      "Epoch:  91 , loss:  2.149848699569702 , count accuracy:  0.405 , edge accuracy:  0.9319573730500096\n",
      "Epoch:  92 , loss:  2.1380088329315186 , count accuracy:  0.402 , edge accuracy:  0.9338897091866213\n",
      "Epoch:  93 , loss:  2.304644823074341 , count accuracy:  0.402 , edge accuracy:  0.9320729280349233\n",
      "Epoch:  94 , loss:  2.3695461750030518 , count accuracy:  0.408 , edge accuracy:  0.9317391025229506\n",
      "Epoch:  95 , loss:  2.2972190380096436 , count accuracy:  0.406 , edge accuracy:  0.9335623033960326\n",
      "Epoch:  96 , loss:  2.261439800262451 , count accuracy:  0.402 , edge accuracy:  0.9329524298645439\n",
      "Epoch:  97 , loss:  2.201672077178955 , count accuracy:  0.415 , edge accuracy:  0.9345830390961032\n",
      "Epoch:  98 , loss:  2.2863404750823975 , count accuracy:  0.412 , edge accuracy:  0.9342106952558259\n",
      "Epoch:  99 , loss:  2.221977710723877 , count accuracy:  0.413 , edge accuracy:  0.9334916864608076\n",
      "Epoch:  100 , loss:  2.222644329071045 , count accuracy:  0.412 , edge accuracy:  0.9339218077935417\n",
      "Epoch:  101 , loss:  2.3099451065063477 , count accuracy:  0.419 , edge accuracy:  0.9340309430570714\n",
      "Epoch:  102 , loss:  2.3079631328582764 , count accuracy:  0.409 , edge accuracy:  0.9325030493676575\n",
      "Epoch:  103 , loss:  2.1578786373138428 , count accuracy:  0.395 , edge accuracy:  0.9344161263401168\n",
      "Epoch:  104 , loss:  2.235250234603882 , count accuracy:  0.412 , edge accuracy:  0.9348205687873147\n",
      "Epoch:  105 , loss:  2.147027015686035 , count accuracy:  0.418 , edge accuracy:  0.9348783462797715\n",
      "Epoch:  106 , loss:  2.2201507091522217 , count accuracy:  0.419 , edge accuracy:  0.9355138986967966\n",
      "Epoch:  107 , loss:  2.1187169551849365 , count accuracy:  0.411 , edge accuracy:  0.9336329203312577\n",
      "Epoch:  108 , loss:  2.2093658447265625 , count accuracy:  0.411 , edge accuracy:  0.93379341336586\n",
      "Epoch:  109 , loss:  2.1756436824798584 , count accuracy:  0.405 , edge accuracy:  0.9343711882904282\n",
      "Epoch:  110 , loss:  2.1418650150299072 , count accuracy:  0.414 , edge accuracy:  0.9358413044873852\n",
      "Epoch:  111 , loss:  2.1606314182281494 , count accuracy:  0.414 , edge accuracy:  0.9356615522886307\n",
      "Epoch:  112 , loss:  2.1200220584869385 , count accuracy:  0.406 , edge accuracy:  0.934351929126276\n",
      "Epoch:  113 , loss:  2.2652487754821777 , count accuracy:  0.421 , edge accuracy:  0.935822045323233\n",
      "Epoch:  114 , loss:  2.0983119010925293 , count accuracy:  0.425 , edge accuracy:  0.9338383514155486\n",
      "Epoch:  115 , loss:  2.0581417083740234 , count accuracy:  0.429 , edge accuracy:  0.9341721769275213\n",
      "Epoch:  116 , loss:  2.2800710201263428 , count accuracy:  0.428 , edge accuracy:  0.935822045323233\n",
      "Epoch:  117 , loss:  2.1589226722717285 , count accuracy:  0.43 , edge accuracy:  0.9354689606471079\n",
      "Epoch:  118 , loss:  2.2353904247283936 , count accuracy:  0.429 , edge accuracy:  0.9372022854208127\n",
      "Epoch:  119 , loss:  2.226597547531128 , count accuracy:  0.403 , edge accuracy:  0.935828465044617\n",
      "Epoch:  120 , loss:  2.053783416748047 , count accuracy:  0.416 , edge accuracy:  0.9358156256018488\n",
      "Epoch:  121 , loss:  2.3179473876953125 , count accuracy:  0.407 , edge accuracy:  0.9352956281697374\n",
      "Epoch:  122 , loss:  2.0529134273529053 , count accuracy:  0.414 , edge accuracy:  0.9362906849842717\n",
      "Epoch:  123 , loss:  2.335205554962158 , count accuracy:  0.427 , edge accuracy:  0.9383257366630289\n",
      "Epoch:  124 , loss:  2.206385374069214 , count accuracy:  0.427 , edge accuracy:  0.9374141362264877\n",
      "Epoch:  125 , loss:  2.0820634365081787 , count accuracy:  0.429 , edge accuracy:  0.9370610515503627\n",
      "Epoch:  126 , loss:  1.9886621236801147 , count accuracy:  0.432 , edge accuracy:  0.9374012967837196\n",
      "Epoch:  127 , loss:  2.1789045333862305 , count accuracy:  0.416 , edge accuracy:  0.9378121589523015\n",
      "Epoch:  128 , loss:  2.05041766166687 , count accuracy:  0.427 , edge accuracy:  0.935269949284201\n",
      "Epoch:  129 , loss:  2.181492328643799 , count accuracy:  0.434 , edge accuracy:  0.936386980805033\n",
      "Epoch:  130 , loss:  2.1278584003448486 , count accuracy:  0.416 , edge accuracy:  0.9367079668742376\n",
      "Epoch:  131 , loss:  2.1479368209838867 , count accuracy:  0.416 , edge accuracy:  0.9355652564678693\n",
      "Epoch:  132 , loss:  2.1656486988067627 , count accuracy:  0.421 , edge accuracy:  0.9355780959106375\n",
      "Epoch:  133 , loss:  2.199862003326416 , count accuracy:  0.425 , edge accuracy:  0.9360659947358284\n",
      "Epoch:  134 , loss:  2.10709285736084 , count accuracy:  0.427 , edge accuracy:  0.9364704371830262\n",
      "Epoch:  135 , loss:  2.0422310829162598 , count accuracy:  0.434 , edge accuracy:  0.9368042626949991\n",
      "Epoch:  136 , loss:  2.1500422954559326 , count accuracy:  0.428 , edge accuracy:  0.9384605508120948\n",
      "Epoch:  137 , loss:  2.084538698196411 , count accuracy:  0.424 , edge accuracy:  0.9367143865956218\n",
      "Epoch:  138 , loss:  2.2892906665802 , count accuracy:  0.431 , edge accuracy:  0.9367850035308468\n",
      "Epoch:  139 , loss:  2.1157445907592773 , count accuracy:  0.431 , edge accuracy:  0.9348398279514669\n",
      "Epoch:  140 , loss:  2.2012758255004883 , count accuracy:  0.426 , edge accuracy:  0.9361815497207421\n",
      "Epoch:  141 , loss:  2.0916194915771484 , count accuracy:  0.435 , edge accuracy:  0.9329845284714643\n",
      "Epoch:  142 , loss:  1.9550838470458984 , count accuracy:  0.427 , edge accuracy:  0.9348398279514669\n",
      "Epoch:  143 , loss:  2.240842342376709 , count accuracy:  0.432 , edge accuracy:  0.9371124093214355\n",
      "Epoch:  144 , loss:  2.1204588413238525 , count accuracy:  0.431 , edge accuracy:  0.9379726519869037\n",
      "Epoch:  145 , loss:  2.136545419692993 , count accuracy:  0.434 , edge accuracy:  0.9362200680490467\n",
      "Epoch:  146 , loss:  2.195040702819824 , count accuracy:  0.439 , edge accuracy:  0.9365346343968671\n",
      "Epoch:  147 , loss:  2.142554759979248 , count accuracy:  0.439 , edge accuracy:  0.9371701868138923\n",
      "Epoch:  148 , loss:  2.1372339725494385 , count accuracy:  0.429 , edge accuracy:  0.9364704371830262\n",
      "Epoch:  149 , loss:  1.9903781414031982 , count accuracy:  0.431 , edge accuracy:  0.9381716633498106\n",
      "Epoch:  150 , loss:  2.008729934692383 , count accuracy:  0.429 , edge accuracy:  0.9383000577774925\n",
      "Epoch:  151 , loss:  2.160226821899414 , count accuracy:  0.436 , edge accuracy:  0.9382615394491879\n",
      "Epoch:  152 , loss:  2.074380874633789 , count accuracy:  0.445 , edge accuracy:  0.9368235218591513\n",
      "Epoch:  153 , loss:  2.027723789215088 , count accuracy:  0.436 , edge accuracy:  0.9385953649611607\n",
      "Epoch:  154 , loss:  2.1855876445770264 , count accuracy:  0.441 , edge accuracy:  0.9384220324837902\n",
      "Epoch:  155 , loss:  2.1038031578063965 , count accuracy:  0.438 , edge accuracy:  0.9373306798484946\n",
      "Epoch:  156 , loss:  2.154909610748291 , count accuracy:  0.435 , edge accuracy:  0.9362906849842717\n",
      "Epoch:  157 , loss:  2.0912325382232666 , count accuracy:  0.422 , edge accuracy:  0.9384926494190152\n",
      "Epoch:  158 , loss:  2.0611534118652344 , count accuracy:  0.432 , edge accuracy:  0.9382101816781152\n",
      "Epoch:  159 , loss:  2.0063302516937256 , count accuracy:  0.444 , edge accuracy:  0.9389548693586698\n",
      "Epoch:  160 , loss:  1.9991614818572998 , count accuracy:  0.443 , edge accuracy:  0.9373114206843423\n",
      "Epoch:  161 , loss:  1.958442211151123 , count accuracy:  0.444 , edge accuracy:  0.9383835141554856\n",
      "Epoch:  162 , loss:  2.21334171295166 , count accuracy:  0.436 , edge accuracy:  0.938691660781922\n",
      "Epoch:  163 , loss:  2.0490927696228027 , count accuracy:  0.446 , edge accuracy:  0.9391153623932721\n",
      "Epoch:  164 , loss:  2.175071954727173 , count accuracy:  0.444 , edge accuracy:  0.938897091866213\n",
      "Epoch:  165 , loss:  2.1463544368743896 , count accuracy:  0.448 , edge accuracy:  0.9385119085831675\n",
      "Epoch:  166 , loss:  2.122861623764038 , count accuracy:  0.445 , edge accuracy:  0.9366501893817808\n",
      "Epoch:  167 , loss:  2.05952525138855 , count accuracy:  0.448 , edge accuracy:  0.9378249983950696\n",
      "Epoch:  168 , loss:  2.1320407390594482 , count accuracy:  0.442 , edge accuracy:  0.9380753675290492\n",
      "Epoch:  169 , loss:  2.0140438079833984 , count accuracy:  0.445 , edge accuracy:  0.9368812993516081\n",
      "Epoch:  170 , loss:  2.022045135498047 , count accuracy:  0.446 , edge accuracy:  0.9374269756692559\n",
      "Epoch:  171 , loss:  1.9167137145996094 , count accuracy:  0.444 , edge accuracy:  0.9384220324837902\n",
      "Epoch:  172 , loss:  2.0613515377044678 , count accuracy:  0.448 , edge accuracy:  0.9379405533799833\n",
      "Epoch:  173 , loss:  2.018104076385498 , count accuracy:  0.451 , edge accuracy:  0.9382615394491879\n",
      "Epoch:  174 , loss:  1.9494966268539429 , count accuracy:  0.454 , edge accuracy:  0.9382422802850356\n",
      "Epoch:  175 , loss:  1.7587087154388428 , count accuracy:  0.446 , edge accuracy:  0.9383449958271811\n",
      "Epoch:  176 , loss:  1.8550444841384888 , count accuracy:  0.458 , edge accuracy:  0.9371830262566605\n",
      "Epoch:  177 , loss:  2.022266387939453 , count accuracy:  0.456 , edge accuracy:  0.9381716633498106\n",
      "Epoch:  178 , loss:  2.0113096237182617 , count accuracy:  0.464 , edge accuracy:  0.9381010464145856\n",
      "Epoch:  179 , loss:  1.8105573654174805 , count accuracy:  0.478 , edge accuracy:  0.9376324067535469\n",
      "Epoch:  180 , loss:  1.9163634777069092 , count accuracy:  0.488 , edge accuracy:  0.9385568466328561\n",
      "Epoch:  181 , loss:  1.863350510597229 , count accuracy:  0.501 , edge accuracy:  0.9364704371830262\n",
      "Epoch:  182 , loss:  1.6614629030227661 , count accuracy:  0.498 , edge accuracy:  0.938685241060538\n",
      "Epoch:  183 , loss:  1.807140588760376 , count accuracy:  0.493 , edge accuracy:  0.9379533928227515\n",
      "Epoch:  184 , loss:  1.8507134914398193 , count accuracy:  0.503 , edge accuracy:  0.9382936380561083\n",
      "Epoch:  185 , loss:  1.717226266860962 , count accuracy:  0.507 , edge accuracy:  0.9382807986133401\n",
      "Epoch:  186 , loss:  1.9944990873336792 , count accuracy:  0.489 , edge accuracy:  0.9387365988316108\n",
      "Epoch:  187 , loss:  1.9143891334533691 , count accuracy:  0.51 , edge accuracy:  0.9357257495024716\n",
      "Epoch:  188 , loss:  1.8687174320220947 , count accuracy:  0.491 , edge accuracy:  0.9355973550747898\n",
      "Epoch:  189 , loss:  1.9194934368133545 , count accuracy:  0.492 , edge accuracy:  0.9359632791936829\n",
      "Epoch:  190 , loss:  2.0154356956481934 , count accuracy:  0.51 , edge accuracy:  0.9353469859408101\n",
      "Epoch:  191 , loss:  1.9457921981811523 , count accuracy:  0.496 , edge accuracy:  0.9377543814598447\n",
      "Epoch:  192 , loss:  1.8166245222091675 , count accuracy:  0.526 , edge accuracy:  0.9372472234705014\n",
      "Epoch:  193 , loss:  1.979361891746521 , count accuracy:  0.516 , edge accuracy:  0.9381010464145856\n",
      "Epoch:  194 , loss:  1.8314417600631714 , count accuracy:  0.52 , edge accuracy:  0.9396738781536881\n",
      "Epoch:  195 , loss:  1.827699899673462 , count accuracy:  0.521 , edge accuracy:  0.9390447454580472\n",
      "Epoch:  196 , loss:  1.8227808475494385 , count accuracy:  0.518 , edge accuracy:  0.9363163638698081\n",
      "Epoch:  197 , loss:  1.7523926496505737 , count accuracy:  0.521 , edge accuracy:  0.935475380368492\n",
      "Epoch:  198 , loss:  1.9599902629852295 , count accuracy:  0.495 , edge accuracy:  0.937080310714515\n",
      "Epoch:  199 , loss:  2.0010786056518555 , count accuracy:  0.469 , edge accuracy:  0.9353213070552738\n",
      "Epoch:  200 , loss:  1.863943099975586 , count accuracy:  0.514 , edge accuracy:  0.9339731655646145\n",
      "Epoch:  201 , loss:  1.879685640335083 , count accuracy:  0.504 , edge accuracy:  0.9360788341785966\n",
      "Epoch:  202 , loss:  1.9052863121032715 , count accuracy:  0.519 , edge accuracy:  0.9384862296976311\n",
      "Epoch:  203 , loss:  1.8513412475585938 , count accuracy:  0.52 , edge accuracy:  0.9362457469345831\n",
      "Epoch:  204 , loss:  2.059642791748047 , count accuracy:  0.537 , edge accuracy:  0.9356487128458625\n",
      "Epoch:  205 , loss:  1.7278437614440918 , count accuracy:  0.514 , edge accuracy:  0.9382487000064197\n",
      "Epoch:  206 , loss:  1.863663673400879 , count accuracy:  0.507 , edge accuracy:  0.9374911728830969\n",
      "Epoch:  207 , loss:  1.857136607170105 , count accuracy:  0.471 , edge accuracy:  0.9354625409257238\n",
      "Epoch:  208 , loss:  2.0660808086395264 , count accuracy:  0.498 , edge accuracy:  0.9337227964306349\n",
      "Epoch:  209 , loss:  1.7690074443817139 , count accuracy:  0.519 , edge accuracy:  0.935545997303717\n",
      "Epoch:  210 , loss:  1.7688298225402832 , count accuracy:  0.516 , edge accuracy:  0.9378763561661424\n",
      "Epoch:  211 , loss:  1.742173433303833 , count accuracy:  0.543 , edge accuracy:  0.9393914104127881\n",
      "Epoch:  212 , loss:  1.870680570602417 , count accuracy:  0.531 , edge accuracy:  0.9386595621750016\n",
      "Epoch:  213 , loss:  1.8515676259994507 , count accuracy:  0.518 , edge accuracy:  0.9384605508120948\n",
      "Epoch:  214 , loss:  1.7366515398025513 , count accuracy:  0.542 , edge accuracy:  0.9385311677473198\n",
      "Epoch:  215 , loss:  1.8430802822113037 , count accuracy:  0.533 , edge accuracy:  0.9387879566026834\n",
      "Epoch:  216 , loss:  1.6865381002426147 , count accuracy:  0.54 , edge accuracy:  0.9396353598253836\n",
      "Epoch:  217 , loss:  1.8010212182998657 , count accuracy:  0.539 , edge accuracy:  0.9392244976568017\n",
      "Epoch:  218 , loss:  1.9431835412979126 , count accuracy:  0.551 , edge accuracy:  0.939314373756179\n",
      "Epoch:  219 , loss:  1.7670519351959229 , count accuracy:  0.544 , edge accuracy:  0.9393785709700199\n",
      "Epoch:  220 , loss:  1.75729238986969 , count accuracy:  0.535 , edge accuracy:  0.938126725300122\n",
      "Epoch:  221 , loss:  1.857451319694519 , count accuracy:  0.503 , edge accuracy:  0.9373884573409514\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-16cb4621fbe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcount_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0medge_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#         print(batch.x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(data_list)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             collate_fn=lambda data_list: Batch.from_data_list(\n\u001b[0;32m---> 32\u001b[0;31m                 data_list, follow_batch),\n\u001b[0m\u001b[1;32m     33\u001b[0m             **kwargs)\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(data_list, follow_batch)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0mcumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_v = []\n",
    "acc_v_count = []\n",
    "acc_v_edge = []\n",
    "ep = 0\n",
    "for epoch in range(500):\n",
    "    ep += 1\n",
    "    count_correct = 0\n",
    "    edge_correct = 0\n",
    "    count_total = 0\n",
    "    edge_total = 0 \n",
    "    for batch in train_loader:\n",
    "#         print(batch.x)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        edge_pred, graph_pred = model(data)\n",
    "        _, graph_pred_max = graph_pred.max(dim=1)\n",
    "        losses = [F.binary_cross_entropy_with_logits(edge_pred.float(), data.y.float()), F.cross_entropy(graph_pred, data.y_graph)]\n",
    "#         print(losses[0].item(), losses[1].item())\n",
    "        loss = sum(losses)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        edge_correct += ((edge_pred > 0.5) == (data.y > 0.5)).sum().item()\n",
    "        count_correct += float(graph_pred_max.eq(data.y_graph).sum().item())\n",
    "#         print(correct, pred, data.y)\n",
    "        count_total += len(graph_pred_max)\n",
    "        edge_total += len(edge_pred)\n",
    "#         print(out, data.y, )\n",
    "    count_acc = count_correct/count_total\n",
    "    edge_acc = edge_correct / edge_total\n",
    "    print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", count accuracy: \", count_acc, \", edge accuracy: \", edge_acc)\n",
    "    loss_v.append(loss)\n",
    "    acc_v_count.append(count_acc)\n",
    "    acc_v_edge.append(edge_acc)\n",
    "plt.plot(np.arange(len(loss_v)), loss_v)\n",
    "plt.plot(np.arange(len(acc_v_count)), acc_v_count)\n",
    "plt.plot(np.arange(len(acc_v_edge)), acc_v_edge)\n",
    "plt.ylim(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[5910], edge_index=[2, 14768], x=[5910, 2], y=[14768], y_graph=[100])\n",
      "Accuracy: 0.6900\n",
      "Batch(batch=[6130], edge_index=[2, 15735], x=[6130, 2], y=[15735], y_graph=[100])\n",
      "Accuracy: 0.7000\n",
      "Batch(batch=[6460], edge_index=[2, 17175], x=[6460, 2], y=[17175], y_graph=[100])\n",
      "Accuracy: 0.6700\n",
      "Batch(batch=[6180], edge_index=[2, 15944], x=[6180, 2], y=[15944], y_graph=[100])\n",
      "Accuracy: 0.6800\n",
      "Batch(batch=[6110], edge_index=[2, 15557], x=[6110, 2], y=[15557], y_graph=[100])\n",
      "Accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    data = batch.to(device)\n",
    "    edge_pred, graph_pred = model(data)\n",
    "    _, graph_pred_max = graph_pred.max(dim=1)\n",
    "    correct = float(graph_pred_max.eq(data.y_graph).sum().item())\n",
    "    acc = correct / len(graph_pred_max)\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Edge & Track Param Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     68,
     94,
     139
    ]
   },
   "outputs": [],
   "source": [
    "class TwoHopAttNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    A module which computes new node features on the graph.\n",
    "    For each node, it aggregates the neighbor node features\n",
    "    (separately on the input and output side), and combines\n",
    "    them with the node's previous features in a fully-connected\n",
    "    network to compute the new features.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
    "                 layer_norm=True):\n",
    "        super(TwoHopAttNetwork, self).__init__()\n",
    "        self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
    "                                hidden_activation=hidden_activation,\n",
    "                                output_activation=hidden_activation,\n",
    "                                layer_norm=layer_norm)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        start, end = edge_index\n",
    "        # Aggregate edge-weighted incoming/outgoing features\n",
    "        mi = scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])\n",
    "        mi2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
    "        mo = scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])\n",
    "        mo2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
    "        node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
    "        return self.network(node_inputs)\n",
    "    \n",
    "def n_hop_front(x, e, edge_index, n):\n",
    "    start, end = edge_index\n",
    "#     print(n, \"-hop forward shapes: \", x.shape, e.shape, edge_index.shape) \n",
    "    if n is 1:\n",
    "        return [scatter_add(e[:,None]*x[start], end, dim=0, dim_size=x.shape[0])]\n",
    "    else:\n",
    "        running_hop = n_hop_front(x, e, edge_index, (n-1))\n",
    "        forward_hop = [scatter_add(e[:, None]*(running_hop[0])[start], end, dim=0, dim_size=x.shape[0])]\n",
    "        return forward_hop + running_hop\n",
    "\n",
    "def n_hop_back(x, e, edge_index, n):\n",
    "    start, end = edge_index\n",
    "#     print(n, \"-hop back shapes: \", x.shape, e.shape, edge_index.shape)\n",
    "    if n is 1:\n",
    "        return [scatter_add(e[:,None]*x[end], start, dim=0, dim_size=x.shape[0])]\n",
    "    else:\n",
    "        running_hop = n_hop_back(x, e, edge_index, (n-1))\n",
    "        back_hop = [scatter_add(e[:, None]*(running_hop[0])[end], start, dim=0, dim_size=x.shape[0])]\n",
    "        return back_hop + running_hop\n",
    "\n",
    "class NHopAttNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    A module which computes new node features on the graph.\n",
    "    For each node, it aggregates the neighbor node features\n",
    "    (separately on the input and output side), and combines\n",
    "    them with the node's previous features in a fully-connected\n",
    "    network to compute the new features.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
    "                 layer_norm=True, hops=1):\n",
    "        super(NHopAttNetwork, self).__init__()\n",
    "        self.network = make_mlp(input_dim*(hops*2 + 1), [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
    "                                hidden_activation=hidden_activation,\n",
    "                                output_activation=hidden_activation,\n",
    "                                layer_norm=layer_norm)\n",
    "        self.hops = hops\n",
    "        \n",
    "    def forward(self, x, e, edge_index):\n",
    "#         print(\"Input shapes: \", x.shape, e.shape, edge_index.shape)       \n",
    "        node_inputs = torch.cat(n_hop_front(x, e, edge_index, self.hops) + [x] + n_hop_back(x, e, edge_index, self.hops), dim=-1)\n",
    "#         print(\"Network shape: \", node_inputs.shape)\n",
    "        return self.network(node_inputs)\n",
    "    \n",
    "\n",
    "        \n",
    "class TwoHopNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    A module which computes new node features on the graph.\n",
    "    For each node, it aggregates the neighbor node features\n",
    "    (separately on the input and output side), and combines\n",
    "    them with the node's previous features in a fully-connected\n",
    "    network to compute the new features.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
    "                 layer_norm=True):\n",
    "        super(TwoHopNetwork, self).__init__()\n",
    "        self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
    "                                hidden_activation=hidden_activation,\n",
    "                                output_activation=hidden_activation,\n",
    "                                layer_norm=layer_norm)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        start, end = edge_index\n",
    "        # Aggregate edge-weighted incoming/outgoing features\n",
    "        mi = scatter_add(x[start], end, dim=0, dim_size=x.shape[0])\n",
    "        mi2 = scatter_add(scatter_add(x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
    "        mo = scatter_add(x[end], start, dim=0, dim_size=x.shape[0])\n",
    "        mo2 = scatter_add(scatter_add(x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
    "        node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
    "        return self.network(node_inputs)\n",
    "\n",
    "class Edge_Track_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Segment classification graph neural network model.\n",
    "    Consists of an input network, an edge network, and a node network.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
    "                 output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
    "        super(Edge_Track_Net, self).__init__()\n",
    "        self.n_graph_iters = n_graph_iters\n",
    "        # Setup the input network\n",
    "        self.input_network = make_mlp(input_dim, [hidden_dim],\n",
    "                                      hidden_activation=nn.ReLU,\n",
    "                                      layer_norm=False)\n",
    "        # Setup the edge network\n",
    "        self.edge_network = EdgeNetwork(input_dim+hidden_dim, hidden_dim,\n",
    "                                        hidden_activation, layer_norm=layer_norm)\n",
    "        # Setup the node layers\n",
    "        self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
    "                                        hidden_activation=nn.ReLU, layer_norm=False)\n",
    "        \n",
    "#         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
    "#                                         layer_norm=False)\n",
    "        self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, output_dim],\n",
    "                                       hidden_activation=nn.ReLU,\n",
    "                                      output_activation=None,\n",
    "                                      layer_norm=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Apply forward pass of the model\"\"\"\n",
    "        # Apply input network to get hidden representation\n",
    "        x = self.input_network(inputs.x)\n",
    "        # Shortcut connect the inputs onto the hidden representation\n",
    "        x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Loop over iterations of edge and node networks\n",
    "        for i in range(self.n_graph_iters):\n",
    "            # Apply edge network\n",
    "            e = torch.sigmoid(self.edge_network(x, inputs.edge_index))\n",
    "            # Apply node network\n",
    "            x = self.node_network(x, e, inputs.edge_index)\n",
    "            # Shortcut connect the inputs onto the hidden representation\n",
    "            x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Apply final edge network\n",
    "        e = self.edge_network(x, inputs.edge_index)\n",
    "        return e, self.output_network(x)\n",
    "    \n",
    "class Edge_Track_Truth_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Segment classification graph neural network model.\n",
    "    Consists of an input network, an edge network, and a node network.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
    "                 output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
    "        super(Edge_Track_Truth_Net, self).__init__()\n",
    "        self.n_graph_iters = n_graph_iters\n",
    "        # Setup the input network\n",
    "        self.input_network = make_mlp(input_dim, [hidden_dim],\n",
    "                                      hidden_activation=nn.ReLU,\n",
    "                                      layer_norm=False)\n",
    "        # Setup the node layers\n",
    "        self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
    "                                        hidden_activation=nn.ReLU, layer_norm=False)\n",
    "        \n",
    "#         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
    "#                                         layer_norm=False)\n",
    "        self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, output_dim],\n",
    "                                       hidden_activation=nn.ReLU,\n",
    "                                      output_activation=None,\n",
    "                                      layer_norm=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Apply forward pass of the model\"\"\"\n",
    "        # Apply input network to get hidden representation\n",
    "        x = self.input_network(inputs.x)\n",
    "        # Shortcut connect the inputs onto the hidden representation\n",
    "        x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Loop over iterations of edge and node networks\n",
    "        for i in range(self.n_graph_iters):\n",
    "            # Apply edge network\n",
    "            e = inputs.y_edges\n",
    "            # Apply node network\n",
    "            x = self.node_network(x, e, inputs.edge_index)\n",
    "            # Shortcut connect the inputs onto the hidden representation\n",
    "            x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Apply final edge network\n",
    "        return self.output_network(x)\n",
    "    \n",
    "class NHop_Edge_Class_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Segment classification graph neural network model.\n",
    "    Consists of an input network, an edge network, and a node network.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
    "                 hidden_activation=nn.Tanh, layer_norm=True, hops=1):\n",
    "        super(NHop_Edge_Class_Net, self).__init__()\n",
    "        self.n_graph_iters = n_graph_iters\n",
    "        # Setup the input network\n",
    "        self.input_network = make_mlp(input_dim, [hidden_dim],\n",
    "                                      output_activation=hidden_activation,\n",
    "                                      layer_norm=layer_norm)\n",
    "        # Setup the edge network\n",
    "        self.edge_network = EdgeNetwork(input_dim+hidden_dim, hidden_dim,\n",
    "                                        hidden_activation, layer_norm=layer_norm)\n",
    "        # Setup the node layers\n",
    "        self.node_network = NHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
    "                                        hidden_activation=nn.ReLU, layer_norm=False, hops=hops)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Apply forward pass of the model\"\"\"\n",
    "        # Apply input network to get hidden representation\n",
    "        x = self.input_network(inputs.x)\n",
    "        # Shortcut connect the inputs onto the hidden representation\n",
    "        x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Loop over iterations of edge and node networks\n",
    "        for i in range(self.n_graph_iters):\n",
    "            # Apply edge network\n",
    "            e = torch.sigmoid(self.edge_network(x, inputs.edge_index))\n",
    "            # Apply node network\n",
    "            x = self.node_network(x, e, inputs.edge_index)\n",
    "            # Shortcut connect the inputs onto the hidden representation\n",
    "            x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Apply final edge network\n",
    "        return self.edge_network(x, inputs.edge_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, val_size = 200, 10\n",
    "train_dataset, val_dataset = load_data(train_size, val_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "t_configs = {'train_size': train_size, 'val_size': val_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print(\"Using \", device)\n",
    "m_configs = {'hidden_dim': 64, 'n_graph_iters': 4, 'hops': 4}\n",
    "m_configs = {'input_dim': 3, **m_configs}#, 'output_dim': 1}\n",
    "model = NHop_Edge_Class_Net(**m_configs).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "o_configs = {'lr': 0.001, 'weight_decay': 1e-4}\n",
    "# optimizer = torch.optim.SGD([\n",
    "#                                 {'params': model.input_network.parameters()},\n",
    "#                                 {'params': model.edge_network.parameters()},\n",
    "#                                 {'params': model.node_network.parameters()},\n",
    "#                                 {'params': model.output_network.parameters(), 'lr': learning_rate*10}], lr=learning_rate, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam([\n",
    "#                                 {'params': model.input_network.parameters()},\n",
    "#                                 {'params': model.edge_network.parameters()},\n",
    "#                                 {'params': model.node_network.parameters(), 'lr': learning_rate*10},\n",
    "#                                 {'params': model.output_network.parameters(), 'lr': learning_rate*10}], lr=learning_rate, weight_decay=1e-4)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), amsgrad=True, **o_configs)\n",
    "s_configs = {'step_size': 20, 'gamma': 0.9}\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, **s_configs)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.3, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression/runs/fwpw76ra\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression/runs/fwpw76ra</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error resolved after 0:00:23.785435, resuming normal operation.\n",
      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x2aab57ea34a8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error resolved after 0:00:11.332204, resuming normal operation.\n",
      "wandb: Network error resolved after 0:00:23.334204, resuming normal operation.\n",
      "wandb: Network error resolved after 0:00:37.807275, resuming normal operation.\n",
      "wandb: Network error resolved after 0:00:38.484777, resuming normal operation.\n"
     ]
    }
   ],
   "source": [
    "hyperconfig = {**m_configs, **t_configs, **s_configs, **o_configs}\n",
    "wandb.init(project=\"node_regression\", config=hyperconfig)\n",
    "wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_validate(model, val_loader, val_size):\n",
    "    model = model.eval()\n",
    "    edge_correct, edge_total, loss = 0, 0, 0\n",
    "    for batch in val_loader:\n",
    "        data = batch.to(device)\n",
    "#             print(len(data.y_params))\n",
    "        edge_pred = model(data)\n",
    "        edge_pred = torch.sigmoid(edge_pred)\n",
    "        edge_correct += ((edge_pred > 0.5) == (data.y_edges > 0.5)).sum().item()\n",
    "        edge_total += len(edge_pred)\n",
    "        loss += F.binary_cross_entropy_with_logits(edge_pred, data.y_edges)\n",
    "    acc = edge_correct / edge_total\n",
    "    return acc, loss.item()/val_size\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , val loss:  0.07246202230453491 , val accuracy:  83.40630249961819 %, lr:  0.001\n",
      "Epoch:  2 , val loss:  0.07213714718818665 , val accuracy:  83.49812001367263 %, lr:  0.001\n",
      "Epoch:  3 , val loss:  0.06964496970176696 , val accuracy:  83.77357255583597 %, lr:  0.001\n",
      "Epoch:  4 , val loss:  0.06716558933258057 , val accuracy:  91.62060639558986 %, lr:  0.001\n",
      "Epoch:  5 , val loss:  0.06460346579551697 , val accuracy:  94.32604126515443 %, lr:  0.001\n",
      "Epoch:  6 , val loss:  0.06392822265625 , val accuracy:  95.3200340361161 %, lr:  0.001\n",
      "Epoch:  7 , val loss:  0.06388763785362243 , val accuracy:  95.47185111381008 %, lr:  0.001\n",
      "Epoch:  8 , val loss:  0.06356757283210754 , val accuracy:  95.82166675151453 %, lr:  0.001\n",
      "Epoch:  9 , val loss:  0.06293382048606873 , val accuracy:  96.00221089301169 %, lr:  0.001\n",
      "Epoch:  10 , val loss:  0.06370933055877685 , val accuracy:  95.75275816175882 %, lr:  0.001\n",
      "Epoch:  11 , val loss:  0.06264554262161255 , val accuracy:  96.32384491749151 %, lr:  0.001\n",
      "Epoch:  12 , val loss:  0.06317314505577087 , val accuracy:  96.11621006392681 %, lr:  0.001\n",
      "Epoch:  13 , val loss:  0.06316614747047425 , val accuracy:  96.55820684940473 %, lr:  0.001\n",
      "Epoch:  14 , val loss:  0.06399056315422058 , val accuracy:  96.40748067286783 %, lr:  0.001\n",
      "Epoch:  15 , val loss:  0.0642193853855133 , val accuracy:  96.44820764939891 %, lr:  0.001\n",
      "Epoch:  16 , val loss:  0.06414175629615784 , val accuracy:  96.35639013534447 %, lr:  0.001\n",
      "Epoch:  17 , val loss:  0.06370117068290711 , val accuracy:  96.80765958065759 %, lr:  0.001\n",
      "Epoch:  18 , val loss:  0.06284512877464295 , val accuracy:  96.8342048421466 %, lr:  0.001\n",
      "Epoch:  19 , val loss:  0.06304460167884826 , val accuracy:  96.64475167453328 %, lr:  0.001\n",
      "Epoch:  20 , val loss:  0.06280137300491333 , val accuracy:  96.97020385306288 %, lr:  0.001\n",
      "Epoch:  21 , val loss:  0.06305537819862365 , val accuracy:  96.90602250165453 %, lr:  0.001\n",
      "Epoch:  22 , val loss:  0.06289728283882141 , val accuracy:  96.76111446462208 %, lr:  0.0003\n",
      "Epoch:  23 , val loss:  0.06274384260177612 , val accuracy:  97.2176565988611 %, lr:  0.0003\n",
      "Epoch:  24 , val loss:  0.0625899076461792 , val accuracy:  97.28020159853384 %, lr:  0.0003\n",
      "Epoch:  25 , val loss:  0.06268133521080017 , val accuracy:  97.21820204943964 %, lr:  0.0003\n",
      "Epoch:  26 , val loss:  0.0636965274810791 , val accuracy:  97.3102013803536 %, lr:  0.0003\n",
      "Epoch:  27 , val loss:  0.06283223032951354 , val accuracy:  97.1845659304296 %, lr:  0.0003\n",
      "Epoch:  28 , val loss:  0.06208457350730896 , val accuracy:  97.33165576977622 %, lr:  0.0003\n",
      "Epoch:  29 , val loss:  0.0635226845741272 , val accuracy:  97.33329212151183 %, lr:  0.0003\n",
      "Epoch:  30 , val loss:  0.06223304271697998 , val accuracy:  97.34347386564461 %, lr:  0.0003\n",
      "Epoch:  31 , val loss:  0.06268552541732789 , val accuracy:  97.368382775398 %, lr:  0.0003\n",
      "Epoch:  32 , val loss:  0.06215623617172241 , val accuracy:  97.35456469407495 %, lr:  0.0003\n",
      "Epoch:  33 , val loss:  0.062455016374588015 , val accuracy:  97.40620068217686 %, lr:  0.0003\n",
      "Epoch:  34 , val loss:  0.06264464259147644 , val accuracy:  97.45165489705529 %, lr:  0.0003\n",
      "Epoch:  35 , val loss:  0.06263546943664551 , val accuracy:  97.4436549552367 %, lr:  0.0003\n",
      "Epoch:  36 , val loss:  0.0625541090965271 , val accuracy:  97.43838226631078 %, lr:  0.0003\n",
      "Epoch:  37 , val loss:  0.0625162124633789 , val accuracy:  97.45729121970021 %, lr:  0.0003\n",
      "Epoch:  38 , val loss:  0.06247410178184509 , val accuracy:  97.4729274696184 %, lr:  0.0003\n",
      "Epoch:  39 , val loss:  0.06262470483779907 , val accuracy:  97.4529276150719 %, lr:  8.999999999999999e-05\n",
      "Epoch:  40 , val loss:  0.06206678152084351 , val accuracy:  97.56947222202021 %, lr:  8.999999999999999e-05\n",
      "Epoch:  41 , val loss:  0.06255432963371277 , val accuracy:  97.56347226565624 %, lr:  8.999999999999999e-05\n",
      "Epoch:  42 , val loss:  0.06259590983390809 , val accuracy:  97.56092682962306 %, lr:  8.999999999999999e-05\n",
      "Epoch:  43 , val loss:  0.06242749094963074 , val accuracy:  97.56638133540847 %, lr:  8.999999999999999e-05\n",
      "Epoch:  44 , val loss:  0.06244623064994812 , val accuracy:  97.58365393706228 %, lr:  8.999999999999999e-05\n",
      "Epoch:  45 , val loss:  0.06256061792373657 , val accuracy:  97.60347197474928 %, lr:  8.999999999999999e-05\n",
      "Epoch:  46 , val loss:  0.06330631375312805 , val accuracy:  97.58547210565742 %, lr:  8.999999999999999e-05\n",
      "Epoch:  47 , val loss:  0.06353855729103089 , val accuracy:  97.58238121904567 %, lr:  8.999999999999999e-05\n",
      "Epoch:  48 , val loss:  0.06338759064674378 , val accuracy:  97.55965411160646 %, lr:  8.999999999999999e-05\n",
      "Epoch:  49 , val loss:  0.06194280982017517 , val accuracy:  97.60201743987317 %, lr:  8.999999999999999e-05\n",
      "Epoch:  50 , val loss:  0.06339772939682006 , val accuracy:  97.6038356084683 %, lr:  8.999999999999999e-05\n",
      "Epoch:  51 , val loss:  0.0633911669254303 , val accuracy:  97.61747187293184 %, lr:  8.999999999999999e-05\n",
      "Epoch:  52 , val loss:  0.062436258792877196 , val accuracy:  97.63201722169293 %, lr:  8.999999999999999e-05\n",
      "Epoch:  53 , val loss:  0.06201566457748413 , val accuracy:  97.62910815194071 %, lr:  8.999999999999999e-05\n",
      "Epoch:  54 , val loss:  0.06238471865653992 , val accuracy:  97.61019919855129 %, lr:  8.999999999999999e-05\n",
      "Epoch:  55 , val loss:  0.062411165237426756 , val accuracy:  97.60565377706344 %, lr:  8.999999999999999e-05\n",
      "Epoch:  56 , val loss:  0.06235005259513855 , val accuracy:  97.61510825375815 %, lr:  8.999999999999999e-05\n",
      "Epoch:  57 , val loss:  0.06241827607154846 , val accuracy:  97.63819899491641 %, lr:  8.999999999999999e-05\n",
      "Epoch:  58 , val loss:  0.06191502213478088 , val accuracy:  97.60474469276586 %, lr:  8.999999999999999e-05\n",
      "Epoch:  59 , val loss:  0.06337471604347229 , val accuracy:  97.62056275954357 %, lr:  8.999999999999999e-05\n",
      "Epoch:  60 , val loss:  0.06240733861923218 , val accuracy:  97.63638082632127 %, lr:  8.999999999999999e-05\n",
      "Epoch:  61 , val loss:  0.06238125562667847 , val accuracy:  97.639471712933 %, lr:  8.999999999999999e-05\n",
      "Epoch:  62 , val loss:  0.0632662832736969 , val accuracy:  97.65547159657021 %, lr:  8.999999999999999e-05\n",
      "Epoch:  63 , val loss:  0.062329167127609254 , val accuracy:  97.65656249772728 %, lr:  8.999999999999999e-05\n",
      "Epoch:  64 , val loss:  0.06348576545715331 , val accuracy:  97.65456251227263 %, lr:  8.999999999999999e-05\n",
      "Epoch:  65 , val loss:  0.062346285581588744 , val accuracy:  97.64128988152814 %, lr:  8.999999999999999e-05\n",
      "Epoch:  66 , val loss:  0.062321817874908446 , val accuracy:  97.64819892218965 %, lr:  8.999999999999999e-05\n",
      "Epoch:  67 , val loss:  0.061870229244232175 , val accuracy:  97.68656227954706 %, lr:  8.999999999999999e-05\n",
      "Epoch:  68 , val loss:  0.06199386715888977 , val accuracy:  97.6672896924386 %, lr:  8.999999999999999e-05\n",
      "Epoch:  69 , val loss:  0.06323344707489013 , val accuracy:  97.69038043359684 %, lr:  8.999999999999999e-05\n",
      "Epoch:  70 , val loss:  0.06248472929000855 , val accuracy:  97.68201685805921 %, lr:  8.999999999999999e-05\n",
      "Epoch:  71 , val loss:  0.06348759531974793 , val accuracy:  97.70074399458913 %, lr:  8.999999999999999e-05\n",
      "Epoch:  72 , val loss:  0.06236934065818787 , val accuracy:  97.70783485211017 %, lr:  8.999999999999999e-05\n",
      "Epoch:  73 , val loss:  0.06236776113510132 , val accuracy:  97.69038043359684 %, lr:  8.999999999999999e-05\n",
      "Epoch:  74 , val loss:  0.06323385238647461 , val accuracy:  97.70547123293649 %, lr:  8.999999999999999e-05\n",
      "Epoch:  75 , val loss:  0.06229628324508667 , val accuracy:  97.69656220682032 %, lr:  8.999999999999999e-05\n",
      "Epoch:  76 , val loss:  0.06334272027015686 , val accuracy:  97.69747129111789 %, lr:  8.999999999999999e-05\n",
      "Epoch:  77 , val loss:  0.062487554550170896 , val accuracy:  97.68619864582803 %, lr:  8.999999999999999e-05\n",
      "Epoch:  78 , val loss:  0.06347944736480712 , val accuracy:  97.71947113111905 %, lr:  2.6999999999999996e-05\n",
      "Epoch:  79 , val loss:  0.06195270419120789 , val accuracy:  97.73674373277285 %, lr:  2.6999999999999996e-05\n",
      "Epoch:  80 , val loss:  0.062453734874725345 , val accuracy:  97.73528919789675 %, lr:  2.6999999999999996e-05\n",
      "Epoch:  81 , val loss:  0.06234834790229797 , val accuracy:  97.75019818037687 %, lr:  2.6999999999999996e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  82 , val loss:  0.062348181009292604 , val accuracy:  97.73492556417771 %, lr:  2.6999999999999996e-05\n",
      "Epoch:  83 , val loss:  0.06194225549697876 , val accuracy:  97.74201642169875 %, lr:  2.6999999999999996e-05\n",
      "Epoch:  84 , val loss:  0.062429362535476686 , val accuracy:  97.73710736649188 %, lr:  2.6999999999999996e-05\n",
      "Epoch:  85 , val loss:  0.06345455050468445 , val accuracy:  97.74165278797973 %, lr:  2.6999999999999996e-05\n",
      "Epoch:  86 , val loss:  0.06195130944252014 , val accuracy:  97.74947091293882 %, lr:  2.6999999999999996e-05\n",
      "Epoch:  87 , val loss:  0.061946827173233035 , val accuracy:  97.74874364550075 %, lr:  2.6999999999999996e-05\n",
      "Epoch:  88 , val loss:  0.06194523572921753 , val accuracy:  97.74419822401292 %, lr:  2.6999999999999996e-05\n",
      "Epoch:  89 , val loss:  0.06319805979728699 , val accuracy:  97.75347088384811 %, lr:  8.099999999999999e-06\n",
      "Epoch:  90 , val loss:  0.062324315309524536 , val accuracy:  97.75419815128618 %, lr:  8.099999999999999e-06\n",
      "Epoch:  91 , val loss:  0.0622744619846344 , val accuracy:  97.76328899426186 %, lr:  8.099999999999999e-06\n",
      "Epoch:  92 , val loss:  0.06330409049987792 , val accuracy:  97.75747085475743 %, lr:  8.099999999999999e-06\n",
      "Epoch:  93 , val loss:  0.062441349029541016 , val accuracy:  97.75928902335255 %, lr:  8.099999999999999e-06\n",
      "Epoch:  94 , val loss:  0.062317436933517455 , val accuracy:  97.75747085475743 %, lr:  8.099999999999999e-06\n",
      "Epoch:  95 , val loss:  0.06243232488632202 , val accuracy:  97.7585617559145 %, lr:  8.099999999999999e-06\n",
      "Epoch:  96 , val loss:  0.06243441104888916 , val accuracy:  97.76292536054282 %, lr:  8.099999999999999e-06\n",
      "Epoch:  97 , val loss:  0.06226995587348938 , val accuracy:  97.76147082566672 %, lr:  8.099999999999999e-06\n",
      "Epoch:  98 , val loss:  0.06231712102890015 , val accuracy:  97.75347088384811 %, lr:  8.099999999999999e-06\n",
      "Epoch:  99 , val loss:  0.062268292903900145 , val accuracy:  97.76365262798089 %, lr:  8.099999999999999e-06\n",
      "Epoch:  100 , val loss:  0.06231798529624939 , val accuracy:  97.75492541872423 %, lr:  2.4299999999999996e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aab53c4d320>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train()\n",
    "# loss_v_node = []\n",
    "loss_v_edge = []\n",
    "# acc_v_node = []\n",
    "acc_v_edge = []\n",
    "ep, lr = 0, get_lr(optimizer)\n",
    "\n",
    "while (lr > 6e-6):\n",
    "    ep += 1\n",
    "#     node_correct = 0\n",
    "    edge_correct = 0\n",
    "#     node_total = 0\n",
    "    edge_total = 0 \n",
    "    for batch in train_loader:\n",
    "#         print(batch)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        edge_pred = model(data)\n",
    "#         print(edge_pred.shape, data.y_edges.shape, node_pred.shape, data.y_params.shape)\n",
    "#         print(edge_pred, data.y_edges, node_pred, data.y_params)\n",
    "#         losses = [F.binary_cross_entropy_with_logits(edge_pred.float(), data.y_edges.float()), F.mse_loss(node_pred.float(), data.y_params.float())]\n",
    "#         print(node_pred, data.y_nodes)\n",
    "#         print(\"Losses: \", losses[0].item(), losses[1].item())\n",
    "#         loss = F.mse_loss(node_pred, data.y_params)\n",
    "        loss = F.binary_cross_entropy_with_logits(edge_pred, data.y_edges)\n",
    "#         loss = sum(losses)\n",
    "#         loss_v_edge.append(loss)\n",
    "#         loss_v_node.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         edge_pred = torch.sigmoid(edge_pred)\n",
    "#         edge_correct += ((edge_pred > 0.5) == (data.y_edges > 0.5)).sum().item()\n",
    "        # A \"correct\" track parameter is one where the pred. is within 5% of the truth\n",
    "#         print(node_pred, data.y_nodes)\n",
    "#         print((((node_pred - data.y_nodes)/data.y_nodes)**2 < 0.05**2).sum().item())\n",
    "#         node_correct += (((node_pred - data.y_params)/data.y_params)**2 < 0.1**2).sum().item()\n",
    "#         node_total += len(node_pred)\n",
    "#         edge_total += len(edge_pred)\n",
    "#         print(out, data.y, )\n",
    "#     node_acc = node_correct/node_total\n",
    "#     edge_acc = edge_correct / edge_total\n",
    "    \n",
    "        \n",
    "    val_acc, val_loss = edge_validate(model, val_loader, 10)\n",
    "    scheduler.step(val_loss)\n",
    "    lr = get_lr(optimizer)\n",
    "#     print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", node accuracy: \", node_acc*100, \"%, edge accuracy: \", edge_acc*100, \"%, lr: \", scheduler.get_lr())\n",
    "    print(\"Epoch: \" , ep, \", val loss: \", val_loss, \", val accuracy: \", val_acc*100, \"%, lr: \", lr)\n",
    "#     acc_v_node.append(node_acc)\n",
    "#     wandb.log({\"Test Accuracy\": node_acc, \"Test Loss\": loss.item(), \"Learning Rate\": scheduler.get_lr()[0]})\n",
    "    acc_v_edge.append(val_acc)\n",
    "    loss_v_edge.append(val_loss)\n",
    "\n",
    "#     if node_acc > 0.5:\n",
    "#         break\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.set_size_inches(16,4)\n",
    "# axs[0].plot(np.arange(len(loss_v_node)-10), loss_v_node[10:])\n",
    "axs[0].plot(np.arange(len(loss_v_edge)-10), loss_v_edge[10:])\n",
    "# axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
    "axs[1].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.9318],\n",
      "        [11.8650],\n",
      "        [11.2290],\n",
      "        ...,\n",
      "        [ 0.7272],\n",
      "        [ 0.6703],\n",
      "        [ 0.7702]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[15.2125],\n",
      "        [15.2125],\n",
      "        [15.2125],\n",
      "        ...,\n",
      "        [ 0.5958],\n",
      "        [ 0.5958],\n",
      "        [ 0.5958]], device='cuda:0')\n",
      "Accuracy: 39.7417%\n",
      "tensor([[13.8930],\n",
      "        [14.0282],\n",
      "        [17.2821],\n",
      "        ...,\n",
      "        [ 1.9400],\n",
      "        [ 1.5565],\n",
      "        [ 1.8785]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[40.8148],\n",
      "        [40.8148],\n",
      "        [40.8148],\n",
      "        ...,\n",
      "        [ 1.7936],\n",
      "        [ 1.7936],\n",
      "        [ 1.7936]], device='cuda:0')\n",
      "Accuracy: 40.2185%\n",
      "tensor([[0.6895],\n",
      "        [0.6651],\n",
      "        [0.6577],\n",
      "        ...,\n",
      "        [1.0724],\n",
      "        [1.4556],\n",
      "        [1.4310]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.9864],\n",
      "        [18.9864],\n",
      "        [18.9864],\n",
      "        ...,\n",
      "        [ 0.6766],\n",
      "        [ 0.6766],\n",
      "        [ 0.6766]], device='cuda:0')\n",
      "Accuracy: 40.0350%\n",
      "tensor([[1.1658],\n",
      "        [1.1077],\n",
      "        [0.6554],\n",
      "        ...,\n",
      "        [0.8939],\n",
      "        [0.8615],\n",
      "        [0.7666]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.9864],\n",
      "        [18.9864],\n",
      "        [18.9864],\n",
      "        ...,\n",
      "        [ 0.6721],\n",
      "        [ 0.6721],\n",
      "        [ 0.6721]], device='cuda:0')\n",
      "Accuracy: 40.3253%\n",
      "tensor([[2.3222],\n",
      "        [2.5033],\n",
      "        [2.3553],\n",
      "        ...,\n",
      "        [0.9325],\n",
      "        [0.8848],\n",
      "        [0.8664]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[2.8667],\n",
      "        [2.8667],\n",
      "        [2.8667],\n",
      "        ...,\n",
      "        [0.8440],\n",
      "        [0.8440],\n",
      "        [0.8440]], device='cuda:0')\n",
      "Accuracy: 40.4110%\n",
      "tensor([[12.1352],\n",
      "        [14.0357],\n",
      "        [17.5757],\n",
      "        ...,\n",
      "        [ 0.7509],\n",
      "        [ 0.8472],\n",
      "        [ 0.9719]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[15.9097],\n",
      "        [15.9097],\n",
      "        [15.9097],\n",
      "        ...,\n",
      "        [ 0.8866],\n",
      "        [ 0.8866],\n",
      "        [ 0.8866]], device='cuda:0')\n",
      "Accuracy: 40.0428%\n",
      "tensor([[0.9942],\n",
      "        [1.1208],\n",
      "        [1.1194],\n",
      "        ...,\n",
      "        [0.9826],\n",
      "        [0.8489],\n",
      "        [0.9707]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.6542],\n",
      "        [1.6542],\n",
      "        [1.6542],\n",
      "        ...,\n",
      "        [1.2293],\n",
      "        [1.2293],\n",
      "        [1.2293]], device='cuda:0')\n",
      "Accuracy: 38.8717%\n",
      "tensor([[ 3.4424],\n",
      "        [ 5.2534],\n",
      "        [23.1656],\n",
      "        ...,\n",
      "        [ 0.8685],\n",
      "        [ 0.5717],\n",
      "        [ 0.5412]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[45.7979],\n",
      "        [45.7979],\n",
      "        [45.7979],\n",
      "        ...,\n",
      "        [ 0.5170],\n",
      "        [ 0.5170],\n",
      "        [ 0.5170]], device='cuda:0')\n",
      "Accuracy: 39.7613%\n",
      "tensor([[ 9.1288],\n",
      "        [11.8913],\n",
      "        [11.2297],\n",
      "        ...,\n",
      "        [ 0.7391],\n",
      "        [ 0.9998],\n",
      "        [ 0.6972]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[15.2125],\n",
      "        [15.2125],\n",
      "        [15.2125],\n",
      "        ...,\n",
      "        [ 1.6608],\n",
      "        [ 1.6608],\n",
      "        [ 1.6608]], device='cuda:0')\n",
      "Accuracy: 40.3495%\n",
      "tensor([[ 9.4903],\n",
      "        [ 8.7859],\n",
      "        [10.1595],\n",
      "        ...,\n",
      "        [ 1.2201],\n",
      "        [ 1.3347],\n",
      "        [ 1.2632]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[12.6091],\n",
      "        [12.6091],\n",
      "        [12.6091],\n",
      "        ...,\n",
      "        [ 1.7351],\n",
      "        [ 1.7351],\n",
      "        [ 1.7351]], device='cuda:0')\n",
      "Accuracy: 39.1402%\n",
      "tensor([[28.3547],\n",
      "        [63.4533],\n",
      "        [81.7252],\n",
      "        ...,\n",
      "        [ 0.7373],\n",
      "        [ 0.6272],\n",
      "        [ 0.6428]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[214.2887],\n",
      "        [214.2887],\n",
      "        [214.2887],\n",
      "        ...,\n",
      "        [  0.6889],\n",
      "        [  0.6889],\n",
      "        [  0.6889]], device='cuda:0')\n",
      "Accuracy: 38.7976%\n",
      "tensor([[1.1035],\n",
      "        [1.3030],\n",
      "        [2.1136],\n",
      "        ...,\n",
      "        [0.5246],\n",
      "        [0.5279],\n",
      "        [0.5917]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[77.3769],\n",
      "        [77.3769],\n",
      "        [77.3769],\n",
      "        ...,\n",
      "        [ 0.5297],\n",
      "        [ 0.5297],\n",
      "        [ 0.5297]], device='cuda:0')\n",
      "Accuracy: 39.7328%\n",
      "tensor([[0.9875],\n",
      "        [0.9888],\n",
      "        [0.9942],\n",
      "        ...,\n",
      "        [1.1358],\n",
      "        [0.9484],\n",
      "        [1.0132]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0031],\n",
      "        [1.0031],\n",
      "        [1.0031],\n",
      "        ...,\n",
      "        [1.0928],\n",
      "        [1.0928],\n",
      "        [1.0928]], device='cuda:0')\n",
      "Accuracy: 39.4175%\n",
      "tensor([[14.6370],\n",
      "        [19.4894],\n",
      "        [18.1789],\n",
      "        ...,\n",
      "        [ 0.9971],\n",
      "        [ 0.8656],\n",
      "        [ 0.9496]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[10.8352],\n",
      "        [10.8352],\n",
      "        [10.8352],\n",
      "        ...,\n",
      "        [ 0.6337],\n",
      "        [ 0.6337],\n",
      "        [ 0.6337]], device='cuda:0')\n",
      "Accuracy: 39.8321%\n",
      "tensor([[2.1587],\n",
      "        [2.2499],\n",
      "        [2.0766],\n",
      "        ...,\n",
      "        [0.8286],\n",
      "        [1.1595],\n",
      "        [1.3049]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.9701],\n",
      "        [1.9701],\n",
      "        [1.9701],\n",
      "        ...,\n",
      "        [0.6973],\n",
      "        [0.6973],\n",
      "        [0.6973]], device='cuda:0')\n",
      "Accuracy: 39.2101%\n",
      "tensor([[1.1895],\n",
      "        [1.2553],\n",
      "        [1.3382],\n",
      "        ...,\n",
      "        [0.6514],\n",
      "        [0.6962],\n",
      "        [0.6892]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.6419],\n",
      "        [1.6419],\n",
      "        [1.6419],\n",
      "        ...,\n",
      "        [0.7746],\n",
      "        [0.7746],\n",
      "        [0.7746]], device='cuda:0')\n",
      "Accuracy: 39.8810%\n",
      "tensor([[0.6917],\n",
      "        [0.6471],\n",
      "        [0.6083],\n",
      "        ...,\n",
      "        [0.9881],\n",
      "        [0.6713],\n",
      "        [0.7153]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[9.5957],\n",
      "        [9.5957],\n",
      "        [9.5957],\n",
      "        ...,\n",
      "        [0.5030],\n",
      "        [0.5053],\n",
      "        [0.5053]], device='cuda:0')\n",
      "Accuracy: 39.1109%\n",
      "tensor([[ 7.0304],\n",
      "        [20.3012],\n",
      "        [30.0342],\n",
      "        ...,\n",
      "        [ 0.7923],\n",
      "        [ 1.3118],\n",
      "        [ 1.0547]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[103.9713],\n",
      "        [103.9713],\n",
      "        [103.9713],\n",
      "        ...,\n",
      "        [  0.5964],\n",
      "        [  0.5964],\n",
      "        [  0.5964]], device='cuda:0')\n",
      "Accuracy: 39.0858%\n",
      "tensor([[ 9.0399],\n",
      "        [11.7952],\n",
      "        [11.1465],\n",
      "        ...,\n",
      "        [ 0.6030],\n",
      "        [ 0.7784],\n",
      "        [ 0.8715]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[15.2125],\n",
      "        [15.2125],\n",
      "        [15.2125],\n",
      "        ...,\n",
      "        [ 0.8757],\n",
      "        [ 0.8757],\n",
      "        [ 0.8757]], device='cuda:0')\n",
      "Accuracy: 39.4866%\n",
      "tensor([[0.9135],\n",
      "        [1.0143],\n",
      "        [1.2914],\n",
      "        ...,\n",
      "        [0.8385],\n",
      "        [0.8471],\n",
      "        [0.7578]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0432],\n",
      "        [1.0432],\n",
      "        [1.0432],\n",
      "        ...,\n",
      "        [0.5182],\n",
      "        [0.5182],\n",
      "        [0.5182]], device='cuda:0')\n",
      "Accuracy: 40.1606%\n",
      "tensor([[1.6345],\n",
      "        [1.6915],\n",
      "        [1.5431],\n",
      "        ...,\n",
      "        [0.6044],\n",
      "        [0.7311],\n",
      "        [0.9333]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.9438],\n",
      "        [1.9438],\n",
      "        [1.9438],\n",
      "        ...,\n",
      "        [0.5980],\n",
      "        [0.5980],\n",
      "        [0.5980]], device='cuda:0')\n",
      "Accuracy: 39.1989%\n",
      "tensor([[10.2383],\n",
      "        [ 8.0740],\n",
      "        [ 7.1587],\n",
      "        ...,\n",
      "        [ 1.0393],\n",
      "        [ 1.1273],\n",
      "        [ 1.0783]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[7.2037],\n",
      "        [7.2037],\n",
      "        [7.2037],\n",
      "        ...,\n",
      "        [1.1689],\n",
      "        [1.1689],\n",
      "        [1.1689]], device='cuda:0')\n",
      "Accuracy: 39.5244%\n",
      "tensor([[0.7564],\n",
      "        [0.7558],\n",
      "        [0.6647],\n",
      "        ...,\n",
      "        [0.6475],\n",
      "        [0.6273],\n",
      "        [0.6765]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.7752],\n",
      "        [0.7752],\n",
      "        [0.7752],\n",
      "        ...,\n",
      "        [0.5488],\n",
      "        [0.5488],\n",
      "        [0.5488]], device='cuda:0')\n",
      "Accuracy: 40.0390%\n",
      "tensor([[ 2.1219],\n",
      "        [ 4.1635],\n",
      "        [31.8953],\n",
      "        ...,\n",
      "        [ 0.7448],\n",
      "        [ 0.6810],\n",
      "        [ 0.6063]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[103.9713],\n",
      "        [103.9713],\n",
      "        [103.9713],\n",
      "        ...,\n",
      "        [  0.6936],\n",
      "        [  0.6936],\n",
      "        [  0.6936]], device='cuda:0')\n",
      "Accuracy: 40.3640%\n",
      "tensor([[5.5135],\n",
      "        [4.3961],\n",
      "        [4.6118],\n",
      "        ...,\n",
      "        [0.6515],\n",
      "        [0.7172],\n",
      "        [0.7335]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[4.7416],\n",
      "        [4.7416],\n",
      "        [4.7416],\n",
      "        ...,\n",
      "        [0.5174],\n",
      "        [0.5174],\n",
      "        [0.5174]], device='cuda:0')\n",
      "Accuracy: 41.8565%\n",
      "tensor([[0.7226],\n",
      "        [0.8478],\n",
      "        [0.6117],\n",
      "        ...,\n",
      "        [0.7012],\n",
      "        [0.7081],\n",
      "        [0.6395]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.2959],\n",
      "        [18.2959],\n",
      "        [18.2959],\n",
      "        ...,\n",
      "        [ 0.5716],\n",
      "        [ 0.5716],\n",
      "        [ 0.5716]], device='cuda:0')\n",
      "Accuracy: 39.6079%\n",
      "tensor([[0.7796],\n",
      "        [0.8318],\n",
      "        [0.7697],\n",
      "        ...,\n",
      "        [0.9296],\n",
      "        [0.9273],\n",
      "        [1.0580]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.8145],\n",
      "        [0.8145],\n",
      "        [0.5644],\n",
      "        ...,\n",
      "        [1.2768],\n",
      "        [1.2768],\n",
      "        [1.2768]], device='cuda:0')\n",
      "Accuracy: 39.3381%\n",
      "tensor([[10.2519],\n",
      "        [ 8.6586],\n",
      "        [ 7.7297],\n",
      "        ...,\n",
      "        [ 1.2707],\n",
      "        [ 1.0032],\n",
      "        [ 0.6826]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[12.3305],\n",
      "        [12.3305],\n",
      "        [12.3305],\n",
      "        ...,\n",
      "        [ 0.6648],\n",
      "        [ 0.6648],\n",
      "        [ 0.6648]], device='cuda:0')\n",
      "Accuracy: 38.8127%\n",
      "tensor([[0.9996],\n",
      "        [0.8601],\n",
      "        [0.9708],\n",
      "        ...,\n",
      "        [0.6847],\n",
      "        [0.6144],\n",
      "        [0.5791]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.2671],\n",
      "        [1.2671],\n",
      "        [1.2671],\n",
      "        ...,\n",
      "        [0.6528],\n",
      "        [0.6528],\n",
      "        [0.6528]], device='cuda:0')\n",
      "Accuracy: 40.3468%\n",
      "tensor([[19.1213],\n",
      "        [16.8965],\n",
      "        [17.0006],\n",
      "        ...,\n",
      "        [ 1.2032],\n",
      "        [ 1.2859],\n",
      "        [ 1.1205]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[11.3675],\n",
      "        [11.3675],\n",
      "        [11.3675],\n",
      "        ...,\n",
      "        [ 1.1216],\n",
      "        [ 1.1216],\n",
      "        [ 1.1216]], device='cuda:0')\n",
      "Accuracy: 40.6948%\n",
      "tensor([[3.6168],\n",
      "        [5.2099],\n",
      "        [5.1324],\n",
      "        ...,\n",
      "        [2.8753],\n",
      "        [3.4861],\n",
      "        [2.0596]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[5.4117],\n",
      "        [5.4117],\n",
      "        [5.4117],\n",
      "        ...,\n",
      "        [1.7091],\n",
      "        [1.7091],\n",
      "        [1.7091]], device='cuda:0')\n",
      "Accuracy: 40.0502%\n",
      "tensor([[10.3463],\n",
      "        [ 8.6515],\n",
      "        [ 7.7605],\n",
      "        ...,\n",
      "        [ 0.6446],\n",
      "        [ 0.6453],\n",
      "        [ 0.7479]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[12.3305],\n",
      "        [12.3305],\n",
      "        [12.3305],\n",
      "        ...,\n",
      "        [ 0.5811],\n",
      "        [ 0.5811],\n",
      "        [ 0.5811]], device='cuda:0')\n",
      "Accuracy: 39.0119%\n",
      "tensor([[0.9783],\n",
      "        [1.0397],\n",
      "        [1.0651],\n",
      "        ...,\n",
      "        [0.6647],\n",
      "        [0.7699],\n",
      "        [0.8835]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[41.3389],\n",
      "        [41.3389],\n",
      "        [41.3389],\n",
      "        ...,\n",
      "        [ 2.3012],\n",
      "        [ 2.3012],\n",
      "        [ 2.3012]], device='cuda:0')\n",
      "Accuracy: 40.6840%\n",
      "tensor([[0.6630],\n",
      "        [0.6878],\n",
      "        [0.6975],\n",
      "        ...,\n",
      "        [0.8447],\n",
      "        [0.8768],\n",
      "        [1.0330]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.7537],\n",
      "        [0.7537],\n",
      "        [0.7537],\n",
      "        ...,\n",
      "        [0.7055],\n",
      "        [0.7055],\n",
      "        [0.7055]], device='cuda:0')\n",
      "Accuracy: 39.3853%\n",
      "tensor([[3.9761],\n",
      "        [4.5978],\n",
      "        [6.2752],\n",
      "        ...,\n",
      "        [0.6555],\n",
      "        [0.9929],\n",
      "        [0.9387]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[114.3767],\n",
      "        [114.3767],\n",
      "        [114.3767],\n",
      "        ...,\n",
      "        [  0.5394],\n",
      "        [  0.5394],\n",
      "        [  0.5394]], device='cuda:0')\n",
      "Accuracy: 40.5195%\n",
      "tensor([[0.9683],\n",
      "        [1.0184],\n",
      "        [1.0687],\n",
      "        ...,\n",
      "        [2.1319],\n",
      "        [2.1325],\n",
      "        [2.3955]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[2.1535],\n",
      "        [2.1535],\n",
      "        [2.1535],\n",
      "        ...,\n",
      "        [2.0440],\n",
      "        [2.0440],\n",
      "        [2.0440]], device='cuda:0')\n",
      "Accuracy: 40.0183%\n",
      "tensor([[1.0741],\n",
      "        [1.1577],\n",
      "        [1.1884],\n",
      "        ...,\n",
      "        [0.7665],\n",
      "        [0.7874],\n",
      "        [0.8470]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0568],\n",
      "        [1.0568],\n",
      "        [1.0568],\n",
      "        ...,\n",
      "        [0.5111],\n",
      "        [0.5111],\n",
      "        [0.5111]], device='cuda:0')\n",
      "Accuracy: 38.4389%\n",
      "tensor([[1.6255],\n",
      "        [1.6056],\n",
      "        [1.8206],\n",
      "        ...,\n",
      "        [0.7076],\n",
      "        [0.8283],\n",
      "        [0.8569]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.5487],\n",
      "        [1.5487],\n",
      "        [1.5487],\n",
      "        ...,\n",
      "        [0.8363],\n",
      "        [0.8363],\n",
      "        [0.8363]], device='cuda:0')\n",
      "Accuracy: 39.5117%\n",
      "tensor([[0.6603],\n",
      "        [1.6645],\n",
      "        [4.5902],\n",
      "        ...,\n",
      "        [0.7540],\n",
      "        [0.7077],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [0.6972]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[34.2068],\n",
      "        [34.2068],\n",
      "        [34.2068],\n",
      "        ...,\n",
      "        [ 0.5591],\n",
      "        [ 0.5591],\n",
      "        [ 0.5591]], device='cuda:0')\n",
      "Accuracy: 40.2999%\n",
      "tensor([[10.2161],\n",
      "        [ 8.5189],\n",
      "        [ 7.6812],\n",
      "        ...,\n",
      "        [ 0.6470],\n",
      "        [ 0.6614],\n",
      "        [ 0.5862]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[12.3305],\n",
      "        [12.3305],\n",
      "        [12.3305],\n",
      "        ...,\n",
      "        [ 0.5768],\n",
      "        [ 0.5768],\n",
      "        [ 0.5768]], device='cuda:0')\n",
      "Accuracy: 40.0605%\n",
      "tensor([[0.9681],\n",
      "        [1.0175],\n",
      "        [1.0679],\n",
      "        ...,\n",
      "        [0.6423],\n",
      "        [0.6531],\n",
      "        [0.6582]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[2.1535],\n",
      "        [2.1535],\n",
      "        [2.1535],\n",
      "        ...,\n",
      "        [0.5419],\n",
      "        [0.5419],\n",
      "        [0.5419]], device='cuda:0')\n",
      "Accuracy: 39.3605%\n",
      "tensor([[0.9883],\n",
      "        [0.9892],\n",
      "        [0.9956],\n",
      "        ...,\n",
      "        [0.7058],\n",
      "        [0.7919],\n",
      "        [0.9199]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0031],\n",
      "        [1.0031],\n",
      "        [1.0031],\n",
      "        ...,\n",
      "        [0.7900],\n",
      "        [0.7900],\n",
      "        [0.7900]], device='cuda:0')\n",
      "Accuracy: 39.9850%\n",
      "tensor([[1.4345],\n",
      "        [1.4077],\n",
      "        [1.2925],\n",
      "        ...,\n",
      "        [1.1382],\n",
      "        [1.3562],\n",
      "        [1.0842]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.5719],\n",
      "        [1.5719],\n",
      "        [1.5719],\n",
      "        ...,\n",
      "        [1.4316],\n",
      "        [1.4316],\n",
      "        [1.4316]], device='cuda:0')\n",
      "Accuracy: 39.1546%\n",
      "tensor([[3.0630],\n",
      "        [2.7623],\n",
      "        [3.2913],\n",
      "        ...,\n",
      "        [0.6739],\n",
      "        [0.5828],\n",
      "        [0.6157]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[49.4070],\n",
      "        [49.4070],\n",
      "        [49.4070],\n",
      "        ...,\n",
      "        [ 0.5294],\n",
      "        [ 0.5294],\n",
      "        [ 0.5294]], device='cuda:0')\n",
      "Accuracy: 40.2626%\n",
      "tensor([[11.9847],\n",
      "        [13.2803],\n",
      "        [10.4962],\n",
      "        ...,\n",
      "        [ 0.7002],\n",
      "        [ 0.5775],\n",
      "        [ 0.5533]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[103.9713],\n",
      "        [103.9713],\n",
      "        [103.9713],\n",
      "        ...,\n",
      "        [  0.5163],\n",
      "        [  0.5163],\n",
      "        [  0.5163]], device='cuda:0')\n",
      "Accuracy: 40.2963%\n",
      "tensor([[1.0355],\n",
      "        [0.8637],\n",
      "        [0.8407],\n",
      "        ...,\n",
      "        [1.0183],\n",
      "        [0.8709],\n",
      "        [0.9781]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[7.4545],\n",
      "        [7.4545],\n",
      "        [7.4545],\n",
      "        ...,\n",
      "        [0.5515],\n",
      "        [0.5515],\n",
      "        [0.5515]], device='cuda:0')\n",
      "Accuracy: 39.2724%\n",
      "tensor([[1.6573],\n",
      "        [1.7834],\n",
      "        [1.5776],\n",
      "        ...,\n",
      "        [0.7427],\n",
      "        [0.7284],\n",
      "        [0.8567]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.6736],\n",
      "        [1.6736],\n",
      "        [1.6736],\n",
      "        ...,\n",
      "        [0.5688],\n",
      "        [0.5688],\n",
      "        [0.5688]], device='cuda:0')\n",
      "Accuracy: 40.3407%\n",
      "tensor([[11.2320],\n",
      "        [13.0427],\n",
      "        [16.5677],\n",
      "        ...,\n",
      "        [ 0.6959],\n",
      "        [ 0.6481],\n",
      "        [ 0.7528]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[15.9097],\n",
      "        [15.9097],\n",
      "        [15.9097],\n",
      "        ...,\n",
      "        [ 0.5118],\n",
      "        [ 0.5118],\n",
      "        [ 0.5118]], device='cuda:0')\n",
      "Accuracy: 39.8308%\n",
      "tensor([[3.6314],\n",
      "        [5.2184],\n",
      "        [5.1166],\n",
      "        ...,\n",
      "        [0.6317],\n",
      "        [0.6797],\n",
      "        [0.5500]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[5.4117],\n",
      "        [5.4117],\n",
      "        [5.4117],\n",
      "        ...,\n",
      "        [0.5336],\n",
      "        [0.5336],\n",
      "        [0.5336]], device='cuda:0')\n",
      "Accuracy: 39.5466%\n",
      "tensor([[ 0.6881],\n",
      "        [11.6658],\n",
      "        [ 6.5289],\n",
      "        ...,\n",
      "        [ 0.6949],\n",
      "        [ 0.7447],\n",
      "        [ 0.8752]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.9864],\n",
      "        [18.9864],\n",
      "        [18.9864],\n",
      "        ...,\n",
      "        [ 0.5053],\n",
      "        [ 0.5053],\n",
      "        [ 0.5053]], device='cuda:0')\n",
      "Accuracy: 39.3142%\n",
      "tensor([[8.2489],\n",
      "        [7.2578],\n",
      "        [7.3865],\n",
      "        ...,\n",
      "        [0.6723],\n",
      "        [0.6653],\n",
      "        [0.6261]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[7.0816],\n",
      "        [7.0816],\n",
      "        [7.0816],\n",
      "        ...,\n",
      "        [0.6795],\n",
      "        [0.6795],\n",
      "        [0.6795]], device='cuda:0')\n",
      "Accuracy: 39.4279%\n",
      "tensor([[42.7952],\n",
      "        [48.9230],\n",
      "        [46.6251],\n",
      "        ...,\n",
      "        [ 0.6276],\n",
      "        [ 0.6505],\n",
      "        [ 0.5349]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[214.2887],\n",
      "        [214.2887],\n",
      "        [214.2887],\n",
      "        ...,\n",
      "        [  0.5513],\n",
      "        [  0.5513],\n",
      "        [  0.5513]], device='cuda:0')\n",
      "Accuracy: 40.1457%\n",
      "tensor([[1.6206],\n",
      "        [1.4773],\n",
      "        [2.0015],\n",
      "        ...,\n",
      "        [0.8882],\n",
      "        [0.9505],\n",
      "        [0.8475]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[2.0819],\n",
      "        [2.0819],\n",
      "        [2.0819],\n",
      "        ...,\n",
      "        [0.9285],\n",
      "        [0.9285],\n",
      "        [0.9285]], device='cuda:0')\n",
      "Accuracy: 40.2122%\n",
      "tensor([[1.3236],\n",
      "        [1.3064],\n",
      "        [1.1554],\n",
      "        ...,\n",
      "        [0.6435],\n",
      "        [0.6298],\n",
      "        [0.6163]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.2227],\n",
      "        [1.2227],\n",
      "        [1.2227],\n",
      "        ...,\n",
      "        [0.5580],\n",
      "        [0.5580],\n",
      "        [0.5580]], device='cuda:0')\n",
      "Accuracy: 39.8365%\n",
      "tensor([[0.6796],\n",
      "        [0.7947],\n",
      "        [0.8771],\n",
      "        ...,\n",
      "        [0.7633],\n",
      "        [0.9490],\n",
      "        [1.0927]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.4249],\n",
      "        [18.4249],\n",
      "        [18.4249],\n",
      "        ...,\n",
      "        [ 0.8176],\n",
      "        [ 0.8176],\n",
      "        [ 0.8176]], device='cuda:0')\n",
      "Accuracy: 37.5792%\n",
      "tensor([[1.0066],\n",
      "        [0.8420],\n",
      "        [0.9938],\n",
      "        ...,\n",
      "        [0.7329],\n",
      "        [0.8331],\n",
      "        [0.7742]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.7756],\n",
      "        [1.7756],\n",
      "        [1.7756],\n",
      "        ...,\n",
      "        [0.8164],\n",
      "        [0.8164],\n",
      "        [0.8164]], device='cuda:0')\n",
      "Accuracy: 40.5097%\n",
      "tensor([[0.7226],\n",
      "        [0.8432],\n",
      "        [0.6172],\n",
      "        ...,\n",
      "        [1.5072],\n",
      "        [1.1013],\n",
      "        [1.3276]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[9.5957],\n",
      "        [9.5957],\n",
      "        [9.5957],\n",
      "        ...,\n",
      "        [1.1248],\n",
      "        [1.1248],\n",
      "        [1.1248]], device='cuda:0')\n",
      "Accuracy: 39.2459%\n",
      "tensor([[1.1484],\n",
      "        [1.2153],\n",
      "        [1.1721],\n",
      "        ...,\n",
      "        [0.6316],\n",
      "        [0.6301],\n",
      "        [0.6537]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.7752],\n",
      "        [0.7752],\n",
      "        [0.7752],\n",
      "        ...,\n",
      "        [0.5931],\n",
      "        [0.5931],\n",
      "        [0.5931]], device='cuda:0')\n",
      "Accuracy: 40.2219%\n",
      "tensor([[2.6271],\n",
      "        [2.6988],\n",
      "        [3.3629],\n",
      "        ...,\n",
      "        [0.6870],\n",
      "        [0.6212],\n",
      "        [0.6703]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[3.5017],\n",
      "        [3.5017],\n",
      "        [3.5017],\n",
      "        ...,\n",
      "        [0.6006],\n",
      "        [0.6006],\n",
      "        [0.6006]], device='cuda:0')\n",
      "Accuracy: 39.0849%\n",
      "tensor([[0.6733],\n",
      "        [0.6504],\n",
      "        [0.6597],\n",
      "        ...,\n",
      "        [1.0149],\n",
      "        [1.2987],\n",
      "        [0.9066]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6718],\n",
      "        [0.6718],\n",
      "        [0.6718],\n",
      "        ...,\n",
      "        [0.6416],\n",
      "        [0.6416],\n",
      "        [0.6416]], device='cuda:0')\n",
      "Accuracy: 40.3180%\n",
      "tensor([[0.9803],\n",
      "        [0.9679],\n",
      "        [0.9910],\n",
      "        ...,\n",
      "        [0.6828],\n",
      "        [0.6682],\n",
      "        [0.6200]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[5.4676],\n",
      "        [5.4676],\n",
      "        [5.4676],\n",
      "        ...,\n",
      "        [0.7276],\n",
      "        [0.7276],\n",
      "        [0.7276]], device='cuda:0')\n",
      "Accuracy: 40.6631%\n",
      "tensor([[14.7487],\n",
      "        [19.8781],\n",
      "        [18.3167],\n",
      "        ...,\n",
      "        [ 0.6486],\n",
      "        [ 0.6342],\n",
      "        [ 0.6402]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[10.8352],\n",
      "        [10.8352],\n",
      "        [10.8352],\n",
      "        ...,\n",
      "        [ 0.6237],\n",
      "        [ 0.6237],\n",
      "        [ 0.6237]], device='cuda:0')\n",
      "Accuracy: 39.3348%\n",
      "tensor([[1.0005],\n",
      "        [1.1341],\n",
      "        [1.1276],\n",
      "        ...,\n",
      "        [0.6037],\n",
      "        [0.6033],\n",
      "        [0.5284]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6658],\n",
      "        [0.6658],\n",
      "        [0.6658],\n",
      "        ...,\n",
      "        [0.5664],\n",
      "        [0.5664],\n",
      "        [0.5664]], device='cuda:0')\n",
      "Accuracy: 40.1885%\n",
      "tensor([[16.8904],\n",
      "        [20.8417],\n",
      "        [20.3371],\n",
      "        ...,\n",
      "        [ 0.7235],\n",
      "        [ 0.6742],\n",
      "        [ 0.7453]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[62.8775],\n",
      "        [62.8775],\n",
      "        [62.8775],\n",
      "        ...,\n",
      "        [ 0.7276],\n",
      "        [ 0.7276],\n",
      "        [ 0.7276]], device='cuda:0')\n",
      "Accuracy: 39.7209%\n",
      "tensor([[0.8520],\n",
      "        [0.8058],\n",
      "        [1.3407],\n",
      "        ...,\n",
      "        [0.8619],\n",
      "        [0.9751],\n",
      "        [0.8014]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.1269],\n",
      "        [1.1269],\n",
      "        [1.1269],\n",
      "        ...,\n",
      "        [0.7729],\n",
      "        [0.7729],\n",
      "        [0.7729]], device='cuda:0')\n",
      "Accuracy: 40.4717%\n",
      "tensor([[0.6712],\n",
      "        [0.6263],\n",
      "        [0.5953],\n",
      "        ...,\n",
      "        [0.5279],\n",
      "        [0.5198],\n",
      "        [0.5139]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[9.9181],\n",
      "        [9.9181],\n",
      "        [9.9181],\n",
      "        ...,\n",
      "        [0.5163],\n",
      "        [0.5163],\n",
      "        [0.5163]], device='cuda:0')\n",
      "Accuracy: 39.5578%\n",
      "tensor([[0.8464],\n",
      "        [0.8655],\n",
      "        [0.9052],\n",
      "        ...,\n",
      "        [0.8541],\n",
      "        [0.9607],\n",
      "        [0.9901]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[28.2485],\n",
      "        [28.2485],\n",
      "        [28.2485],\n",
      "        ...,\n",
      "        [ 0.5693],\n",
      "        [ 0.5693],\n",
      "        [ 0.5693]], device='cuda:0')\n",
      "Accuracy: 38.7823%\n",
      "tensor([[0.9980],\n",
      "        [0.8870],\n",
      "        [0.9275],\n",
      "        ...,\n",
      "        [1.7981],\n",
      "        [1.4017],\n",
      "        [1.2597]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.8174],\n",
      "        [1.8174],\n",
      "        [1.8174],\n",
      "        ...,\n",
      "        [1.5891],\n",
      "        [1.5891],\n",
      "        [1.5891]], device='cuda:0')\n",
      "Accuracy: 39.9508%\n",
      "tensor([[0.9969],\n",
      "        [0.9015],\n",
      "        [0.9987],\n",
      "        ...,\n",
      "        [0.6854],\n",
      "        [0.7988],\n",
      "        [0.6971]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6272],\n",
      "        [0.6272],\n",
      "        [0.6272],\n",
      "        ...,\n",
      "        [0.5574],\n",
      "        [0.5574],\n",
      "        [0.5574]], device='cuda:0')\n",
      "Accuracy: 39.1757%\n",
      "tensor([[5.6407],\n",
      "        [5.8813],\n",
      "        [5.0981],\n",
      "        ...,\n",
      "        [0.6493],\n",
      "        [0.5865],\n",
      "        [0.6767]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[4.2333],\n",
      "        [4.2333],\n",
      "        [4.2333],\n",
      "        ...,\n",
      "        [0.6468],\n",
      "        [0.6468],\n",
      "        [0.6468]], device='cuda:0')\n",
      "Accuracy: 39.7403%\n",
      "tensor([[2.6274],\n",
      "        [2.7943],\n",
      "        [3.6031],\n",
      "        ...,\n",
      "        [1.1684],\n",
      "        [1.0011],\n",
      "        [1.0178]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[3.5017],\n",
      "        [3.5017],\n",
      "        [3.5017],\n",
      "        ...,\n",
      "        [1.0661],\n",
      "        [1.0661],\n",
      "        [1.0661]], device='cuda:0')\n",
      "Accuracy: 38.7006%\n",
      "tensor([[3.1372],\n",
      "        [4.5701],\n",
      "        [7.6276],\n",
      "        ...,\n",
      "        [0.5648],\n",
      "        [0.6136],\n",
      "        [0.7399]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.9803],\n",
      "        [18.9803],\n",
      "        [18.9803],\n",
      "        ...,\n",
      "        [ 0.7229],\n",
      "        [ 0.7229],\n",
      "        [ 0.7229]], device='cuda:0')\n",
      "Accuracy: 39.4491%\n",
      "tensor([[12.9539],\n",
      "        [12.2334],\n",
      "        [11.3214],\n",
      "        ...,\n",
      "        [ 0.6566],\n",
      "        [ 0.5275],\n",
      "        [ 0.5185]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[10.0892],\n",
      "        [10.0892],\n",
      "        [10.0892],\n",
      "        ...,\n",
      "        [ 0.5517],\n",
      "        [ 0.5517],\n",
      "        [ 0.5517]], device='cuda:0')\n",
      "Accuracy: 40.2761%\n",
      "tensor([[3.6755],\n",
      "        [3.6912],\n",
      "        [4.2473],\n",
      "        ...,\n",
      "        [0.8420],\n",
      "        [0.9263],\n",
      "        [0.8659]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[4.1409],\n",
      "        [4.1409],\n",
      "        [4.1409],\n",
      "        ...,\n",
      "        [0.6053],\n",
      "        [0.6053],\n",
      "        [0.6053]], device='cuda:0')\n",
      "Accuracy: 39.6207%\n",
      "tensor([[0.9930],\n",
      "        [1.1189],\n",
      "        [1.1182],\n",
      "        ...,\n",
      "        [1.0980],\n",
      "        [0.9079],\n",
      "        [0.9797]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.6542],\n",
      "        [1.6542],\n",
      "        [1.6542],\n",
      "        ...,\n",
      "        [1.0477],\n",
      "        [1.0477],\n",
      "        [1.0477]], device='cuda:0')\n",
      "Accuracy: 40.8742%\n",
      "tensor([[2.3119],\n",
      "        [3.0012],\n",
      "        [3.4853],\n",
      "        ...,\n",
      "        [0.7756],\n",
      "        [0.8348],\n",
      "        [0.7605]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[4.2260],\n",
      "        [4.2260],\n",
      "        [4.2260],\n",
      "        ...,\n",
      "        [0.8264],\n",
      "        [0.8264],\n",
      "        [0.8264]], device='cuda:0')\n",
      "Accuracy: 39.4977%\n",
      "tensor([[0.9552],\n",
      "        [0.9512],\n",
      "        [1.1259],\n",
      "        ...,\n",
      "        [0.7132],\n",
      "        [0.8764],\n",
      "        [0.7109]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.9803],\n",
      "        [18.9803],\n",
      "        [18.9803],\n",
      "        ...,\n",
      "        [ 0.5077],\n",
      "        [ 0.5077],\n",
      "        [ 0.5077]], device='cuda:0')\n",
      "Accuracy: 40.1390%\n",
      "tensor([[1.0961],\n",
      "        [1.0131],\n",
      "        [0.9886],\n",
      "        ...,\n",
      "        [0.9215],\n",
      "        [0.8816],\n",
      "        [1.0348]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6300],\n",
      "        [0.6300],\n",
      "        [0.6300],\n",
      "        ...,\n",
      "        [0.6538],\n",
      "        [0.6538],\n",
      "        [0.6538]], device='cuda:0')\n",
      "Accuracy: 39.7940%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9016],\n",
      "        [1.0014],\n",
      "        [1.2399],\n",
      "        ...,\n",
      "        [0.6275],\n",
      "        [0.6268],\n",
      "        [0.6755]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0432],\n",
      "        [1.0432],\n",
      "        [1.0432],\n",
      "        ...,\n",
      "        [0.6954],\n",
      "        [0.6954],\n",
      "        [0.6954]], device='cuda:0')\n",
      "Accuracy: 39.1318%\n",
      "tensor([[0.9803],\n",
      "        [0.9692],\n",
      "        [0.9925],\n",
      "        ...,\n",
      "        [0.5200],\n",
      "        [0.5255],\n",
      "        [0.5377]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[5.4676],\n",
      "        [5.4676],\n",
      "        [5.4676],\n",
      "        ...,\n",
      "        [0.5036],\n",
      "        [0.5036],\n",
      "        [0.5036]], device='cuda:0')\n",
      "Accuracy: 39.6506%\n",
      "tensor([[19.0480],\n",
      "        [23.0835],\n",
      "        [21.6653],\n",
      "        ...,\n",
      "        [ 1.5495],\n",
      "        [ 1.5566],\n",
      "        [ 1.3213]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[66.0761],\n",
      "        [66.0761],\n",
      "        [66.0761],\n",
      "        ...,\n",
      "        [ 1.1489],\n",
      "        [ 1.1489],\n",
      "        [ 1.1489]], device='cuda:0')\n",
      "Accuracy: 39.7656%\n",
      "tensor([[10.7145],\n",
      "        [ 6.7402],\n",
      "        [ 8.7517],\n",
      "        ...,\n",
      "        [ 0.8141],\n",
      "        [ 0.7114],\n",
      "        [ 0.8462]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[9.6110],\n",
      "        [9.6110],\n",
      "        [9.6110],\n",
      "        ...,\n",
      "        [0.7663],\n",
      "        [0.7663],\n",
      "        [0.7663]], device='cuda:0')\n",
      "Accuracy: 38.7527%\n",
      "tensor([[10.4775],\n",
      "        [ 8.1635],\n",
      "        [ 6.9152],\n",
      "        ...,\n",
      "        [ 0.8971],\n",
      "        [ 1.0843],\n",
      "        [ 0.8726]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[7.2037],\n",
      "        [7.2037],\n",
      "        [7.2037],\n",
      "        ...,\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917]], device='cuda:0')\n",
      "Accuracy: 38.9668%\n",
      "tensor([[32.4640],\n",
      "        [32.3690],\n",
      "        [43.8462],\n",
      "        ...,\n",
      "        [ 1.8761],\n",
      "        [ 1.6347],\n",
      "        [ 1.5169]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[77.1132],\n",
      "        [77.1132],\n",
      "        [77.1132],\n",
      "        ...,\n",
      "        [ 1.6917],\n",
      "        [ 1.6917],\n",
      "        [ 1.6917]], device='cuda:0')\n",
      "Accuracy: 39.9223%\n",
      "tensor([[0.9733],\n",
      "        [0.9466],\n",
      "        [0.9591],\n",
      "        ...,\n",
      "        [0.5838],\n",
      "        [0.5999],\n",
      "        [0.7291]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.9247],\n",
      "        [0.9247],\n",
      "        [0.9247],\n",
      "        ...,\n",
      "        [0.5667],\n",
      "        [0.5667],\n",
      "        [0.5667]], device='cuda:0')\n",
      "Accuracy: 39.6083%\n",
      "tensor([[1.0348],\n",
      "        [0.8618],\n",
      "        [0.8457],\n",
      "        ...,\n",
      "        [0.8780],\n",
      "        [0.9837],\n",
      "        [0.5215]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[7.4545],\n",
      "        [7.4545],\n",
      "        [7.4545],\n",
      "        ...,\n",
      "        [1.2338],\n",
      "        [1.2338],\n",
      "        [1.2338]], device='cuda:0')\n",
      "Accuracy: 39.0186%\n",
      "tensor([[1.0539],\n",
      "        [1.0836],\n",
      "        [1.0144],\n",
      "        ...,\n",
      "        [0.9879],\n",
      "        [0.8594],\n",
      "        [0.7651]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6624],\n",
      "        [0.6624],\n",
      "        [0.6624],\n",
      "        ...,\n",
      "        [1.0003],\n",
      "        [1.0003],\n",
      "        [1.0003]], device='cuda:0')\n",
      "Accuracy: 40.4452%\n",
      "tensor([[0.6560],\n",
      "        [0.7484],\n",
      "        [0.8034],\n",
      "        ...,\n",
      "        [0.8664],\n",
      "        [0.8966],\n",
      "        [0.7544]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.5559],\n",
      "        [0.5559],\n",
      "        [0.5559],\n",
      "        ...,\n",
      "        [1.0908],\n",
      "        [1.0908],\n",
      "        [1.1814]], device='cuda:0')\n",
      "Accuracy: 39.5069%\n",
      "tensor([[0.6713],\n",
      "        [0.6502],\n",
      "        [0.6608],\n",
      "        ...,\n",
      "        [1.1412],\n",
      "        [1.2072],\n",
      "        [0.9134]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6718],\n",
      "        [0.6718],\n",
      "        [0.6718],\n",
      "        ...,\n",
      "        [1.1390],\n",
      "        [1.1390],\n",
      "        [1.1390]], device='cuda:0')\n",
      "Accuracy: 39.1823%\n",
      "tensor([[1.6302],\n",
      "        [1.2663],\n",
      "        [1.7483],\n",
      "        ...,\n",
      "        [0.7675],\n",
      "        [0.7321],\n",
      "        [0.6926]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.7191],\n",
      "        [1.7191],\n",
      "        [1.7191],\n",
      "        ...,\n",
      "        [0.7097],\n",
      "        [0.7097],\n",
      "        [0.7097]], device='cuda:0')\n",
      "Accuracy: 40.5287%\n",
      "tensor([[0.9975],\n",
      "        [0.9531],\n",
      "        [0.9131],\n",
      "        ...,\n",
      "        [1.1248],\n",
      "        [0.7863],\n",
      "        [1.0304]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[3.8672],\n",
      "        [3.8672],\n",
      "        [3.8672],\n",
      "        ...,\n",
      "        [0.5144],\n",
      "        [0.5074],\n",
      "        [0.5074]], device='cuda:0')\n",
      "Accuracy: 40.6298%\n",
      "tensor([[0.8473],\n",
      "        [0.8746],\n",
      "        [0.7258],\n",
      "        ...,\n",
      "        [0.6936],\n",
      "        [0.7743],\n",
      "        [0.7342]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0484],\n",
      "        [1.0484],\n",
      "        [1.0484],\n",
      "        ...,\n",
      "        [0.7965],\n",
      "        [0.7965],\n",
      "        [0.7965]], device='cuda:0')\n",
      "Accuracy: 39.0264%\n",
      "tensor([[8.5380],\n",
      "        [7.4409],\n",
      "        [8.9080],\n",
      "        ...,\n",
      "        [0.9483],\n",
      "        [0.8375],\n",
      "        [0.7380]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[6.1454],\n",
      "        [6.1454],\n",
      "        [6.1454],\n",
      "        ...,\n",
      "        [0.8144],\n",
      "        [0.8144],\n",
      "        [0.8144]], device='cuda:0')\n",
      "Accuracy: 39.3465%\n",
      "tensor([[0.9399],\n",
      "        [0.9246],\n",
      "        [0.9130],\n",
      "        ...,\n",
      "        [0.6532],\n",
      "        [0.6188],\n",
      "        [0.6643]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.7312],\n",
      "        [0.7312],\n",
      "        [0.7312],\n",
      "        ...,\n",
      "        [0.6452],\n",
      "        [0.6452],\n",
      "        [0.6452]], device='cuda:0')\n",
      "Accuracy: 38.6133%\n",
      "tensor([[17.3492],\n",
      "        [21.3735],\n",
      "        [20.9378],\n",
      "        ...,\n",
      "        [ 0.7750],\n",
      "        [ 0.7245],\n",
      "        [ 0.8494]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[62.8775],\n",
      "        [62.8775],\n",
      "        [62.8775],\n",
      "        ...,\n",
      "        [ 1.1988],\n",
      "        [ 0.5820],\n",
      "        [ 0.5820]], device='cuda:0')\n",
      "Accuracy: 40.3640%\n",
      "tensor([[0.7486],\n",
      "        [0.7896],\n",
      "        [0.9446],\n",
      "        ...,\n",
      "        [0.9740],\n",
      "        [0.8918],\n",
      "        [0.8121]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.9247],\n",
      "        [0.9247],\n",
      "        [0.9247],\n",
      "        ...,\n",
      "        [0.6448],\n",
      "        [0.6448],\n",
      "        [0.6448]], device='cuda:0')\n",
      "Accuracy: 38.9745%\n",
      "tensor([[0.7439],\n",
      "        [0.7359],\n",
      "        [0.6380],\n",
      "        ...,\n",
      "        [0.5949],\n",
      "        [0.8614],\n",
      "        [0.9297]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.7752],\n",
      "        [0.7752],\n",
      "        [0.7752],\n",
      "        ...,\n",
      "        [0.6405],\n",
      "        [0.6405],\n",
      "        [0.6405]], device='cuda:0')\n",
      "Accuracy: 40.1297%\n",
      "tensor([[1.0853],\n",
      "        [1.0139],\n",
      "        [1.0190],\n",
      "        ...,\n",
      "        [1.0269],\n",
      "        [1.0126],\n",
      "        [0.8494]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0948],\n",
      "        [1.0948],\n",
      "        [1.0948],\n",
      "        ...,\n",
      "        [0.8433],\n",
      "        [0.8433],\n",
      "        [0.8433]], device='cuda:0')\n",
      "Accuracy: 39.8106%\n",
      "tensor([[0.7379],\n",
      "        [0.7385],\n",
      "        [0.6666],\n",
      "        ...,\n",
      "        [0.7068],\n",
      "        [0.8132],\n",
      "        [0.8594]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.9289],\n",
      "        [0.9289],\n",
      "        [0.9289],\n",
      "        ...,\n",
      "        [0.5385],\n",
      "        [0.5385],\n",
      "        [0.5385]], device='cuda:0')\n",
      "Accuracy: 40.2084%\n",
      "tensor([[35.6363],\n",
      "        [40.4104],\n",
      "        [31.6950],\n",
      "        ...,\n",
      "        [ 0.9692],\n",
      "        [ 1.0891],\n",
      "        [ 1.0799]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[81.0337],\n",
      "        [81.0337],\n",
      "        [81.0337],\n",
      "        ...,\n",
      "        [ 0.7141],\n",
      "        [ 0.7141],\n",
      "        [ 0.7141]], device='cuda:0')\n",
      "Accuracy: 39.1416%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "#     print(batch)\n",
    "    data = batch.to(device)\n",
    "    node_pred = model(data)\n",
    "#     edge_pred = torch.sigmoid(edge_pred)\n",
    "#     print(edge_pred, data.y_edges, node_pred, data.y_params)\n",
    "    print(node_pred, data.y_params)\n",
    "#     edge_correct = ((edge_pred > 0.5) == (data.y_edges > 0.5)).sum().item()\n",
    "    correct = (((node_pred - data.y_params)/data.y_params)**2 < 0.1**2).sum().item()\n",
    "    acc = correct / (len(node_pred))*100\n",
    "#     edge_acc = edge_correct / len(edge_pred)*100\n",
    "#     print('Accuracy: {:.4f}%'.format(acc), ', edge accuracy: {:.4f}%'.format(edge_acc))\n",
    "    print('Accuracy: {:.4f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()\n",
    "print(torch.cuda.memory_allocated(0)/1024**3, torch.cuda.max_memory_allocated(0)/1024**3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Getting Weights & Bias to Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=19, out_features=16, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retry attempt failed:\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 169, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576271582&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=MmIGu%2F4ONY2zZtXV60r4n2VtQ%2F7%2BfOmVBHMam3wT3aKVoHGK84OediGBAASfRnCU%2ByxJnJoe6wgqBm8OA4RFnwbWS%2BT1gP1VBHVekU3e0%2FBjKnK8lLsunIwyrwC9DhNkHSaiPTduRingNiJZ1K096%2BHtW8DSs%2BVkivZt%2FHH4Sh24d1JcpFjjkb8GUWGOc2XuFhCKq%2FQ6v7cIiQPmaCfZ7tIsPYZNaEJ5WnLcgsMIcUFlMpayxtmovih59VHK9%2Bu7pLnnEIleq%2FVVwSp1Nxn3Cuvyf%2FefL9nIOD9RrfbYHqTIWZB2cEMVI4XuNkEPrYUuV5aNadYZ%2BXP1VYzyt%2BGgVQ%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
      "    url, data=progress, headers=extra_headers)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
      "    return request('put', url, data=data, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576271582&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=MmIGu%2F4ONY2zZtXV60r4n2VtQ%2F7%2BfOmVBHMam3wT3aKVoHGK84OediGBAASfRnCU%2ByxJnJoe6wgqBm8OA4RFnwbWS%2BT1gP1VBHVekU3e0%2FBjKnK8lLsunIwyrwC9DhNkHSaiPTduRingNiJZ1K096%2BHtW8DSs%2BVkivZt%2FHH4Sh24d1JcpFjjkb8GUWGOc2XuFhCKq%2FQ6v7cIiQPmaCfZ7tIsPYZNaEJ5WnLcgsMIcUFlMpayxtmovih59VHK9%2Bu7pLnnEIleq%2FVVwSp1Nxn3Cuvyf%2FefL9nIOD9RrfbYHqTIWZB2cEMVI4XuNkEPrYUuV5aNadYZ%2BXP1VYzyt%2BGgVQ%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 980, in upload_file\n",
      "    util.sentry_reraise(retry.TransientException(exc=e))\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/util.py\", line 92, in sentry_reraise\n",
      "    six.reraise(type(exc), exc, sys.exc_info()[2])\n",
      "  File \"/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/six.py\", line 692, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
      "    url, data=progress, headers=extra_headers)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
      "    return request('put', url, data=data, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "wandb.retry.TransientException: None\n",
      "wandb: Network error (TransientException), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n",
      "wandb: ERROR Error uploading \"wandb-metadata.json\": CommError, None\n"
     ]
    }
   ],
   "source": [
    "model.output_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint as pp\n",
    "from time import time as tt\n",
    "sys.path.append('..')\n",
    "sys.path.append('/global/common/cori_cle7/software/jupyter/19-11/lib/python3.7/site-packages')\n",
    "sys.path.append('/global/homes/d/danieltm/.local/lib/python3.7/site-packages')\n",
    "import wandb\n",
    "# External imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'bayes',\n",
       " 'metric': {'goal': 'maximize', 'name': 'Best Accuracy'},\n",
       " 'name': 'Track Param Sweep',\n",
       " 'parameters': {'epochs': {'distribution': 'q_normal',\n",
       "   'max': 250,\n",
       "   'min': 50,\n",
       "   'mu': 150,\n",
       "   'sigma': 50},\n",
       "  'hidden_dim': {'distribution': 'q_log_normal',\n",
       "   'max': 4.159,\n",
       "   'min': 1.386,\n",
       "   'mu': 2.8,\n",
       "   'sigma': 0.8},\n",
       "  'lr': {'distribution': 'log_normal',\n",
       "   'max': -2.3,\n",
       "   'min': -11.5,\n",
       "   'mu': -6.9,\n",
       "   'sigma': 1.5},\n",
       "  'n_graph_iters': {'max': 8, 'min': 1},\n",
       "  'network': {'values': ['Edge_Track_Truth_Net']},\n",
       "  'optimizer': {'values': ['AdamW']},\n",
       "  'train_size': {'max': 800, 'min': 100},\n",
       "  'weight_decay': {'distribution': 'log_uniform', 'max': -4.6, 'min': -11.5}}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'config.yaml') as file:\n",
    "    sweep_config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "sweep_id = wandb.sweep(sweep_config, entity= \"murnanedaniel\", project= \"node_regression_sweep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     12,
     38,
     64,
     109
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: txex35gz with config:\n",
      "\tepochs: 173\n",
      "\thidden_dim: 36\n",
      "\tlr: 0.002223379986022571\n",
      "\tn_graph_iters: 5\n",
      "\tnetwork: Edge_Track_Truth_Net\n",
      "\toptimizer: AdamW\n",
      "\ttrain_size: 292\n",
      "\tweight_decay: 0.00021762208861989958\n",
      "wandb: Agent Started Run: txex35gz\n",
      "Initialising W&B...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/txex35gz\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/txex35gz</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "config: {'epochs': 173, 'hidden_dim': 36, 'lr': 0.002223379986022571, 'n_graph_iters': 5, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 292, 'weight_decay': 0.0002176220886198996}\n",
      "Using  cuda\n",
      "Loading model...\n",
      "Model configs:  {'input_dim': 3, 'hidden_dim': 36, 'n_graph_iters': 5, 'output_dim': 1}\n",
      "Loading optimiser\n",
      "Loading scheduler...\n",
      "Training...\n",
      "Epoch:  1 , validation loss:  1.8970849990844727 , validation accuracy:  9.256994867244508 %, lr:  0.002223379986022571\n",
      "Epoch:  2 , validation loss:  1.8765539169311523 , validation accuracy:  11.486839874620815 %, lr:  0.002223379986022571\n",
      "Epoch:  3 , validation loss:  1.8755508422851563 , validation accuracy:  12.343501455422938 %, lr:  0.002223379986022571\n",
      "Epoch:  4 , validation loss:  1.8715837478637696 , validation accuracy:  13.172389166026424 %, lr:  0.002223379986022571\n",
      "Epoch:  5 , validation loss:  1.880539894104004 , validation accuracy:  10.921623581097897 %, lr:  0.002223379986022571\n",
      "Epoch:  6 , validation loss:  1.8723861694335937 , validation accuracy:  10.33548671002276 %, lr:  0.002223379986022571\n",
      "Epoch:  7 , validation loss:  1.8658079147338866 , validation accuracy:  11.843571791847467 %, lr:  0.002223379986022571\n",
      "Epoch:  8 , validation loss:  1.8629955291748046 , validation accuracy:  11.67873206872049 %, lr:  0.002223379986022571\n",
      "Epoch:  9 , validation loss:  1.8841968536376954 , validation accuracy:  10.174253983025476 %, lr:  0.002223379986022571\n",
      "Epoch:  10 , validation loss:  1.8708663940429688 , validation accuracy:  10.274167775817975 %, lr:  0.002223379986022571\n",
      "Epoch:  11 , validation loss:  1.8617652893066405 , validation accuracy:  12.353961744199049 %, lr:  0.002223379986022571\n",
      "Epoch:  12 , validation loss:  1.8640022277832031 , validation accuracy:  12.503652083581315 %, lr:  0.002223379986022571\n",
      "Epoch:  13 , validation loss:  1.8625238418579102 , validation accuracy:  11.781892158029715 %, lr:  0.002223379986022571\n",
      "Epoch:  14 , validation loss:  1.8604522705078126 , validation accuracy:  12.916653140431182 %, lr:  0.002223379986022571\n",
      "Epoch:  15 , validation loss:  1.8602184295654296 , validation accuracy:  12.39039240510895 %, lr:  0.002223379986022571\n",
      "Epoch:  16 , validation loss:  1.8647550582885741 , validation accuracy:  11.884330848113 %, lr:  0.002223379986022571\n",
      "Epoch:  17 , validation loss:  1.8623626708984375 , validation accuracy:  10.902506501610523 %, lr:  0.002223379986022571\n",
      "Epoch:  18 , validation loss:  1.8592668533325196 , validation accuracy:  12.450629240474825 %, lr:  0.002223379986022571\n",
      "Epoch:  19 , validation loss:  1.8605863571166992 , validation accuracy:  13.346607079090605 %, lr:  0.002223379986022571\n",
      "Epoch:  20 , validation loss:  1.8664567947387696 , validation accuracy:  12.323662976709626 %, lr:  0.002223379986022571\n",
      "Epoch:  21 , validation loss:  1.862752342224121 , validation accuracy:  12.27388643011986 %, lr:  0.002223379986022571\n",
      "Epoch:  22 , validation loss:  1.8619066238403321 , validation accuracy:  12.31608828483727 %, lr:  0.002223379986022571\n",
      "Epoch:  23 , validation loss:  1.8602188110351563 , validation accuracy:  12.46902492073626 %, lr:  0.002223379986022571\n",
      "Epoch:  24 , validation loss:  1.8596076965332031 , validation accuracy:  13.313422714697426 %, lr:  0.002223379986022571\n",
      "Epoch:  25 , validation loss:  1.8583532333374024 , validation accuracy:  12.8106074542182 %, lr:  0.002223379986022571\n",
      "Epoch:  26 , validation loss:  1.8651525497436523 , validation accuracy:  13.311258517019612 %, lr:  0.002223379986022571\n",
      "Epoch:  27 , validation loss:  1.8594324111938476 , validation accuracy:  11.739329603699336 %, lr:  0.002223379986022571\n",
      "Epoch:  28 , validation loss:  1.8594205856323243 , validation accuracy:  11.627152024065879 %, lr:  0.002223379986022571\n",
      "Epoch:  29 , validation loss:  1.858237075805664 , validation accuracy:  13.003581747156787 %, lr:  0.002223379986022571\n",
      "Epoch:  30 , validation loss:  1.8592216491699218 , validation accuracy:  12.931441824562922 %, lr:  0.002223379986022571\n",
      "Epoch:  31 , validation loss:  1.8662528991699219 , validation accuracy:  13.44796367033498 %, lr:  0.002223379986022571\n",
      "Epoch:  32 , validation loss:  1.8596782684326172 , validation accuracy:  12.450268540861856 %, lr:  0.002223379986022571\n",
      "Epoch:  33 , validation loss:  1.8617345809936523 , validation accuracy:  11.318032455751174 %, lr:  0.002223379986022571\n",
      "Epoch:  34 , validation loss:  1.8593191146850585 , validation accuracy:  12.765159302984067 %, lr:  0.002223379986022571\n",
      "Epoch:  35 , validation loss:  1.8589960098266602 , validation accuracy:  13.302962425921317 %, lr:  0.002223379986022571\n",
      "Epoch:  36 , validation loss:  1.8606969833374023 , validation accuracy:  13.989013089788955 %, lr:  0.002223379986022571\n",
      "Epoch:  37 , validation loss:  1.8591793060302735 , validation accuracy:  12.017068305685708 %, lr:  0.002223379986022571\n",
      "Epoch:  38 , validation loss:  1.858823585510254 , validation accuracy:  11.772153268479544 %, lr:  0.002223379986022571\n",
      "Epoch:  39 , validation loss:  1.863187026977539 , validation accuracy:  11.701816843950526 %, lr:  0.002223379986022571\n",
      "Epoch:  40 , validation loss:  1.8584503173828124 , validation accuracy:  11.760250181251555 %, lr:  0.002223379986022571\n",
      "Epoch:  41 , validation loss:  1.8572250366210938 , validation accuracy:  11.608034944578504 %, lr:  0.002223379986022571\n",
      "Epoch:  42 , validation loss:  1.8597099304199218 , validation accuracy:  13.645266358629197 %, lr:  0.002223379986022571\n",
      "Epoch:  43 , validation loss:  1.8602407455444336 , validation accuracy:  12.199943009461151 %, lr:  0.002223379986022571\n",
      "Epoch:  44 , validation loss:  1.8583749771118163 , validation accuracy:  11.77936726073893 %, lr:  0.002223379986022571\n",
      "Epoch:  45 , validation loss:  1.8586620330810546 , validation accuracy:  12.997810553349275 %, lr:  0.002223379986022571\n",
      "Epoch:  46 , validation loss:  1.8590202331542969 , validation accuracy:  11.854392780236548 %, lr:  0.002223379986022571\n",
      "Epoch:  47 , validation loss:  1.860488510131836 , validation accuracy:  11.239039240510895 %, lr:  0.002223379986022571\n",
      "Epoch:  48 , validation loss:  1.8577409744262696 , validation accuracy:  12.125278189576502 %, lr:  0.002223379986022571\n",
      "Epoch:  49 , validation loss:  1.8584442138671875 , validation accuracy:  12.946591208307634 %, lr:  0.002223379986022571\n",
      "Epoch:  50 , validation loss:  1.859341812133789 , validation accuracy:  11.723819520341655 %, lr:  0.002223379986022571\n",
      "Epoch:  51 , validation loss:  1.8624185562133788 , validation accuracy:  11.065903426285624 %, lr:  0.002223379986022571\n",
      "Epoch:  52 , validation loss:  1.8546770095825196 , validation accuracy:  12.963183390504222 %, lr:  0.002223379986022571\n",
      "Epoch:  53 , validation loss:  1.8479997634887695 , validation accuracy:  12.66849180670829 %, lr:  0.002223379986022571\n",
      "Epoch:  54 , validation loss:  1.8570812225341797 , validation accuracy:  12.851727210096703 %, lr:  0.002223379986022571\n",
      "Epoch:  55 , validation loss:  1.8563135147094727 , validation accuracy:  12.428987263696666 %, lr:  0.002223379986022571\n",
      "Epoch:  56 , validation loss:  1.866143035888672 , validation accuracy:  13.687468213346607 %, lr:  0.002223379986022571\n",
      "Epoch:  57 , validation loss:  1.8408073425292968 , validation accuracy:  14.921782288927604 %, lr:  0.002223379986022571\n",
      "Epoch:  58 , validation loss:  1.8474803924560548 , validation accuracy:  14.013901363083836 %, lr:  0.002223379986022571\n",
      "Epoch:  59 , validation loss:  1.790151596069336 , validation accuracy:  15.182207409491449 %, lr:  0.002223379986022571\n",
      "Epoch:  60 , validation loss:  1.8694211959838867 , validation accuracy:  13.103856239562257 %, lr:  0.002223379986022571\n",
      "Epoch:  61 , validation loss:  1.8789506912231446 , validation accuracy:  10.490226843986598 %, lr:  0.002223379986022571\n",
      "Epoch:  62 , validation loss:  1.7118616104125977 , validation accuracy:  15.179682512200666 %, lr:  0.002223379986022571\n",
      "Epoch:  63 , validation loss:  1.8365230560302734 , validation accuracy:  13.151829288087175 %, lr:  0.002223379986022571\n",
      "Epoch:  64 , validation loss:  1.877248764038086 , validation accuracy:  10.885914319413935 %, lr:  0.002223379986022571\n",
      "Epoch:  65 , validation loss:  1.8241140365600585 , validation accuracy:  13.788824804590986 %, lr:  0.002223379986022571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  66 , validation loss:  1.8681299209594726 , validation accuracy:  11.758446683186708 %, lr:  0.002223379986022571\n",
      "Epoch:  67 , validation loss:  1.8448713302612305 , validation accuracy:  12.312841988320548 %, lr:  0.002223379986022571\n",
      "Epoch:  68 , validation loss:  1.8441734313964844 , validation accuracy:  12.971840181215486 %, lr:  0.002223379986022571\n",
      "Epoch:  69 , validation loss:  1.8767066955566407 , validation accuracy:  11.958634968384679 %, lr:  0.002223379986022571\n",
      "Epoch:  70 , validation loss:  1.8767049789428711 , validation accuracy:  12.160987451260464 %, lr:  0.002223379986022571\n",
      "Epoch:  71 , validation loss:  1.8770126342773437 , validation accuracy:  12.74820642117451 %, lr:  0.002223379986022571\n",
      "Epoch:  72 , validation loss:  1.8766077041625977 , validation accuracy:  11.86341027056078 %, lr:  0.002223379986022571\n",
      "Epoch:  73 , validation loss:  1.87622127532959 , validation accuracy:  12.381735614397686 %, lr:  0.002223379986022571\n",
      "Epoch:  74 , validation loss:  1.8771820068359375 , validation accuracy:  12.423216069889156 %, lr:  0.002223379986022571\n",
      "Epoch:  75 , validation loss:  1.876499557495117 , validation accuracy:  11.558619097601708 %, lr:  0.002223379986022571\n",
      "Epoch:  76 , validation loss:  1.8788997650146484 , validation accuracy:  11.540944816566212 %, lr:  0.002223379986022571\n",
      "Epoch:  77 , validation loss:  1.8763755798339843 , validation accuracy:  12.33231976742089 %, lr:  0.002223379986022571\n",
      "Epoch:  78 , validation loss:  1.8767751693725585 , validation accuracy:  12.643603533413408 %, lr:  0.002223379986022571\n",
      "Epoch:  79 , validation loss:  1.8763322830200195 , validation accuracy:  11.54707670998669 %, lr:  0.002223379986022571\n",
      "Epoch:  80 , validation loss:  1.8761566162109375 , validation accuracy:  12.898257460169745 %, lr:  0.002223379986022571\n",
      "Epoch:  81 , validation loss:  1.876511573791504 , validation accuracy:  12.280379023153309 %, lr:  0.002223379986022571\n",
      "Epoch:  82 , validation loss:  1.876321029663086 , validation accuracy:  12.589498591468013 %, lr:  0.002223379986022571\n",
      "Epoch:  83 , validation loss:  1.8762216567993164 , validation accuracy:  12.73161423897792 %, lr:  0.0005558449965056428\n",
      "Epoch:  84 , validation loss:  1.8761550903320312 , validation accuracy:  12.799065066603182 %, lr:  0.0005558449965056428\n",
      "Epoch:  85 , validation loss:  1.8765811920166016 , validation accuracy:  12.93829511720934 %, lr:  0.0005558449965056428\n",
      "Epoch:  86 , validation loss:  1.8763256072998047 , validation accuracy:  12.610779868633202 %, lr:  0.0005558449965056428\n",
      "Epoch:  87 , validation loss:  1.8761892318725586 , validation accuracy:  12.224831282756034 %, lr:  0.0005558449965056428\n",
      "Epoch:  88 , validation loss:  1.8761983871459962 , validation accuracy:  12.762634405693282 %, lr:  0.0005558449965056428\n",
      "Epoch:  89 , validation loss:  1.8763145446777343 , validation accuracy:  12.755059713820927 %, lr:  0.0005558449965056428\n",
      "Epoch:  90 , validation loss:  1.876220703125 , validation accuracy:  12.926752729594321 %, lr:  0.0005558449965056428\n",
      "Epoch:  91 , validation loss:  1.8764003753662108 , validation accuracy:  12.697347775745838 %, lr:  0.0005558449965056428\n",
      "Epoch:  92 , validation loss:  1.876371192932129 , validation accuracy:  12.122031893059779 %, lr:  0.0005558449965056428\n",
      "Epoch:  93 , validation loss:  1.8763574600219726 , validation accuracy:  13.021256028192282 %, lr:  0.0005558449965056428\n",
      "Epoch:  94 , validation loss:  1.8761648178100585 , validation accuracy:  12.946230508694665 %, lr:  0.0005558449965056428\n",
      "Epoch:  95 , validation loss:  1.8764421463012695 , validation accuracy:  12.286510916573787 %, lr:  0.0005558449965056428\n",
      "Epoch:  96 , validation loss:  1.8762435913085938 , validation accuracy:  12.665606209804537 %, lr:  0.0005558449965056428\n",
      "Epoch:  97 , validation loss:  1.876566505432129 , validation accuracy:  12.2475553583731 %, lr:  0.0005558449965056428\n",
      "Epoch:  98 , validation loss:  1.8765600204467774 , validation accuracy:  12.561364021656404 %, lr:  0.0005558449965056428\n",
      "Epoch:  99 , validation loss:  1.8763154983520507 , validation accuracy:  12.79545807047349 %, lr:  0.0005558449965056428\n",
      "Epoch:  100 , validation loss:  1.8762617111206055 , validation accuracy:  12.558117725139681 %, lr:  0.0005558449965056428\n",
      "Epoch:  101 , validation loss:  1.8763967514038087 , validation accuracy:  12.592384188371767 %, lr:  0.0005558449965056428\n",
      "Epoch:  102 , validation loss:  1.8762929916381836 , validation accuracy:  12.308513592964914 %, lr:  0.0005558449965056428\n",
      "Epoch:  103 , validation loss:  1.8767515182495118 , validation accuracy:  12.062516456919841 %, lr:  0.0005558449965056428\n",
      "Epoch:  104 , validation loss:  1.8762924194335937 , validation accuracy:  12.869401491132201 %, lr:  0.0001389612491264107\n",
      "Epoch:  105 , validation loss:  1.8763742446899414 , validation accuracy:  12.636389541154022 %, lr:  0.0001389612491264107\n",
      "Epoch:  106 , validation loss:  1.8764339447021485 , validation accuracy:  12.460007430412027 %, lr:  0.0001389612491264107\n",
      "Epoch:  107 , validation loss:  1.876433753967285 , validation accuracy:  12.484174304480971 %, lr:  0.0001389612491264107\n",
      "Epoch:  108 , validation loss:  1.8763843536376954 , validation accuracy:  12.587334393790195 %, lr:  0.0001389612491264107\n",
      "Epoch:  109 , validation loss:  1.8764102935791016 , validation accuracy:  12.668131107095324 %, lr:  0.0001389612491264107\n",
      "Epoch:  110 , validation loss:  1.876405906677246 , validation accuracy:  12.557035626300772 %, lr:  0.0001389612491264107\n",
      "Epoch:  111 , validation loss:  1.8763925552368164 , validation accuracy:  12.741353128528093 %, lr:  0.0001389612491264107\n",
      "Epoch:  112 , validation loss:  1.8763799667358398 , validation accuracy:  12.593826986823641 %, lr:  0.0001389612491264107\n",
      "Epoch:  113 , validation loss:  1.876495933532715 , validation accuracy:  12.608254971342417 %, lr:  0.0001389612491264107\n",
      "Epoch:  114 , validation loss:  1.8763177871704102 , validation accuracy:  12.778144489050963 %, lr:  0.0001389612491264107\n",
      "Epoch:  115 , validation loss:  1.8763595581054688 , validation accuracy:  12.512669573905546 %, lr:  0.0001389612491264107\n",
      "Epoch:  116 , validation loss:  1.8763587951660157 , validation accuracy:  12.643964233026377 %, lr:  0.0001389612491264107\n",
      "Epoch:  117 , validation loss:  1.8764371871948242 , validation accuracy:  12.44774364357107 %, lr:  0.0001389612491264107\n",
      "Epoch:  118 , validation loss:  1.8763462066650392 , validation accuracy:  12.51699796926118 %, lr:  0.0001389612491264107\n",
      "Epoch:  119 , validation loss:  1.8763656616210938 , validation accuracy:  12.571824310432515 %, lr:  0.0001389612491264107\n",
      "Epoch:  120 , validation loss:  1.8763971328735352 , validation accuracy:  12.511226775453672 %, lr:  0.0001389612491264107\n",
      "Epoch:  121 , validation loss:  1.876434898376465 , validation accuracy:  12.625568552764943 %, lr:  0.0001389612491264107\n",
      "Epoch:  122 , validation loss:  1.8764446258544922 , validation accuracy:  12.4473829439581 %, lr:  0.0001389612491264107\n",
      "Epoch:  123 , validation loss:  1.8763849258422851 , validation accuracy:  12.471910517640014 %, lr:  0.0001389612491264107\n",
      "Epoch:  124 , validation loss:  1.8763708114624023 , validation accuracy:  12.563528219334222 %, lr:  0.0001389612491264107\n",
      "Epoch:  125 , validation loss:  1.8763998031616211 , validation accuracy:  12.646128430704193 %, lr:  3.474031228160267e-05\n",
      "Epoch:  126 , validation loss:  1.8763870239257812 , validation accuracy:  12.577595504240024 %, lr:  3.474031228160267e-05\n",
      "Epoch:  127 , validation loss:  1.8763935089111328 , validation accuracy:  12.529983155328075 %, lr:  3.474031228160267e-05\n",
      "Epoch:  128 , validation loss:  1.8764078140258789 , validation accuracy:  12.496438091321927 %, lr:  3.474031228160267e-05\n",
      "Epoch:  129 , validation loss:  1.8763925552368164 , validation accuracy:  12.544771839459818 %, lr:  3.474031228160267e-05\n",
      "Epoch:  130 , validation loss:  1.8763916015625 , validation accuracy:  12.542607641782 %, lr:  3.474031228160267e-05\n",
      "Epoch:  131 , validation loss:  1.8763910293579102 , validation accuracy:  12.51627657003524 %, lr:  3.474031228160267e-05\n",
      "Epoch:  132 , validation loss:  1.8764053344726563 , validation accuracy:  12.53286875223183 %, lr:  3.474031228160267e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  133 , validation loss:  1.8764049530029296 , validation accuracy:  12.549100234815446 %, lr:  3.474031228160267e-05\n",
      "Epoch:  134 , validation loss:  1.876380157470703 , validation accuracy:  12.514473071970395 %, lr:  3.474031228160267e-05\n",
      "Epoch:  135 , validation loss:  1.876397705078125 , validation accuracy:  12.537918546813398 %, lr:  3.474031228160267e-05\n",
      "Epoch:  136 , validation loss:  1.8763849258422851 , validation accuracy:  12.536836447974492 %, lr:  3.474031228160267e-05\n",
      "Epoch:  137 , validation loss:  1.8763813018798827 , validation accuracy:  12.560642622430466 %, lr:  3.474031228160267e-05\n",
      "Epoch:  138 , validation loss:  1.8763824462890626 , validation accuracy:  12.554871428622958 %, lr:  3.474031228160267e-05\n",
      "Epoch:  139 , validation loss:  1.8763835906982422 , validation accuracy:  12.554510729009987 %, lr:  3.474031228160267e-05\n",
      "Epoch:  140 , validation loss:  1.8763805389404298 , validation accuracy:  12.563888918947189 %, lr:  3.474031228160267e-05\n",
      "Epoch:  141 , validation loss:  1.876375389099121 , validation accuracy:  12.591662789145827 %, lr:  3.474031228160267e-05\n",
      "Epoch:  142 , validation loss:  1.8763677597045898 , validation accuracy:  12.550903732880295 %, lr:  3.474031228160267e-05\n",
      "Epoch:  143 , validation loss:  1.8763885498046875 , validation accuracy:  12.50076648667756 %, lr:  3.474031228160267e-05\n",
      "Epoch:  144 , validation loss:  1.8763818740844727 , validation accuracy:  12.541164843330124 %, lr:  3.474031228160267e-05\n",
      "Epoch:  145 , validation loss:  1.8763734817504882 , validation accuracy:  12.542607641782 %, lr:  3.474031228160267e-05\n",
      "Epoch:  146 , validation loss:  1.8763751983642578 , validation accuracy:  12.554871428622958 %, lr:  8.685078070400668e-06\n",
      "Epoch:  147 , validation loss:  1.8763765335083007 , validation accuracy:  12.555953527461867 %, lr:  8.685078070400668e-06\n",
      "Epoch:  148 , validation loss:  1.8763792037963867 , validation accuracy:  12.554871428622958 %, lr:  8.685078070400668e-06\n",
      "Epoch:  149 , validation loss:  1.8763742446899414 , validation accuracy:  12.563167519721253 %, lr:  8.685078070400668e-06\n",
      "Epoch:  150 , validation loss:  1.8763763427734375 , validation accuracy:  12.548018135976541 %, lr:  8.685078070400668e-06\n",
      "Epoch:  151 , validation loss:  1.876378059387207 , validation accuracy:  12.563167519721253 %, lr:  8.685078070400668e-06\n",
      "Epoch:  152 , validation loss:  1.876378631591797 , validation accuracy:  12.561724721269375 %, lr:  8.685078070400668e-06\n",
      "Epoch:  153 , validation loss:  1.8763772964477539 , validation accuracy:  12.561003322043435 %, lr:  8.685078070400668e-06\n",
      "Epoch:  154 , validation loss:  1.8763750076293946 , validation accuracy:  12.560281922817495 %, lr:  8.685078070400668e-06\n",
      "Epoch:  155 , validation loss:  1.8763805389404298 , validation accuracy:  12.550543033267324 %, lr:  8.685078070400668e-06\n",
      "Epoch:  156 , validation loss:  1.87637939453125 , validation accuracy:  12.551264432493264 %, lr:  8.685078070400668e-06\n",
      "Epoch:  157 , validation loss:  1.87637939453125 , validation accuracy:  12.55270723094514 %, lr:  8.685078070400668e-06\n",
      "Epoch:  158 , validation loss:  1.8763750076293946 , validation accuracy:  12.551264432493264 %, lr:  8.685078070400668e-06\n",
      "Epoch:  159 , validation loss:  1.8763818740844727 , validation accuracy:  12.54188624255606 %, lr:  8.685078070400668e-06\n",
      "Epoch:  160 , validation loss:  1.876377487182617 , validation accuracy:  12.565331717399067 %, lr:  8.685078070400668e-06\n",
      "Epoch:  161 , validation loss:  1.876378059387207 , validation accuracy:  12.55306793055811 %, lr:  8.685078070400668e-06\n",
      "Epoch:  162 , validation loss:  1.8763788223266602 , validation accuracy:  12.551625132106233 %, lr:  8.685078070400668e-06\n",
      "Epoch:  163 , validation loss:  1.8763744354248046 , validation accuracy:  12.557757025526712 %, lr:  8.685078070400668e-06\n",
      "Epoch:  164 , validation loss:  1.8763814926147462 , validation accuracy:  12.534311550683706 %, lr:  8.685078070400668e-06\n",
      "Epoch:  165 , validation loss:  1.8763776779174806 , validation accuracy:  12.556314227074836 %, lr:  8.685078070400668e-06\n",
      "Epoch:  166 , validation loss:  1.8763805389404298 , validation accuracy:  12.539722044878246 %, lr:  8.685078070400668e-06\n",
      "Epoch:  167 , validation loss:  1.876375389099121 , validation accuracy:  12.549100234815446 %, lr:  2.171269517600167e-06\n",
      "wandb: Agent Finished Run: txex35gz \n",
      "\n",
      "wandb: Agent Starting Run: pjgen773 with config:\n",
      "\tepochs: 157\n",
      "\thidden_dim: 17\n",
      "\tlr: 0.001166754679869392\n",
      "\tn_graph_iters: 3\n",
      "\tnetwork: Edge_Track_Truth_Net\n",
      "\toptimizer: AdamW\n",
      "\ttrain_size: 365\n",
      "\tweight_decay: 3.582884498686503e-05\n",
      "wandb: Agent Started Run: pjgen773\n",
      "Initialising W&B...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/pjgen773\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/pjgen773</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "config: {'epochs': 157, 'hidden_dim': 17, 'lr': 0.001166754679869392, 'n_graph_iters': 3, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 365, 'weight_decay': 3.582884498686503e-05}\n",
      "Using  cuda\n",
      "Loading model...\n",
      "Model configs:  {'input_dim': 3, 'hidden_dim': 17, 'n_graph_iters': 3, 'output_dim': 1}\n",
      "Loading optimiser\n",
      "Loading scheduler...\n",
      "Training...\n",
      "Epoch:  1 , validation loss:  1.8794410705566407 , validation accuracy:  11.07888861235252 %, lr:  0.001166754679869392\n",
      "Epoch:  2 , validation loss:  1.8830406188964843 , validation accuracy:  10.013381955641162 %, lr:  0.001166754679869392\n",
      "Epoch:  3 , validation loss:  1.885198211669922 , validation accuracy:  9.734921854428851 %, lr:  0.001166754679869392\n",
      "Epoch:  4 , validation loss:  1.8883790969848633 , validation accuracy:  9.53004447426228 %, lr:  0.001166754679869392\n",
      "Epoch:  5 , validation loss:  1.8760457992553712 , validation accuracy:  10.700875417960678 %, lr:  0.001166754679869392\n",
      "Epoch:  6 , validation loss:  1.8749399185180664 , validation accuracy:  10.8628295441839 %, lr:  0.001166754679869392\n",
      "Epoch:  7 , validation loss:  1.8749055862426758 , validation accuracy:  10.690415129184567 %, lr:  0.001166754679869392\n",
      "Epoch:  8 , validation loss:  1.8751474380493165 , validation accuracy:  11.20477277727881 %, lr:  0.001166754679869392\n",
      "Epoch:  9 , validation loss:  1.8737136840820312 , validation accuracy:  10.915130988064451 %, lr:  0.001166754679869392\n",
      "Epoch:  10 , validation loss:  1.8743400573730469 , validation accuracy:  11.360234310468584 %, lr:  0.001166754679869392\n",
      "Epoch:  11 , validation loss:  1.8722763061523438 , validation accuracy:  10.725763691255558 %, lr:  0.001166754679869392\n",
      "Epoch:  12 , validation loss:  1.8897653579711915 , validation accuracy:  9.476300231929851 %, lr:  0.001166754679869392\n",
      "Epoch:  13 , validation loss:  1.868301010131836 , validation accuracy:  10.508622524248032 %, lr:  0.001166754679869392\n",
      "Epoch:  14 , validation loss:  1.8319957733154297 , validation accuracy:  14.91889669202385 %, lr:  0.001166754679869392\n",
      "Epoch:  15 , validation loss:  1.8397998809814453 , validation accuracy:  12.140427573321213 %, lr:  0.001166754679869392\n",
      "Epoch:  16 , validation loss:  2.3843544006347654 , validation accuracy:  13.07968936549331 %, lr:  0.001166754679869392\n",
      "Epoch:  17 , validation loss:  1.8890148162841798 , validation accuracy:  10.576073351873294 %, lr:  0.001166754679869392\n",
      "Epoch:  18 , validation loss:  1.8863887786865234 , validation accuracy:  10.915491687677418 %, lr:  0.001166754679869392\n",
      "Epoch:  19 , validation loss:  1.8845123291015624 , validation accuracy:  10.936051565616669 %, lr:  0.001166754679869392\n",
      "Epoch:  20 , validation loss:  1.8829648971557618 , validation accuracy:  10.649656072919033 %, lr:  0.001166754679869392\n",
      "Epoch:  21 , validation loss:  1.8805782318115234 , validation accuracy:  10.473995361402977 %, lr:  0.001166754679869392\n",
      "Epoch:  22 , validation loss:  1.8647689819335938 , validation accuracy:  10.794296617719729 %, lr:  0.001166754679869392\n",
      "Epoch:  23 , validation loss:  1.930759811401367 , validation accuracy:  14.36558348572892 %, lr:  0.001166754679869392\n",
      "Epoch:  24 , validation loss:  1.8893049240112305 , validation accuracy:  10.642442080659647 %, lr:  0.001166754679869392\n",
      "Epoch:  25 , validation loss:  1.8889991760253906 , validation accuracy:  10.66805175318047 %, lr:  0.001166754679869392\n",
      "Epoch:  26 , validation loss:  1.888579750061035 , validation accuracy:  10.735141881192762 %, lr:  0.001166754679869392\n",
      "Epoch:  27 , validation loss:  1.8894996643066406 , validation accuracy:  10.488784045534718 %, lr:  0.001166754679869392\n",
      "Epoch:  28 , validation loss:  1.8888017654418945 , validation accuracy:  10.597715328651452 %, lr:  0.001166754679869392\n",
      "Epoch:  29 , validation loss:  1.8904382705688476 , validation accuracy:  10.281742467690332 %, lr:  0.001166754679869392\n",
      "Epoch:  30 , validation loss:  1.887472915649414 , validation accuracy:  10.710975007123817 %, lr:  0.001166754679869392\n",
      "Epoch:  31 , validation loss:  1.8880855560302734 , validation accuracy:  10.332601113119006 %, lr:  0.001166754679869392\n",
      "Epoch:  32 , validation loss:  1.8847158432006836 , validation accuracy:  10.721435295899928 %, lr:  0.001166754679869392\n",
      "Epoch:  33 , validation loss:  1.8817474365234375 , validation accuracy:  10.686447433441904 %, lr:  0.001166754679869392\n",
      "Epoch:  34 , validation loss:  1.869094467163086 , validation accuracy:  10.909359794256941 %, lr:  0.001166754679869392\n",
      "Epoch:  35 , validation loss:  1.5720709800720214 , validation accuracy:  15.577534185305819 %, lr:  0.001166754679869392\n",
      "Epoch:  36 , validation loss:  1.2997472763061524 , validation accuracy:  21.056561306309717 %, lr:  0.001166754679869392\n",
      "Epoch:  37 , validation loss:  1.5900188446044923 , validation accuracy:  19.389046995552576 %, lr:  0.001166754679869392\n",
      "Epoch:  38 , validation loss:  1.5435911178588868 , validation accuracy:  15.219720169240258 %, lr:  0.001166754679869392\n",
      "Epoch:  39 , validation loss:  1.4026803016662597 , validation accuracy:  20.232362690674833 %, lr:  0.001166754679869392\n",
      "Epoch:  40 , validation loss:  1.268997573852539 , validation accuracy:  20.994881672491967 %, lr:  0.001166754679869392\n",
      "Epoch:  41 , validation loss:  1.1036632537841797 , validation accuracy:  21.948932148795805 %, lr:  0.001166754679869392\n",
      "Epoch:  42 , validation loss:  1.1882102012634277 , validation accuracy:  20.7863972961957 %, lr:  0.001166754679869392\n",
      "Epoch:  43 , validation loss:  1.1513134002685548 , validation accuracy:  23.37982751344508 %, lr:  0.001166754679869392\n",
      "Epoch:  44 , validation loss:  1.573976707458496 , validation accuracy:  16.73574064255029 %, lr:  0.001166754679869392\n",
      "Epoch:  45 , validation loss:  1.2360441207885742 , validation accuracy:  19.48607519144132 %, lr:  0.001166754679869392\n",
      "Epoch:  46 , validation loss:  1.249138641357422 , validation accuracy:  17.175794170372853 %, lr:  0.001166754679869392\n",
      "Epoch:  47 , validation loss:  1.1136408805847169 , validation accuracy:  22.50404885315558 %, lr:  0.001166754679869392\n",
      "Epoch:  48 , validation loss:  1.0428122520446776 , validation accuracy:  23.576769502126325 %, lr:  0.001166754679869392\n",
      "Epoch:  49 , validation loss:  1.1198001861572267 , validation accuracy:  22.692334051125563 %, lr:  0.001166754679869392\n",
      "Epoch:  50 , validation loss:  1.4801968574523925 , validation accuracy:  22.596748653688696 %, lr:  0.001166754679869392\n",
      "Epoch:  51 , validation loss:  1.7135295867919922 , validation accuracy:  20.33299788269327 %, lr:  0.001166754679869392\n",
      "Epoch:  52 , validation loss:  1.4383548736572265 , validation accuracy:  20.314962902044805 %, lr:  0.001166754679869392\n",
      "Epoch:  53 , validation loss:  1.183948802947998 , validation accuracy:  22.997485923697603 %, lr:  0.001166754679869392\n",
      "Epoch:  54 , validation loss:  1.0849857330322266 , validation accuracy:  22.231720645363747 %, lr:  0.001166754679869392\n",
      "Epoch:  55 , validation loss:  1.2415063858032227 , validation accuracy:  24.419003098409675 %, lr:  0.001166754679869392\n",
      "Epoch:  56 , validation loss:  1.0399466514587403 , validation accuracy:  26.486533279949793 %, lr:  0.001166754679869392\n",
      "Epoch:  57 , validation loss:  1.0533711433410644 , validation accuracy:  24.21160082095232 %, lr:  0.001166754679869392\n",
      "Epoch:  58 , validation loss:  1.1398504257202149 , validation accuracy:  24.951756426765353 %, lr:  0.001166754679869392\n",
      "Epoch:  59 , validation loss:  1.198128890991211 , validation accuracy:  23.15222605766144 %, lr:  0.001166754679869392\n",
      "Epoch:  60 , validation loss:  1.1332330703735352 , validation accuracy:  19.25919513488362 %, lr:  0.001166754679869392\n",
      "Epoch:  61 , validation loss:  1.042642879486084 , validation accuracy:  22.05173153849206 %, lr:  0.001166754679869392\n",
      "Epoch:  62 , validation loss:  1.1737432479858398 , validation accuracy:  22.755456483395193 %, lr:  0.001166754679869392\n",
      "Epoch:  63 , validation loss:  0.9737550735473632 , validation accuracy:  23.66333740923896 %, lr:  0.001166754679869392\n",
      "Epoch:  64 , validation loss:  1.2218246459960938 , validation accuracy:  25.493527245445264 %, lr:  0.001166754679869392\n",
      "Epoch:  65 , validation loss:  1.200306224822998 , validation accuracy:  25.7564772632999 %, lr:  0.001166754679869392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  66 , validation loss:  1.380025291442871 , validation accuracy:  12.0794693387294 %, lr:  0.001166754679869392\n",
      "Epoch:  67 , validation loss:  1.3084972381591797 , validation accuracy:  24.209436623274502 %, lr:  0.001166754679869392\n",
      "Epoch:  68 , validation loss:  1.136939239501953 , validation accuracy:  24.62640537586703 %, lr:  0.001166754679869392\n",
      "Epoch:  69 , validation loss:  1.1580348014831543 , validation accuracy:  23.27883162181367 %, lr:  0.001166754679869392\n",
      "Epoch:  70 , validation loss:  1.349592399597168 , validation accuracy:  20.41920509019294 %, lr:  0.001166754679869392\n",
      "Epoch:  71 , validation loss:  1.581709384918213 , validation accuracy:  19.662818001796285 %, lr:  0.001166754679869392\n",
      "Epoch:  72 , validation loss:  1.21463623046875 , validation accuracy:  23.463509823653958 %, lr:  0.001166754679869392\n",
      "Epoch:  73 , validation loss:  1.6271135330200195 , validation accuracy:  22.11016487579309 %, lr:  0.001166754679869392\n",
      "Epoch:  74 , validation loss:  1.0561957359313965 , validation accuracy:  28.053773098301466 %, lr:  0.001166754679869392\n",
      "Epoch:  75 , validation loss:  1.1585793495178223 , validation accuracy:  21.12329073470904 %, lr:  0.001166754679869392\n",
      "Epoch:  76 , validation loss:  0.9940083503723145 , validation accuracy:  25.661613265088967 %, lr:  0.001166754679869392\n",
      "Epoch:  77 , validation loss:  1.465658950805664 , validation accuracy:  23.76252980280552 %, lr:  0.001166754679869392\n",
      "Epoch:  78 , validation loss:  1.1490548133850098 , validation accuracy:  13.811909579821021 %, lr:  0.001166754679869392\n",
      "Epoch:  79 , validation loss:  1.1334520339965821 , validation accuracy:  22.3839358820368 %, lr:  0.001166754679869392\n",
      "Epoch:  80 , validation loss:  2.231058692932129 , validation accuracy:  20.24498717712876 %, lr:  0.001166754679869392\n",
      "Epoch:  81 , validation loss:  0.9076107025146485 , validation accuracy:  27.847813619295987 %, lr:  0.001166754679869392\n",
      "Epoch:  82 , validation loss:  1.0692813873291016 , validation accuracy:  17.054238400802195 %, lr:  0.001166754679869392\n",
      "Epoch:  83 , validation loss:  1.3333798408508302 , validation accuracy:  22.375279091325535 %, lr:  0.001166754679869392\n",
      "Epoch:  84 , validation loss:  1.5192298889160156 , validation accuracy:  22.294482378020408 %, lr:  0.001166754679869392\n",
      "Epoch:  85 , validation loss:  1.3978574752807618 , validation accuracy:  23.48370900198024 %, lr:  0.001166754679869392\n",
      "Epoch:  86 , validation loss:  1.1527766227722167 , validation accuracy:  22.387542878166492 %, lr:  0.001166754679869392\n",
      "Epoch:  87 , validation loss:  1.2625709533691407 , validation accuracy:  20.637789055652345 %, lr:  0.001166754679869392\n",
      "Epoch:  88 , validation loss:  1.0098834037780762 , validation accuracy:  25.31245603973467 %, lr:  0.001166754679869392\n",
      "Epoch:  89 , validation loss:  1.2164962768554688 , validation accuracy:  16.540241452320924 %, lr:  0.001166754679869392\n",
      "Epoch:  90 , validation loss:  1.2189621925354004 , validation accuracy:  23.276306724522886 %, lr:  0.001166754679869392\n",
      "Epoch:  91 , validation loss:  1.3480238914489746 , validation accuracy:  23.488037397335873 %, lr:  0.001166754679869392\n",
      "Epoch:  92 , validation loss:  1.2280844688415526 , validation accuracy:  23.938190514321576 %, lr:  0.001166754679869392\n",
      "Epoch:  93 , validation loss:  1.4816596984863282 , validation accuracy:  22.242541633752825 %, lr:  0.001166754679869392\n",
      "Epoch:  94 , validation loss:  1.0602256774902343 , validation accuracy:  20.33335858230624 %, lr:  0.001166754679869392\n",
      "Epoch:  95 , validation loss:  1.2432995796203614 , validation accuracy:  23.98904915975025 %, lr:  0.001166754679869392\n",
      "Epoch:  96 , validation loss:  1.3603510856628418 , validation accuracy:  15.674562381194566 %, lr:  0.001166754679869392\n",
      "Epoch:  97 , validation loss:  1.794692611694336 , validation accuracy:  23.839358820367988 %, lr:  0.001166754679869392\n",
      "Epoch:  98 , validation loss:  1.0328154563903809 , validation accuracy:  26.105995188267162 %, lr:  0.001166754679869392\n",
      "Epoch:  99 , validation loss:  1.2894248962402344 , validation accuracy:  14.49218904988115 %, lr:  0.001166754679869392\n",
      "Epoch:  100 , validation loss:  1.1716888427734375 , validation accuracy:  13.122973319049628 %, lr:  0.001166754679869392\n",
      "Epoch:  101 , validation loss:  1.0450764656066895 , validation accuracy:  23.65251642084988 %, lr:  0.001166754679869392\n",
      "Epoch:  102 , validation loss:  1.2992178916931152 , validation accuracy:  24.149199787908625 %, lr:  0.000291688669967348\n",
      "Epoch:  103 , validation loss:  0.8997855186462402 , validation accuracy:  29.781524244424485 %, lr:  0.000291688669967348\n",
      "Epoch:  104 , validation loss:  0.8542816162109375 , validation accuracy:  30.56965289876244 %, lr:  0.000291688669967348\n",
      "Epoch:  105 , validation loss:  0.8903159141540528 , validation accuracy:  29.0572394215821 %, lr:  0.000291688669967348\n",
      "Epoch:  106 , validation loss:  1.6363748550415038 , validation accuracy:  24.84967843629504 %, lr:  0.000291688669967348\n",
      "Epoch:  107 , validation loss:  0.8036284446716309 , validation accuracy:  30.73954241647099 %, lr:  0.000291688669967348\n",
      "Epoch:  108 , validation loss:  0.8329010009765625 , validation accuracy:  30.522040549850487 %, lr:  0.000291688669967348\n",
      "Epoch:  109 , validation loss:  0.8416542053222656 , validation accuracy:  31.064532767756344 %, lr:  0.000291688669967348\n",
      "Epoch:  110 , validation loss:  1.221745491027832 , validation accuracy:  28.128798617799085 %, lr:  0.000291688669967348\n",
      "Epoch:  111 , validation loss:  0.8572187423706055 , validation accuracy:  30.793286658803414 %, lr:  0.000291688669967348\n",
      "Epoch:  112 , validation loss:  0.9431818008422852 , validation accuracy:  30.836931311972705 %, lr:  0.000291688669967348\n",
      "Epoch:  113 , validation loss:  0.8779728889465332 , validation accuracy:  29.772506754100252 %, lr:  0.000291688669967348\n",
      "Epoch:  114 , validation loss:  1.0826800346374512 , validation accuracy:  27.344998358816763 %, lr:  0.000291688669967348\n",
      "Epoch:  115 , validation loss:  0.8022812843322754 , validation accuracy:  33.068579817413855 %, lr:  0.000291688669967348\n",
      "Epoch:  116 , validation loss:  1.2317794799804687 , validation accuracy:  21.53412759388109 %, lr:  0.000291688669967348\n",
      "Epoch:  117 , validation loss:  0.8375868797302246 , validation accuracy:  32.81753288678721 %, lr:  0.000291688669967348\n",
      "Epoch:  118 , validation loss:  1.9711797714233399 , validation accuracy:  21.064135998182074 %, lr:  0.000291688669967348\n",
      "Epoch:  119 , validation loss:  0.9030830383300781 , validation accuracy:  30.835127813907853 %, lr:  0.000291688669967348\n",
      "Epoch:  120 , validation loss:  0.8192254066467285 , validation accuracy:  31.802524175891563 %, lr:  0.000291688669967348\n",
      "Epoch:  121 , validation loss:  0.9917502403259277 , validation accuracy:  29.318025241758917 %, lr:  0.000291688669967348\n",
      "Epoch:  122 , validation loss:  0.9201807022094727 , validation accuracy:  32.88786931131623 %, lr:  0.000291688669967348\n",
      "Epoch:  123 , validation loss:  0.8803923606872559 , validation accuracy:  32.68299193114966 %, lr:  0.000291688669967348\n",
      "Epoch:  124 , validation loss:  0.8053635597229004 , validation accuracy:  32.74431086535444 %, lr:  0.000291688669967348\n",
      "Epoch:  125 , validation loss:  0.8129973411560059 , validation accuracy:  31.67519721251339 %, lr:  0.000291688669967348\n",
      "Epoch:  126 , validation loss:  1.4542930603027344 , validation accuracy:  27.733832541597682 %, lr:  0.000291688669967348\n",
      "Epoch:  127 , validation loss:  0.8048851013183593 , validation accuracy:  32.77100263671417 %, lr:  0.000291688669967348\n",
      "Epoch:  128 , validation loss:  0.9672592163085938 , validation accuracy:  30.783547769253243 %, lr:  0.000291688669967348\n",
      "Epoch:  129 , validation loss:  1.112614917755127 , validation accuracy:  30.961733378060085 %, lr:  0.000291688669967348\n",
      "Epoch:  130 , validation loss:  1.0413976669311524 , validation accuracy:  26.07461432193883 %, lr:  0.000291688669967348\n",
      "Epoch:  131 , validation loss:  1.3952496528625489 , validation accuracy:  27.02469710250001 %, lr:  0.000291688669967348\n",
      "Epoch:  132 , validation loss:  1.369748592376709 , validation accuracy:  24.83633255061517 %, lr:  0.000291688669967348\n",
      "Epoch:  133 , validation loss:  0.8187275886535644 , validation accuracy:  30.959569180382267 %, lr:  0.000291688669967348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  134 , validation loss:  0.9458410263061523 , validation accuracy:  23.383795209187742 %, lr:  0.000291688669967348\n",
      "Epoch:  135 , validation loss:  0.8861897468566895 , validation accuracy:  28.575344738655094 %, lr:  0.000291688669967348\n",
      "Epoch:  136 , validation loss:  0.9067770957946777 , validation accuracy:  32.399121335742805 %, lr:  7.2922167491837e-05\n",
      "Epoch:  137 , validation loss:  0.7916918754577636 , validation accuracy:  33.64425639971289 %, lr:  7.2922167491837e-05\n",
      "Epoch:  138 , validation loss:  0.7788257598876953 , validation accuracy:  33.91622390789175 %, lr:  7.2922167491837e-05\n",
      "Epoch:  139 , validation loss:  0.7676527500152588 , validation accuracy:  34.424088962952546 %, lr:  7.2922167491837e-05\n",
      "Epoch:  140 , validation loss:  0.7918067932128906 , validation accuracy:  34.22173648007676 %, lr:  7.2922167491837e-05\n",
      "Epoch:  141 , validation loss:  0.808712387084961 , validation accuracy:  33.72902080876067 %, lr:  7.2922167491837e-05\n",
      "Epoch:  142 , validation loss:  0.7838750839233398 , validation accuracy:  33.60097244615656 %, lr:  7.2922167491837e-05\n",
      "Epoch:  143 , validation loss:  0.7906850337982178 , validation accuracy:  33.57500207402278 %, lr:  7.2922167491837e-05\n",
      "Epoch:  144 , validation loss:  0.7942712306976318 , validation accuracy:  34.16077824548494 %, lr:  7.2922167491837e-05\n",
      "Epoch:  145 , validation loss:  0.814669418334961 , validation accuracy:  33.6922294482378 %, lr:  7.2922167491837e-05\n",
      "Epoch:  146 , validation loss:  0.7898048877716064 , validation accuracy:  33.83542719458662 %, lr:  7.2922167491837e-05\n",
      "Epoch:  147 , validation loss:  0.828010368347168 , validation accuracy:  33.26948950183776 %, lr:  7.2922167491837e-05\n",
      "Epoch:  148 , validation loss:  0.7990206241607666 , validation accuracy:  33.79286464025624 %, lr:  7.2922167491837e-05\n",
      "Epoch:  149 , validation loss:  0.7737254619598388 , validation accuracy:  34.01613770068425 %, lr:  7.2922167491837e-05\n",
      "Epoch:  150 , validation loss:  0.8741440773010254 , validation accuracy:  33.33802242830193 %, lr:  7.2922167491837e-05\n",
      "Epoch:  151 , validation loss:  0.7726516723632812 , validation accuracy:  34.14238256522351 %, lr:  7.2922167491837e-05\n",
      "Epoch:  152 , validation loss:  0.7940683841705323 , validation accuracy:  33.81053892129174 %, lr:  7.2922167491837e-05\n",
      "Epoch:  153 , validation loss:  0.7685935020446777 , validation accuracy:  34.18133812342419 %, lr:  7.2922167491837e-05\n",
      "Epoch:  154 , validation loss:  0.7822577476501464 , validation accuracy:  34.20117660213751 %, lr:  7.2922167491837e-05\n",
      "Epoch:  155 , validation loss:  0.8065115928649902 , validation accuracy:  32.498674428922335 %, lr:  7.2922167491837e-05\n",
      "Epoch:  156 , validation loss:  0.7645637512207031 , validation accuracy:  34.51642806387269 %, lr:  7.2922167491837e-05\n",
      "Epoch:  157 , validation loss:  0.8005198478698731 , validation accuracy:  33.94832617344601 %, lr:  7.2922167491837e-05\n",
      "wandb: Agent Finished Run: pjgen773 \n",
      "\n",
      "wandb: Agent Starting Run: r0u1b0z1 with config:\n",
      "\tepochs: 180\n",
      "\thidden_dim: 19\n",
      "\tlr: 0.0008020155923685281\n",
      "\tn_graph_iters: 2\n",
      "\tnetwork: Edge_Track_Truth_Net\n",
      "\toptimizer: AdamW\n",
      "\ttrain_size: 363\n",
      "\tweight_decay: 0.00015770158871663577\n",
      "wandb: Agent Started Run: r0u1b0z1\n",
      "Initialising W&B...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/r0u1b0z1\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/r0u1b0z1</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "config: {'epochs': 180, 'hidden_dim': 19, 'lr': 0.0008020155923685281, 'n_graph_iters': 2, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 363, 'weight_decay': 0.00015770158871663577}\n",
      "Using  cuda\n",
      "Loading model...\n",
      "Model configs:  {'input_dim': 3, 'hidden_dim': 19, 'n_graph_iters': 2, 'output_dim': 1}\n",
      "Loading optimiser\n",
      "Loading scheduler...\n",
      "Training...\n",
      "Epoch:  1 , validation loss:  1.8813880920410155 , validation accuracy:  10.781311431652833 %, lr:  0.0008020155923685281\n",
      "Epoch:  2 , validation loss:  1.879414939880371 , validation accuracy:  10.966350333106092 %, lr:  0.0008020155923685281\n",
      "Epoch:  3 , validation loss:  1.8776962280273437 , validation accuracy:  10.761833652552491 %, lr:  0.0008020155923685281\n",
      "Epoch:  4 , validation loss:  1.875347900390625 , validation accuracy:  11.569800785603757 %, lr:  0.0008020155923685281\n",
      "Epoch:  5 , validation loss:  1.8758623123168945 , validation accuracy:  11.42047114583446 %, lr:  0.0008020155923685281\n",
      "Epoch:  6 , validation loss:  1.8746952056884765 , validation accuracy:  12.826478237188851 %, lr:  0.0008020155923685281\n",
      "Epoch:  7 , validation loss:  1.8728702545166016 , validation accuracy:  12.286150216960817 %, lr:  0.0008020155923685281\n",
      "Epoch:  8 , validation loss:  1.8725797653198242 , validation accuracy:  11.938075090445428 %, lr:  0.0008020155923685281\n",
      "Epoch:  9 , validation loss:  1.871828269958496 , validation accuracy:  12.741713828141062 %, lr:  0.0008020155923685281\n",
      "Epoch:  10 , validation loss:  1.8723827362060548 , validation accuracy:  11.902005129148495 %, lr:  0.0008020155923685281\n",
      "Epoch:  11 , validation loss:  1.8702669143676758 , validation accuracy:  13.186095751319261 %, lr:  0.0008020155923685281\n",
      "Epoch:  12 , validation loss:  1.8686391830444335 , validation accuracy:  12.66416341135266 %, lr:  0.0008020155923685281\n",
      "Epoch:  13 , validation loss:  1.8661577224731445 , validation accuracy:  12.768405599500793 %, lr:  0.0008020155923685281\n",
      "Epoch:  14 , validation loss:  1.890913200378418 , validation accuracy:  9.558900443299825 %, lr:  0.0008020155923685281\n",
      "Epoch:  15 , validation loss:  1.872749137878418 , validation accuracy:  12.197778811783335 %, lr:  0.0008020155923685281\n",
      "Epoch:  16 , validation loss:  1.6975906372070313 , validation accuracy:  15.62442513499183 %, lr:  0.0008020155923685281\n",
      "Epoch:  17 , validation loss:  1.6338253021240234 , validation accuracy:  14.844231872139202 %, lr:  0.0008020155923685281\n",
      "Epoch:  18 , validation loss:  1.5562023162841796 , validation accuracy:  17.51557320578995 %, lr:  0.0008020155923685281\n",
      "Epoch:  19 , validation loss:  1.8931898117065429 , validation accuracy:  11.611641940708198 %, lr:  0.0008020155923685281\n",
      "Epoch:  20 , validation loss:  1.868027687072754 , validation accuracy:  10.79790361384942 %, lr:  0.0008020155923685281\n",
      "Epoch:  21 , validation loss:  1.8417713165283203 , validation accuracy:  10.642442080659647 %, lr:  0.0008020155923685281\n",
      "Epoch:  22 , validation loss:  1.717660140991211 , validation accuracy:  15.71892843358979 %, lr:  0.0008020155923685281\n",
      "Epoch:  23 , validation loss:  1.5213638305664063 , validation accuracy:  21.744415468242202 %, lr:  0.0008020155923685281\n",
      "Epoch:  24 , validation loss:  1.778910255432129 , validation accuracy:  11.113876474810542 %, lr:  0.0008020155923685281\n",
      "Epoch:  25 , validation loss:  1.8064430236816407 , validation accuracy:  16.852607317152348 %, lr:  0.0008020155923685281\n",
      "Epoch:  26 , validation loss:  1.3043251037597656 , validation accuracy:  19.788341467109603 %, lr:  0.0008020155923685281\n",
      "Epoch:  27 , validation loss:  1.3337764739990234 , validation accuracy:  17.612240702065726 %, lr:  0.0008020155923685281\n",
      "Epoch:  28 , validation loss:  1.2736388206481934 , validation accuracy:  18.850161773776417 %, lr:  0.0008020155923685281\n",
      "Epoch:  29 , validation loss:  1.291592502593994 , validation accuracy:  19.84352850789391 %, lr:  0.0008020155923685281\n",
      "Epoch:  30 , validation loss:  1.234402847290039 , validation accuracy:  17.221963720832928 %, lr:  0.0008020155923685281\n",
      "Epoch:  31 , validation loss:  1.3444416046142578 , validation accuracy:  18.88514963623444 %, lr:  0.0008020155923685281\n",
      "Epoch:  32 , validation loss:  1.3410743713378905 , validation accuracy:  17.427562500225438 %, lr:  0.0008020155923685281\n",
      "Epoch:  33 , validation loss:  1.1770970344543457 , validation accuracy:  20.526332875244822 %, lr:  0.0008020155923685281\n",
      "Epoch:  34 , validation loss:  1.4160242080688477 , validation accuracy:  16.192527025418503 %, lr:  0.0008020155923685281\n",
      "Epoch:  35 , validation loss:  1.461897087097168 , validation accuracy:  14.40742464083336 %, lr:  0.0008020155923685281\n",
      "Epoch:  36 , validation loss:  1.513101291656494 , validation accuracy:  15.770147778631433 %, lr:  0.0008020155923685281\n",
      "Epoch:  37 , validation loss:  1.3058067321777345 , validation accuracy:  18.81697740938324 %, lr:  0.0008020155923685281\n",
      "Epoch:  38 , validation loss:  1.1402990341186523 , validation accuracy:  18.54753479849516 %, lr:  0.0008020155923685281\n",
      "Epoch:  39 , validation loss:  1.0552688598632813 , validation accuracy:  20.658348933591594 %, lr:  0.0008020155923685281\n",
      "Epoch:  40 , validation loss:  1.3593310356140136 , validation accuracy:  18.744476787176406 %, lr:  0.0008020155923685281\n",
      "Epoch:  41 , validation loss:  1.2303820610046388 , validation accuracy:  21.579575745115225 %, lr:  0.0008020155923685281\n",
      "Epoch:  42 , validation loss:  1.4101480484008788 , validation accuracy:  17.9357882548992 %, lr:  0.0008020155923685281\n",
      "Epoch:  43 , validation loss:  1.3602951049804688 , validation accuracy:  19.07451693304333 %, lr:  0.0008020155923685281\n",
      "Epoch:  44 , validation loss:  1.3639586448669434 , validation accuracy:  12.88527227410285 %, lr:  0.0008020155923685281\n",
      "Epoch:  45 , validation loss:  1.7440269470214844 , validation accuracy:  16.22066159523011 %, lr:  0.0008020155923685281\n",
      "Epoch:  46 , validation loss:  1.5929553031921386 , validation accuracy:  17.79511540584117 %, lr:  0.0008020155923685281\n",
      "Epoch:  47 , validation loss:  1.1050966262817383 , validation accuracy:  21.09732036257525 %, lr:  0.0008020155923685281\n",
      "Epoch:  48 , validation loss:  1.3854284286499023 , validation accuracy:  16.53194536122263 %, lr:  0.0008020155923685281\n",
      "Epoch:  49 , validation loss:  0.9920208930969239 , validation accuracy:  22.66852787666959 %, lr:  0.0008020155923685281\n",
      "Epoch:  50 , validation loss:  1.0532361030578614 , validation accuracy:  22.56789268465115 %, lr:  0.0008020155923685281\n",
      "Epoch:  51 , validation loss:  1.0249624252319336 , validation accuracy:  23.208855896897624 %, lr:  0.0008020155923685281\n",
      "Epoch:  52 , validation loss:  1.3387636184692382 , validation accuracy:  17.739928365056866 %, lr:  0.0008020155923685281\n",
      "Epoch:  53 , validation loss:  1.172872257232666 , validation accuracy:  13.516496596799152 %, lr:  0.0008020155923685281\n",
      "Epoch:  54 , validation loss:  1.8857461929321289 , validation accuracy:  19.99682584340587 %, lr:  0.0008020155923685281\n",
      "Epoch:  55 , validation loss:  1.0712093353271483 , validation accuracy:  21.858757245553477 %, lr:  0.0008020155923685281\n",
      "Epoch:  56 , validation loss:  1.2835704803466796 , validation accuracy:  20.101068031554 %, lr:  0.0008020155923685281\n",
      "Epoch:  57 , validation loss:  1.0998748779296874 , validation accuracy:  21.66253665609817 %, lr:  0.0008020155923685281\n",
      "Epoch:  58 , validation loss:  1.261256504058838 , validation accuracy:  13.14894369118342 %, lr:  0.0008020155923685281\n",
      "Epoch:  59 , validation loss:  1.3864546775817872 , validation accuracy:  17.44631888009984 %, lr:  0.0008020155923685281\n",
      "Epoch:  60 , validation loss:  1.2266440391540527 , validation accuracy:  16.776499698815822 %, lr:  0.0008020155923685281\n",
      "Epoch:  61 , validation loss:  1.109868621826172 , validation accuracy:  22.66203528363614 %, lr:  0.0008020155923685281\n",
      "Epoch:  62 , validation loss:  1.1967796325683593 , validation accuracy:  21.496614834132284 %, lr:  0.0008020155923685281\n",
      "Epoch:  63 , validation loss:  1.0824108123779297 , validation accuracy:  22.304942666796517 %, lr:  0.0008020155923685281\n",
      "Epoch:  64 , validation loss:  1.1852971076965333 , validation accuracy:  19.549558323323918 %, lr:  0.0008020155923685281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  65 , validation loss:  1.1968267440795899 , validation accuracy:  22.238573938010163 %, lr:  0.0008020155923685281\n",
      "Epoch:  66 , validation loss:  1.1850406646728515 , validation accuracy:  23.523385959406866 %, lr:  0.0008020155923685281\n",
      "Epoch:  67 , validation loss:  1.2862966537475586 , validation accuracy:  23.97822817136117 %, lr:  0.0008020155923685281\n",
      "Epoch:  68 , validation loss:  1.0739420890808105 , validation accuracy:  22.30566406602246 %, lr:  0.0008020155923685281\n",
      "Epoch:  69 , validation loss:  2.408732223510742 , validation accuracy:  19.762731794588785 %, lr:  0.0008020155923685281\n",
      "Epoch:  70 , validation loss:  1.028159236907959 , validation accuracy:  20.687204902629137 %, lr:  0.00020050389809213204\n",
      "Epoch:  71 , validation loss:  0.9536089897155762 , validation accuracy:  25.12344944253875 %, lr:  0.00020050389809213204\n",
      "Epoch:  72 , validation loss:  1.091306781768799 , validation accuracy:  23.934944217804855 %, lr:  0.00020050389809213204\n",
      "Epoch:  73 , validation loss:  1.2239054679870605 , validation accuracy:  23.340511255631423 %, lr:  0.00020050389809213204\n",
      "Epoch:  74 , validation loss:  0.9314729690551757 , validation accuracy:  26.265063717586628 %, lr:  0.00020050389809213204\n",
      "Epoch:  75 , validation loss:  0.9466351509094239 , validation accuracy:  25.112989153762637 %, lr:  0.00020050389809213204\n",
      "Epoch:  76 , validation loss:  0.9251284599304199 , validation accuracy:  26.42377154729313 %, lr:  0.00020050389809213204\n",
      "Epoch:  77 , validation loss:  0.9340061187744141 , validation accuracy:  24.791605798606977 %, lr:  0.00020050389809213204\n",
      "Epoch:  78 , validation loss:  0.8739388465881348 , validation accuracy:  26.653176501141612 %, lr:  0.00020050389809213204\n",
      "Epoch:  79 , validation loss:  0.9260313987731934 , validation accuracy:  26.281655899783217 %, lr:  0.00020050389809213204\n",
      "Epoch:  80 , validation loss:  0.942111873626709 , validation accuracy:  25.436897406209084 %, lr:  0.00020050389809213204\n",
      "Epoch:  81 , validation loss:  1.061767578125 , validation accuracy:  23.29037400942869 %, lr:  0.00020050389809213204\n",
      "Epoch:  82 , validation loss:  0.9220597267150878 , validation accuracy:  26.62432053210407 %, lr:  0.00020050389809213204\n",
      "Epoch:  83 , validation loss:  1.2154945373535155 , validation accuracy:  24.77068522105476 %, lr:  0.00020050389809213204\n",
      "Epoch:  84 , validation loss:  1.0125413894653321 , validation accuracy:  24.83669325022814 %, lr:  0.00020050389809213204\n",
      "Epoch:  85 , validation loss:  0.9111343383789062 , validation accuracy:  26.879335158473378 %, lr:  0.00020050389809213204\n",
      "Epoch:  86 , validation loss:  1.216498851776123 , validation accuracy:  24.38473663517759 %, lr:  0.00020050389809213204\n",
      "Epoch:  87 , validation loss:  0.8894895553588867 , validation accuracy:  26.064154033162723 %, lr:  0.00020050389809213204\n",
      "Epoch:  88 , validation loss:  1.1024544715881348 , validation accuracy:  25.25294060359473 %, lr:  0.00020050389809213204\n",
      "Epoch:  89 , validation loss:  0.9919034004211426 , validation accuracy:  25.204246155843872 %, lr:  0.00020050389809213204\n",
      "Epoch:  90 , validation loss:  0.8849070549011231 , validation accuracy:  27.19278312214371 %, lr:  0.00020050389809213204\n",
      "Epoch:  91 , validation loss:  1.250246810913086 , validation accuracy:  23.616807159165916 %, lr:  0.00020050389809213204\n",
      "Epoch:  92 , validation loss:  0.8652881622314453 , validation accuracy:  26.767878978065855 %, lr:  0.00020050389809213204\n",
      "Epoch:  93 , validation loss:  1.3846283912658692 , validation accuracy:  23.18360692398977 %, lr:  0.00020050389809213204\n",
      "Epoch:  94 , validation loss:  0.9762701034545899 , validation accuracy:  26.115734077817333 %, lr:  0.00020050389809213204\n",
      "Epoch:  95 , validation loss:  1.0722857475280763 , validation accuracy:  23.148258361918778 %, lr:  0.00020050389809213204\n",
      "Epoch:  96 , validation loss:  1.0479215621948241 , validation accuracy:  26.607006950681544 %, lr:  0.00020050389809213204\n",
      "Epoch:  97 , validation loss:  0.8785940170288086 , validation accuracy:  27.279711728869316 %, lr:  0.00020050389809213204\n",
      "Epoch:  98 , validation loss:  1.109819507598877 , validation accuracy:  25.125613640216564 %, lr:  0.00020050389809213204\n",
      "Epoch:  99 , validation loss:  0.9219995498657226 , validation accuracy:  25.64538178250535 %, lr:  0.00020050389809213204\n",
      "Epoch:  100 , validation loss:  1.0222323417663575 , validation accuracy:  25.33554081496471 %, lr:  0.00020050389809213204\n",
      "Epoch:  101 , validation loss:  0.8971223831176758 , validation accuracy:  26.882581454990103 %, lr:  0.00020050389809213204\n",
      "Epoch:  102 , validation loss:  0.9589913368225098 , validation accuracy:  25.500380538091683 %, lr:  0.00020050389809213204\n",
      "Epoch:  103 , validation loss:  1.081144428253174 , validation accuracy:  25.702011621741526 %, lr:  0.00020050389809213204\n",
      "Epoch:  104 , validation loss:  0.870908260345459 , validation accuracy:  28.10066404798748 %, lr:  0.00020050389809213204\n",
      "Epoch:  105 , validation loss:  0.9331453323364258 , validation accuracy:  26.12799786465829 %, lr:  0.00020050389809213204\n",
      "Epoch:  106 , validation loss:  1.0480691909790039 , validation accuracy:  23.233022770966567 %, lr:  0.00020050389809213204\n",
      "Epoch:  107 , validation loss:  0.8680705070495606 , validation accuracy:  27.01459751333687 %, lr:  0.00020050389809213204\n",
      "Epoch:  108 , validation loss:  0.8766464233398438 , validation accuracy:  27.35581934720584 %, lr:  0.00020050389809213204\n",
      "Epoch:  109 , validation loss:  0.8976217269897461 , validation accuracy:  28.095974953018874 %, lr:  0.00020050389809213204\n",
      "Epoch:  110 , validation loss:  0.8540549278259277 , validation accuracy:  28.021670832747198 %, lr:  0.00020050389809213204\n",
      "Epoch:  111 , validation loss:  0.9294508934020996 , validation accuracy:  27.21947489350344 %, lr:  0.00020050389809213204\n",
      "Epoch:  112 , validation loss:  0.8586661338806152 , validation accuracy:  28.19011755200387 %, lr:  0.00020050389809213204\n",
      "Epoch:  113 , validation loss:  0.8747140884399414 , validation accuracy:  26.89376314299215 %, lr:  0.00020050389809213204\n",
      "Epoch:  114 , validation loss:  1.020540142059326 , validation accuracy:  26.36822380689586 %, lr:  0.00020050389809213204\n",
      "Epoch:  115 , validation loss:  0.8640363693237305 , validation accuracy:  28.33692229448238 %, lr:  0.00020050389809213204\n",
      "Epoch:  116 , validation loss:  1.4627189636230469 , validation accuracy:  21.517535411684502 %, lr:  0.00020050389809213204\n",
      "Epoch:  117 , validation loss:  0.9023487091064453 , validation accuracy:  26.900616435638565 %, lr:  0.00020050389809213204\n",
      "Epoch:  118 , validation loss:  0.8628451347351074 , validation accuracy:  28.297966736281694 %, lr:  0.00020050389809213204\n",
      "Epoch:  119 , validation loss:  0.9093761444091797 , validation accuracy:  26.943178989968942 %, lr:  0.00020050389809213204\n",
      "Epoch:  120 , validation loss:  1.6675180435180663 , validation accuracy:  23.976424673296325 %, lr:  0.00020050389809213204\n",
      "Epoch:  121 , validation loss:  0.9063900947570801 , validation accuracy:  26.172724616666486 %, lr:  0.00020050389809213204\n",
      "Epoch:  122 , validation loss:  0.9777487754821778 , validation accuracy:  26.389505084061042 %, lr:  0.00020050389809213204\n",
      "Epoch:  123 , validation loss:  1.16453218460083 , validation accuracy:  25.98119312217978 %, lr:  0.00020050389809213204\n",
      "Epoch:  124 , validation loss:  1.057822036743164 , validation accuracy:  26.605924851842634 %, lr:  0.00020050389809213204\n",
      "Epoch:  125 , validation loss:  0.9473642349243164 , validation accuracy:  26.48581188072385 %, lr:  0.00020050389809213204\n",
      "Epoch:  126 , validation loss:  1.0643866539001465 , validation accuracy:  26.259653223392093 %, lr:  0.00020050389809213204\n",
      "Epoch:  127 , validation loss:  0.8752276420593261 , validation accuracy:  27.767377605603826 %, lr:  0.00020050389809213204\n",
      "Epoch:  128 , validation loss:  0.9787263870239258 , validation accuracy:  26.286344994751822 %, lr:  0.00020050389809213204\n",
      "Epoch:  129 , validation loss:  0.8718699455261231 , validation accuracy:  27.84564942161817 %, lr:  0.00020050389809213204\n",
      "Epoch:  130 , validation loss:  1.2192983627319336 , validation accuracy:  23.749905316351597 %, lr:  0.00020050389809213204\n",
      "Epoch:  131 , validation loss:  0.8708565711975098 , validation accuracy:  27.88965477440043 %, lr:  5.012597452303301e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  132 , validation loss:  0.8659470558166504 , validation accuracy:  28.278488957181345 %, lr:  5.012597452303301e-05\n",
      "Epoch:  133 , validation loss:  0.8327462196350097 , validation accuracy:  28.84623014799505 %, lr:  5.012597452303301e-05\n",
      "Epoch:  134 , validation loss:  0.8385174751281739 , validation accuracy:  28.661551946154763 %, lr:  5.012597452303301e-05\n",
      "Epoch:  135 , validation loss:  0.8581607818603516 , validation accuracy:  28.452706870245525 %, lr:  5.012597452303301e-05\n",
      "Epoch:  136 , validation loss:  0.8476727485656739 , validation accuracy:  28.4307041938544 %, lr:  5.012597452303301e-05\n",
      "Epoch:  137 , validation loss:  0.8656230926513672 , validation accuracy:  28.438639585339725 %, lr:  5.012597452303301e-05\n",
      "Epoch:  138 , validation loss:  0.8672338485717773 , validation accuracy:  28.042952109912385 %, lr:  5.012597452303301e-05\n",
      "Epoch:  139 , validation loss:  0.8496648788452148 , validation accuracy:  28.363614065842107 %, lr:  5.012597452303301e-05\n",
      "Epoch:  140 , validation loss:  0.8407341003417969 , validation accuracy:  28.624039186405952 %, lr:  5.012597452303301e-05\n",
      "Epoch:  141 , validation loss:  0.8398469924926758 , validation accuracy:  28.612496798790936 %, lr:  5.012597452303301e-05\n",
      "Epoch:  142 , validation loss:  0.8646501541137696 , validation accuracy:  28.28281735253698 %, lr:  5.012597452303301e-05\n",
      "Epoch:  143 , validation loss:  0.8314034461975097 , validation accuracy:  28.72611717687627 %, lr:  5.012597452303301e-05\n",
      "Epoch:  144 , validation loss:  0.8627188682556153 , validation accuracy:  28.189396152777928 %, lr:  5.012597452303301e-05\n",
      "Epoch:  145 , validation loss:  0.8477380752563477 , validation accuracy:  28.45018197295474 %, lr:  5.012597452303301e-05\n",
      "Epoch:  146 , validation loss:  0.8553605079650879 , validation accuracy:  28.040427212621598 %, lr:  5.012597452303301e-05\n",
      "Epoch:  147 , validation loss:  0.8854970932006836 , validation accuracy:  28.27307846298681 %, lr:  5.012597452303301e-05\n",
      "Epoch:  148 , validation loss:  0.846497917175293 , validation accuracy:  28.108599439472805 %, lr:  5.012597452303301e-05\n",
      "Epoch:  149 , validation loss:  0.8325001716613769 , validation accuracy:  28.876528915484474 %, lr:  5.012597452303301e-05\n",
      "Epoch:  150 , validation loss:  0.8532512664794922 , validation accuracy:  28.642434866667386 %, lr:  5.012597452303301e-05\n",
      "Epoch:  151 , validation loss:  0.8604220390319824 , validation accuracy:  28.18795335432605 %, lr:  5.012597452303301e-05\n",
      "Epoch:  152 , validation loss:  0.9817575454711914 , validation accuracy:  27.380346920887753 %, lr:  5.012597452303301e-05\n",
      "Epoch:  153 , validation loss:  0.8377297401428223 , validation accuracy:  28.771565328110405 %, lr:  5.012597452303301e-05\n",
      "Epoch:  154 , validation loss:  0.839276123046875 , validation accuracy:  28.502844116448262 %, lr:  5.012597452303301e-05\n",
      "Epoch:  155 , validation loss:  0.8440298080444336 , validation accuracy:  28.486612633864645 %, lr:  5.012597452303301e-05\n",
      "Epoch:  156 , validation loss:  0.8229964256286622 , validation accuracy:  28.955161431111787 %, lr:  5.012597452303301e-05\n",
      "Epoch:  157 , validation loss:  0.8208683013916016 , validation accuracy:  29.049664729709747 %, lr:  5.012597452303301e-05\n",
      "Epoch:  158 , validation loss:  0.8559879302978516 , validation accuracy:  28.691490014031213 %, lr:  5.012597452303301e-05\n",
      "Epoch:  159 , validation loss:  0.8247974395751954 , validation accuracy:  28.82206327392611 %, lr:  5.012597452303301e-05\n",
      "Epoch:  160 , validation loss:  0.855403995513916 , validation accuracy:  28.348103982484428 %, lr:  5.012597452303301e-05\n",
      "Epoch:  161 , validation loss:  0.8375555038452148 , validation accuracy:  28.823866771990954 %, lr:  5.012597452303301e-05\n",
      "Epoch:  162 , validation loss:  0.9314363479614258 , validation accuracy:  27.96612309234992 %, lr:  5.012597452303301e-05\n",
      "Epoch:  163 , validation loss:  0.8277857780456543 , validation accuracy:  28.877611014323385 %, lr:  5.012597452303301e-05\n",
      "Epoch:  164 , validation loss:  0.8479404449462891 , validation accuracy:  29.144889427533645 %, lr:  5.012597452303301e-05\n",
      "Epoch:  165 , validation loss:  0.8501813888549805 , validation accuracy:  28.81917767702235 %, lr:  5.012597452303301e-05\n",
      "Epoch:  166 , validation loss:  0.8334155082702637 , validation accuracy:  28.995559787764346 %, lr:  5.012597452303301e-05\n",
      "Epoch:  167 , validation loss:  0.8790533065795898 , validation accuracy:  28.643156265893328 %, lr:  5.012597452303301e-05\n",
      "Epoch:  168 , validation loss:  0.8190205574035645 , validation accuracy:  29.14164313101692 %, lr:  5.012597452303301e-05\n",
      "Epoch:  169 , validation loss:  0.8276859283447265 , validation accuracy:  28.96742521795274 %, lr:  5.012597452303301e-05\n",
      "Epoch:  170 , validation loss:  0.8241167068481445 , validation accuracy:  29.197912270640135 %, lr:  5.012597452303301e-05\n",
      "Epoch:  171 , validation loss:  0.8477712631225586 , validation accuracy:  28.605643506144517 %, lr:  5.012597452303301e-05\n",
      "Epoch:  172 , validation loss:  0.8226022720336914 , validation accuracy:  28.77877932036979 %, lr:  5.012597452303301e-05\n",
      "Epoch:  173 , validation loss:  0.8159697532653809 , validation accuracy:  29.132264941079715 %, lr:  5.012597452303301e-05\n",
      "Epoch:  174 , validation loss:  0.9160764694213868 , validation accuracy:  28.137094708897376 %, lr:  5.012597452303301e-05\n",
      "Epoch:  175 , validation loss:  0.8279041290283203 , validation accuracy:  29.230375235807372 %, lr:  5.012597452303301e-05\n",
      "Epoch:  176 , validation loss:  0.8398367881774902 , validation accuracy:  29.26283820097461 %, lr:  5.012597452303301e-05\n",
      "Epoch:  177 , validation loss:  0.8980484008789062 , validation accuracy:  28.88013591161417 %, lr:  5.012597452303301e-05\n",
      "Epoch:  178 , validation loss:  0.8576035499572754 , validation accuracy:  28.126634420121267 %, lr:  5.012597452303301e-05\n",
      "Epoch:  179 , validation loss:  0.8385269165039062 , validation accuracy:  28.748119853267397 %, lr:  5.012597452303301e-05\n",
      "Epoch:  180 , validation loss:  0.8480135917663574 , validation accuracy:  29.179155890765728 %, lr:  5.012597452303301e-05\n",
      "wandb: Agent Finished Run: r0u1b0z1 \n",
      "\n",
      "wandb: Agent Starting Run: 9wv3f7w6 with config:\n",
      "\tepochs: 172\n",
      "\thidden_dim: 34\n",
      "\tlr: 0.0008700796900365365\n",
      "\tn_graph_iters: 4\n",
      "\tnetwork: Edge_Track_Truth_Net\n",
      "\toptimizer: AdamW\n",
      "\ttrain_size: 146\n",
      "\tweight_decay: 0.00016358100599050222\n",
      "wandb: Agent Started Run: 9wv3f7w6\n",
      "Initialising W&B...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/9wv3f7w6\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/9wv3f7w6</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "config: {'epochs': 172, 'hidden_dim': 34, 'lr': 0.0008700796900365365, 'n_graph_iters': 4, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 146, 'weight_decay': 0.00016358100599050222}\n",
      "Using  cuda\n",
      "Loading model...\n",
      "Model configs:  {'input_dim': 3, 'hidden_dim': 34, 'n_graph_iters': 4, 'output_dim': 1}\n",
      "Loading optimiser\n",
      "Loading scheduler...\n",
      "Training...\n",
      "Epoch:  1 , validation loss:  1.9091020584106446 , validation accuracy:  14.68768824011052 %, lr:  0.0008700796900365365\n",
      "Epoch:  2 , validation loss:  1.8828346252441406 , validation accuracy:  11.820126317004462 %, lr:  0.0008700796900365365\n",
      "Epoch:  3 , validation loss:  1.8781972885131837 , validation accuracy:  10.52449330721868 %, lr:  0.0008700796900365365\n",
      "Epoch:  4 , validation loss:  1.878797721862793 , validation accuracy:  10.185435671027525 %, lr:  0.0008700796900365365\n",
      "Epoch:  5 , validation loss:  1.8755914688110351 , validation accuracy:  11.070953220867194 %, lr:  0.0008700796900365365\n",
      "Epoch:  6 , validation loss:  1.874929428100586 , validation accuracy:  11.211265370312258 %, lr:  0.0008700796900365365\n",
      "Epoch:  7 , validation loss:  1.8787546157836914 , validation accuracy:  9.9776726939572 %, lr:  0.0008700796900365365\n",
      "Epoch:  8 , validation loss:  1.873971939086914 , validation accuracy:  11.122893965134775 %, lr:  0.0008700796900365365\n",
      "Epoch:  9 , validation loss:  1.8713409423828125 , validation accuracy:  12.834774328287146 %, lr:  0.0008700796900365365\n",
      "Epoch:  10 , validation loss:  1.871236801147461 , validation accuracy:  12.979775572700811 %, lr:  0.0008700796900365365\n",
      "Epoch:  11 , validation loss:  1.8720191955566405 , validation accuracy:  12.623404355087128 %, lr:  0.0008700796900365365\n",
      "Epoch:  12 , validation loss:  1.87054443359375 , validation accuracy:  11.270420106839225 %, lr:  0.0008700796900365365\n",
      "Epoch:  13 , validation loss:  1.8748615264892579 , validation accuracy:  10.416644122940856 %, lr:  0.0008700796900365365\n",
      "Epoch:  14 , validation loss:  1.8672977447509767 , validation accuracy:  11.803173435194903 %, lr:  0.0008700796900365365\n",
      "Epoch:  15 , validation loss:  1.8674930572509765 , validation accuracy:  12.164955147003127 %, lr:  0.0008700796900365365\n",
      "Epoch:  16 , validation loss:  1.8677070617675782 , validation accuracy:  11.097284292613955 %, lr:  0.0008700796900365365\n",
      "Epoch:  17 , validation loss:  1.8665931701660157 , validation accuracy:  11.86846006514235 %, lr:  0.0008700796900365365\n",
      "Epoch:  18 , validation loss:  1.8662399291992187 , validation accuracy:  10.745602169968873 %, lr:  0.0008700796900365365\n",
      "Epoch:  19 , validation loss:  1.8653430938720703 , validation accuracy:  11.680896266398307 %, lr:  0.0008700796900365365\n",
      "Epoch:  20 , validation loss:  1.8633066177368165 , validation accuracy:  11.042097251829649 %, lr:  0.0008700796900365365\n",
      "Epoch:  21 , validation loss:  1.8655145645141602 , validation accuracy:  11.628955522130726 %, lr:  0.0008700796900365365\n",
      "Epoch:  22 , validation loss:  1.8602149963378907 , validation accuracy:  11.119647668618052 %, lr:  0.0008700796900365365\n",
      "Epoch:  23 , validation loss:  1.8637565612792968 , validation accuracy:  11.90020163108365 %, lr:  0.0008700796900365365\n",
      "Epoch:  24 , validation loss:  1.8670286178588866 , validation accuracy:  11.609117043417411 %, lr:  0.0008700796900365365\n",
      "Epoch:  25 , validation loss:  1.861711311340332 , validation accuracy:  11.702538243176464 %, lr:  0.0008700796900365365\n",
      "Epoch:  26 , validation loss:  1.864016342163086 , validation accuracy:  12.371996724847515 %, lr:  0.0008700796900365365\n",
      "Epoch:  27 , validation loss:  1.8580778121948243 , validation accuracy:  11.567275888312972 %, lr:  0.0008700796900365365\n",
      "Epoch:  28 , validation loss:  1.8646917343139648 , validation accuracy:  13.237315096360902 %, lr:  0.0008700796900365365\n",
      "Epoch:  29 , validation loss:  1.8161035537719727 , validation accuracy:  11.21595446528086 %, lr:  0.0008700796900365365\n",
      "Epoch:  30 , validation loss:  1.7410322189331056 , validation accuracy:  19.261359332561437 %, lr:  0.0008700796900365365\n",
      "Epoch:  31 , validation loss:  1.8659385681152343 , validation accuracy:  11.368891101179848 %, lr:  0.0008700796900365365\n",
      "Epoch:  32 , validation loss:  1.8962068557739258 , validation accuracy:  11.192508990437853 %, lr:  0.0008700796900365365\n",
      "Epoch:  33 , validation loss:  1.880035972595215 , validation accuracy:  10.939658561746363 %, lr:  0.0008700796900365365\n",
      "Epoch:  34 , validation loss:  1.8759328842163085 , validation accuracy:  10.703761014864432 %, lr:  0.0008700796900365365\n",
      "Epoch:  35 , validation loss:  1.8734626770019531 , validation accuracy:  11.22064356024946 %, lr:  0.0008700796900365365\n",
      "Epoch:  36 , validation loss:  1.8701082229614259 , validation accuracy:  11.303604471232402 %, lr:  0.0008700796900365365\n",
      "Epoch:  37 , validation loss:  1.8684453964233398 , validation accuracy:  11.764217876994218 %, lr:  0.0008700796900365365\n",
      "Epoch:  38 , validation loss:  1.8554546356201171 , validation accuracy:  11.374662294987358 %, lr:  0.0008700796900365365\n",
      "Epoch:  39 , validation loss:  1.7743034362792969 , validation accuracy:  12.60500867482569 %, lr:  0.0008700796900365365\n",
      "Epoch:  40 , validation loss:  1.537874412536621 , validation accuracy:  19.062253146202373 %, lr:  0.0008700796900365365\n",
      "Epoch:  41 , validation loss:  1.855858612060547 , validation accuracy:  11.724540919567593 %, lr:  0.0008700796900365365\n",
      "Epoch:  42 , validation loss:  1.612173080444336 , validation accuracy:  20.35463985947143 %, lr:  0.0008700796900365365\n",
      "Epoch:  43 , validation loss:  1.5371548652648925 , validation accuracy:  19.03772557252046 %, lr:  0.0008700796900365365\n",
      "Epoch:  44 , validation loss:  1.5401498794555664 , validation accuracy:  19.957148885979244 %, lr:  0.0008700796900365365\n",
      "Epoch:  45 , validation loss:  1.5458714485168457 , validation accuracy:  21.013277352753402 %, lr:  0.0008700796900365365\n",
      "Epoch:  46 , validation loss:  1.4173523902893066 , validation accuracy:  21.943882354214235 %, lr:  0.0008700796900365365\n",
      "Epoch:  47 , validation loss:  1.318661594390869 , validation accuracy:  15.67672657887238 %, lr:  0.0008700796900365365\n",
      "Epoch:  48 , validation loss:  1.2798543930053712 , validation accuracy:  23.55729172302598 %, lr:  0.0008700796900365365\n",
      "Epoch:  49 , validation loss:  1.1925409317016602 , validation accuracy:  23.49561208920823 %, lr:  0.0008700796900365365\n",
      "Epoch:  50 , validation loss:  1.7558570861816407 , validation accuracy:  16.386944116808962 %, lr:  0.0008700796900365365\n",
      "Epoch:  51 , validation loss:  1.1730181694030761 , validation accuracy:  24.65742554258239 %, lr:  0.0008700796900365365\n",
      "Epoch:  52 , validation loss:  1.8743942260742188 , validation accuracy:  10.246393905619339 %, lr:  0.0008700796900365365\n",
      "Epoch:  53 , validation loss:  1.3083318710327148 , validation accuracy:  24.24334238689362 %, lr:  0.0008700796900365365\n",
      "Epoch:  54 , validation loss:  1.1964189529418945 , validation accuracy:  24.19392653991682 %, lr:  0.0008700796900365365\n",
      "Epoch:  55 , validation loss:  1.6691991806030273 , validation accuracy:  13.34336078257388 %, lr:  0.0008700796900365365\n",
      "Epoch:  56 , validation loss:  1.453813362121582 , validation accuracy:  21.510682119038087 %, lr:  0.0008700796900365365\n",
      "Epoch:  57 , validation loss:  1.216287612915039 , validation accuracy:  20.288631830298044 %, lr:  0.0008700796900365365\n",
      "Epoch:  58 , validation loss:  1.8511173248291015 , validation accuracy:  11.88938064269457 %, lr:  0.0008700796900365365\n",
      "Epoch:  59 , validation loss:  1.784700584411621 , validation accuracy:  14.651978978426555 %, lr:  0.0008700796900365365\n",
      "Epoch:  60 , validation loss:  1.3472758293151856 , validation accuracy:  23.86316499482396 %, lr:  0.0008700796900365365\n",
      "Epoch:  61 , validation loss:  1.1223159790039063 , validation accuracy:  25.81671409866577 %, lr:  0.0008700796900365365\n",
      "Epoch:  62 , validation loss:  1.136856746673584 , validation accuracy:  25.89787151158387 %, lr:  0.0008700796900365365\n",
      "Epoch:  63 , validation loss:  1.0784418106079101 , validation accuracy:  22.244705831430643 %, lr:  0.0008700796900365365\n",
      "Epoch:  64 , validation loss:  1.7639089584350587 , validation accuracy:  26.279852401718372 %, lr:  0.0008700796900365365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  65 , validation loss:  1.6932043075561523 , validation accuracy:  21.44070639412204 %, lr:  0.0008700796900365365\n",
      "Epoch:  66 , validation loss:  1.2593038558959961 , validation accuracy:  25.01199326213123 %, lr:  0.0008700796900365365\n",
      "Epoch:  67 , validation loss:  1.6258859634399414 , validation accuracy:  24.519998990041085 %, lr:  0.0008700796900365365\n",
      "Epoch:  68 , validation loss:  1.2179710388183593 , validation accuracy:  26.45984150859006 %, lr:  0.0008700796900365365\n",
      "Epoch:  69 , validation loss:  1.5390396118164062 , validation accuracy:  13.65500524817937 %, lr:  0.0008700796900365365\n",
      "Epoch:  70 , validation loss:  1.7202926635742188 , validation accuracy:  12.805196960023663 %, lr:  0.0008700796900365365\n",
      "Epoch:  71 , validation loss:  2.1845218658447267 , validation accuracy:  21.404997132438076 %, lr:  0.0008700796900365365\n",
      "Epoch:  72 , validation loss:  1.9830757141113282 , validation accuracy:  18.94177947547062 %, lr:  0.0008700796900365365\n",
      "Epoch:  73 , validation loss:  1.0595307350158691 , validation accuracy:  23.050148067191124 %, lr:  0.0008700796900365365\n",
      "Epoch:  74 , validation loss:  1.9067169189453126 , validation accuracy:  21.59905352421557 %, lr:  0.0008700796900365365\n",
      "Epoch:  75 , validation loss:  1.383343505859375 , validation accuracy:  26.34044993669722 %, lr:  0.0008700796900365365\n",
      "Epoch:  76 , validation loss:  1.0287103652954102 , validation accuracy:  24.4997998117148 %, lr:  0.0008700796900365365\n",
      "Epoch:  77 , validation loss:  1.7320590972900392 , validation accuracy:  13.17022496834861 %, lr:  0.0008700796900365365\n",
      "Epoch:  78 , validation loss:  1.0700763702392577 , validation accuracy:  26.47066249697914 %, lr:  0.0008700796900365365\n",
      "Epoch:  79 , validation loss:  1.3808688163757323 , validation accuracy:  24.570496935856788 %, lr:  0.0008700796900365365\n",
      "Epoch:  80 , validation loss:  1.0555846214294433 , validation accuracy:  25.689026435674634 %, lr:  0.0008700796900365365\n",
      "Epoch:  81 , validation loss:  1.3167749404907227 , validation accuracy:  24.444973470543466 %, lr:  0.0008700796900365365\n",
      "Epoch:  82 , validation loss:  1.138130283355713 , validation accuracy:  26.979970350491815 %, lr:  0.0008700796900365365\n",
      "Epoch:  83 , validation loss:  1.0336505889892578 , validation accuracy:  32.0265186355455 %, lr:  0.0008700796900365365\n",
      "Epoch:  84 , validation loss:  1.5250054359436036 , validation accuracy:  22.485292473281177 %, lr:  0.0008700796900365365\n",
      "Epoch:  85 , validation loss:  0.9738507270812988 , validation accuracy:  30.38497469692215 %, lr:  0.0008700796900365365\n",
      "Epoch:  86 , validation loss:  1.2661834716796876 , validation accuracy:  26.601235756874033 %, lr:  0.0008700796900365365\n",
      "Epoch:  87 , validation loss:  1.1661727905273438 , validation accuracy:  24.245506584571437 %, lr:  0.0008700796900365365\n",
      "Epoch:  88 , validation loss:  1.8942483901977538 , validation accuracy:  14.519602220466817 %, lr:  0.0008700796900365365\n",
      "Epoch:  89 , validation loss:  1.5688469886779786 , validation accuracy:  15.371214006687369 %, lr:  0.0008700796900365365\n",
      "Epoch:  90 , validation loss:  1.7916484832763673 , validation accuracy:  17.360111672600176 %, lr:  0.0008700796900365365\n",
      "Epoch:  91 , validation loss:  1.0151030540466308 , validation accuracy:  28.029606224232523 %, lr:  0.0008700796900365365\n",
      "Epoch:  92 , validation loss:  1.338762092590332 , validation accuracy:  16.785156489527086 %, lr:  0.0008700796900365365\n",
      "Epoch:  93 , validation loss:  1.5106770515441894 , validation accuracy:  14.871284343111899 %, lr:  0.0008700796900365365\n",
      "Epoch:  94 , validation loss:  1.0265830993652343 , validation accuracy:  25.586948445204317 %, lr:  0.0008700796900365365\n",
      "Epoch:  95 , validation loss:  1.7462806701660156 , validation accuracy:  20.516233286081683 %, lr:  0.0008700796900365365\n",
      "Epoch:  96 , validation loss:  1.4238821983337402 , validation accuracy:  22.927510198781555 %, lr:  0.0008700796900365365\n",
      "Epoch:  97 , validation loss:  2.007895278930664 , validation accuracy:  19.50122457518603 %, lr:  0.0008700796900365365\n",
      "Epoch:  98 , validation loss:  1.8319753646850585 , validation accuracy:  11.950699576899353 %, lr:  0.0008700796900365365\n",
      "Epoch:  99 , validation loss:  1.716162872314453 , validation accuracy:  14.9935615119085 %, lr:  0.0008700796900365365\n",
      "Epoch:  100 , validation loss:  1.555234718322754 , validation accuracy:  18.481887468934747 %, lr:  0.0008700796900365365\n",
      "Epoch:  101 , validation loss:  1.3176687240600586 , validation accuracy:  22.56176079123067 %, lr:  0.0008700796900365365\n",
      "Epoch:  102 , validation loss:  1.3892216682434082 , validation accuracy:  17.54587197327937 %, lr:  0.0008700796900365365\n",
      "Epoch:  103 , validation loss:  1.449809455871582 , validation accuracy:  19.574085897005833 %, lr:  0.0008700796900365365\n",
      "Epoch:  104 , validation loss:  1.339412021636963 , validation accuracy:  15.453453518444373 %, lr:  0.0008700796900365365\n",
      "Epoch:  105 , validation loss:  1.0522964477539063 , validation accuracy:  27.152384765491146 %, lr:  0.0008700796900365365\n",
      "Epoch:  106 , validation loss:  1.0426014900207519 , validation accuracy:  27.088540933995574 %, lr:  0.00021751992250913413\n",
      "Epoch:  107 , validation loss:  1.0932597160339355 , validation accuracy:  31.214944506364546 %, lr:  0.00021751992250913413\n",
      "Epoch:  108 , validation loss:  0.947214412689209 , validation accuracy:  22.28366138963133 %, lr:  0.00021751992250913413\n",
      "Epoch:  109 , validation loss:  0.9468029022216797 , validation accuracy:  34.172681332712926 %, lr:  0.00021751992250913413\n",
      "Epoch:  110 , validation loss:  0.8535520553588867 , validation accuracy:  35.94443783161821 %, lr:  0.00021751992250913413\n",
      "Epoch:  111 , validation loss:  0.8654616355895997 , validation accuracy:  36.53742799533976 %, lr:  0.00021751992250913413\n",
      "Epoch:  112 , validation loss:  1.439758014678955 , validation accuracy:  22.35003011841768 %, lr:  0.00021751992250913413\n",
      "Epoch:  113 , validation loss:  0.8719218254089356 , validation accuracy:  36.24562200844758 %, lr:  0.00021751992250913413\n",
      "Epoch:  114 , validation loss:  0.9124546051025391 , validation accuracy:  35.601412499684386 %, lr:  0.00021751992250913413\n",
      "Epoch:  115 , validation loss:  0.8706149101257324 , validation accuracy:  36.46853436926262 %, lr:  0.00021751992250913413\n",
      "Epoch:  116 , validation loss:  0.9688322067260742 , validation accuracy:  37.0965123954422 %, lr:  0.00021751992250913413\n",
      "Epoch:  117 , validation loss:  0.9642034530639648 , validation accuracy:  31.75058343162398 %, lr:  0.00021751992250913413\n",
      "Epoch:  118 , validation loss:  0.9446479797363281 , validation accuracy:  30.19993579546889 %, lr:  0.00021751992250913413\n",
      "Epoch:  119 , validation loss:  0.9206454277038574 , validation accuracy:  24.5903354145701 %, lr:  0.00021751992250913413\n",
      "Epoch:  120 , validation loss:  0.9856614112854004 , validation accuracy:  30.81709283325939 %, lr:  0.00021751992250913413\n",
      "Epoch:  121 , validation loss:  0.8510397911071778 , validation accuracy:  35.52386208289599 %, lr:  0.00021751992250913413\n",
      "Epoch:  122 , validation loss:  1.0360285758972168 , validation accuracy:  28.686079519836678 %, lr:  0.00021751992250913413\n",
      "Epoch:  123 , validation loss:  1.1119613647460938 , validation accuracy:  31.970610195535258 %, lr:  0.00021751992250913413\n",
      "Epoch:  124 , validation loss:  0.8385290145874024 , validation accuracy:  38.35932174044777 %, lr:  0.00021751992250913413\n",
      "Epoch:  125 , validation loss:  1.0371879577636718 , validation accuracy:  35.27173305343043 %, lr:  0.00021751992250913413\n",
      "Epoch:  126 , validation loss:  0.7970840454101562 , validation accuracy:  33.16669011214151 %, lr:  0.00021751992250913413\n",
      "Epoch:  127 , validation loss:  0.8473675727844239 , validation accuracy:  27.84564942161817 %, lr:  0.00021751992250913413\n",
      "Epoch:  128 , validation loss:  0.8718366622924805 , validation accuracy:  38.30088840314674 %, lr:  0.00021751992250913413\n",
      "Epoch:  129 , validation loss:  1.0377089500427246 , validation accuracy:  30.861458885654613 %, lr:  0.00021751992250913413\n",
      "Epoch:  130 , validation loss:  0.7974385261535645 , validation accuracy:  38.92778433048741 %, lr:  0.00021751992250913413\n",
      "Epoch:  131 , validation loss:  1.3939054489135743 , validation accuracy:  19.050350058974384 %, lr:  0.00021751992250913413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  132 , validation loss:  0.8495532035827636 , validation accuracy:  30.44412943344912 %, lr:  0.00021751992250913413\n",
      "Epoch:  133 , validation loss:  0.9021702766418457 , validation accuracy:  38.13027748621226 %, lr:  0.00021751992250913413\n",
      "Epoch:  134 , validation loss:  1.1213175773620605 , validation accuracy:  32.93439956138927 %, lr:  0.00021751992250913413\n",
      "Epoch:  135 , validation loss:  0.95166015625 , validation accuracy:  38.00980381548051 %, lr:  0.00021751992250913413\n",
      "Epoch:  136 , validation loss:  0.9642169952392579 , validation accuracy:  33.76004097547604 %, lr:  0.00021751992250913413\n",
      "Epoch:  137 , validation loss:  0.8909928321838378 , validation accuracy:  36.02162754879364 %, lr:  0.00021751992250913413\n",
      "Epoch:  138 , validation loss:  0.962371826171875 , validation accuracy:  33.47797387813402 %, lr:  0.00021751992250913413\n",
      "Epoch:  139 , validation loss:  0.8349101066589355 , validation accuracy:  40.10474716760629 %, lr:  0.00021751992250913413\n",
      "Epoch:  140 , validation loss:  3.6241119384765623 , validation accuracy:  27.694876983397 %, lr:  0.00021751992250913413\n",
      "Epoch:  141 , validation loss:  0.8459962844848633 , validation accuracy:  38.99451375888673 %, lr:  0.00021751992250913413\n",
      "Epoch:  142 , validation loss:  0.8373771667480469 , validation accuracy:  37.232135449918665 %, lr:  0.00021751992250913413\n",
      "Epoch:  143 , validation loss:  0.8586843490600586 , validation accuracy:  40.05713481869434 %, lr:  0.00021751992250913413\n",
      "Epoch:  144 , validation loss:  0.7716686725616455 , validation accuracy:  39.42879609290179 %, lr:  0.00021751992250913413\n",
      "Epoch:  145 , validation loss:  0.8137798309326172 , validation accuracy:  37.040243255818986 %, lr:  0.00021751992250913413\n",
      "Epoch:  146 , validation loss:  1.7415000915527343 , validation accuracy:  28.853444140254435 %, lr:  0.00021751992250913413\n",
      "Epoch:  147 , validation loss:  1.0251032829284668 , validation accuracy:  36.679904342462635 %, lr:  0.00021751992250913413\n",
      "Epoch:  148 , validation loss:  0.843055534362793 , validation accuracy:  40.62343321105617 %, lr:  0.00021751992250913413\n",
      "Epoch:  149 , validation loss:  0.7347175121307373 , validation accuracy:  39.9528926305462 %, lr:  0.00021751992250913413\n",
      "Epoch:  150 , validation loss:  0.8593297958374023 , validation accuracy:  36.22181583399161 %, lr:  0.00021751992250913413\n",
      "Epoch:  151 , validation loss:  1.2638029098510741 , validation accuracy:  29.56474377702993 %, lr:  0.00021751992250913413\n",
      "Epoch:  152 , validation loss:  0.9223179817199707 , validation accuracy:  30.781383571575425 %, lr:  0.00021751992250913413\n",
      "Epoch:  153 , validation loss:  1.2662925720214844 , validation accuracy:  36.19981315760048 %, lr:  0.00021751992250913413\n",
      "Epoch:  154 , validation loss:  1.7762203216552734 , validation accuracy:  29.26428099942649 %, lr:  0.00021751992250913413\n",
      "Epoch:  155 , validation loss:  0.7612086772918701 , validation accuracy:  38.93427692352086 %, lr:  0.00021751992250913413\n",
      "Epoch:  156 , validation loss:  1.3173569679260253 , validation accuracy:  31.88043529229293 %, lr:  0.00021751992250913413\n",
      "Epoch:  157 , validation loss:  0.9008918762207031 , validation accuracy:  17.52819769224388 %, lr:  0.00021751992250913413\n",
      "Epoch:  158 , validation loss:  1.1305258750915528 , validation accuracy:  33.12701315471489 %, lr:  0.00021751992250913413\n",
      "Epoch:  159 , validation loss:  0.6899665355682373 , validation accuracy:  41.39605178203644 %, lr:  0.00021751992250913413\n",
      "Epoch:  160 , validation loss:  0.8177039146423339 , validation accuracy:  34.66575770364199 %, lr:  0.00021751992250913413\n",
      "Epoch:  161 , validation loss:  0.8420660018920898 , validation accuracy:  29.65347588182038 %, lr:  0.00021751992250913413\n",
      "Epoch:  162 , validation loss:  0.8792328834533691 , validation accuracy:  38.08338653652625 %, lr:  0.00021751992250913413\n",
      "Epoch:  163 , validation loss:  0.8341251373291015 , validation accuracy:  38.81199975472426 %, lr:  0.00021751992250913413\n",
      "Epoch:  164 , validation loss:  0.7425952434539795 , validation accuracy:  42.54488004934371 %, lr:  0.00021751992250913413\n",
      "Epoch:  165 , validation loss:  1.2195145606994628 , validation accuracy:  25.43401180930533 %, lr:  0.00021751992250913413\n",
      "Epoch:  166 , validation loss:  0.8244542121887207 , validation accuracy:  36.39603374705579 %, lr:  0.00021751992250913413\n",
      "Epoch:  167 , validation loss:  0.7377734661102295 , validation accuracy:  38.200974610354244 %, lr:  0.00021751992250913413\n",
      "Epoch:  168 , validation loss:  0.9013158798217773 , validation accuracy:  37.57011098727091 %, lr:  0.00021751992250913413\n",
      "Epoch:  169 , validation loss:  0.7860296249389649 , validation accuracy:  27.886047778270733 %, lr:  0.00021751992250913413\n",
      "Epoch:  170 , validation loss:  0.7998441696166992 , validation accuracy:  40.04198543494963 %, lr:  0.00021751992250913413\n",
      "Epoch:  171 , validation loss:  0.7374943733215332 , validation accuracy:  37.82909330938288 %, lr:  0.00021751992250913413\n",
      "Epoch:  172 , validation loss:  1.053414249420166 , validation accuracy:  25.17430808796742 %, lr:  0.00021751992250913413\n",
      "wandb: Agent Finished Run: 9wv3f7w6 \n",
      "\n",
      "wandb: Agent Starting Run: fles6abx with config:\n",
      "\tepochs: 211\n",
      "\thidden_dim: 46\n",
      "\tlr: 0.0009623351230037094\n",
      "\tn_graph_iters: 2\n",
      "\tnetwork: Edge_Track_Truth_Net\n",
      "\toptimizer: AdamW\n",
      "\ttrain_size: 413\n",
      "\tweight_decay: 2.0068652397108902e-05\n",
      "wandb: Agent Started Run: fles6abx\n",
      "Initialising W&B...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fles6abx\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fles6abx</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "config: {'epochs': 211, 'hidden_dim': 46, 'lr': 0.0009623351230037094, 'n_graph_iters': 2, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 413, 'weight_decay': 2.0068652397108905e-05}\n",
      "Using  cuda\n",
      "Loading model...\n",
      "Model configs:  {'input_dim': 3, 'hidden_dim': 46, 'n_graph_iters': 2, 'output_dim': 1}\n",
      "Loading optimiser\n",
      "Loading scheduler...\n",
      "Training...\n",
      "Epoch:  1 , validation loss:  1.878549575805664 , validation accuracy:  10.806921104173655 %, lr:  0.0009623351230037094\n",
      "Epoch:  2 , validation loss:  1.8768560409545898 , validation accuracy:  10.813052997594133 %, lr:  0.0009623351230037094\n",
      "Epoch:  3 , validation loss:  1.8763357162475587 , validation accuracy:  10.39896984190536 %, lr:  0.0009623351230037094\n",
      "Epoch:  4 , validation loss:  1.8820119857788087 , validation accuracy:  9.786862598696432 %, lr:  0.0009623351230037094\n",
      "Epoch:  5 , validation loss:  1.8735223770141602 , validation accuracy:  10.906834896966156 %, lr:  0.0009623351230037094\n",
      "Epoch:  6 , validation loss:  1.8740242004394532 , validation accuracy:  10.737306078870578 %, lr:  0.0009623351230037094\n",
      "Epoch:  7 , validation loss:  1.8778112411499024 , validation accuracy:  10.084079079783146 %, lr:  0.0009623351230037094\n",
      "Epoch:  8 , validation loss:  1.871331787109375 , validation accuracy:  12.686887486969725 %, lr:  0.0009623351230037094\n",
      "Epoch:  9 , validation loss:  1.8749990463256836 , validation accuracy:  13.559419850742499 %, lr:  0.0009623351230037094\n",
      "Epoch:  10 , validation loss:  1.8678085327148437 , validation accuracy:  12.457121833508273 %, lr:  0.0009623351230037094\n",
      "Epoch:  11 , validation loss:  1.868357276916504 , validation accuracy:  11.507399752560065 %, lr:  0.0009623351230037094\n",
      "Epoch:  12 , validation loss:  1.8668481826782226 , validation accuracy:  12.017068305685708 %, lr:  0.0009623351230037094\n",
      "Epoch:  13 , validation loss:  1.8658418655395508 , validation accuracy:  11.938435790058398 %, lr:  0.0009623351230037094\n",
      "Epoch:  14 , validation loss:  1.8653430938720703 , validation accuracy:  12.662359913287812 %, lr:  0.0009623351230037094\n",
      "Epoch:  15 , validation loss:  1.8647773742675782 , validation accuracy:  12.984464667669412 %, lr:  0.0009623351230037094\n",
      "Epoch:  16 , validation loss:  1.8660457611083985 , validation accuracy:  13.271581559592988 %, lr:  0.0009623351230037094\n",
      "Epoch:  17 , validation loss:  1.876143455505371 , validation accuracy:  11.668993179170318 %, lr:  0.0009623351230037094\n",
      "Epoch:  18 , validation loss:  1.8663200378417968 , validation accuracy:  12.69518357806802 %, lr:  0.0009623351230037094\n",
      "Epoch:  19 , validation loss:  1.8690092086791992 , validation accuracy:  11.982080443227684 %, lr:  0.0009623351230037094\n",
      "Epoch:  20 , validation loss:  1.8649164199829102 , validation accuracy:  13.437142681945902 %, lr:  0.0009623351230037094\n",
      "Epoch:  21 , validation loss:  1.8641124725341798 , validation accuracy:  12.511948174679608 %, lr:  0.0009623351230037094\n",
      "Epoch:  22 , validation loss:  1.8614019393920898 , validation accuracy:  13.188620648610044 %, lr:  0.0009623351230037094\n",
      "Epoch:  23 , validation loss:  1.8124277114868164 , validation accuracy:  15.217555971562444 %, lr:  0.0009623351230037094\n",
      "Epoch:  24 , validation loss:  1.8086629867553712 , validation accuracy:  13.0374875107759 %, lr:  0.0009623351230037094\n",
      "Epoch:  25 , validation loss:  1.3741058349609374 , validation accuracy:  22.897572130905104 %, lr:  0.0009623351230037094\n",
      "Epoch:  26 , validation loss:  1.778122329711914 , validation accuracy:  10.121952539144925 %, lr:  0.0009623351230037094\n",
      "Epoch:  27 , validation loss:  1.5936247825622558 , validation accuracy:  18.081150198925837 %, lr:  0.0009623351230037094\n",
      "Epoch:  28 , validation loss:  1.2334193229675292 , validation accuracy:  19.27686941591912 %, lr:  0.0009623351230037094\n",
      "Epoch:  29 , validation loss:  1.2050050735473632 , validation accuracy:  23.618610657230764 %, lr:  0.0009623351230037094\n",
      "Epoch:  30 , validation loss:  1.2857711791992188 , validation accuracy:  16.44104905875436 %, lr:  0.0009623351230037094\n",
      "Epoch:  31 , validation loss:  1.7269590377807618 , validation accuracy:  20.860340716854413 %, lr:  0.0009623351230037094\n",
      "Epoch:  32 , validation loss:  1.2796895980834961 , validation accuracy:  24.313318111809664 %, lr:  0.0009623351230037094\n",
      "Epoch:  33 , validation loss:  1.6405042648315429 , validation accuracy:  16.605888781881337 %, lr:  0.0009623351230037094\n",
      "Epoch:  34 , validation loss:  1.2176339149475097 , validation accuracy:  22.61478363433716 %, lr:  0.0009623351230037094\n",
      "Epoch:  35 , validation loss:  1.406186008453369 , validation accuracy:  17.769866432933316 %, lr:  0.0009623351230037094\n",
      "Epoch:  36 , validation loss:  1.5232032775878905 , validation accuracy:  17.377785953635673 %, lr:  0.0009623351230037094\n",
      "Epoch:  37 , validation loss:  2.26080322265625 , validation accuracy:  21.090467069928835 %, lr:  0.0009623351230037094\n",
      "Epoch:  38 , validation loss:  1.0945672988891602 , validation accuracy:  33.27670349409715 %, lr:  0.0009623351230037094\n",
      "Epoch:  39 , validation loss:  1.3072185516357422 , validation accuracy:  31.87827109461512 %, lr:  0.0009623351230037094\n",
      "Epoch:  40 , validation loss:  1.7738916397094726 , validation accuracy:  12.931802524175891 %, lr:  0.0009623351230037094\n",
      "Epoch:  41 , validation loss:  1.3055990219116211 , validation accuracy:  19.029429481422167 %, lr:  0.0009623351230037094\n",
      "Epoch:  42 , validation loss:  1.5328802108764648 , validation accuracy:  19.677967385540995 %, lr:  0.0009623351230037094\n",
      "Epoch:  43 , validation loss:  1.1573363304138184 , validation accuracy:  31.542820454553656 %, lr:  0.0009623351230037094\n",
      "Epoch:  44 , validation loss:  1.1984390258789062 , validation accuracy:  32.094330162783734 %, lr:  0.0009623351230037094\n",
      "Epoch:  45 , validation loss:  1.1493013381958008 , validation accuracy:  30.851719996104443 %, lr:  0.0009623351230037094\n",
      "Epoch:  46 , validation loss:  0.9898947715759278 , validation accuracy:  35.26199416388026 %, lr:  0.0009623351230037094\n",
      "Epoch:  47 , validation loss:  1.37811222076416 , validation accuracy:  24.513506397007635 %, lr:  0.0009623351230037094\n",
      "Epoch:  48 , validation loss:  1.4442789077758789 , validation accuracy:  18.04147324149921 %, lr:  0.0009623351230037094\n",
      "Epoch:  49 , validation loss:  1.3680171012878417 , validation accuracy:  31.246325372692873 %, lr:  0.0009623351230037094\n",
      "Epoch:  50 , validation loss:  1.441175365447998 , validation accuracy:  23.594443783161818 %, lr:  0.0009623351230037094\n",
      "Epoch:  51 , validation loss:  0.9483741760253906 , validation accuracy:  39.749458048831514 %, lr:  0.0009623351230037094\n",
      "Epoch:  52 , validation loss:  1.134354019165039 , validation accuracy:  28.68824371751449 %, lr:  0.0009623351230037094\n",
      "Epoch:  53 , validation loss:  1.6096343994140625 , validation accuracy:  23.016242303572007 %, lr:  0.0009623351230037094\n",
      "Epoch:  54 , validation loss:  1.1088279724121093 , validation accuracy:  24.19464793914276 %, lr:  0.0009623351230037094\n",
      "Epoch:  55 , validation loss:  1.3940546989440918 , validation accuracy:  24.32630329787656 %, lr:  0.0009623351230037094\n",
      "Epoch:  56 , validation loss:  1.46423282623291 , validation accuracy:  21.885809716526175 %, lr:  0.0009623351230037094\n",
      "Epoch:  57 , validation loss:  1.1658645629882813 , validation accuracy:  28.938569248915197 %, lr:  0.0009623351230037094\n",
      "Epoch:  58 , validation loss:  1.0027233123779298 , validation accuracy:  30.761905792475087 %, lr:  0.0009623351230037094\n",
      "Epoch:  59 , validation loss:  1.1047062873840332 , validation accuracy:  35.34495507486321 %, lr:  0.0009623351230037094\n",
      "Epoch:  60 , validation loss:  1.5376065254211426 , validation accuracy:  18.42201133318184 %, lr:  0.0009623351230037094\n",
      "Epoch:  61 , validation loss:  1.135129737854004 , validation accuracy:  28.278488957181345 %, lr:  0.0009623351230037094\n",
      "Epoch:  62 , validation loss:  1.1635416984558105 , validation accuracy:  32.77533103206981 %, lr:  0.0009623351230037094\n",
      "Epoch:  63 , validation loss:  1.0287334442138671 , validation accuracy:  37.19822968629954 %, lr:  0.0009623351230037094\n",
      "Epoch:  64 , validation loss:  1.3969810485839844 , validation accuracy:  30.124910275971274 %, lr:  0.0009623351230037094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  65 , validation loss:  1.2528239250183106 , validation accuracy:  25.814549900987956 %, lr:  0.0009623351230037094\n",
      "Epoch:  66 , validation loss:  1.3192296981811524 , validation accuracy:  23.706260663182306 %, lr:  0.0009623351230037094\n",
      "Epoch:  67 , validation loss:  1.0039659500122071 , validation accuracy:  35.43765487539632 %, lr:  0.0009623351230037094\n",
      "Epoch:  68 , validation loss:  0.9390053749084473 , validation accuracy:  42.98962267213488 %, lr:  0.0009623351230037094\n",
      "Epoch:  69 , validation loss:  1.0332667350769043 , validation accuracy:  35.511958995667996 %, lr:  0.0009623351230037094\n",
      "Epoch:  70 , validation loss:  1.097170639038086 , validation accuracy:  30.914842428374072 %, lr:  0.0009623351230037094\n",
      "Epoch:  71 , validation loss:  1.311798095703125 , validation accuracy:  20.679269511143815 %, lr:  0.0009623351230037094\n",
      "Epoch:  72 , validation loss:  1.2232470512390137 , validation accuracy:  29.664657569822428 %, lr:  0.0009623351230037094\n",
      "Epoch:  73 , validation loss:  1.252298641204834 , validation accuracy:  26.93560429809659 %, lr:  0.0009623351230037094\n",
      "Epoch:  74 , validation loss:  1.1611184120178222 , validation accuracy:  32.31291412824314 %, lr:  0.0009623351230037094\n",
      "Epoch:  75 , validation loss:  1.507094669342041 , validation accuracy:  25.193785867067763 %, lr:  0.0009623351230037094\n",
      "Epoch:  76 , validation loss:  1.0153990745544434 , validation accuracy:  37.46298320221902 %, lr:  0.0009623351230037094\n",
      "Epoch:  77 , validation loss:  1.0909978866577148 , validation accuracy:  37.49111777203063 %, lr:  0.0009623351230037094\n",
      "Epoch:  78 , validation loss:  0.964591121673584 , validation accuracy:  36.90245600366471 %, lr:  0.0009623351230037094\n",
      "Epoch:  79 , validation loss:  1.5997607231140136 , validation accuracy:  26.351992324312235 %, lr:  0.0009623351230037094\n",
      "Epoch:  80 , validation loss:  0.9592877388000488 , validation accuracy:  44.75596867684561 %, lr:  0.0009623351230037094\n",
      "Epoch:  81 , validation loss:  1.9306144714355469 , validation accuracy:  32.601473818618594 %, lr:  0.0009623351230037094\n",
      "Epoch:  82 , validation loss:  1.129542636871338 , validation accuracy:  29.168334902376653 %, lr:  0.0009623351230037094\n",
      "Epoch:  83 , validation loss:  0.9934643745422364 , validation accuracy:  37.202918781268146 %, lr:  0.0009623351230037094\n",
      "Epoch:  84 , validation loss:  0.8373519897460937 , validation accuracy:  42.02222631015117 %, lr:  0.0009623351230037094\n",
      "Epoch:  85 , validation loss:  1.6206398010253906 , validation accuracy:  19.13295027034436 %, lr:  0.0009623351230037094\n",
      "Epoch:  86 , validation loss:  1.3931850433349608 , validation accuracy:  30.701668957109206 %, lr:  0.0009623351230037094\n",
      "Epoch:  87 , validation loss:  0.8755559921264648 , validation accuracy:  38.53967154693243 %, lr:  0.0009623351230037094\n",
      "Epoch:  88 , validation loss:  0.9211544990539551 , validation accuracy:  30.872279874043695 %, lr:  0.0009623351230037094\n",
      "Epoch:  89 , validation loss:  1.4629279136657716 , validation accuracy:  17.19455055024726 %, lr:  0.0009623351230037094\n",
      "Epoch:  90 , validation loss:  1.1096799850463868 , validation accuracy:  31.774028906466985 %, lr:  0.0009623351230037094\n",
      "Epoch:  91 , validation loss:  1.2592382431030273 , validation accuracy:  26.390587182899957 %, lr:  0.0009623351230037094\n",
      "Epoch:  92 , validation loss:  1.5525779724121094 , validation accuracy:  12.746042223496696 %, lr:  0.0009623351230037094\n",
      "Epoch:  93 , validation loss:  2.839781951904297 , validation accuracy:  26.531260031957988 %, lr:  0.0009623351230037094\n",
      "Epoch:  94 , validation loss:  1.1145710945129395 , validation accuracy:  25.44519349730738 %, lr:  0.0009623351230037094\n",
      "Epoch:  95 , validation loss:  1.307628345489502 , validation accuracy:  18.88118194049178 %, lr:  0.0009623351230037094\n",
      "Epoch:  96 , validation loss:  0.9778950691223145 , validation accuracy:  43.065369590858424 %, lr:  0.0009623351230037094\n",
      "Epoch:  97 , validation loss:  1.0653388977050782 , validation accuracy:  21.777239133022412 %, lr:  0.0009623351230037094\n",
      "Epoch:  98 , validation loss:  1.0662969589233398 , validation accuracy:  37.34503442877806 %, lr:  0.0009623351230037094\n",
      "Epoch:  99 , validation loss:  1.0181438446044921 , validation accuracy:  26.952917879519116 %, lr:  0.0009623351230037094\n",
      "Epoch:  100 , validation loss:  1.1278355598449707 , validation accuracy:  38.691526083992514 %, lr:  0.0009623351230037094\n",
      "Epoch:  101 , validation loss:  1.1030046463012695 , validation accuracy:  23.277388823361793 %, lr:  0.0009623351230037094\n",
      "Epoch:  102 , validation loss:  1.1972317695617676 , validation accuracy:  20.590898105966332 %, lr:  0.0009623351230037094\n",
      "Epoch:  103 , validation loss:  1.1186842918395996 , validation accuracy:  31.6492268403796 %, lr:  0.0009623351230037094\n",
      "Epoch:  104 , validation loss:  0.9857280731201172 , validation accuracy:  33.997020621196874 %, lr:  0.0009623351230037094\n",
      "Epoch:  105 , validation loss:  1.3811622619628907 , validation accuracy:  19.400589383167592 %, lr:  0.00024058378075092734\n",
      "Epoch:  106 , validation loss:  0.8587214469909668 , validation accuracy:  41.42418635184805 %, lr:  0.00024058378075092734\n",
      "Epoch:  107 , validation loss:  1.4383726119995117 , validation accuracy:  35.83298165121069 %, lr:  0.00024058378075092734\n",
      "Epoch:  108 , validation loss:  1.1109819412231445 , validation accuracy:  32.16214169002197 %, lr:  0.00024058378075092734\n",
      "Epoch:  109 , validation loss:  0.8090746879577637 , validation accuracy:  44.032044553616196 %, lr:  0.00024058378075092734\n",
      "Epoch:  110 , validation loss:  0.9041536331176758 , validation accuracy:  38.12594909085662 %, lr:  0.00024058378075092734\n",
      "Epoch:  111 , validation loss:  0.8493800163269043 , validation accuracy:  46.45053545857545 %, lr:  0.00024058378075092734\n",
      "Epoch:  112 , validation loss:  0.8541783332824707 , validation accuracy:  47.98964070711552 %, lr:  0.00024058378075092734\n",
      "Epoch:  113 , validation loss:  1.011113739013672 , validation accuracy:  37.63972601257399 %, lr:  0.00024058378075092734\n",
      "Epoch:  114 , validation loss:  0.8012811660766601 , validation accuracy:  46.20020992717475 %, lr:  0.00024058378075092734\n",
      "Epoch:  115 , validation loss:  0.8084605216979981 , validation accuracy:  46.0526837854703 %, lr:  0.00024058378075092734\n",
      "Epoch:  116 , validation loss:  0.9042512893676757 , validation accuracy:  44.20301617016365 %, lr:  0.00024058378075092734\n",
      "Epoch:  117 , validation loss:  0.8582484245300293 , validation accuracy:  48.040860052157164 %, lr:  0.00024058378075092734\n",
      "Epoch:  118 , validation loss:  1.2835267066955567 , validation accuracy:  34.798495161214696 %, lr:  0.00024058378075092734\n",
      "Epoch:  119 , validation loss:  0.93409423828125 , validation accuracy:  39.218508218540684 %, lr:  0.00024058378075092734\n",
      "Epoch:  120 , validation loss:  0.7888566970825195 , validation accuracy:  50.32408860225293 %, lr:  0.00024058378075092734\n",
      "Epoch:  121 , validation loss:  1.0131292343139648 , validation accuracy:  44.81981250834118 %, lr:  0.00024058378075092734\n",
      "Epoch:  122 , validation loss:  0.7705791473388672 , validation accuracy:  51.47363826878614 %, lr:  0.00024058378075092734\n",
      "Epoch:  123 , validation loss:  0.8280835151672363 , validation accuracy:  49.778350087830354 %, lr:  0.00024058378075092734\n",
      "Epoch:  124 , validation loss:  0.8077017784118652 , validation accuracy:  47.59034623555849 %, lr:  0.00024058378075092734\n",
      "Epoch:  125 , validation loss:  0.7965360164642334 , validation accuracy:  51.59266914106602 %, lr:  0.00024058378075092734\n",
      "Epoch:  126 , validation loss:  0.9946831703186035 , validation accuracy:  34.38982249972046 %, lr:  0.00024058378075092734\n",
      "Epoch:  127 , validation loss:  0.7786267757415771 , validation accuracy:  50.466564949375815 %, lr:  0.00024058378075092734\n",
      "Epoch:  128 , validation loss:  0.7518147468566895 , validation accuracy:  43.147248403002465 %, lr:  0.00024058378075092734\n",
      "Epoch:  129 , validation loss:  0.8964925765991211 , validation accuracy:  41.61499644710881 %, lr:  0.00024058378075092734\n",
      "Epoch:  130 , validation loss:  0.861816120147705 , validation accuracy:  38.721464151868965 %, lr:  0.00024058378075092734\n",
      "Epoch:  131 , validation loss:  0.7664056777954101 , validation accuracy:  51.33152262127623 %, lr:  0.00024058378075092734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  132 , validation loss:  0.889768123626709 , validation accuracy:  46.71240337759118 %, lr:  0.00024058378075092734\n",
      "Epoch:  133 , validation loss:  1.0471166610717773 , validation accuracy:  50.55637915300517 %, lr:  0.00024058378075092734\n",
      "Epoch:  134 , validation loss:  0.7649023056030273 , validation accuracy:  54.16229318385941 %, lr:  0.00024058378075092734\n",
      "Epoch:  135 , validation loss:  0.8467382431030274 , validation accuracy:  51.91946299041621 %, lr:  0.00024058378075092734\n",
      "Epoch:  136 , validation loss:  0.8965774536132812 , validation accuracy:  35.91449976374175 %, lr:  0.00024058378075092734\n",
      "Epoch:  137 , validation loss:  0.963715648651123 , validation accuracy:  35.44811516417243 %, lr:  0.00024058378075092734\n",
      "Epoch:  138 , validation loss:  0.7683077335357666 , validation accuracy:  51.123759644205904 %, lr:  0.00024058378075092734\n",
      "Epoch:  139 , validation loss:  0.7721261024475098 , validation accuracy:  50.43482338343451 %, lr:  0.00024058378075092734\n",
      "Epoch:  140 , validation loss:  0.7682314395904541 , validation accuracy:  53.87192999541911 %, lr:  0.00024058378075092734\n",
      "Epoch:  141 , validation loss:  0.7540744781494141 , validation accuracy:  49.60593567283102 %, lr:  0.00024058378075092734\n",
      "Epoch:  142 , validation loss:  0.8210134506225586 , validation accuracy:  51.90864200202713 %, lr:  0.00024058378075092734\n",
      "Epoch:  143 , validation loss:  0.8415225982666016 , validation accuracy:  51.01338556263729 %, lr:  0.00024058378075092734\n",
      "Epoch:  144 , validation loss:  0.8968653678894043 , validation accuracy:  41.427071948751795 %, lr:  0.00024058378075092734\n",
      "Epoch:  145 , validation loss:  1.3684798240661622 , validation accuracy:  37.39950007033642 %, lr:  0.00024058378075092734\n",
      "Epoch:  146 , validation loss:  0.8054887771606445 , validation accuracy:  52.16618152568723 %, lr:  0.00024058378075092734\n",
      "Epoch:  147 , validation loss:  0.8038029670715332 , validation accuracy:  50.46331865285909 %, lr:  0.00024058378075092734\n",
      "Epoch:  148 , validation loss:  0.7463179588317871 , validation accuracy:  57.25673516352317 %, lr:  0.00024058378075092734\n",
      "Epoch:  149 , validation loss:  0.770248556137085 , validation accuracy:  52.089352508124755 %, lr:  0.00024058378075092734\n",
      "Epoch:  150 , validation loss:  0.7985824584960938 , validation accuracy:  56.225855669656866 %, lr:  0.00024058378075092734\n",
      "Epoch:  151 , validation loss:  1.0790095329284668 , validation accuracy:  39.19073434834204 %, lr:  0.00024058378075092734\n",
      "Epoch:  152 , validation loss:  0.7767439365386963 , validation accuracy:  46.34088277623278 %, lr:  0.00024058378075092734\n",
      "Epoch:  153 , validation loss:  0.8708792686462402 , validation accuracy:  54.011520745638244 %, lr:  0.00024058378075092734\n",
      "Epoch:  154 , validation loss:  0.8899920463562012 , validation accuracy:  51.96130414552065 %, lr:  0.00024058378075092734\n",
      "Epoch:  155 , validation loss:  0.8224380493164063 , validation accuracy:  52.58783937324836 %, lr:  0.00024058378075092734\n",
      "Epoch:  156 , validation loss:  0.8086453437805176 , validation accuracy:  50.570085738298 %, lr:  0.00024058378075092734\n",
      "Epoch:  157 , validation loss:  0.8152135848999024 , validation accuracy:  56.27743571431147 %, lr:  0.00024058378075092734\n",
      "Epoch:  158 , validation loss:  0.7287994384765625 , validation accuracy:  56.37410321058726 %, lr:  0.00024058378075092734\n",
      "Epoch:  159 , validation loss:  0.8556712150573731 , validation accuracy:  44.023027063291956 %, lr:  0.00024058378075092734\n",
      "Epoch:  160 , validation loss:  0.7321031093597412 , validation accuracy:  57.75522202864677 %, lr:  0.00024058378075092734\n",
      "Epoch:  161 , validation loss:  0.7827497482299804 , validation accuracy:  51.80584261233088 %, lr:  0.00024058378075092734\n",
      "Epoch:  162 , validation loss:  0.7442350387573242 , validation accuracy:  45.40414588135147 %, lr:  0.00024058378075092734\n",
      "Epoch:  163 , validation loss:  0.8465593338012696 , validation accuracy:  37.521416539520054 %, lr:  0.00024058378075092734\n",
      "Epoch:  164 , validation loss:  0.8977270126342773 , validation accuracy:  53.15413776561017 %, lr:  0.00024058378075092734\n",
      "Epoch:  165 , validation loss:  0.847159481048584 , validation accuracy:  44.73324460122854 %, lr:  0.00024058378075092734\n",
      "Epoch:  166 , validation loss:  0.7785361766815185 , validation accuracy:  52.18313440749678 %, lr:  0.00024058378075092734\n",
      "Epoch:  167 , validation loss:  1.2183941841125487 , validation accuracy:  44.68382875425175 %, lr:  0.00024058378075092734\n",
      "Epoch:  168 , validation loss:  0.7798810958862304 , validation accuracy:  54.332543401180935 %, lr:  0.00024058378075092734\n",
      "Epoch:  169 , validation loss:  1.0672648429870606 , validation accuracy:  40.670684860355145 %, lr:  0.00024058378075092734\n",
      "Epoch:  170 , validation loss:  0.7633292198181152 , validation accuracy:  54.32785430621233 %, lr:  0.00024058378075092734\n",
      "Epoch:  171 , validation loss:  1.0000286102294922 , validation accuracy:  48.968940156327214 %, lr:  0.00024058378075092734\n",
      "Epoch:  172 , validation loss:  0.7324105739593506 , validation accuracy:  58.80774349929122 %, lr:  0.00024058378075092734\n",
      "Epoch:  173 , validation loss:  0.7866692543029785 , validation accuracy:  54.56483395193317 %, lr:  0.00024058378075092734\n",
      "Epoch:  174 , validation loss:  0.7520936965942383 , validation accuracy:  57.49912530343855 %, lr:  0.00024058378075092734\n",
      "Epoch:  175 , validation loss:  1.203322696685791 , validation accuracy:  49.731819837757314 %, lr:  0.00024058378075092734\n",
      "Epoch:  176 , validation loss:  0.7310639381408691 , validation accuracy:  55.38506487182539 %, lr:  0.00024058378075092734\n",
      "Epoch:  177 , validation loss:  0.7446837902069092 , validation accuracy:  52.16582082607425 %, lr:  0.00024058378075092734\n",
      "Epoch:  178 , validation loss:  0.9239301681518555 , validation accuracy:  49.28310951922349 %, lr:  0.00024058378075092734\n",
      "Epoch:  179 , validation loss:  0.7833447933197022 , validation accuracy:  42.308261103235836 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  180 , validation loss:  0.7936612129211426 , validation accuracy:  54.584672430646485 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  181 , validation loss:  0.6986138343811035 , validation accuracy:  58.41530232038061 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  182 , validation loss:  0.6887392997741699 , validation accuracy:  57.973084594880234 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  183 , validation loss:  0.7097855567932129 , validation accuracy:  58.9595980363513 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  184 , validation loss:  0.7063705921173096 , validation accuracy:  58.000497765465894 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  185 , validation loss:  0.7158604621887207 , validation accuracy:  59.15221162967692 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  186 , validation loss:  0.6937165260314941 , validation accuracy:  59.245993529048945 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  187 , validation loss:  0.6870162010192871 , validation accuracy:  59.52842132600392 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  188 , validation loss:  0.696524715423584 , validation accuracy:  59.03570565468783 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  189 , validation loss:  0.6996571063995362 , validation accuracy:  59.34518592261551 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  190 , validation loss:  0.6979296207427979 , validation accuracy:  59.22579435072266 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  191 , validation loss:  0.7140697956085205 , validation accuracy:  59.59875775053294 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  192 , validation loss:  0.7036675930023193 , validation accuracy:  59.19910257936293 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  193 , validation loss:  0.7072044372558594 , validation accuracy:  59.600200548984816 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  194 , validation loss:  0.9661325454711914 , validation accuracy:  53.55451433600612 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  195 , validation loss:  0.7028179168701172 , validation accuracy:  59.70516413635888 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  196 , validation loss:  0.700844669342041 , validation accuracy:  59.952964770468796 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  197 , validation loss:  0.7041447639465332 , validation accuracy:  60.09724461565653 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  198 , validation loss:  0.6965395927429199 , validation accuracy:  60.12357568740329 %, lr:  6.0145945187731835e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  199 , validation loss:  0.6863747119903565 , validation accuracy:  60.20076540457872 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  200 , validation loss:  0.696424150466919 , validation accuracy:  60.02402259422376 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  201 , validation loss:  0.703196382522583 , validation accuracy:  59.63518841144283 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  202 , validation loss:  0.6961596012115479 , validation accuracy:  59.97316394879508 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  203 , validation loss:  0.7115865230560303 , validation accuracy:  58.95526964099568 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  204 , validation loss:  0.6988650321960449 , validation accuracy:  59.5803620702715 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  205 , validation loss:  0.6946366786956787 , validation accuracy:  59.958375264663346 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  206 , validation loss:  0.7022865772247314 , validation accuracy:  60.122493588564375 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  207 , validation loss:  0.7042452335357666 , validation accuracy:  59.103517181926065 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  208 , validation loss:  0.7042398929595948 , validation accuracy:  60.05540346055208 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  209 , validation loss:  0.6991732120513916 , validation accuracy:  58.91487128434311 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  210 , validation loss:  0.7499145984649658 , validation accuracy:  57.76712511587475 %, lr:  6.0145945187731835e-05\n",
      "Epoch:  211 , validation loss:  0.7040509223937989 , validation accuracy:  59.39784806610903 %, lr:  6.0145945187731835e-05\n",
      "wandb: Agent Finished Run: fles6abx \n",
      "\n",
      "wandb: Agent Starting Run: ktdqi5wp with config:\n",
      "\tepochs: 159\n",
      "\thidden_dim: 38\n",
      "\tlr: 0.001286366901168298\n",
      "\tn_graph_iters: 2\n",
      "\tnetwork: Edge_Track_Truth_Net\n",
      "\toptimizer: AdamW\n",
      "\ttrain_size: 525\n",
      "\tweight_decay: 1.2787232891571813e-05\n",
      "wandb: Agent Started Run: ktdqi5wp\n",
      "Initialising W&B...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ktdqi5wp\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ktdqi5wp</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "config: {'epochs': 159, 'hidden_dim': 38, 'lr': 0.001286366901168298, 'n_graph_iters': 2, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 525, 'weight_decay': 1.2787232891571813e-05}\n",
      "Using  cuda\n",
      "Loading model...\n",
      "Model configs:  {'input_dim': 3, 'hidden_dim': 38, 'n_graph_iters': 2, 'output_dim': 1}\n",
      "Loading optimiser\n",
      "Loading scheduler...\n",
      "Training...\n",
      "Epoch:  1 , validation loss:  1.8796390533447265 , validation accuracy:  10.25108300058794 %, lr:  0.001286366901168298\n",
      "Epoch:  2 , validation loss:  1.876226043701172 , validation accuracy:  10.541806888641208 %, lr:  0.001286366901168298\n",
      "Epoch:  3 , validation loss:  1.874910545349121 , validation accuracy:  11.219922161023522 %, lr:  0.001286366901168298\n",
      "Epoch:  4 , validation loss:  1.8753677368164063 , validation accuracy:  13.43317498620324 %, lr:  0.001286366901168298\n",
      "Epoch:  5 , validation loss:  1.8720743179321289 , validation accuracy:  11.16834211636891 %, lr:  0.001286366901168298\n",
      "Epoch:  6 , validation loss:  1.8829517364501953 , validation accuracy:  10.079029285201576 %, lr:  0.001286366901168298\n",
      "Epoch:  7 , validation loss:  1.8688592910766602 , validation accuracy:  11.134436352749793 %, lr:  0.001286366901168298\n",
      "Epoch:  8 , validation loss:  1.867416763305664 , validation accuracy:  12.545132539072787 %, lr:  0.001286366901168298\n",
      "Epoch:  9 , validation loss:  1.867936897277832 , validation accuracy:  13.6640227385036 %, lr:  0.001286366901168298\n",
      "Epoch:  10 , validation loss:  1.8660648345947266 , validation accuracy:  12.729450041300105 %, lr:  0.001286366901168298\n",
      "Epoch:  11 , validation loss:  1.8650169372558594 , validation accuracy:  12.53250805261886 %, lr:  0.001286366901168298\n",
      "Epoch:  12 , validation loss:  1.8689624786376953 , validation accuracy:  14.200743762601942 %, lr:  0.001286366901168298\n",
      "Epoch:  13 , validation loss:  1.8757347106933593 , validation accuracy:  11.049311244089036 %, lr:  0.001286366901168298\n",
      "Epoch:  14 , validation loss:  1.8653406143188476 , validation accuracy:  13.842929746536381 %, lr:  0.001286366901168298\n",
      "Epoch:  15 , validation loss:  1.818312644958496 , validation accuracy:  18.051212131049382 %, lr:  0.001286366901168298\n",
      "Epoch:  16 , validation loss:  1.7921865463256836 , validation accuracy:  28.121223925926724 %, lr:  0.001286366901168298\n",
      "Epoch:  17 , validation loss:  1.7980815887451171 , validation accuracy:  29.902719314382175 %, lr:  0.001286366901168298\n",
      "Epoch:  18 , validation loss:  2.047748565673828 , validation accuracy:  19.95173839178471 %, lr:  0.001286366901168298\n",
      "Epoch:  19 , validation loss:  1.6879928588867188 , validation accuracy:  18.493069156936794 %, lr:  0.001286366901168298\n",
      "Epoch:  20 , validation loss:  1.7327634811401367 , validation accuracy:  17.923885167671216 %, lr:  0.001286366901168298\n",
      "Epoch:  21 , validation loss:  1.4680061340332031 , validation accuracy:  25.014157459809045 %, lr:  0.001286366901168298\n",
      "Epoch:  22 , validation loss:  1.6256830215454101 , validation accuracy:  17.399788630026798 %, lr:  0.001286366901168298\n",
      "Epoch:  23 , validation loss:  1.8589149475097657 , validation accuracy:  12.292642809994266 %, lr:  0.001286366901168298\n",
      "Epoch:  24 , validation loss:  1.5777531623840333 , validation accuracy:  25.314259537799515 %, lr:  0.001286366901168298\n",
      "Epoch:  25 , validation loss:  1.411991786956787 , validation accuracy:  27.869816295687116 %, lr:  0.001286366901168298\n",
      "Epoch:  26 , validation loss:  1.837466049194336 , validation accuracy:  15.400069975724918 %, lr:  0.001286366901168298\n",
      "Epoch:  27 , validation loss:  1.553652286529541 , validation accuracy:  27.128217891422203 %, lr:  0.001286366901168298\n",
      "Epoch:  28 , validation loss:  1.4198530197143555 , validation accuracy:  13.773675420846274 %, lr:  0.001286366901168298\n",
      "Epoch:  29 , validation loss:  1.8933406829833985 , validation accuracy:  15.394659481530375 %, lr:  0.001286366901168298\n",
      "Epoch:  30 , validation loss:  1.0308399200439453 , validation accuracy:  32.10911884691548 %, lr:  0.001286366901168298\n",
      "Epoch:  31 , validation loss:  1.060704803466797 , validation accuracy:  37.064049430274956 %, lr:  0.001286366901168298\n",
      "Epoch:  32 , validation loss:  1.107761764526367 , validation accuracy:  39.175584964597334 %, lr:  0.001286366901168298\n",
      "Epoch:  33 , validation loss:  1.6797740936279297 , validation accuracy:  12.881665277973156 %, lr:  0.001286366901168298\n",
      "Epoch:  34 , validation loss:  1.6899213790893555 , validation accuracy:  21.322396921068105 %, lr:  0.001286366901168298\n",
      "Epoch:  35 , validation loss:  1.4418318748474122 , validation accuracy:  16.303983205826018 %, lr:  0.001286366901168298\n",
      "Epoch:  36 , validation loss:  1.4924723625183105 , validation accuracy:  33.10356767987188 %, lr:  0.001286366901168298\n",
      "Epoch:  37 , validation loss:  1.1635151863098145 , validation accuracy:  38.30882379463207 %, lr:  0.001286366901168298\n",
      "Epoch:  38 , validation loss:  1.1647061347961425 , validation accuracy:  21.484351047291327 %, lr:  0.001286366901168298\n",
      "Epoch:  39 , validation loss:  0.9129223823547363 , validation accuracy:  38.28537831978907 %, lr:  0.001286366901168298\n",
      "Epoch:  40 , validation loss:  0.9214010238647461 , validation accuracy:  39.66721853707451 %, lr:  0.001286366901168298\n",
      "Epoch:  41 , validation loss:  0.9558856010437011 , validation accuracy:  40.32116693538788 %, lr:  0.001286366901168298\n",
      "Epoch:  42 , validation loss:  0.9949382781982422 , validation accuracy:  42.71008047208365 %, lr:  0.001286366901168298\n",
      "Epoch:  43 , validation loss:  1.0569672584533691 , validation accuracy:  40.77095935276061 %, lr:  0.001286366901168298\n",
      "Epoch:  44 , validation loss:  1.2940355300903321 , validation accuracy:  27.19891501556419 %, lr:  0.001286366901168298\n",
      "Epoch:  45 , validation loss:  1.1537090301513673 , validation accuracy:  42.03521149621807 %, lr:  0.001286366901168298\n",
      "Epoch:  46 , validation loss:  0.9158880233764648 , validation accuracy:  47.91245098994008 %, lr:  0.001286366901168298\n",
      "Epoch:  47 , validation loss:  1.1874869346618653 , validation accuracy:  29.143446629081765 %, lr:  0.001286366901168298\n",
      "Epoch:  48 , validation loss:  1.2747064590454102 , validation accuracy:  33.011949978177675 %, lr:  0.001286366901168298\n",
      "Epoch:  49 , validation loss:  0.8824891090393067 , validation accuracy:  47.59034623555849 %, lr:  0.001286366901168298\n",
      "Epoch:  50 , validation loss:  1.5246311187744142 , validation accuracy:  32.95604153816743 %, lr:  0.001286366901168298\n",
      "Epoch:  51 , validation loss:  1.4054178237915038 , validation accuracy:  23.66297670962599 %, lr:  0.001286366901168298\n",
      "Epoch:  52 , validation loss:  0.9383426666259765 , validation accuracy:  49.970242281930034 %, lr:  0.001286366901168298\n",
      "Epoch:  53 , validation loss:  1.1494476318359375 , validation accuracy:  33.810899620904706 %, lr:  0.001286366901168298\n",
      "Epoch:  54 , validation loss:  0.90535888671875 , validation accuracy:  46.471816735740646 %, lr:  0.001286366901168298\n",
      "Epoch:  55 , validation loss:  1.4236634254455567 , validation accuracy:  39.55107326169839 %, lr:  0.001286366901168298\n",
      "Epoch:  56 , validation loss:  1.379433536529541 , validation accuracy:  27.421466676766254 %, lr:  0.001286366901168298\n",
      "Epoch:  57 , validation loss:  1.3170714378356934 , validation accuracy:  26.080746215359312 %, lr:  0.001286366901168298\n",
      "Epoch:  58 , validation loss:  1.0160831451416015 , validation accuracy:  36.53742799533976 %, lr:  0.001286366901168298\n",
      "Epoch:  59 , validation loss:  0.9645595550537109 , validation accuracy:  46.97932109118847 %, lr:  0.001286366901168298\n",
      "Epoch:  60 , validation loss:  1.0415096282958984 , validation accuracy:  29.594321145293414 %, lr:  0.001286366901168298\n",
      "Epoch:  61 , validation loss:  0.9393609046936036 , validation accuracy:  46.86534001349016 %, lr:  0.001286366901168298\n",
      "Epoch:  62 , validation loss:  1.0913604736328124 , validation accuracy:  34.82338343450957 %, lr:  0.001286366901168298\n",
      "Epoch:  63 , validation loss:  0.9682025909423828 , validation accuracy:  38.50396228524847 %, lr:  0.001286366901168298\n",
      "Epoch:  64 , validation loss:  1.129267120361328 , validation accuracy:  30.46396791216243 %, lr:  0.001286366901168298\n",
      "Epoch:  65 , validation loss:  1.356828498840332 , validation accuracy:  29.690627941956215 %, lr:  0.001286366901168298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  66 , validation loss:  1.1080848693847656 , validation accuracy:  44.351263711094035 %, lr:  0.001286366901168298\n",
      "Epoch:  67 , validation loss:  0.9877760887145997 , validation accuracy:  41.58505837923236 %, lr:  0.001286366901168298\n",
      "Epoch:  68 , validation loss:  0.9201435089111328 , validation accuracy:  45.07915553006612 %, lr:  0.001286366901168298\n",
      "Epoch:  69 , validation loss:  0.916505241394043 , validation accuracy:  47.5279452025148 %, lr:  0.001286366901168298\n",
      "Epoch:  70 , validation loss:  0.8583855628967285 , validation accuracy:  36.75276566428244 %, lr:  0.001286366901168298\n",
      "Epoch:  71 , validation loss:  2.004546546936035 , validation accuracy:  25.111185655697792 %, lr:  0.001286366901168298\n",
      "Epoch:  72 , validation loss:  0.9875454902648926 , validation accuracy:  41.462781210435764 %, lr:  0.001286366901168298\n",
      "Epoch:  73 , validation loss:  1.0909289360046386 , validation accuracy:  24.515670594685453 %, lr:  0.001286366901168298\n",
      "Epoch:  74 , validation loss:  1.0622727394104003 , validation accuracy:  18.16916090449035 %, lr:  0.001286366901168298\n",
      "Epoch:  75 , validation loss:  1.0740278244018555 , validation accuracy:  32.65485736133805 %, lr:  0.001286366901168298\n",
      "Epoch:  76 , validation loss:  0.8707795143127441 , validation accuracy:  50.06727047781878 %, lr:  0.001286366901168298\n",
      "Epoch:  77 , validation loss:  0.917882251739502 , validation accuracy:  22.645443101439554 %, lr:  0.001286366901168298\n",
      "Epoch:  78 , validation loss:  0.8782808303833007 , validation accuracy:  46.87543960265331 %, lr:  0.001286366901168298\n",
      "Epoch:  79 , validation loss:  1.627283477783203 , validation accuracy:  28.24602599201411 %, lr:  0.001286366901168298\n",
      "Epoch:  80 , validation loss:  1.331174087524414 , validation accuracy:  28.54648876961755 %, lr:  0.001286366901168298\n",
      "Epoch:  81 , validation loss:  0.9654205322265625 , validation accuracy:  33.23991213357428 %, lr:  0.001286366901168298\n",
      "Epoch:  82 , validation loss:  0.9849920272827148 , validation accuracy:  42.65561483052529 %, lr:  0.001286366901168298\n",
      "Epoch:  83 , validation loss:  0.8457913398742676 , validation accuracy:  48.89391463682959 %, lr:  0.001286366901168298\n",
      "Epoch:  84 , validation loss:  1.020444965362549 , validation accuracy:  31.05876157394883 %, lr:  0.001286366901168298\n",
      "Epoch:  85 , validation loss:  0.924379539489746 , validation accuracy:  41.40542997197364 %, lr:  0.001286366901168298\n",
      "Epoch:  86 , validation loss:  0.804705810546875 , validation accuracy:  44.479312073698146 %, lr:  0.001286366901168298\n",
      "Epoch:  87 , validation loss:  0.9095450401306152 , validation accuracy:  40.302410555513475 %, lr:  0.001286366901168298\n",
      "Epoch:  88 , validation loss:  0.9186718940734864 , validation accuracy:  45.73635022489621 %, lr:  0.001286366901168298\n",
      "Epoch:  89 , validation loss:  1.5044994354248047 , validation accuracy:  27.61408027009187 %, lr:  0.001286366901168298\n",
      "Epoch:  90 , validation loss:  1.2503050804138183 , validation accuracy:  37.31473566128864 %, lr:  0.001286366901168298\n",
      "Epoch:  91 , validation loss:  1.3462058067321778 , validation accuracy:  34.50632847470955 %, lr:  0.001286366901168298\n",
      "Epoch:  92 , validation loss:  0.9699469566345215 , validation accuracy:  34.98209126421607 %, lr:  0.001286366901168298\n",
      "Epoch:  93 , validation loss:  1.1965786933898925 , validation accuracy:  36.411543830413464 %, lr:  0.001286366901168298\n",
      "Epoch:  94 , validation loss:  0.837041187286377 , validation accuracy:  34.18458441994092 %, lr:  0.001286366901168298\n",
      "Epoch:  95 , validation loss:  1.0189000129699708 , validation accuracy:  40.37779677462406 %, lr:  0.001286366901168298\n",
      "Epoch:  96 , validation loss:  1.4382244110107423 , validation accuracy:  35.71034378280112 %, lr:  0.001286366901168298\n",
      "Epoch:  97 , validation loss:  1.778433609008789 , validation accuracy:  25.984800118309476 %, lr:  0.001286366901168298\n",
      "Epoch:  98 , validation loss:  0.8560129165649414 , validation accuracy:  42.24946706632184 %, lr:  0.001286366901168298\n",
      "Epoch:  99 , validation loss:  0.7604604721069336 , validation accuracy:  49.09554572047944 %, lr:  0.001286366901168298\n",
      "Epoch:  100 , validation loss:  0.8362545013427735 , validation accuracy:  47.23649991523559 %, lr:  0.001286366901168298\n",
      "Epoch:  101 , validation loss:  0.8103240013122559 , validation accuracy:  44.036012249358855 %, lr:  0.001286366901168298\n",
      "Epoch:  102 , validation loss:  1.2021234512329102 , validation accuracy:  17.57797423883364 %, lr:  0.001286366901168298\n",
      "Epoch:  103 , validation loss:  0.8755885124206543 , validation accuracy:  44.33503222851042 %, lr:  0.001286366901168298\n",
      "Epoch:  104 , validation loss:  1.6646762847900392 , validation accuracy:  32.64331497372303 %, lr:  0.001286366901168298\n",
      "Epoch:  105 , validation loss:  0.8640491485595703 , validation accuracy:  24.213404319017165 %, lr:  0.001286366901168298\n",
      "Epoch:  106 , validation loss:  0.7951356410980225 , validation accuracy:  42.2029368162488 %, lr:  0.001286366901168298\n",
      "Epoch:  107 , validation loss:  0.9918663024902343 , validation accuracy:  35.71286868009191 %, lr:  0.001286366901168298\n",
      "Epoch:  108 , validation loss:  0.8445972442626953 , validation accuracy:  29.757357370355543 %, lr:  0.001286366901168298\n",
      "Epoch:  109 , validation loss:  0.8270759582519531 , validation accuracy:  43.140395110356046 %, lr:  0.001286366901168298\n",
      "Epoch:  110 , validation loss:  1.1173297882080078 , validation accuracy:  30.834767114294888 %, lr:  0.001286366901168298\n",
      "Epoch:  111 , validation loss:  0.9155976295471191 , validation accuracy:  37.31293216322379 %, lr:  0.001286366901168298\n",
      "Epoch:  112 , validation loss:  0.8522953033447266 , validation accuracy:  39.115708828844426 %, lr:  0.001286366901168298\n",
      "Epoch:  113 , validation loss:  1.1282124519348145 , validation accuracy:  37.908807923849096 %, lr:  0.001286366901168298\n",
      "Epoch:  114 , validation loss:  0.8947365760803223 , validation accuracy:  27.66169261900382 %, lr:  0.001286366901168298\n",
      "Epoch:  115 , validation loss:  1.3633949279785156 , validation accuracy:  39.41545020722193 %, lr:  0.001286366901168298\n",
      "Epoch:  116 , validation loss:  0.8404021263122559 , validation accuracy:  44.39887606000599 %, lr:  0.001286366901168298\n",
      "Epoch:  117 , validation loss:  0.8109944343566895 , validation accuracy:  40.087433586183764 %, lr:  0.001286366901168298\n",
      "Epoch:  118 , validation loss:  0.7681354522705078 , validation accuracy:  32.492181835888886 %, lr:  0.001286366901168298\n",
      "Epoch:  119 , validation loss:  0.787183141708374 , validation accuracy:  44.67986105850908 %, lr:  0.001286366901168298\n",
      "Epoch:  120 , validation loss:  1.0816365242004395 , validation accuracy:  30.267747322707123 %, lr:  0.0003215917252920745\n",
      "Epoch:  121 , validation loss:  0.7618224143981933 , validation accuracy:  49.59655748289382 %, lr:  0.0003215917252920745\n",
      "Epoch:  122 , validation loss:  0.6603634357452393 , validation accuracy:  51.26515389248988 %, lr:  0.0003215917252920745\n",
      "Epoch:  123 , validation loss:  0.6671493530273438 , validation accuracy:  49.49195459513272 %, lr:  0.0003215917252920745\n",
      "Epoch:  124 , validation loss:  0.6733799934387207 , validation accuracy:  52.09764859922306 %, lr:  0.0003215917252920745\n",
      "Epoch:  125 , validation loss:  0.6722089767456054 , validation accuracy:  53.61511187098497 %, lr:  0.0003215917252920745\n",
      "Epoch:  126 , validation loss:  0.857049560546875 , validation accuracy:  47.04749331803967 %, lr:  0.0003215917252920745\n",
      "Epoch:  127 , validation loss:  0.6658608913421631 , validation accuracy:  54.09376025739524 %, lr:  0.0003215917252920745\n",
      "Epoch:  128 , validation loss:  0.6739674568176269 , validation accuracy:  52.025508676629194 %, lr:  0.0003215917252920745\n",
      "Epoch:  129 , validation loss:  0.6479688167572022 , validation accuracy:  52.785142061542565 %, lr:  0.0003215917252920745\n",
      "Epoch:  130 , validation loss:  0.668792724609375 , validation accuracy:  51.32178373172606 %, lr:  0.0003215917252920745\n",
      "Epoch:  131 , validation loss:  0.7336249351501465 , validation accuracy:  49.970602981543 %, lr:  0.0003215917252920745\n",
      "Epoch:  132 , validation loss:  0.8872123718261719 , validation accuracy:  47.28591576221239 %, lr:  0.0003215917252920745\n",
      "Epoch:  133 , validation loss:  0.7273683547973633 , validation accuracy:  45.908764639895544 %, lr:  0.0003215917252920745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  134 , validation loss:  0.9518499374389648 , validation accuracy:  39.89590209169705 %, lr:  0.0003215917252920745\n",
      "Epoch:  135 , validation loss:  0.7694330215454102 , validation accuracy:  53.49896659560884 %, lr:  0.0003215917252920745\n",
      "Epoch:  136 , validation loss:  0.6389562129974365 , validation accuracy:  55.70500542852918 %, lr:  0.0003215917252920745\n",
      "Epoch:  137 , validation loss:  0.854582691192627 , validation accuracy:  48.01525037963634 %, lr:  0.0003215917252920745\n",
      "Epoch:  138 , validation loss:  0.625816011428833 , validation accuracy:  52.038854562309055 %, lr:  0.0003215917252920745\n",
      "Epoch:  139 , validation loss:  0.8573714256286621 , validation accuracy:  49.06705045105487 %, lr:  0.0003215917252920745\n",
      "Epoch:  140 , validation loss:  0.727449893951416 , validation accuracy:  52.150671442329546 %, lr:  0.0003215917252920745\n",
      "Epoch:  141 , validation loss:  0.6487175464630127 , validation accuracy:  49.61639596160713 %, lr:  0.0003215917252920745\n",
      "Epoch:  142 , validation loss:  0.7114501953125 , validation accuracy:  46.70555008494476 %, lr:  0.0003215917252920745\n",
      "Epoch:  143 , validation loss:  0.722783899307251 , validation accuracy:  45.20359689654053 %, lr:  0.0003215917252920745\n",
      "Epoch:  144 , validation loss:  0.8941027641296386 , validation accuracy:  42.736411543830414 %, lr:  0.0003215917252920745\n",
      "Epoch:  145 , validation loss:  0.770181131362915 , validation accuracy:  46.532053571106516 %, lr:  0.0003215917252920745\n",
      "Epoch:  146 , validation loss:  0.6546854019165039 , validation accuracy:  52.88217025743131 %, lr:  0.0003215917252920745\n",
      "Epoch:  147 , validation loss:  0.749916410446167 , validation accuracy:  53.464339432763786 %, lr:  0.0003215917252920745\n",
      "Epoch:  148 , validation loss:  0.71405029296875 , validation accuracy:  43.10648934673693 %, lr:  0.0003215917252920745\n",
      "Epoch:  149 , validation loss:  0.7307813167572021 , validation accuracy:  33.417015643542214 %, lr:  0.0003215917252920745\n",
      "Epoch:  150 , validation loss:  0.8116367340087891 , validation accuracy:  41.83754810831088 %, lr:  0.0003215917252920745\n",
      "Epoch:  151 , validation loss:  0.7965562820434571 , validation accuracy:  48.24213043619404 %, lr:  0.0003215917252920745\n",
      "Epoch:  152 , validation loss:  0.6198931694030761 , validation accuracy:  55.45936899209707 %, lr:  0.0003215917252920745\n",
      "Epoch:  153 , validation loss:  0.6917325973510742 , validation accuracy:  52.85475708684565 %, lr:  0.0003215917252920745\n",
      "Epoch:  154 , validation loss:  0.6561293125152587 , validation accuracy:  53.69049809009555 %, lr:  0.0003215917252920745\n",
      "Epoch:  155 , validation loss:  0.6955145359039306 , validation accuracy:  54.44652447887923 %, lr:  0.0003215917252920745\n",
      "Epoch:  156 , validation loss:  0.6651365280151367 , validation accuracy:  47.91209029032712 %, lr:  0.0003215917252920745\n",
      "Epoch:  157 , validation loss:  0.652103042602539 , validation accuracy:  55.05863172208816 %, lr:  0.0003215917252920745\n",
      "Epoch:  158 , validation loss:  0.7697356700897217 , validation accuracy:  45.66926009688392 %, lr:  0.0003215917252920745\n",
      "Epoch:  159 , validation loss:  0.6443178176879882 , validation accuracy:  53.73955323745938 %, lr:  0.0003215917252920745\n",
      "wandb: Agent Finished Run: ktdqi5wp \n",
      "\n",
      "wandb: Agent Starting Run: ylshjy3t with config:\n",
      "\tepochs: 181\n",
      "\thidden_dim: 56\n",
      "\tlr: 0.0027652584263859483\n",
      "\tn_graph_iters: 2\n",
      "\tnetwork: Edge_Track_Truth_Net\n",
      "\toptimizer: AdamW\n",
      "\ttrain_size: 394\n",
      "\tweight_decay: 0.0001876569683955251\n",
      "wandb: Agent Started Run: ylshjy3t\n",
      "Initialising W&B...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ylshjy3t\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ylshjy3t</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "config: {'epochs': 181, 'hidden_dim': 56, 'lr': 0.0027652584263859483, 'n_graph_iters': 2, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 394, 'weight_decay': 0.0001876569683955251}\n",
      "Using  cuda\n",
      "Loading model...\n",
      "Model configs:  {'input_dim': 3, 'hidden_dim': 56, 'n_graph_iters': 2, 'output_dim': 1}\n",
      "Loading optimiser\n",
      "Loading scheduler...\n",
      "Training...\n",
      "Epoch:  1 , validation loss:  1.8854427337646484 , validation accuracy:  12.217617290496648 %, lr:  0.0027652584263859483\n",
      "Epoch:  2 , validation loss:  1.8725807189941406 , validation accuracy:  11.719130425373054 %, lr:  0.0027652584263859483\n",
      "Epoch:  3 , validation loss:  1.8863094329833985 , validation accuracy:  9.442394468310736 %, lr:  0.0027652584263859483\n",
      "Epoch:  4 , validation loss:  1.8776731491088867 , validation accuracy:  11.467362095520471 %, lr:  0.0027652584263859483\n",
      "Epoch:  5 , validation loss:  1.8675628662109376 , validation accuracy:  10.956250743942952 %, lr:  0.0027652584263859483\n",
      "Epoch:  6 , validation loss:  1.8692047119140625 , validation accuracy:  12.543329041007938 %, lr:  0.0027652584263859483\n",
      "Epoch:  7 , validation loss:  1.871173095703125 , validation accuracy:  14.49759954407569 %, lr:  0.0027652584263859483\n",
      "Epoch:  8 , validation loss:  1.86627140045166 , validation accuracy:  11.476740285457673 %, lr:  0.0027652584263859483\n",
      "Epoch:  9 , validation loss:  1.868490982055664 , validation accuracy:  11.038129556086988 %, lr:  0.0027652584263859483\n",
      "Epoch:  10 , validation loss:  1.8661186218261718 , validation accuracy:  12.113735801961484 %, lr:  0.0027652584263859483\n",
      "Epoch:  11 , validation loss:  1.8690509796142578 , validation accuracy:  10.80908530185147 %, lr:  0.0027652584263859483\n",
      "Epoch:  12 , validation loss:  1.865870475769043 , validation accuracy:  13.081853563171128 %, lr:  0.0027652584263859483\n",
      "Epoch:  13 , validation loss:  1.8698129653930664 , validation accuracy:  10.595190431360667 %, lr:  0.0027652584263859483\n",
      "Epoch:  14 , validation loss:  1.8650182723999023 , validation accuracy:  11.954667272642016 %, lr:  0.0027652584263859483\n",
      "Epoch:  15 , validation loss:  1.866790771484375 , validation accuracy:  12.102554113959435 %, lr:  0.0027652584263859483\n",
      "Epoch:  16 , validation loss:  1.865317153930664 , validation accuracy:  11.961881264901402 %, lr:  0.0027652584263859483\n",
      "Epoch:  17 , validation loss:  1.8651145935058593 , validation accuracy:  12.995285656058492 %, lr:  0.0027652584263859483\n",
      "Epoch:  18 , validation loss:  1.8643335342407226 , validation accuracy:  11.944567683478875 %, lr:  0.0027652584263859483\n",
      "Epoch:  19 , validation loss:  1.8777606964111329 , validation accuracy:  10.389230952355188 %, lr:  0.0027652584263859483\n",
      "Epoch:  20 , validation loss:  1.8689493179321288 , validation accuracy:  11.189984093147068 %, lr:  0.0027652584263859483\n",
      "Epoch:  21 , validation loss:  1.8657087326049804 , validation accuracy:  12.955608698631865 %, lr:  0.0027652584263859483\n",
      "Epoch:  22 , validation loss:  1.8689748764038085 , validation accuracy:  10.582205245293771 %, lr:  0.0027652584263859483\n",
      "Epoch:  23 , validation loss:  1.8698904037475585 , validation accuracy:  10.340175804991361 %, lr:  0.0027652584263859483\n",
      "Epoch:  24 , validation loss:  1.8738250732421875 , validation accuracy:  11.556815599536861 %, lr:  0.0027652584263859483\n",
      "Epoch:  25 , validation loss:  1.8673171997070312 , validation accuracy:  11.307211467362094 %, lr:  0.0027652584263859483\n",
      "Epoch:  26 , validation loss:  1.865333366394043 , validation accuracy:  12.56929941314173 %, lr:  0.0027652584263859483\n",
      "Epoch:  27 , validation loss:  1.865208625793457 , validation accuracy:  13.260760571203908 %, lr:  0.0027652584263859483\n",
      "Epoch:  28 , validation loss:  1.8694639205932617 , validation accuracy:  13.742294554517942 %, lr:  0.0027652584263859483\n",
      "Epoch:  29 , validation loss:  1.8658906936645507 , validation accuracy:  12.744960124657787 %, lr:  0.0027652584263859483\n",
      "Epoch:  30 , validation loss:  1.8679492950439454 , validation accuracy:  12.430430062148544 %, lr:  0.0027652584263859483\n",
      "Epoch:  31 , validation loss:  1.8662918090820313 , validation accuracy:  11.71588412885633 %, lr:  0.0027652584263859483\n",
      "Epoch:  32 , validation loss:  1.8660186767578124 , validation accuracy:  13.10060994304553 %, lr:  0.0027652584263859483\n",
      "Epoch:  33 , validation loss:  1.8712881088256836 , validation accuracy:  10.7358632804187 %, lr:  0.0027652584263859483\n",
      "Epoch:  34 , validation loss:  1.8664922714233398 , validation accuracy:  13.446881571496075 %, lr:  0.0027652584263859483\n",
      "Epoch:  35 , validation loss:  1.864325714111328 , validation accuracy:  13.602343104685849 %, lr:  0.0027652584263859483\n",
      "Epoch:  36 , validation loss:  1.8683507919311524 , validation accuracy:  10.783475629330649 %, lr:  0.0027652584263859483\n",
      "Epoch:  37 , validation loss:  1.8686182022094726 , validation accuracy:  11.31514685884742 %, lr:  0.0027652584263859483\n",
      "Epoch:  38 , validation loss:  1.8675411224365235 , validation accuracy:  14.311478543783524 %, lr:  0.0027652584263859483\n",
      "Epoch:  39 , validation loss:  1.8667526245117188 , validation accuracy:  12.327991372065258 %, lr:  0.0006913146065964871\n",
      "Epoch:  40 , validation loss:  1.86466064453125 , validation accuracy:  13.47429474208174 %, lr:  0.0006913146065964871\n",
      "Epoch:  41 , validation loss:  1.863321876525879 , validation accuracy:  12.060352259242025 %, lr:  0.0006913146065964871\n",
      "Epoch:  42 , validation loss:  1.865037727355957 , validation accuracy:  11.508842551011943 %, lr:  0.0006913146065964871\n",
      "Epoch:  43 , validation loss:  1.870180320739746 , validation accuracy:  12.978693473861902 %, lr:  0.0006913146065964871\n",
      "Epoch:  44 , validation loss:  1.8673595428466796 , validation accuracy:  12.404820389627721 %, lr:  0.0006913146065964871\n",
      "Epoch:  45 , validation loss:  1.8847633361816407 , validation accuracy:  12.075140943373768 %, lr:  0.0006913146065964871\n",
      "Epoch:  46 , validation loss:  1.8753623962402344 , validation accuracy:  11.310818463491788 %, lr:  0.0006913146065964871\n",
      "Epoch:  47 , validation loss:  1.8666194915771483 , validation accuracy:  12.440529651311683 %, lr:  0.0006913146065964871\n",
      "Epoch:  48 , validation loss:  1.8802360534667968 , validation accuracy:  11.273666403355948 %, lr:  0.0006913146065964871\n",
      "Epoch:  49 , validation loss:  1.6906015396118164 , validation accuracy:  17.30528533142884 %, lr:  0.0006913146065964871\n",
      "Epoch:  50 , validation loss:  1.6605913162231445 , validation accuracy:  15.647149210608896 %, lr:  0.0006913146065964871\n",
      "Epoch:  51 , validation loss:  1.4846080780029296 , validation accuracy:  13.241282792103565 %, lr:  0.0006913146065964871\n",
      "Epoch:  52 , validation loss:  1.2945161819458009 , validation accuracy:  23.26404293768193 %, lr:  0.0006913146065964871\n",
      "Epoch:  53 , validation loss:  1.3009424209594727 , validation accuracy:  21.981395113963043 %, lr:  0.0006913146065964871\n",
      "Epoch:  54 , validation loss:  1.7897747039794922 , validation accuracy:  18.772611356988016 %, lr:  0.0006913146065964871\n",
      "Epoch:  55 , validation loss:  1.3812335014343262 , validation accuracy:  18.424896930085595 %, lr:  0.0006913146065964871\n",
      "Epoch:  56 , validation loss:  1.4778395652770997 , validation accuracy:  17.328370106658873 %, lr:  0.0006913146065964871\n",
      "Epoch:  57 , validation loss:  1.8499940872192382 , validation accuracy:  20.95520471506534 %, lr:  0.0006913146065964871\n",
      "Epoch:  58 , validation loss:  1.82171630859375 , validation accuracy:  19.890419457579924 %, lr:  0.0006913146065964871\n",
      "Epoch:  59 , validation loss:  1.3307007789611816 , validation accuracy:  27.803086867287792 %, lr:  0.0006913146065964871\n",
      "Epoch:  60 , validation loss:  1.2829394340515137 , validation accuracy:  28.064233387077575 %, lr:  0.0006913146065964871\n",
      "Epoch:  61 , validation loss:  1.4482111930847168 , validation accuracy:  13.597293310104277 %, lr:  0.0006913146065964871\n",
      "Epoch:  62 , validation loss:  1.5755845069885255 , validation accuracy:  19.9553453879144 %, lr:  0.0006913146065964871\n",
      "Epoch:  63 , validation loss:  1.5935895919799805 , validation accuracy:  21.525470803169828 %, lr:  0.0006913146065964871\n",
      "Epoch:  64 , validation loss:  1.4991907119750976 , validation accuracy:  27.201439912854973 %, lr:  0.0006913146065964871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  65 , validation loss:  1.1740797996520995 , validation accuracy:  33.798275134450776 %, lr:  0.0006913146065964871\n",
      "Epoch:  66 , validation loss:  1.2692875862121582 , validation accuracy:  26.95616417603584 %, lr:  0.0006913146065964871\n",
      "Epoch:  67 , validation loss:  1.6141521453857421 , validation accuracy:  30.346019138721463 %, lr:  0.0006913146065964871\n",
      "Epoch:  68 , validation loss:  1.6945066452026367 , validation accuracy:  18.81805950822215 %, lr:  0.0006913146065964871\n",
      "Epoch:  69 , validation loss:  1.0825698852539063 , validation accuracy:  37.45576920995964 %, lr:  0.0006913146065964871\n",
      "Epoch:  70 , validation loss:  1.290786361694336 , validation accuracy:  31.62325646824581 %, lr:  0.0006913146065964871\n",
      "Epoch:  71 , validation loss:  1.3210551261901855 , validation accuracy:  28.03898441416972 %, lr:  0.0006913146065964871\n",
      "Epoch:  72 , validation loss:  1.236750602722168 , validation accuracy:  31.8714178019687 %, lr:  0.0006913146065964871\n",
      "Epoch:  73 , validation loss:  1.06967134475708 , validation accuracy:  36.496308239461264 %, lr:  0.0006913146065964871\n",
      "Epoch:  74 , validation loss:  1.1039572715759278 , validation accuracy:  31.91145545900829 %, lr:  0.0006913146065964871\n",
      "Epoch:  75 , validation loss:  1.3656742095947265 , validation accuracy:  31.716677668004863 %, lr:  0.0006913146065964871\n",
      "Epoch:  76 , validation loss:  2.0483665466308594 , validation accuracy:  21.040690523339066 %, lr:  0.0006913146065964871\n",
      "Epoch:  77 , validation loss:  1.3524271965026855 , validation accuracy:  26.021230779219373 %, lr:  0.0006913146065964871\n",
      "Epoch:  78 , validation loss:  1.2273294448852539 , validation accuracy:  33.29365637590671 %, lr:  0.0006913146065964871\n",
      "Epoch:  79 , validation loss:  0.9999866485595703 , validation accuracy:  36.016938453825034 %, lr:  0.0006913146065964871\n",
      "Epoch:  80 , validation loss:  2.1350168228149413 , validation accuracy:  25.870458340998198 %, lr:  0.0006913146065964871\n",
      "Epoch:  81 , validation loss:  1.1661058425903321 , validation accuracy:  25.828256486280793 %, lr:  0.0006913146065964871\n",
      "Epoch:  82 , validation loss:  1.1350038528442383 , validation accuracy:  25.9526978527552 %, lr:  0.0006913146065964871\n",
      "Epoch:  83 , validation loss:  1.4146041870117188 , validation accuracy:  31.187892035391844 %, lr:  0.0006913146065964871\n",
      "Epoch:  84 , validation loss:  1.4467392921447755 , validation accuracy:  26.16623202363304 %, lr:  0.0006913146065964871\n",
      "Epoch:  85 , validation loss:  1.7991790771484375 , validation accuracy:  12.440890350924654 %, lr:  0.0006913146065964871\n",
      "Epoch:  86 , validation loss:  1.153927993774414 , validation accuracy:  29.96908804316853 %, lr:  0.0006913146065964871\n",
      "Epoch:  87 , validation loss:  1.514892864227295 , validation accuracy:  27.443469353157386 %, lr:  0.0006913146065964871\n",
      "Epoch:  88 , validation loss:  1.0938991546630858 , validation accuracy:  38.76546950465122 %, lr:  0.0006913146065964871\n",
      "Epoch:  89 , validation loss:  1.243097686767578 , validation accuracy:  20.847355530787514 %, lr:  0.0006913146065964871\n",
      "Epoch:  90 , validation loss:  2.1665231704711916 , validation accuracy:  24.650932949548945 %, lr:  0.0006913146065964871\n",
      "Epoch:  91 , validation loss:  1.0001707077026367 , validation accuracy:  41.56774479780983 %, lr:  0.0006913146065964871\n",
      "Epoch:  92 , validation loss:  1.175321674346924 , validation accuracy:  31.660769227994617 %, lr:  0.0006913146065964871\n",
      "Epoch:  93 , validation loss:  1.1193004608154298 , validation accuracy:  34.85296080277306 %, lr:  0.0006913146065964871\n",
      "Epoch:  94 , validation loss:  0.9916489601135254 , validation accuracy:  35.90800717070831 %, lr:  0.0006913146065964871\n",
      "Epoch:  95 , validation loss:  1.4352840423583983 , validation accuracy:  26.638387817009875 %, lr:  0.0006913146065964871\n",
      "Epoch:  96 , validation loss:  1.2639152526855468 , validation accuracy:  39.17702776304921 %, lr:  0.0006913146065964871\n",
      "Epoch:  97 , validation loss:  1.1570500373840331 , validation accuracy:  32.773166834391986 %, lr:  0.0006913146065964871\n",
      "Epoch:  98 , validation loss:  1.0205677986145019 , validation accuracy:  41.83682670908494 %, lr:  0.0006913146065964871\n",
      "Epoch:  99 , validation loss:  1.3942800521850587 , validation accuracy:  20.185471740988824 %, lr:  0.0006913146065964871\n",
      "Epoch:  100 , validation loss:  1.2310525894165039 , validation accuracy:  31.52370337506628 %, lr:  0.0006913146065964871\n",
      "Epoch:  101 , validation loss:  1.748249626159668 , validation accuracy:  12.753256215756082 %, lr:  0.0006913146065964871\n",
      "Epoch:  102 , validation loss:  1.2598732948303222 , validation accuracy:  31.888370683778255 %, lr:  0.0006913146065964871\n",
      "Epoch:  103 , validation loss:  1.1075519561767577 , validation accuracy:  35.87482280631512 %, lr:  0.0006913146065964871\n",
      "Epoch:  104 , validation loss:  1.4185041427612304 , validation accuracy:  18.782710946151155 %, lr:  0.0006913146065964871\n",
      "Epoch:  105 , validation loss:  1.8119892120361327 , validation accuracy:  12.592744887984736 %, lr:  0.0006913146065964871\n",
      "Epoch:  106 , validation loss:  1.471756362915039 , validation accuracy:  27.364476137917105 %, lr:  0.0006913146065964871\n",
      "Epoch:  107 , validation loss:  1.284585189819336 , validation accuracy:  28.237369201302847 %, lr:  0.0006913146065964871\n",
      "Epoch:  108 , validation loss:  1.430631732940674 , validation accuracy:  26.11645547704327 %, lr:  0.0006913146065964871\n",
      "Epoch:  109 , validation loss:  1.1137072563171386 , validation accuracy:  36.3476999989179 %, lr:  0.0006913146065964871\n",
      "Epoch:  110 , validation loss:  1.3964055061340332 , validation accuracy:  31.186449236939968 %, lr:  0.0006913146065964871\n",
      "Epoch:  111 , validation loss:  1.1028635025024414 , validation accuracy:  37.75731408640198 %, lr:  0.0006913146065964871\n",
      "Epoch:  112 , validation loss:  1.290597152709961 , validation accuracy:  33.15731192220431 %, lr:  0.0006913146065964871\n",
      "Epoch:  113 , validation loss:  1.2120914459228516 , validation accuracy:  29.826611696045653 %, lr:  0.0006913146065964871\n",
      "Epoch:  114 , validation loss:  1.343691349029541 , validation accuracy:  36.00359256814517 %, lr:  0.0006913146065964871\n",
      "Epoch:  115 , validation loss:  0.9972082138061523 , validation accuracy:  41.12552707230945 %, lr:  0.00017282865164912177\n",
      "Epoch:  116 , validation loss:  0.8877442359924317 , validation accuracy:  44.742262091552774 %, lr:  0.00017282865164912177\n",
      "Epoch:  117 , validation loss:  0.8480795860290528 , validation accuracy:  46.989420680351614 %, lr:  0.00017282865164912177\n",
      "Epoch:  118 , validation loss:  0.9067536354064941 , validation accuracy:  45.76556689354672 %, lr:  0.00017282865164912177\n",
      "Epoch:  119 , validation loss:  1.1911712646484376 , validation accuracy:  37.912414919978794 %, lr:  0.00017282865164912177\n",
      "Epoch:  120 , validation loss:  0.8672427177429199 , validation accuracy:  46.837566143291525 %, lr:  0.00017282865164912177\n",
      "Epoch:  121 , validation loss:  0.9701091766357421 , validation accuracy:  42.38256522350752 %, lr:  0.00017282865164912177\n",
      "Epoch:  122 , validation loss:  0.9504230499267579 , validation accuracy:  43.13823091267823 %, lr:  0.00017282865164912177\n",
      "Epoch:  123 , validation loss:  0.8176285743713378 , validation accuracy:  45.17834792363268 %, lr:  0.00017282865164912177\n",
      "Epoch:  124 , validation loss:  0.8153799057006836 , validation accuracy:  47.334970909576214 %, lr:  0.00017282865164912177\n",
      "Epoch:  125 , validation loss:  1.655937385559082 , validation accuracy:  36.27988847167967 %, lr:  0.00017282865164912177\n",
      "Epoch:  126 , validation loss:  0.8624917030334472 , validation accuracy:  45.58665988551394 %, lr:  0.00017282865164912177\n",
      "Epoch:  127 , validation loss:  0.8310579299926758 , validation accuracy:  47.93337156749231 %, lr:  0.00017282865164912177\n",
      "Epoch:  128 , validation loss:  0.9464837074279785 , validation accuracy:  40.73272519378587 %, lr:  0.00017282865164912177\n",
      "Epoch:  129 , validation loss:  0.8660709381103515 , validation accuracy:  43.20496034107755 %, lr:  0.00017282865164912177\n",
      "Epoch:  130 , validation loss:  0.9152312278747559 , validation accuracy:  46.916920058144775 %, lr:  0.00017282865164912177\n",
      "Epoch:  131 , validation loss:  0.852107048034668 , validation accuracy:  47.3198215258315 %, lr:  0.00017282865164912177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  132 , validation loss:  0.92957763671875 , validation accuracy:  46.48516262142051 %, lr:  0.00017282865164912177\n",
      "Epoch:  133 , validation loss:  0.8168927192687988 , validation accuracy:  47.78043493159332 %, lr:  0.00017282865164912177\n",
      "Epoch:  134 , validation loss:  0.8150508880615235 , validation accuracy:  48.31499175801384 %, lr:  0.00017282865164912177\n",
      "Epoch:  135 , validation loss:  0.7973195552825928 , validation accuracy:  48.989139334653494 %, lr:  0.00017282865164912177\n",
      "Epoch:  136 , validation loss:  0.8341896057128906 , validation accuracy:  47.25381349665812 %, lr:  0.00017282865164912177\n",
      "Epoch:  137 , validation loss:  0.8310612678527832 , validation accuracy:  50.490731823444754 %, lr:  0.00017282865164912177\n",
      "Epoch:  138 , validation loss:  0.9898387908935546 , validation accuracy:  43.14508420532464 %, lr:  0.00017282865164912177\n",
      "Epoch:  139 , validation loss:  0.7954098224639893 , validation accuracy:  49.90748054927337 %, lr:  0.00017282865164912177\n",
      "Epoch:  140 , validation loss:  0.8848856925964356 , validation accuracy:  48.18369709889301 %, lr:  0.00017282865164912177\n",
      "Epoch:  141 , validation loss:  0.809971809387207 , validation accuracy:  49.25894264515454 %, lr:  0.00017282865164912177\n",
      "Epoch:  142 , validation loss:  0.8697308540344239 , validation accuracy:  44.27299189507969 %, lr:  0.00017282865164912177\n",
      "Epoch:  143 , validation loss:  0.8543578147888183 , validation accuracy:  48.959561966390005 %, lr:  0.00017282865164912177\n",
      "Epoch:  144 , validation loss:  0.9388646125793457 , validation accuracy:  48.833317101850746 %, lr:  0.00017282865164912177\n",
      "Epoch:  145 , validation loss:  0.7931929111480713 , validation accuracy:  51.216459444739016 %, lr:  0.00017282865164912177\n",
      "Epoch:  146 , validation loss:  0.8320839881896973 , validation accuracy:  42.20365821547474 %, lr:  0.00017282865164912177\n",
      "Epoch:  147 , validation loss:  0.7886894702911377 , validation accuracy:  50.83195365731372 %, lr:  0.00017282865164912177\n",
      "Epoch:  148 , validation loss:  0.8959216117858887 , validation accuracy:  46.47434163303143 %, lr:  0.00017282865164912177\n",
      "Epoch:  149 , validation loss:  0.8281922340393066 , validation accuracy:  50.796965794855694 %, lr:  0.00017282865164912177\n",
      "Epoch:  150 , validation loss:  0.7776147365570069 , validation accuracy:  51.2377407219042 %, lr:  0.00017282865164912177\n",
      "Epoch:  151 , validation loss:  0.7552031993865966 , validation accuracy:  51.83902697672406 %, lr:  0.00017282865164912177\n",
      "Epoch:  152 , validation loss:  0.7634076595306396 , validation accuracy:  51.67671215088786 %, lr:  0.00017282865164912177\n",
      "Epoch:  153 , validation loss:  0.8099335670471192 , validation accuracy:  50.0705167743355 %, lr:  0.00017282865164912177\n",
      "Epoch:  154 , validation loss:  0.8878345489501953 , validation accuracy:  48.160612323662974 %, lr:  0.00017282865164912177\n",
      "Epoch:  155 , validation loss:  0.8620566368103028 , validation accuracy:  48.618340132521034 %, lr:  0.00017282865164912177\n",
      "Epoch:  156 , validation loss:  1.181729507446289 , validation accuracy:  45.421459462773996 %, lr:  0.00017282865164912177\n",
      "Epoch:  157 , validation loss:  0.8553838729858398 , validation accuracy:  50.34681267787 %, lr:  0.00017282865164912177\n",
      "Epoch:  158 , validation loss:  0.786921215057373 , validation accuracy:  51.76039446109675 %, lr:  0.00017282865164912177\n",
      "Epoch:  159 , validation loss:  0.782235050201416 , validation accuracy:  51.862833151180034 %, lr:  0.00017282865164912177\n",
      "Epoch:  160 , validation loss:  0.7482382297515869 , validation accuracy:  51.70737161799025 %, lr:  0.00017282865164912177\n",
      "Epoch:  161 , validation loss:  0.8135046005249024 , validation accuracy:  51.0696547022605 %, lr:  0.00017282865164912177\n",
      "Epoch:  162 , validation loss:  0.8559027671813965 , validation accuracy:  50.84926723873625 %, lr:  0.00017282865164912177\n",
      "Epoch:  163 , validation loss:  0.792514705657959 , validation accuracy:  51.56273107318956 %, lr:  0.00017282865164912177\n",
      "Epoch:  164 , validation loss:  0.7892641544342041 , validation accuracy:  51.295813359592266 %, lr:  0.00017282865164912177\n",
      "Epoch:  165 , validation loss:  0.7436711311340332 , validation accuracy:  48.86073027243642 %, lr:  0.00017282865164912177\n",
      "Epoch:  166 , validation loss:  0.8520591735839844 , validation accuracy:  49.78917107621943 %, lr:  0.00017282865164912177\n",
      "Epoch:  167 , validation loss:  1.2555193901062012 , validation accuracy:  41.07106143075108 %, lr:  0.00017282865164912177\n",
      "Epoch:  168 , validation loss:  0.7791379451751709 , validation accuracy:  51.484098557562255 %, lr:  0.00017282865164912177\n",
      "Epoch:  169 , validation loss:  1.0667552947998047 , validation accuracy:  45.79117656606754 %, lr:  0.00017282865164912177\n",
      "Epoch:  170 , validation loss:  1.07796630859375 , validation accuracy:  46.3347508828123 %, lr:  0.00017282865164912177\n",
      "Epoch:  171 , validation loss:  0.7350554943084717 , validation accuracy:  52.82301552090435 %, lr:  0.00017282865164912177\n",
      "Epoch:  172 , validation loss:  1.5347043037414552 , validation accuracy:  38.830034735372735 %, lr:  0.00017282865164912177\n",
      "Epoch:  173 , validation loss:  1.1707054138183595 , validation accuracy:  42.72450845660243 %, lr:  0.00017282865164912177\n",
      "Epoch:  174 , validation loss:  0.758837366104126 , validation accuracy:  53.706008173453235 %, lr:  0.00017282865164912177\n",
      "Epoch:  175 , validation loss:  1.2957512855529785 , validation accuracy:  39.6250166823571 %, lr:  0.00017282865164912177\n",
      "Epoch:  176 , validation loss:  0.7463548660278321 , validation accuracy:  53.55884273136174 %, lr:  0.00017282865164912177\n",
      "Epoch:  177 , validation loss:  0.7517717361450196 , validation accuracy:  52.09368090348039 %, lr:  0.00017282865164912177\n",
      "Epoch:  178 , validation loss:  0.98841552734375 , validation accuracy:  44.94028617907293 %, lr:  0.00017282865164912177\n",
      "Epoch:  179 , validation loss:  0.8063377380371094 , validation accuracy:  49.49015109706787 %, lr:  0.00017282865164912177\n",
      "Epoch:  180 , validation loss:  0.7806938171386719 , validation accuracy:  52.069514029411444 %, lr:  0.00017282865164912177\n",
      "Epoch:  181 , validation loss:  0.922697639465332 , validation accuracy:  50.84133184725093 %, lr:  0.00017282865164912177\n",
      "wandb: Agent Finished Run: ylshjy3t \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Ctrl-c pressed. Waiting for runs to end. Press ctrl-c again to terminate them.\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "           \n",
    "    print(\"Initialising W&B...\")\n",
    "    wandb.init()\n",
    "\n",
    "    from torch_geometric.data import Data\n",
    "    from torch_geometric.data import DataLoader\n",
    "    from torch_scatter import scatter_add\n",
    "    \n",
    "    # Local imports\n",
    "    from utils.toy_utils import load_data, make_mlp\n",
    "\n",
    "    class TwoHopAttNetwork(nn.Module):\n",
    "        \"\"\"\n",
    "        A module which computes new node features on the graph.\n",
    "        For each node, it aggregates the neighbor node features\n",
    "        (separately on the input and output side), and combines\n",
    "        them with the node's previous features in a fully-connected\n",
    "        network to compute the new features.\n",
    "        \"\"\"\n",
    "        def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
    "                     layer_norm=True):\n",
    "            super(TwoHopAttNetwork, self).__init__()\n",
    "            self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
    "                                    hidden_activation=hidden_activation,\n",
    "                                    output_activation=hidden_activation,\n",
    "                                    layer_norm=layer_norm)\n",
    "\n",
    "        def forward(self, x, e, edge_index):\n",
    "            start, end = edge_index\n",
    "            # Aggregate edge-weighted incoming/outgoing features\n",
    "            mi = scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])\n",
    "            mi2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
    "            mo = scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])\n",
    "            mo2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
    "            node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
    "            return self.network(node_inputs)\n",
    "\n",
    "    class TwoHopNetwork(nn.Module):\n",
    "        \"\"\"\n",
    "        A module which computes new node features on the graph.\n",
    "        For each node, it aggregates the neighbor node features\n",
    "        (separately on the input and output side), and combines\n",
    "        them with the node's previous features in a fully-connected\n",
    "        network to compute the new features.\n",
    "        \"\"\"\n",
    "        def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
    "                     layer_norm=True):\n",
    "            super(TwoHopNetwork, self).__init__()\n",
    "            self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
    "                                    hidden_activation=hidden_activation,\n",
    "                                    output_activation=hidden_activation,\n",
    "                                    layer_norm=layer_norm)\n",
    "\n",
    "        def forward(self, x, e, edge_index):\n",
    "            start, end = edge_index\n",
    "            # Aggregate edge-weighted incoming/outgoing features\n",
    "            mi = scatter_add(x[start], end, dim=0, dim_size=x.shape[0])\n",
    "            mi2 = scatter_add(scatter_add(x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
    "            mo = scatter_add(x[end], start, dim=0, dim_size=x.shape[0])\n",
    "            mo2 = scatter_add(scatter_add(x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
    "            node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
    "            return self.network(node_inputs)\n",
    "\n",
    "    class Edge_Track_Net(nn.Module):\n",
    "        \"\"\"\n",
    "        Segment classification graph neural network model.\n",
    "        Consists of an input network, an edge network, and a node network.\n",
    "        \"\"\"\n",
    "        def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
    "                     output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
    "            super(Edge_Track_Net, self).__init__()\n",
    "            self.n_graph_iters = n_graph_iters\n",
    "            # Setup the input network\n",
    "            self.input_network = make_mlp(input_dim, [hidden_dim],\n",
    "                                          hidden_activation=nn.ReLU,\n",
    "                                          layer_norm=False)\n",
    "            # Setup the edge network\n",
    "            self.edge_network = EdgeNetwork(input_dim+hidden_dim, hidden_dim,\n",
    "                                            hidden_activation, layer_norm=layer_norm)\n",
    "            # Setup the node layers\n",
    "            self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
    "                                            hidden_activation=nn.ReLU, layer_norm=False)\n",
    "\n",
    "    #         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
    "    #                                         layer_norm=False)\n",
    "            self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, output_dim],\n",
    "                                           hidden_activation=nn.ReLU,\n",
    "                                          output_activation=None,\n",
    "                                          layer_norm=False)\n",
    "\n",
    "        def forward(self, inputs):\n",
    "            \"\"\"Apply forward pass of the model\"\"\"\n",
    "            # Apply input network to get hidden representation\n",
    "            x = self.input_network(inputs.x)\n",
    "            # Shortcut connect the inputs onto the hidden representation\n",
    "            x = torch.cat([x, inputs.x], dim=-1)\n",
    "            # Loop over iterations of edge and node networks\n",
    "            for i in range(self.n_graph_iters):\n",
    "                # Apply edge network\n",
    "                e = torch.sigmoid(self.edge_network(x, inputs.edge_index))\n",
    "                # Apply node network\n",
    "                x = self.node_network(x, e, inputs.edge_index)\n",
    "                # Shortcut connect the inputs onto the hidden representation\n",
    "                x = torch.cat([x, inputs.x], dim=-1)\n",
    "            # Apply final edge network\n",
    "            e = self.edge_network(x, inputs.edge_index)\n",
    "            return e, self.output_network(x)\n",
    "\n",
    "    class Edge_Track_Truth_Net(nn.Module):\n",
    "        \"\"\"\n",
    "        Segment classification graph neural network model.\n",
    "        Consists of an input network, an edge network, and a node network.\n",
    "        \"\"\"\n",
    "        def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
    "                     output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
    "            super(Edge_Track_Truth_Net, self).__init__()\n",
    "            self.n_graph_iters = n_graph_iters\n",
    "            # Setup the input network\n",
    "            self.input_network = make_mlp(input_dim, [hidden_dim],\n",
    "                                          hidden_activation=nn.ReLU,\n",
    "                                          layer_norm=False)\n",
    "            # Setup the node layers\n",
    "            self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
    "                                            hidden_activation=nn.ReLU, layer_norm=False)\n",
    "\n",
    "    #         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
    "    #                                         layer_norm=False)\n",
    "            self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
    "                                           hidden_activation=nn.ReLU,\n",
    "                                          output_activation=None,\n",
    "                                          layer_norm=False)\n",
    "\n",
    "        def forward(self, inputs):\n",
    "            \"\"\"Apply forward pass of the model\"\"\"\n",
    "            # Apply input network to get hidden representation\n",
    "            x = self.input_network(inputs.x)\n",
    "            # Shortcut connect the inputs onto the hidden representation\n",
    "            x = torch.cat([x, inputs.x], dim=-1)\n",
    "            # Loop over iterations of edge and node networks\n",
    "            for i in range(self.n_graph_iters):\n",
    "                # Apply edge network\n",
    "                e = inputs.y_edges\n",
    "                # Apply node network\n",
    "                x = self.node_network(x, e, inputs.edge_index)\n",
    "                # Shortcut connect the inputs onto the hidden representation\n",
    "                x = torch.cat([x, inputs.x], dim=-1)\n",
    "            # Apply final edge network\n",
    "            return self.output_network(x)\n",
    "\n",
    "    def validate(model, val_loader, val_size):\n",
    "        model = model.eval()\n",
    "        node_correct, node_total, loss = 0, 0, 0\n",
    "        for batch in val_loader:\n",
    "            data = batch.to(device)\n",
    "#             print(len(data.y_params))\n",
    "            node_pred = model(data)\n",
    "            node_correct += (((node_pred - data.y_params)/data.y_params)**2 < 0.1**2).sum().item()\n",
    "            node_total += len(node_pred)\n",
    "            loss += F.mse_loss(node_pred, data.y_params)\n",
    "        acc = node_correct / node_total\n",
    "        return acc, loss.item()/val_size\n",
    "\n",
    "    def get_lr(optimizer):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            return param_group['lr']\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    train_dataset, val_dataset = load_data(train_size=wandb.config.get(\"train_size\",0), test_size=20)\n",
    "    train_loader, val_loader = DataLoader(train_dataset, batch_size=2, shuffle=True), DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    print(\"config:\", dict(wandb.config.user_items()))\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Using \", device)\n",
    "    \n",
    "    m_dic = [\"hidden_dim\", \"n_graph_iters\"]\n",
    "    m_configs = {k:wandb.config.get(k,0) for k in m_dic} \n",
    "    m_configs = {'input_dim': 3, **m_configs, 'output_dim': 1}\n",
    "        \n",
    "    print(\"Loading model...\")\n",
    "    print(\"Model configs: \", m_configs)\n",
    "    model = Edge_Track_Truth_Net(**m_configs).to(device)\n",
    "    wandb.watch(model, log='all')\n",
    "    \n",
    "    print(\"Loading optimiser\")\n",
    "    o_dic = [\"lr\", \"weight_decay\"]\n",
    "    o_configs = {k:wandb.config.get(k,0) for k in o_dic} \n",
    "    optimizer_fn = getattr(torch.optim, wandb.config.get(\"optimizer\",0))\n",
    "#     optimizer_kwargs = {\"Adam\": {}, \"SGD\": {}}\n",
    "    optimizer = optimizer_fn(model.parameters(), amsgrad=True, **o_configs)\n",
    "    \n",
    "    print(\"Loading scheduler...\")\n",
    "#     s_dic = [\"step_size\", \"gamma\"]\n",
    "#     s_configs = {k:wandb.config.get(k,0) for k in s_dic} \n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    \n",
    "    ep, lr = 0, get_lr(optimizer)\n",
    "    best_acc = 0\n",
    "#     for epoch in range(wandb.config.get(\"epochs\", 0)):\n",
    "    while (lr > 6e-6):\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            data = batch.to(device)\n",
    "            node_pred = model(data)\n",
    "            loss = F.mse_loss(node_pred, data.y_params)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        ep += 1\n",
    "        val_acc, val_loss = validate(model, val_loader, 20)\n",
    "        if (val_acc > best_acc): best_acc = val_acc\n",
    "        scheduler.step(val_loss)\n",
    "        lr = get_lr(optimizer)\n",
    "        print(\"Epoch: \" , ep, \", validation loss: \", val_loss, \", validation accuracy: \", val_acc*100, \"%, lr: \", lr)\n",
    "        wandb.log({\"Validation Accuracy\": val_acc, \"Best Accuracy\": best_acc, \"Validation Loss\": val_loss, \"Learning Rate\": lr, \"Epochs\": ep})\n",
    "            \n",
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error resolved after 0:00:11.240625, resuming normal operation.\n"
     ]
    },
    {
     "ename": "ControllerError",
     "evalue": "Only sweeps with a local controller are currently supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mControllerError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d64628e1e9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msweep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, verbose, print_status, print_actions, print_debug)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mprint_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mprint_debug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_if_not_started\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36m_start_if_not_started\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mis_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sweep_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'controller'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'local'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mControllerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only sweeps with a local controller are currently supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;31m# reset controller state, we might want to parse this and decide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mControllerError\u001b[0m: Only sweeps with a local controller are currently supported."
     ]
    }
   ],
   "source": [
    "sweep = wandb.controller(sweep_id)\n",
    "sweep.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-v1.2.0-gpu [conda env:root] *",
   "language": "python",
   "name": "conda-root-pytorch-v1.2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
