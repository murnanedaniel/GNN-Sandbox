{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Graph Training Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint as pp\n",
    "from time import time as tt\n",
    "sys.path.append('..')\n",
    "\n",
    "sys.path.append('/global/common/cori_cle7/software/jupyter/19-11/lib/python3.7/site-packages')\n",
    "sys.path.append('/global/homes/d/danieltm/.local/lib/python3.7/site-packages')\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "# os.environ['WANDB_MODE'] = 'dryrun'\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "# Limit CPU usage on Jupyter\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "# Local imports\n",
    "from utils.toy_utils import *\n",
    "from datasets.hitgraphs_params import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading TrackML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mhitgraphs_med_000\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls $SCRATCH/ExaTrkX/node_tracker_data/\n",
    "g1 = np.load(\"/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/event000001000_g000.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/\"\n",
    "filenames = [os.path.join(input_dir, f) for f in os.listdir(input_dir)\n",
    "                         if f.endswith('.npz') and not f.endswith('_ID.npz')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graphs = [load_graph(fi) for fi in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_mask = [~(np.isnan(g[3]).any()) for g in full_graphs]\n",
    "cut_full_graphs = np.array(full_graphs)[cut_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_full_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),\n",
    "                                         edge_index=torch.from_numpy(di[1]), y_edges=torch.from_numpy(di[2]), \n",
    "                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in full_graphs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2aab7fd80cf8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(np.concatenate(np.array([di[3][:,0] for di in full_graphs]))[:100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Constructing PyG Datastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(1000)]\n",
    "test_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using \", device)\n",
    "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
    "model = Net(train_dataset).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Edge Classification Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , loss:  0.5512356758117676 , accuracy:  0.6864395625058761\n",
      "Epoch:  2 , loss:  0.5046652555465698 , accuracy:  0.7436710645899276\n",
      "Epoch:  3 , loss:  0.48637688159942627 , accuracy:  0.7629634272462315\n",
      "Epoch:  4 , loss:  0.47630026936531067 , accuracy:  0.7705349587890564\n",
      "Epoch:  5 , loss:  0.4798726439476013 , accuracy:  0.7736814064997336\n",
      "Epoch:  6 , loss:  0.4695682227611542 , accuracy:  0.7731611770973706\n",
      "Epoch:  7 , loss:  0.4612908959388733 , accuracy:  0.7738506377511047\n",
      "Epoch:  8 , loss:  0.44322115182876587 , accuracy:  0.7768779968034097\n",
      "Epoch:  9 , loss:  0.46184107661247253 , accuracy:  0.7758438058228087\n",
      "Epoch:  10 , loss:  0.43595728278160095 , accuracy:  0.7730358206148735\n",
      "Epoch:  11 , loss:  0.40324726700782776 , accuracy:  0.7812466702184336\n",
      "Epoch:  12 , loss:  0.3373474180698395 , accuracy:  0.7961014133943402\n",
      "Epoch:  13 , loss:  0.27982667088508606 , accuracy:  0.8321476699363816\n",
      "Epoch:  14 , loss:  0.2253979742527008 , accuracy:  0.8571813594910527\n",
      "Epoch:  15 , loss:  0.21640172600746155 , accuracy:  0.8812498041304961\n",
      "Epoch:  16 , loss:  0.1846497803926468 , accuracy:  0.9013381804506565\n",
      "Epoch:  17 , loss:  0.2350691705942154 , accuracy:  0.8991068350622081\n",
      "Epoch:  18 , loss:  0.1935807168483734 , accuracy:  0.8991256385345827\n",
      "Epoch:  19 , loss:  0.15857245028018951 , accuracy:  0.912563853458272\n",
      "Epoch:  20 , loss:  0.18233557045459747 , accuracy:  0.9181923595223918\n",
      "Epoch:  21 , loss:  0.16060705482959747 , accuracy:  0.9187752671660033\n",
      "Epoch:  22 , loss:  0.15544316172599792 , accuracy:  0.9248111817982387\n",
      "Epoch:  23 , loss:  0.12819615006446838 , accuracy:  0.9281519320567865\n",
      "Epoch:  24 , loss:  0.1715494692325592 , accuracy:  0.9166567426118023\n",
      "Epoch:  25 , loss:  0.15350672602653503 , accuracy:  0.9195086025886113\n",
      "Epoch:  26 , loss:  0.13381382822990417 , accuracy:  0.9310163276818453\n",
      "Epoch:  27 , loss:  0.16854779422283173 , accuracy:  0.9178727004920242\n",
      "Epoch:  28 , loss:  0.12585857510566711 , accuracy:  0.9288288570622708\n",
      "Epoch:  29 , loss:  0.1297493726015091 , accuracy:  0.936086997398853\n",
      "Epoch:  30 , loss:  0.13670764863491058 , accuracy:  0.9336112068695352\n",
      "Epoch:  31 , loss:  0.12563517689704895 , accuracy:  0.9378733272744367\n",
      "Epoch:  32 , loss:  0.10643548518419266 , accuracy:  0.9423736249960826\n",
      "Epoch:  33 , loss:  0.11343897879123688 , accuracy:  0.9475069729543389\n",
      "Epoch:  34 , loss:  0.10112588107585907 , accuracy:  0.9496004262120404\n",
      "Epoch:  35 , loss:  0.10293048620223999 , accuracy:  0.9479018458742048\n",
      "Epoch:  36 , loss:  0.10879960656166077 , accuracy:  0.9497132470462879\n",
      "Epoch:  37 , loss:  0.08479493856430054 , accuracy:  0.9517252185903664\n",
      "Epoch:  38 , loss:  0.08469492197036743 , accuracy:  0.9548340593562945\n",
      "Epoch:  39 , loss:  0.09417087584733963 , accuracy:  0.9555423234824031\n",
      "Epoch:  40 , loss:  0.09632786363363266 , accuracy:  0.9555172521859037\n",
      "Epoch:  41 , loss:  0.09234034270048141 , accuracy:  0.9530728007772102\n",
      "Epoch:  42 , loss:  0.07967119663953781 , accuracy:  0.9559309285781441\n",
      "Epoch:  43 , loss:  0.08349929749965668 , accuracy:  0.957924096649848\n",
      "Epoch:  44 , loss:  0.07990405708551407 , accuracy:  0.957710990629603\n",
      "Epoch:  45 , loss:  0.09039483219385147 , accuracy:  0.9594722492086872\n",
      "Epoch:  46 , loss:  0.0847826823592186 , accuracy:  0.9588266633238272\n",
      "Epoch:  47 , loss:  0.07450012862682343 , accuracy:  0.9607258140336582\n",
      "Epoch:  48 , loss:  0.08207990229129791 , accuracy:  0.9606819392647842\n",
      "Epoch:  49 , loss:  0.08625155687332153 , accuracy:  0.9572221003478643\n",
      "Epoch:  50 , loss:  0.08353188633918762 , accuracy:  0.9602118524554201\n",
      "Epoch:  51 , loss:  0.07035135477781296 , accuracy:  0.9608699739885299\n",
      "Epoch:  52 , loss:  0.07894345372915268 , accuracy:  0.9623930552508697\n",
      "Epoch:  53 , loss:  0.08261425048112869 , accuracy:  0.9617098624212604\n",
      "Epoch:  54 , loss:  0.07314658910036087 , accuracy:  0.9608449026920305\n",
      "Epoch:  55 , loss:  0.07553153485059738 , accuracy:  0.9610956156570246\n",
      "Epoch:  56 , loss:  0.08274070173501968 , accuracy:  0.9619856466827541\n",
      "Epoch:  57 , loss:  0.07393041253089905 , accuracy:  0.9628004638189852\n",
      "Epoch:  58 , loss:  0.07949676364660263 , accuracy:  0.9619104327932558\n",
      "Epoch:  59 , loss:  0.07388246804475784 , accuracy:  0.9609201165815288\n",
      "Epoch:  60 , loss:  0.07234286516904831 , accuracy:  0.9622676987683726\n",
      "Epoch:  61 , loss:  0.07553829252719879 , accuracy:  0.964154313829954\n",
      "Epoch:  62 , loss:  0.07114172726869583 , accuracy:  0.9638973330408349\n",
      "Epoch:  63 , loss:  0.07683456689119339 , accuracy:  0.9638597260960857\n",
      "Epoch:  64 , loss:  0.07580337673425674 , accuracy:  0.9636027453069667\n",
      "Epoch:  65 , loss:  0.07201939821243286 , accuracy:  0.9629508915979818\n",
      "Epoch:  66 , loss:  0.06553474068641663 , accuracy:  0.9643987589708233\n",
      "Epoch:  67 , loss:  0.0714544951915741 , accuracy:  0.9651320943934313\n",
      "Epoch:  68 , loss:  0.06275434046983719 , accuracy:  0.9649503274938105\n",
      "Epoch:  69 , loss:  0.06658802181482315 , accuracy:  0.966097339308659\n",
      "Epoch:  70 , loss:  0.0704989805817604 , accuracy:  0.9662540349117804\n",
      "Epoch:  71 , loss:  0.059061162173748016 , accuracy:  0.9654705568961734\n",
      "Epoch:  72 , loss:  0.06813564896583557 , accuracy:  0.9660597323639099\n",
      "Epoch:  73 , loss:  0.06905221194028854 , accuracy:  0.9658716976401642\n",
      "Epoch:  74 , loss:  0.0689922496676445 , accuracy:  0.9655771099062961\n",
      "Epoch:  75 , loss:  0.06837943941354752 , accuracy:  0.9663229809771537\n",
      "Epoch:  76 , loss:  0.05394389107823372 , accuracy:  0.9671127268168855\n",
      "Epoch:  77 , loss:  0.07251249998807907 , accuracy:  0.9667930677865179\n",
      "Epoch:  78 , loss:  0.07537279278039932 , accuracy:  0.9664169983390266\n",
      "Epoch:  79 , loss:  0.06626568734645844 , accuracy:  0.9660221254191608\n",
      "Epoch:  80 , loss:  0.07760695368051529 , accuracy:  0.9664734087561503\n",
      "Epoch:  81 , loss:  0.06580779701471329 , accuracy:  0.9625748221504905\n",
      "Epoch:  82 , loss:  0.05862663313746452 , accuracy:  0.9656147168510452\n",
      "Epoch:  83 , loss:  0.060530368238687515 , accuracy:  0.9675577423297502\n",
      "Epoch:  84 , loss:  0.05909406766295433 , accuracy:  0.969168573129838\n",
      "Epoch:  85 , loss:  0.06882461905479431 , accuracy:  0.9686734150239744\n",
      "Epoch:  86 , loss:  0.0680612325668335 , accuracy:  0.9690244131749663\n",
      "Epoch:  87 , loss:  0.05981859937310219 , accuracy:  0.971330972452913\n",
      "Epoch:  88 , loss:  0.05889563262462616 , accuracy:  0.9706289761509292\n",
      "Epoch:  89 , loss:  0.06496661901473999 , accuracy:  0.9716819706039048\n",
      "Epoch:  90 , loss:  0.05609319731593132 , accuracy:  0.9718637375035256\n",
      "Epoch:  91 , loss:  0.05172021687030792 , accuracy:  0.9737190134444828\n",
      "Epoch:  92 , loss:  0.061566054821014404 , accuracy:  0.972841518067003\n",
      "Epoch:  93 , loss:  0.05868617817759514 , accuracy:  0.9713121689805384\n",
      "Epoch:  94 , loss:  0.05601102486252785 , accuracy:  0.9713936506941615\n",
      "Epoch:  95 , loss:  0.0565975159406662 , accuracy:  0.972885392835877\n",
      "Epoch:  96 , loss:  0.06436861306428909 , accuracy:  0.9743332602087186\n",
      "Epoch:  97 , loss:  0.05844764783978462 , accuracy:  0.9742831176157197\n",
      "Epoch:  98 , loss:  0.04329262301325798 , accuracy:  0.972797643298129\n",
      "Epoch:  99 , loss:  0.04300661012530327 , accuracy:  0.9760318405465542\n",
      "Epoch:  100 , loss:  0.060396987944841385 , accuracy:  0.9762888213356733\n",
      "Epoch:  101 , loss:  0.050678230822086334 , accuracy:  0.9777053495878906\n",
      "Epoch:  102 , loss:  0.0520532988011837 , accuracy:  0.976345231752797\n",
      "Epoch:  103 , loss:  0.04601125046610832 , accuracy:  0.9768403898586606\n",
      "Epoch:  104 , loss:  0.05154242366552353 , accuracy:  0.9773230123162744\n",
      "Epoch:  105 , loss:  0.04324488714337349 , accuracy:  0.9760757153154282\n",
      "Epoch:  106 , loss:  0.05357293039560318 , accuracy:  0.9770597637030305\n",
      "Epoch:  107 , loss:  0.05393035709857941 , accuracy:  0.977210191482027\n",
      "Epoch:  108 , loss:  0.06744545698165894 , accuracy:  0.9722147356545175\n",
      "Epoch:  109 , loss:  0.050511591136455536 , accuracy:  0.9722084678303927\n",
      "Epoch:  110 , loss:  0.04840807616710663 , accuracy:  0.9769281393964085\n",
      "Epoch:  111 , loss:  0.04603151977062225 , accuracy:  0.9788460935786142\n",
      "Epoch:  112 , loss:  0.049852970987558365 , accuracy:  0.9779121877840108\n",
      "Epoch:  113 , loss:  0.06091667711734772 , accuracy:  0.977517314864145\n",
      "Epoch:  114 , loss:  0.045730751007795334 , accuracy:  0.9755742893854399\n",
      "Epoch:  115 , loss:  0.046588025987148285 , accuracy:  0.9791594847848569\n",
      "Epoch:  116 , loss:  0.04268786311149597 , accuracy:  0.979761195900843\n",
      "Epoch:  117 , loss:  0.05151399224996567 , accuracy:  0.9765896768936664\n",
      "Epoch:  118 , loss:  0.045346617698669434 , accuracy:  0.9789275752922373\n",
      "Epoch:  119 , loss:  0.040606942027807236 , accuracy:  0.9785201667241217\n",
      "Epoch:  120 , loss:  0.03887306526303291 , accuracy:  0.9797486602525933\n",
      "Epoch:  121 , loss:  0.043499015271663666 , accuracy:  0.9801874079413332\n",
      "Epoch:  122 , loss:  0.042412832379341125 , accuracy:  0.9791469491366073\n",
      "Epoch:  123 , loss:  0.04148733615875244 , accuracy:  0.980193675765458\n",
      "Epoch:  124 , loss:  0.03858195245265961 , accuracy:  0.9796609107148453\n",
      "Epoch:  125 , loss:  0.03824522718787193 , accuracy:  0.9811714563289354\n",
      "Epoch:  126 , loss:  0.04555254429578781 , accuracy:  0.97946034034285\n",
      "Epoch:  127 , loss:  0.04094495251774788 , accuracy:  0.977899652135761\n",
      "Epoch:  128 , loss:  0.03822688013315201 , accuracy:  0.9811401172083112\n",
      "Epoch:  129 , loss:  0.030357101932168007 , accuracy:  0.9822557899025354\n",
      "Epoch:  130 , loss:  0.03848995640873909 , accuracy:  0.9800933905794603\n",
      "Epoch:  131 , loss:  0.034991804510354996 , accuracy:  0.9812341345701839\n",
      "Epoch:  132 , loss:  0.03558206930756569 , accuracy:  0.9811965276254349\n",
      "Epoch:  133 , loss:  0.047384537756443024 , accuracy:  0.9814033658215551\n",
      "Epoch:  134 , loss:  0.03825727105140686 , accuracy:  0.9815224544799273\n",
      "Epoch:  135 , loss:  0.03913990408182144 , accuracy:  0.9816979535554232\n",
      "Epoch:  136 , loss:  0.050426892936229706 , accuracy:  0.9813344197561816\n",
      "Epoch:  137 , loss:  0.04604649543762207 , accuracy:  0.9807640477608198\n",
      "Epoch:  138 , loss:  0.04506449028849602 , accuracy:  0.9819486665204175\n",
      "Epoch:  139 , loss:  0.07405521720647812 , accuracy:  0.9720267009307719\n",
      "Epoch:  140 , loss:  0.04675091430544853 , accuracy:  0.9755868250336895\n",
      "Epoch:  141 , loss:  0.03860006853938103 , accuracy:  0.980538406092325\n",
      "Epoch:  142 , loss:  0.03254537656903267 , accuracy:  0.9821555047165377\n",
      "Epoch:  143 , loss:  0.040432099252939224 , accuracy:  0.9814973831834278\n",
      "Epoch:  144 , loss:  0.04703542962670326 , accuracy:  0.9801372653483343\n",
      "Epoch:  145 , loss:  0.03535279259085655 , accuracy:  0.9815099188316776\n",
      "Epoch:  146 , loss:  0.03875648230314255 , accuracy:  0.9833150521796359\n",
      "Epoch:  147 , loss:  0.04009599611163139 , accuracy:  0.9814033658215551\n",
      "Epoch:  148 , loss:  0.045232970267534256 , accuracy:  0.9813845623491805\n",
      "Epoch:  149 , loss:  0.03929991275072098 , accuracy:  0.9841612084364912\n",
      "Epoch:  150 , loss:  0.03452068567276001 , accuracy:  0.9841047980193676\n",
      "Epoch:  151 , loss:  0.03560980409383774 , accuracy:  0.9832962487072613\n",
      "Epoch:  152 , loss:  0.041717901825904846 , accuracy:  0.9828010906013978\n",
      "Epoch:  153 , loss:  0.057955581694841385 , accuracy:  0.9778056347738883\n",
      "Epoch:  154 , loss:  0.04936639219522476 , accuracy:  0.9731674449214955\n",
      "Epoch:  155 , loss:  0.04441019147634506 , accuracy:  0.977122441944279\n",
      "Epoch:  156 , loss:  0.03909330815076828 , accuracy:  0.981967469992792\n",
      "Epoch:  157 , loss:  0.030724773183465004 , accuracy:  0.9836660503306277\n",
      "Epoch:  158 , loss:  0.0435817688703537 , accuracy:  0.9832774452348867\n",
      "Epoch:  159 , loss:  0.033314041793346405 , accuracy:  0.9824124855056567\n",
      "Epoch:  160 , loss:  0.0374787338078022 , accuracy:  0.983264909586637\n",
      "Epoch:  161 , loss:  0.030533701181411743 , accuracy:  0.9833213200037607\n",
      "Epoch:  162 , loss:  0.035522811114788055 , accuracy:  0.9842301545018647\n",
      "Epoch:  163 , loss:  0.0327361561357975 , accuracy:  0.9842364223259895\n",
      "Epoch:  164 , loss:  0.03695467859506607 , accuracy:  0.9837914068131248\n",
      "Epoch:  165 , loss:  0.03675539046525955 , accuracy:  0.9829201792597699\n",
      "Epoch:  166 , loss:  0.039733801037073135 , accuracy:  0.9826381271741514\n",
      "Epoch:  167 , loss:  0.03238556906580925 , accuracy:  0.9838791563508728\n",
      "Epoch:  168 , loss:  0.030454277992248535 , accuracy:  0.9841925475571155\n",
      "Epoch:  169 , loss:  0.043676987290382385 , accuracy:  0.983007928797518\n",
      "Epoch:  170 , loss:  0.04005815088748932 , accuracy:  0.9820050769375411\n",
      "Epoch:  171 , loss:  0.045554470270872116 , accuracy:  0.9817418283242972\n",
      "Epoch:  172 , loss:  0.03457340970635414 , accuracy:  0.9826694662947758\n",
      "Epoch:  173 , loss:  0.033884212374687195 , accuracy:  0.9835406938481306\n",
      "Epoch:  174 , loss:  0.030815908685326576 , accuracy:  0.9840483876022439\n",
      "Epoch:  175 , loss:  0.03124821186065674 , accuracy:  0.9849258829797236\n",
      "Epoch:  176 , loss:  0.03896614909172058 , accuracy:  0.9772603340750259\n",
      "Epoch:  177 , loss:  0.034430284053087234 , accuracy:  0.9812529380425585\n",
      "Epoch:  178 , loss:  0.037297699600458145 , accuracy:  0.9817731674449215\n",
      "Epoch:  179 , loss:  0.0333557203412056 , accuracy:  0.9834090695415086\n",
      "Epoch:  180 , loss:  0.0382612943649292 , accuracy:  0.9839042276473722\n",
      "Epoch:  181 , loss:  0.03331493213772774 , accuracy:  0.9845811526528565\n",
      "Epoch:  182 , loss:  0.024810975417494774 , accuracy:  0.9847002413112288\n",
      "Epoch:  183 , loss:  0.0436268150806427 , accuracy:  0.9776990817637657\n",
      "Epoch:  184 , loss:  0.04014063626527786 , accuracy:  0.9790341283023598\n",
      "Epoch:  185 , loss:  0.037939392030239105 , accuracy:  0.9835156225516312\n",
      "Epoch:  186 , loss:  0.026451334357261658 , accuracy:  0.9848882760349744\n",
      "Epoch:  187 , loss:  0.02467665821313858 , accuracy:  0.9855338619198345\n",
      "Epoch:  188 , loss:  0.03608778864145279 , accuracy:  0.9855338619198345\n",
      "Epoch:  189 , loss:  0.02868589572608471 , accuracy:  0.9848067943213513\n",
      "Epoch:  190 , loss:  0.026818392798304558 , accuracy:  0.9853708984925883\n",
      "Epoch:  191 , loss:  0.030235012993216515 , accuracy:  0.9854649158544612\n",
      "Epoch:  192 , loss:  0.029142208397388458 , accuracy:  0.9861230373875709\n",
      "Epoch:  193 , loss:  0.02885563299059868 , accuracy:  0.9865680529004356\n",
      "Epoch:  194 , loss:  0.030767781659960747 , accuracy:  0.9868438371619292\n",
      "Epoch:  195 , loss:  0.031723205000162125 , accuracy:  0.9850136325174715\n",
      "Epoch:  196 , loss:  0.03449144959449768 , accuracy:  0.985471183678586\n",
      "Epoch:  197 , loss:  0.03040768951177597 , accuracy:  0.985991413080949\n",
      "Epoch:  198 , loss:  0.02778073027729988 , accuracy:  0.9841800119088658\n",
      "Epoch:  199 , loss:  0.031113574281334877 , accuracy:  0.984737848255978\n",
      "Epoch:  200 , loss:  0.0350588783621788 , accuracy:  0.985038703813971\n",
      "Epoch:  201 , loss:  0.03575316071510315 , accuracy:  0.9850261681657213\n",
      "Epoch:  202 , loss:  0.027306491509079933 , accuracy:  0.9857469679400797\n",
      "Epoch:  203 , loss:  0.02635180577635765 , accuracy:  0.9861669121564449\n",
      "Epoch:  204 , loss:  0.05310515686869621 , accuracy:  0.9747782757215833\n",
      "Epoch:  205 , loss:  0.04839653521776199 , accuracy:  0.9793851264533517\n",
      "Epoch:  206 , loss:  0.03698990121483803 , accuracy:  0.9839481024162462\n",
      "Epoch:  207 , loss:  0.03777533397078514 , accuracy:  0.9848255977937259\n",
      "Epoch:  208 , loss:  0.03729405999183655 , accuracy:  0.9835845686170046\n",
      "Epoch:  209 , loss:  0.031062213703989983 , accuracy:  0.9845059387633583\n",
      "Epoch:  210 , loss:  0.023279579356312752 , accuracy:  0.9856529505782068\n",
      "Epoch:  211 , loss:  0.03791983425617218 , accuracy:  0.9857657714124541\n",
      "Epoch:  212 , loss:  0.03225843608379364 , accuracy:  0.9841549406123664\n",
      "Epoch:  213 , loss:  0.035936351865530014 , accuracy:  0.9843993857532357\n",
      "Epoch:  214 , loss:  0.034864574670791626 , accuracy:  0.9852768811307154\n",
      "Epoch:  215 , loss:  0.028552347794175148 , accuracy:  0.9857908427089536\n",
      "Epoch:  216 , loss:  0.02753402292728424 , accuracy:  0.9852267385377166\n",
      "Epoch:  217 , loss:  0.031228698790073395 , accuracy:  0.9858535209502022\n",
      "Epoch:  218 , loss:  0.028560616075992584 , accuracy:  0.9865429816039362\n",
      "Epoch:  219 , loss:  0.031074870377779007 , accuracy:  0.9857156288194553\n",
      "Epoch:  220 , loss:  0.03851897269487381 , accuracy:  0.9836785859788775\n",
      "Epoch:  221 , loss:  0.039986029267311096 , accuracy:  0.983396533893259\n",
      "Epoch:  222 , loss:  0.033866241574287415 , accuracy:  0.9857281644677051\n",
      "Epoch:  223 , loss:  0.026249274611473083 , accuracy:  0.9867122128553073\n",
      "Epoch:  224 , loss:  0.0259819608181715 , accuracy:  0.9858033783572033\n",
      "Epoch:  225 , loss:  0.02425507828593254 , accuracy:  0.9853708984925883\n",
      "Epoch:  226 , loss:  0.03318915516138077 , accuracy:  0.9861105017393212\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-f515b0ae1d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/d/danieltm/ExaTrkX/eta-tracker/notebooks/toy_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_graph_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# Apply edge network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0;31m# Apply node network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/d/danieltm/ExaTrkX/eta-tracker/notebooks/toy_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0medge_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNodeNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 152\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \"\"\"\n\u001b[1;32m   1681\u001b[0m     return torch.layer_norm(input, normalized_shape, weight, bias, eps,\n\u001b[0;32m-> 1682\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_v = []\n",
    "acc_v = []\n",
    "ep = 0\n",
    "for epoch in range(500):\n",
    "    ep += 1\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in train_loader:\n",
    "#         print(batch.x)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        pred = model(data)\n",
    "        loss = F.binary_cross_entropy_with_logits(pred.float(), data.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += ((pred > 0.5) == (data.y > 0.5)).sum().item()\n",
    "#         print(correct, pred, data.y)\n",
    "        total += len(pred)\n",
    "#         print(out, data.y, )\n",
    "    acc = correct/total\n",
    "    print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", accuracy: \", acc)\n",
    "    loss_v.append(loss)\n",
    "    acc_v.append(acc)\n",
    "plt.plot(np.arange(len(loss_v)), loss_v)\n",
    "plt.plot(np.arange(len(acc_v)), acc_v)\n",
    "plt.ylim(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[5930], edge_index=[2, 14580], x=[5930, 2], y=[14580])\n",
      "Accuracy: 0.9812\n",
      "Batch(batch=[5880], edge_index=[2, 14637], x=[5880, 2], y=[14637])\n",
      "Accuracy: 0.9832\n",
      "Batch(batch=[5580], edge_index=[2, 14190], x=[5580, 2], y=[14190])\n",
      "Accuracy: 0.9862\n",
      "Batch(batch=[5710], edge_index=[2, 14652], x=[5710, 2], y=[14652])\n",
      "Accuracy: 0.9838\n",
      "Batch(batch=[5470], edge_index=[2, 12952], x=[5470, 2], y=[12952])\n",
      "Accuracy: 0.9866\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    data = batch.to(device)\n",
    "    pred = model(data)\n",
    "    correct = ((pred > 0.5) == (data.y > 0.5)).sum().item()\n",
    "    acc = correct / len(pred)\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Track Count Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(1000)]\n",
    "test_dataset = [gen_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using \", device)\n",
    "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
    "model = Net(train_dataset).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 9,  9,  7,  4,  7,  3,  5,  7,  6,  7,  4,  7,  2,  6,  5,  6,  7,  9,\n",
      "         5,  9,  6,  9,  5,  7,  8,  8,  4,  4,  7,  5,  6,  4,  4,  8, 10,  1,\n",
      "         5,  8,  8,  5,  8,  4,  9,  5,  9,  6,  2,  9,  5,  4,  7,  4,  9,  5,\n",
      "         9,  5,  5,  4,  9,  6,  5,  7,  6,  4,  7,  4, 11,  4, 11,  5,  7,  4,\n",
      "         7,  7,  9,  5,  3,  7,  3,  6,  3,  8,  3,  6,  6,  4,  6,  4,  8,  3,\n",
      "         7,  7,  8,  2,  6,  6,  3,  4,  8,  2], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 3, 10,  9,  3,  7,  7,  5,  8,  4,  6, 10,  4,  7,  5,  3,  5, 10,  7,\n",
      "         4,  6,  9,  5,  7,  4,  8,  4,  3,  6,  3,  6,  5,  4,  9,  7,  6,  8,\n",
      "         7,  8,  9,  3,  3,  7,  9,  8,  7,  4, 11,  6,  6,  4,  4,  8,  5,  7,\n",
      "         4,  5,  6,  6,  7,  4,  6,  3,  7,  5,  6,  8,  6,  8,  8,  9,  4,  8,\n",
      "         4,  7,  7,  5,  6,  7,  5,  7,  3,  7,  6,  5,  8,  5,  2,  5,  7,  5,\n",
      "         7,  3,  9,  9,  5,  9,  7,  4,  6,  7], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 8,  4,  2,  7,  7,  4,  5,  6,  9,  6,  3,  7,  7,  5,  9,  3,  5,  5,\n",
      "         4,  5,  9,  9,  7,  7,  8,  3,  7,  5,  9,  6,  7,  3,  6,  5,  9,  3,\n",
      "        10,  3,  7,  5,  9,  6,  5,  8,  4,  3,  3,  6,  4,  5,  4, 10,  7,  5,\n",
      "         5,  6,  9,  5,  6,  5,  6,  4,  7,  4,  3,  3,  6,  8,  6, 10,  7,  7,\n",
      "         8,  4,  5,  3,  8,  8,  4,  2,  5,  5,  3,  9,  5, 11,  9,  5,  3,  6,\n",
      "         9,  4,  9,  8,  7,  7,  5,  4,  6,  7], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 4,  4,  6,  7,  9,  8,  4,  8,  4,  4,  3, 11,  4,  6,  9,  6,  7,  5,\n",
      "         7,  8,  6,  5,  4,  7,  9,  9,  4,  4,  9,  9,  4,  6,  5,  4,  6,  7,\n",
      "         4,  9,  4,  4,  6,  8,  6,  2,  6,  6,  3,  7,  6,  7,  2,  7,  7,  3,\n",
      "         3,  6,  7,  7,  7,  3,  7,  7,  5,  2,  9,  7, 10,  8,  7,  7,  3,  8,\n",
      "         3,  5,  6,  7,  7,  6,  5,  6,  7, 11,  2,  8, 10,  7,  8,  7,  6,  5,\n",
      "         4, 10, 10,  4,  3,  7,  8,  6,  5,  7], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 4,  4,  7,  8,  7,  5,  2,  6,  6,  2,  7,  4,  7,  4,  6,  5,  7,  7,\n",
      "         5,  6,  2, 10,  4,  5,  7,  8,  5,  7,  5,  8, 10,  5,  8,  4,  7,  8,\n",
      "         6,  9,  5,  5,  9,  8,  9,  5,  3,  7,  7,  6, 10,  7,  6,  3,  7,  7,\n",
      "         5,  9,  4,  6,  5,  9,  5,  5,  5,  9,  9,  7,  7,  6,  6,  5,  6,  7,\n",
      "         4,  4,  6,  4,  3,  7,  3,  8,  6,  3,  5,  5,  5,  8,  6,  5,  3,  8,\n",
      "        11,  5,  3,  4,  4,  8,  5,  8,  9,  3], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 4,  8,  3,  5,  4,  4,  8,  7,  7,  7,  8,  9,  4,  9,  9,  6,  5,  7,\n",
      "         7,  7,  8,  5,  5,  9,  6,  5,  3,  8,  4,  5,  7,  5,  3, 10,  6,  5,\n",
      "         3,  6,  5,  2,  5, 11,  5,  6,  4,  6,  8,  7,  5,  7,  9,  6,  8,  3,\n",
      "         7,  8,  2,  8,  4,  4,  4,  9,  6,  4,  6,  6,  6,  5,  9,  4,  7,  8,\n",
      "         4,  5,  3,  7,  5,  7,  3,  8,  4,  8,  8,  8,  5,  6,  9,  8,  6,  5,\n",
      "         6, 10,  7,  9,  4,  7,  2,  4,  7, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 5,  3,  7,  6,  6,  7,  8,  3,  2,  6,  3,  4,  3,  8,  3,  4,  4,  4,\n",
      "         8,  5,  6,  3,  4,  8,  4,  7,  6,  9,  7,  9,  9,  9,  5,  6,  7,  4,\n",
      "         5,  8,  3,  6,  9,  3,  8,  6,  9,  5,  5,  6,  7,  1, 10,  4,  8,  6,\n",
      "         5,  6, 10,  4,  9,  8,  4,  7,  4,  5,  4,  5,  9,  5,  7,  9,  7,  6,\n",
      "         5, 10,  9,  8,  3,  6,  2,  4,  8,  6,  7,  7,  5,  3,  4,  6,  8,  9,\n",
      "         5,  8,  6,  6,  6,  5,  5,  4,  6,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 7,  7,  4,  8,  6,  6,  7,  3,  6,  5,  3,  5,  7, 10,  6,  7,  9, 10,\n",
      "         4,  4,  5,  6,  5,  7,  8,  9,  7,  3,  7,  3,  5,  8,  8,  9,  6,  5,\n",
      "         7, 10,  8,  7,  7,  5,  8,  4,  7, 10,  8,  5,  8,  7,  7,  9,  7,  7,\n",
      "         4,  8,  5,  8,  5,  6, 10,  3,  3,  7,  7, 10,  5,  8,  7,  3,  9, 10,\n",
      "         3,  4, 10,  8,  5,  5,  4, 10,  7,  6,  5, 10,  9,  6,  8,  5,  9,  5,\n",
      "         7,  3,  4,  6,  3,  6,  5,  7,  8,  8], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([10,  6,  6,  8,  9,  6,  4,  6,  9,  6,  9,  8,  7,  4,  7, 10,  9,  5,\n",
      "         4,  9,  4,  6,  4,  4,  8,  4,  5,  4,  8, 10,  2,  2,  7,  5,  5,  7,\n",
      "         6,  3, 11,  9,  7, 10,  4,  5,  3,  2,  8,  4,  5,  3,  8,  9,  4,  8,\n",
      "         5, 11,  4,  9,  6,  7,  8,  4,  5,  3,  3, 10,  9,  7,  2,  7,  9, 10,\n",
      "         5,  4,  6,  3,  9,  3,  7,  5,  7,  8,  5,  7,  4,  4,  5,  4,  8,  8,\n",
      "         6,  3,  7,  9, 10,  8, 10,  4,  6,  5], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 9,  5,  5,  8,  9,  4,  5,  8,  5,  3,  8,  6,  9,  1,  6,  6,  7,  6,\n",
      "         4,  5,  6,  4,  8,  4,  8,  7,  7,  8,  9,  6,  9, 10,  7,  8,  3,  3,\n",
      "         8,  5,  6,  5,  8,  3,  9,  7,  7,  8,  5, 10,  4,  3,  4,  7,  6,  8,\n",
      "         4,  3,  3,  1,  4,  8,  9, 10,  6,  4,  8,  2, 10,  7,  4,  2,  6,  4,\n",
      "         8, 10,  4,  8,  2, 10,  8,  8,  3,  3,  9,  4,  8,  7,  6,  3,  3,  6,\n",
      "         9,  7,  9,  7,  5, 10,  8,  7,  3,  8], device='cuda:0')\n",
      "Epoch:  1 , loss:  2.449791431427002 , accuracy:  0.14\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([ 6,  7,  9, 10,  6,  8,  2,  3,  4,  9,  7,  7,  5,  8,  3,  5, 10,  3,\n",
      "         4,  7,  4,  6,  5,  7,  7,  4,  4,  4,  5,  7,  7,  6,  7,  3,  5,  5,\n",
      "         5,  8,  4,  7,  4,  7,  5,  4,  6,  9,  6,  8,  4,  6,  8,  6, 10,  8,\n",
      "         4,  5,  6,  6,  5,  4,  7,  7,  6,  3,  4,  5,  5,  4,  4,  9,  5,  3,\n",
      "         9,  3,  7,  5,  5,  3,  4,  5,  7,  4,  8,  5,  7,  5,  7,  7,  6,  7,\n",
      "         5,  7,  5,  8,  8,  4,  6, 10,  6,  3], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([6, 6, 4, 6, 4, 6, 6, 4, 4, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 4, 4, 6, 6, 4, 4, 6, 4, 4, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 4, 4, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 4, 6, 4,\n",
      "        6, 6, 6, 6], device='cuda:0') tensor([11,  7,  2,  9,  3,  8,  8,  4,  3,  9,  6,  6,  6,  8,  5,  7,  3,  5,\n",
      "         9,  8,  8,  5,  5,  8,  7,  8,  7,  9,  6,  4,  8, 10,  3,  5,  4,  9,\n",
      "         9,  6,  3,  7,  9,  7,  9,  9,  7,  7,  5,  8,  4,  7,  7,  9,  7,  7,\n",
      "         7,  9,  9,  2,  9,  3,  4, 10,  5,  5,  5,  8,  5,  3,  6,  4,  9,  7,\n",
      "         7,  7,  8, 10,  4,  5,  2,  9,  3,  8,  4,  7,  8,  8,  8,  6,  6,  3,\n",
      "         4,  5,  8,  5,  9,  6,  8,  7,  9,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 4, 6, 4, 4, 6, 4, 4, 6, 6, 4, 4, 4, 6, 6, 4, 4, 6, 4, 4, 6, 4, 6, 4,\n",
      "        4, 6, 6, 4, 4, 6, 4, 6, 4, 4, 6, 4, 6, 4, 6, 4, 4, 4, 4, 4, 4, 4, 6, 4,\n",
      "        4, 6, 6, 4, 4, 4, 4, 6, 4, 4, 4, 4, 6, 4, 4, 6, 4, 4, 4, 4, 6, 6, 4, 4,\n",
      "        4, 4, 4, 4, 6, 4, 4, 4, 6, 6, 4, 6, 4, 4, 4, 6, 6, 4, 6, 4, 6, 4, 4, 4,\n",
      "        4, 4, 6, 6], device='cuda:0') tensor([ 4,  6,  8,  5,  4, 10,  8,  5,  6,  8,  6,  8,  6,  6,  8,  5,  4,  8,\n",
      "         6,  3,  7,  5,  9,  4,  5,  7,  5,  6,  3,  6,  3,  8,  5,  3,  9,  4,\n",
      "         8,  5, 10,  5,  9,  5,  3,  7,  6,  4,  8,  6,  7, 11,  5,  3,  5,  7,\n",
      "         9,  7,  5,  5,  3,  5,  9,  4,  3, 10,  2,  7,  8,  9, 10,  9,  6,  6,\n",
      "         6,  4,  3,  1,  7,  3,  4,  7,  8,  8,  7,  9,  6,  5,  4,  4,  9,  7,\n",
      "         7,  6,  8,  7,  5,  5,  3,  5,  9, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 5, 5, 5, 5, 4, 5, 5, 5, 4, 5, 6, 5, 5, 5, 5, 5, 6, 4, 5, 5, 6, 5, 4,\n",
      "        5, 5, 4, 5, 5, 6, 5, 5, 4, 5, 5, 6, 5, 6, 5, 4, 5, 5, 4, 5, 5, 5, 4, 6,\n",
      "        4, 4, 5, 5, 5, 5, 5, 5, 4, 4, 5, 4, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 6, 5, 4, 4,\n",
      "        5, 4, 4, 5], device='cuda:0') tensor([ 3,  5,  9,  5, 10,  4,  9,  6,  7,  5,  9,  8,  5,  8,  8,  5,  6,  5,\n",
      "         3,  8,  6,  5,  9,  2,  5,  7,  6,  7,  6,  3,  6,  7,  3, 10,  8,  7,\n",
      "        10,  3,  7,  5,  8,  7,  5,  8,  9,  7,  5,  8,  1,  4,  6,  8,  2, 11,\n",
      "         7,  8,  3,  4,  7,  3,  5,  9,  7,  4,  4,  8,  4,  9,  6,  8,  4,  5,\n",
      "         4,  5,  8,  4,  9,  5,  5,  6,  3,  4,  6,  9,  4,  7,  6,  5,  8,  4,\n",
      "         7,  4,  6, 11,  4,  4,  4,  4,  4,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 4,  7,  4,  2, 10,  7,  4,  7,  3,  7,  5,  9,  5,  8,  6,  7,  6, 10,\n",
      "         6,  6,  4,  4,  3,  6,  3, 10,  8,  7,  9,  5,  6,  7,  4,  5,  7,  8,\n",
      "         6,  3,  7,  9,  8,  5,  5,  3,  4,  5, 10,  4,  6,  4,  7,  6,  4,  5,\n",
      "         5,  1,  7,  4,  3,  8,  6,  6,  2,  5,  4,  7,  8,  7,  9,  8,  7, 10,\n",
      "         3,  7,  8,  7,  9,  9,  3, 10,  4,  6,  8,  5,  6,  7,  8,  4,  9,  4,\n",
      "         4,  2,  8,  5,  5,  9,  7,  4,  6,  6], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 8,  8,  6,  6,  7,  9,  8,  7,  7,  7,  7,  8,  5,  6,  5,  8,  6,  6,\n",
      "         6,  6,  6,  7,  7,  4,  8,  3,  5,  6,  9,  3,  4,  5,  5,  4,  2,  7,\n",
      "         6,  5,  4,  9,  8,  8,  5,  7,  8,  5,  4, 10,  5,  5,  7,  9,  4,  6,\n",
      "         7,  9,  4,  6,  5,  7,  6,  3,  4,  6,  9,  4,  5,  5,  8,  3,  5,  5,\n",
      "         8,  4,  9,  3,  6,  3,  8,  4,  7,  4,  7,  8,  9,  9,  9,  4,  9,  2,\n",
      "        10,  6,  8,  4,  3,  6, 10,  8,  4,  6], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 5,  2,  5,  8,  8,  5,  8,  4,  5,  4,  9,  9,  8,  7,  3,  4,  5,  4,\n",
      "         7,  4,  7,  4,  8,  9,  7,  3,  7,  9,  3,  8,  7,  7,  8,  8,  8,  7,\n",
      "         9,  6,  9,  6,  3,  7,  6,  8,  6,  7,  6,  5,  8, 10,  8,  6,  9,  5,\n",
      "         7,  7,  7,  9,  6,  3,  7,  6,  5,  7,  9,  7,  3,  7,  8,  6,  6,  4,\n",
      "         8,  7,  8,  3,  7,  4,  3,  3,  9,  7,  4,  6,  6,  4,  7,  4,  4,  8,\n",
      "         3,  6,  7,  3,  6,  7,  5,  6,  8, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([10,  5,  5,  4,  5,  7,  5,  8,  5,  2,  9,  3,  5,  4,  7,  2, 10,  2,\n",
      "         4,  9,  4,  3,  5,  5,  6,  7, 11,  7,  8,  7,  8,  8,  9,  3,  4,  6,\n",
      "         6,  3,  9,  4,  3, 10,  3,  6,  9,  3,  2,  8, 10,  6,  5,  9,  6,  3,\n",
      "         5,  7,  6, 11,  5,  3,  5,  7,  3,  5,  4,  4,  8,  5,  7,  4, 10,  4,\n",
      "         6,  9,  7,  9,  6,  2,  8,  5,  7,  7,  7, 11,  8,  2,  9,  5,  7,  2,\n",
      "         4,  7, 11, 11,  5,  6,  7,  4,  9,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 3,  7,  5,  9,  5,  4,  3,  2,  3,  5,  6,  7,  8,  8,  5, 10,  7,  7,\n",
      "         7,  7,  6,  7,  3,  7,  7,  5,  3,  6,  6,  7,  4,  5,  5, 10,  6,  6,\n",
      "        10,  8,  5,  4,  6,  8, 10,  3,  7,  3,  8,  7,  3,  5,  9,  9,  6,  5,\n",
      "         4, 10,  6, 10,  9,  3,  7,  7,  6,  5,  3,  7, 10,  4,  6,  9,  9,  6,\n",
      "         7,  8,  5,  5, 10,  8,  7, 11,  7,  4,  8,  6,  6,  4,  8,  8,  5,  9,\n",
      "         6,  5,  7,  6,  6,  8, 10,  6,  7,  4], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 4,  2,  8,  3, 10,  7,  5, 10,  7,  8, 10,  5,  6,  6,  4,  7,  1,  6,\n",
      "         5, 10,  7,  2,  6,  7,  9,  9,  9,  7,  9,  4,  3,  4,  7,  9,  9, 10,\n",
      "         5,  4,  7,  5,  3,  8,  5,  3,  5,  3,  2,  6,  7,  3,  8,  5,  4,  4,\n",
      "         9,  5,  6,  3,  9,  6,  8,  5,  9,  8,  4,  7,  3,  6,  5,  7,  3,  2,\n",
      "         6,  6,  9,  4,  6,  4,  5,  6,  4,  4,  3,  2,  4,  6,  4,  4,  4,  4,\n",
      "         9,  7,  5,  4,  7,  6,  7,  8,  8,  7], device='cuda:0')\n",
      "Epoch:  2 , loss:  2.38297176361084 , accuracy:  0.141\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 8,  9,  5,  4,  7,  7,  7,  7,  7,  4,  8,  7,  5,  2,  6,  3,  7,  9,\n",
      "         6,  5,  7,  4,  4,  5,  8,  8,  4,  3,  5,  8,  7,  4,  7,  8,  9,  2,\n",
      "         3,  9,  4,  4, 11,  9,  4,  4,  3,  9,  7,  7,  3,  7,  7,  8,  6,  8,\n",
      "         4,  5,  5,  2,  7,  9,  5,  7,  6,  3,  7,  7,  8,  7,  5,  8,  6,  3,\n",
      "         4,  3,  7, 11,  7,  7,  5,  6,  7,  5,  6,  3,  6,  8,  7,  3,  7,  7,\n",
      "         6,  7, 10,  7,  6,  9,  5,  9,  7,  5], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5], device='cuda:0') tensor([ 3,  4,  4,  7,  4,  7,  7,  5,  8,  5,  5,  8,  9,  8,  5,  4,  7,  6,\n",
      "         6,  7,  4,  7,  5,  5,  5, 11,  3,  6,  8,  8,  8,  9,  4,  7,  3,  5,\n",
      "         4,  9,  4,  6,  9, 10,  1,  5,  4, 10,  8,  3,  8,  7,  5,  9,  6,  7,\n",
      "         4,  7,  9,  8,  5,  6,  8,  8,  3,  9,  9,  2,  5,  3,  5,  7,  6,  9,\n",
      "         3,  3,  6,  7,  6,  4,  9,  4,  2,  4,  4,  7,  9,  7,  9,  3,  3,  5,\n",
      "         7,  5,  6,  6,  5,  4,  7,  7,  4,  5], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 4, 5, 5, 4, 5, 4, 4, 5, 5, 4, 4, 5, 4, 4,\n",
      "        5, 4, 5, 4, 5, 5, 5, 4, 4, 4, 4, 5, 4, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 4,\n",
      "        4, 5, 5, 5, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4, 4, 5, 5, 4, 5, 5, 5, 4, 4,\n",
      "        4, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 5, 5, 4, 5, 4, 5, 4, 5, 4,\n",
      "        5, 4, 5, 5], device='cuda:0') tensor([ 6,  4,  5, 10,  7, 10,  6,  4,  5,  6,  3,  2,  7,  6,  6,  6,  5,  5,\n",
      "         6,  6,  4,  5,  8,  6,  4,  2,  8,  6,  8,  8,  9,  4,  3,  6,  2,  6,\n",
      "         4,  6,  7,  6,  5,  4,  7,  7,  3,  9,  5,  4,  4,  8,  5, 10,  4,  4,\n",
      "         6,  4,  5,  8,  6,  5,  6,  6,  6,  6,  5,  6,  3,  6,  7,  9,  4,  4,\n",
      "         2,  7,  5,  3,  7,  6,  6,  5,  5,  9, 10,  5,  6,  3,  5,  5, 10,  6,\n",
      "         7,  7,  8,  3,  7,  6,  9,  7,  9,  8], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 5, 5, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 4, 5, 4, 5, 4, 4, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4,\n",
      "        4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4,\n",
      "        4, 4, 4, 5], device='cuda:0') tensor([ 6,  9,  9,  7,  4, 10,  8,  4,  4,  6,  4, 11,  9,  7,  2,  2,  5,  7,\n",
      "         7,  4,  5,  4,  4,  9,  7,  5,  6,  5,  7,  3,  5,  3,  3,  5,  6, 10,\n",
      "         8,  5,  5,  6,  5, 10,  4,  3,  6,  9,  4,  4,  4,  3,  3,  4,  6,  5,\n",
      "         5,  5,  5,  7,  9,  6,  9,  9,  9,  5,  4,  3,  3,  7,  7,  9,  3,  9,\n",
      "         5,  8,  6,  3,  4,  4,  3,  7,  6,  7,  3,  8,  4,  3,  6,  8,  5,  9,\n",
      "         7,  7,  2,  7,  8,  6,  4,  9,  4, 10], device='cuda:0')\n",
      "torch.Size([100]) torch.Size([100]) tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4], device='cuda:0') tensor([ 4,  4,  4,  6,  4,  4,  8,  6,  7,  6,  9,  5,  8,  7,  8, 10,  4,  9,\n",
      "         4,  7,  5,  8,  6,  5, 10,  7,  9,  3,  2,  4,  5,  5,  4, 10,  3,  4,\n",
      "         3,  8,  5,  9, 10,  8,  8,  6,  8,  5,  7,  5,  8,  5,  7,  7,  9,  5,\n",
      "         3,  5, 10,  4,  6,  6,  7,  9,  3, 10,  6,  3,  6,  7,  5,  5,  8,  8,\n",
      "        10,  6,  5,  7,  6,  6,  4,  9,  2,  8,  9,  4,  9,  7,  5,  4,  8,  4,\n",
      "         4,  5,  8,  8,  2,  7,  8,  9,  4,  9], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-31fb8df39f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_v = []\n",
    "acc_v = []\n",
    "ep = 0\n",
    "for epoch in range(500):\n",
    "    ep += 1\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in train_loader:\n",
    "#         print(batch.x)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        out = model(data)\n",
    "        _, pred = out.max(dim=1)\n",
    "        print(pred.shape, data.y.shape, pred, data.y)\n",
    "        loss = F.cross_entropy(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        correct += float(pred.eq(data.y).sum().item())\n",
    "#         print(correct, pred, data.y)\n",
    "        total += len(pred)\n",
    "#         print(out, data.y, )\n",
    "    acc = correct/total\n",
    "    print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", accuracy: \", acc)\n",
    "    loss_v.append(loss)\n",
    "    acc_v.append(acc)\n",
    "plt.plot(np.arange(len(loss_v)), loss_v)\n",
    "plt.plot(np.arange(len(acc_v)), acc_v)\n",
    "plt.ylim(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[6110], edge_index=[2, 16297], x=[6110, 2], y=[100])\n",
      "tensor([ 7,  7,  7,  4,  6,  4,  6,  9,  7,  9,  8,  2,  5,  6,  5,  6,  7,  7,\n",
      "         9,  7,  4,  7,  9,  9,  5,  8,  5,  5,  4,  9,  7,  4,  9,  3,  9,  4,\n",
      "         6,  5,  4,  6,  4,  7,  3,  5,  5,  4,  5,  5, 10,  5,  2,  7,  9,  6,\n",
      "        10,  4,  3,  9,  4,  9,  4,  8,  6,  9,  9,  5,  1,  9,  7,  9,  5,  4,\n",
      "         9,  6,  4,  9,  4,  4,  3,  7,  7,  9,  4,  4,  3,  7,  7,  4,  6,  9,\n",
      "         7,  9, 10,  7,  9,  4, 10,  5,  7,  6], device='cuda:0') tensor([ 7,  7,  8,  4,  6,  4,  5, 11,  8, 10,  8,  3,  5,  6,  4,  6,  7,  6,\n",
      "         8,  7,  4,  7,  9,  8,  5,  8,  5,  5,  2, 10,  7,  5,  9,  2,  8,  4,\n",
      "         6,  5,  4,  6,  4,  7,  3,  5,  6,  5,  5,  6, 10,  5,  2,  6,  7,  6,\n",
      "        11,  4,  3,  9,  3,  9,  4,  8,  6,  8,  6,  6,  2,  8,  7,  8,  5,  4,\n",
      "         6,  5,  3,  9,  4,  3,  3,  6,  8, 10,  5,  4,  3,  7,  9,  4,  6,  5,\n",
      "         7,  9,  9,  7, 10,  4, 11,  5,  6,  6], device='cuda:0')\n",
      "Accuracy: 0.5800\n",
      "Batch(batch=[6030], edge_index=[2, 15800], x=[6030, 2], y=[100])\n",
      "tensor([ 4,  6,  8,  3,  8,  6, 10,  6,  7,  9,  3,  6,  7,  6,  5,  8,  4,  4,\n",
      "         4,  6,  4,  6,  7,  5,  6, 10,  8,  5,  9,  2,  5,  6,  4,  9,  7,  9,\n",
      "         9,  8,  6,  9,  4,  7,  3,  4,  4,  4,  6,  4,  7,  9,  3,  4,  9,  4,\n",
      "         6,  8,  4,  7,  9,  5,  5,  8,  3,  7,  5,  7,  4,  9,  5,  3,  7,  8,\n",
      "         9,  4,  9,  8,  9,  4,  3,  2,  7,  8,  7,  6,  5,  7,  7,  5,  5,  7,\n",
      "         7,  7,  6,  4,  7,  9,  7,  7,  5,  2], device='cuda:0') tensor([ 4,  5,  8,  2,  6,  6, 10,  6,  8,  6,  2,  6,  8,  5,  6,  7,  4,  4,\n",
      "         4,  5,  4,  6,  7,  5,  6,  9,  7,  5, 10,  2,  5,  6,  3,  9,  6,  8,\n",
      "        10,  8,  6,  9,  4,  8,  3,  4,  5,  4,  5,  4,  7,  8,  3,  3,  8,  3,\n",
      "         6,  8,  4,  7,  9,  5,  5,  8,  3,  8,  6,  7,  4,  8,  4,  3,  7,  9,\n",
      "         9,  4,  9,  8,  8,  5,  4,  2,  7,  8,  6,  6,  6,  9,  7,  3,  6,  8,\n",
      "         8,  8,  6,  4,  8,  9,  6,  9,  4,  3], device='cuda:0')\n",
      "Accuracy: 0.5400\n",
      "Batch(batch=[6180], edge_index=[2, 16398], x=[6180, 2], y=[100])\n",
      "tensor([ 7,  8,  5,  4,  9,  9,  9,  4,  9,  9,  6,  7,  5,  9,  3, 10,  3,  8,\n",
      "         4,  3,  3,  1,  5,  5,  4,  7,  9,  6,  6,  9,  2,  5,  4,  5,  5,  7,\n",
      "         5,  4,  6,  7,  9,  8,  4,  7,  4,  5,  6,  5,  6,  9,  7,  2,  7,  4,\n",
      "         2,  9,  6,  9,  3,  4, 10,  9,  5,  9,  6,  5,  7,  7,  6,  9,  5,  6,\n",
      "         5,  5,  5, 10,  8,  9,  6,  6,  7, 10,  7,  9,  4,  3,  5,  7,  5,  9,\n",
      "         4,  9,  9,  9, 10,  4,  5,  5,  7,  7], device='cuda:0') tensor([ 6,  7,  5,  4,  7,  9, 10,  3,  9,  8,  6,  6,  5,  7,  3, 11,  3,  7,\n",
      "         4,  3,  3,  1,  4,  5,  4,  7,  7,  6,  6, 10,  5,  5,  4,  5,  5,  7,\n",
      "         5,  3,  5,  9,  9,  9,  4,  7,  4,  6,  6,  6,  6,  8,  6,  2,  6,  4,\n",
      "         2,  8,  5,  9,  3,  4,  8,  9,  6,  7,  7,  6,  7,  7,  6, 10,  6,  6,\n",
      "         5,  7,  5, 10,  8,  9,  6,  6,  7, 10,  7,  8,  5,  3,  5,  7,  6,  9,\n",
      "         4,  9,  8,  9,  9,  4,  4,  6,  7,  7], device='cuda:0')\n",
      "Accuracy: 0.6000\n",
      "Batch(batch=[6120], edge_index=[2, 16169], x=[6120, 2], y=[100])\n",
      "tensor([ 7,  9,  3,  4,  6,  2,  4,  9,  5,  7,  8, 10,  9,  7,  6,  6,  9,  9,\n",
      "         6,  5,  4,  5,  5,  4,  9,  9,  3,  7,  4,  4,  4,  8,  7,  9,  1,  4,\n",
      "         9, 10,  7,  9, 10,  7,  9,  5,  7,  9,  4,  4,  5,  4,  9,  7,  4,  7,\n",
      "         5,  8,  9,  9,  4,  6,  9,  7,  7,  7,  6,  9,  5,  7,  4,  7,  5,  5,\n",
      "         4,  4, 10,  5,  9,  8,  9,  9,  2,  9,  4,  5,  3,  6,  6,  9,  6,  9,\n",
      "         7,  9,  7,  6,  4,  7,  6,  5,  7,  6], device='cuda:0') tensor([ 7,  8,  2,  4,  7,  2,  4,  9,  6,  7,  7, 10,  8,  6,  6,  5,  8,  8,\n",
      "         5,  5,  4,  5,  5,  5, 10,  9,  4,  8,  4,  5,  4,  8,  6,  8,  1,  4,\n",
      "         8,  8,  6,  9, 11,  6,  8,  5,  6,  8,  3,  3,  3,  3,  9,  7,  3,  7,\n",
      "         3,  8,  8,  8,  4,  6,  9,  7,  7,  7,  6,  8,  5,  7,  4,  8,  5,  5,\n",
      "         5,  4,  8,  5,  9,  9,  8,  7,  2,  8,  3,  5,  3,  6,  6,  8,  6,  9,\n",
      "         7,  8,  6,  5,  4,  6,  6,  5,  6,  6], device='cuda:0')\n",
      "Accuracy: 0.5100\n",
      "Batch(batch=[6080], edge_index=[2, 15661], x=[6080, 2], y=[100])\n",
      "tensor([ 7,  4,  6,  7,  6,  4,  4,  7,  7,  3,  7,  4,  9,  9, 10,  6,  9,  5,\n",
      "         7,  8,  9,  9,  7, 10,  4,  7,  9,  7,  5,  6,  6,  5,  9,  9,  4,  9,\n",
      "         4, 10,  5,  5,  4,  5,  7,  6,  4,  7,  9,  7,  7,  8,  5,  5,  2,  4,\n",
      "         7,  9,  3,  6,  9,  9,  4,  3,  7,  6,  4,  4,  4,  7,  5,  4, 10,  5,\n",
      "         7,  5,  4,  5,  8,  9,  6,  5,  5, 10,  5,  7,  1,  4,  4,  7,  5,  6,\n",
      "         7,  9,  7,  5, 10,  9,  6,  9,  9,  6], device='cuda:0') tensor([ 8,  4,  5,  8,  5,  4,  3,  6,  7,  3,  7,  4,  9,  9, 10,  7,  9,  6,\n",
      "         7,  8,  8,  9,  6, 10,  4,  6,  3,  8,  5,  6,  5,  5,  8,  9,  4,  9,\n",
      "         4,  9,  5,  6,  4,  5,  6,  5,  3,  8,  9,  7,  7,  9,  5,  5,  3,  3,\n",
      "         8,  8,  2,  5,  8,  8,  4,  2,  6,  6,  3,  5,  3,  7,  5,  5,  9,  5,\n",
      "         6,  5,  4,  5,  8,  9,  7,  6,  3,  9,  5,  7,  1,  4,  5,  7,  5,  6,\n",
      "         6,  7,  6,  5, 10,  8,  6,  8,  8,  6], device='cuda:0')\n",
      "Accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    data = batch.to(device)\n",
    "    _, pred = model(data).max(dim=1)\n",
    "    print(pred, data.y)\n",
    "    correct = float(pred.eq(data.y).sum().item())\n",
    "    acc = correct / len(pred)\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combined Counter & Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = [gen_edge_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(1000)]\n",
    "test_dataset = [gen_edge_graph_class(event_size_min, event_size_max, max_curve, min_curve, height, num_layers, max_angle) for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].y_graph.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using \", device)\n",
    "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
    "model = Edge_Graph_Class_Net(input_dim=2, hidden_dim=16, n_graph_iters=4, output_dim=12).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , loss:  3.1576285362243652 , count accuracy:  0.122 , edge accuracy:  0.6513064133016627\n",
      "Epoch:  2 , loss:  3.1742045879364014 , count accuracy:  0.134 , edge accuracy:  0.6614945111382166\n",
      "Epoch:  3 , loss:  3.0324511528015137 , count accuracy:  0.134 , edge accuracy:  0.6614945111382166\n",
      "Epoch:  4 , loss:  3.011707305908203 , count accuracy:  0.158 , edge accuracy:  0.6614945111382166\n",
      "Epoch:  5 , loss:  3.0208494663238525 , count accuracy:  0.196 , edge accuracy:  0.6620851255055531\n",
      "Epoch:  6 , loss:  3.003718137741089 , count accuracy:  0.182 , edge accuracy:  0.6734865506837003\n",
      "Epoch:  7 , loss:  2.8945674896240234 , count accuracy:  0.193 , edge accuracy:  0.6919881877126532\n",
      "Epoch:  8 , loss:  2.9283816814422607 , count accuracy:  0.194 , edge accuracy:  0.7084547730628491\n",
      "Epoch:  9 , loss:  2.8948309421539307 , count accuracy:  0.204 , edge accuracy:  0.7297875072221865\n",
      "Epoch:  10 , loss:  2.914076328277588 , count accuracy:  0.208 , edge accuracy:  0.746857546382487\n",
      "Epoch:  11 , loss:  2.802792549133301 , count accuracy:  0.216 , edge accuracy:  0.7610258714771779\n",
      "Epoch:  12 , loss:  2.8270790576934814 , count accuracy:  0.247 , edge accuracy:  0.7690762020928291\n",
      "Epoch:  13 , loss:  2.7655274868011475 , count accuracy:  0.247 , edge accuracy:  0.7779418373242601\n",
      "Epoch:  14 , loss:  2.808720111846924 , count accuracy:  0.254 , edge accuracy:  0.7958464402644925\n",
      "Epoch:  15 , loss:  2.6588196754455566 , count accuracy:  0.259 , edge accuracy:  0.8237080310714515\n",
      "Epoch:  16 , loss:  2.656951427459717 , count accuracy:  0.266 , edge accuracy:  0.8548436797842973\n",
      "Epoch:  17 , loss:  2.6260929107666016 , count accuracy:  0.273 , edge accuracy:  0.8773512229569237\n",
      "Epoch:  18 , loss:  2.5608267784118652 , count accuracy:  0.272 , edge accuracy:  0.8878089490916095\n",
      "Epoch:  19 , loss:  2.58125376701355 , count accuracy:  0.273 , edge accuracy:  0.9003723438402773\n",
      "Epoch:  20 , loss:  2.567147731781006 , count accuracy:  0.273 , edge accuracy:  0.9057199717532259\n",
      "Epoch:  21 , loss:  2.507758617401123 , count accuracy:  0.276 , edge accuracy:  0.9089234127238878\n",
      "Epoch:  22 , loss:  2.519458770751953 , count accuracy:  0.291 , edge accuracy:  0.9125954933555883\n",
      "Epoch:  23 , loss:  2.466383457183838 , count accuracy:  0.287 , edge accuracy:  0.9154458496501252\n",
      "Epoch:  24 , loss:  2.516859531402588 , count accuracy:  0.307 , edge accuracy:  0.9169865827823073\n",
      "Epoch:  25 , loss:  2.4069888591766357 , count accuracy:  0.288 , edge accuracy:  0.9167233742055595\n",
      "Epoch:  26 , loss:  2.520430326461792 , count accuracy:  0.288 , edge accuracy:  0.9171534955382936\n",
      "Epoch:  27 , loss:  2.5352001190185547 , count accuracy:  0.297 , edge accuracy:  0.9195673107787122\n",
      "Epoch:  28 , loss:  2.4262051582336426 , count accuracy:  0.31 , edge accuracy:  0.9197855813057714\n",
      "Epoch:  29 , loss:  2.428661584854126 , count accuracy:  0.31 , edge accuracy:  0.9215189060794762\n",
      "Epoch:  30 , loss:  2.467913866043091 , count accuracy:  0.292 , edge accuracy:  0.9207164409064647\n",
      "Epoch:  31 , loss:  2.4559147357940674 , count accuracy:  0.291 , edge accuracy:  0.9211786608461193\n",
      "Epoch:  32 , loss:  2.435981273651123 , count accuracy:  0.323 , edge accuracy:  0.9214739680297875\n",
      "Epoch:  33 , loss:  2.349578380584717 , count accuracy:  0.324 , edge accuracy:  0.922417667073249\n",
      "Epoch:  34 , loss:  2.4482226371765137 , count accuracy:  0.319 , edge accuracy:  0.9236630930217629\n",
      "Epoch:  35 , loss:  2.389862537384033 , count accuracy:  0.335 , edge accuracy:  0.9241317326828016\n",
      "Epoch:  36 , loss:  2.457862377166748 , count accuracy:  0.353 , edge accuracy:  0.924439879309238\n",
      "Epoch:  37 , loss:  2.384885787963867 , count accuracy:  0.352 , edge accuracy:  0.9241381524041856\n",
      "Epoch:  38 , loss:  2.327662944793701 , count accuracy:  0.335 , edge accuracy:  0.923887783270206\n",
      "Epoch:  39 , loss:  2.3603055477142334 , count accuracy:  0.328 , edge accuracy:  0.9231880336393401\n",
      "Epoch:  40 , loss:  2.4143574237823486 , count accuracy:  0.323 , edge accuracy:  0.9241830904538743\n",
      "Epoch:  41 , loss:  2.3928160667419434 , count accuracy:  0.314 , edge accuracy:  0.923605315529306\n",
      "Epoch:  42 , loss:  2.3331708908081055 , count accuracy:  0.341 , edge accuracy:  0.9241959298966425\n",
      "Epoch:  43 , loss:  2.352027416229248 , count accuracy:  0.359 , edge accuracy:  0.9256467869294472\n",
      "Epoch:  44 , loss:  2.3379623889923096 , count accuracy:  0.359 , edge accuracy:  0.927444308916993\n",
      "Epoch:  45 , loss:  2.403022289276123 , count accuracy:  0.374 , edge accuracy:  0.9267573987288952\n",
      "Epoch:  46 , loss:  2.396306037902832 , count accuracy:  0.378 , edge accuracy:  0.9265583873659883\n",
      "Epoch:  47 , loss:  2.395338535308838 , count accuracy:  0.38 , edge accuracy:  0.9251460486614881\n",
      "Epoch:  48 , loss:  2.359173536300659 , count accuracy:  0.348 , edge accuracy:  0.9255376516659177\n",
      "Epoch:  49 , loss:  2.243870258331299 , count accuracy:  0.366 , edge accuracy:  0.925345060024395\n",
      "Epoch:  50 , loss:  2.382564067840576 , count accuracy:  0.378 , edge accuracy:  0.9261346857546382\n",
      "Epoch:  51 , loss:  2.3130781650543213 , count accuracy:  0.388 , edge accuracy:  0.9288181292931886\n",
      "Epoch:  52 , loss:  2.3007421493530273 , count accuracy:  0.395 , edge accuracy:  0.9275406047377543\n",
      "Epoch:  53 , loss:  2.38906192779541 , count accuracy:  0.381 , edge accuracy:  0.9281247993837067\n",
      "Epoch:  54 , loss:  2.4518377780914307 , count accuracy:  0.375 , edge accuracy:  0.9269628298131861\n",
      "Epoch:  55 , loss:  2.1836540699005127 , count accuracy:  0.387 , edge accuracy:  0.9280349232843295\n",
      "Epoch:  56 , loss:  2.303584337234497 , count accuracy:  0.393 , edge accuracy:  0.9277973935931181\n",
      "Epoch:  57 , loss:  2.3001396656036377 , count accuracy:  0.389 , edge accuracy:  0.9290235603774796\n",
      "Epoch:  58 , loss:  2.2036349773406982 , count accuracy:  0.398 , edge accuracy:  0.9304551582461321\n",
      "Epoch:  59 , loss:  2.3271288871765137 , count accuracy:  0.393 , edge accuracy:  0.9297554086152661\n",
      "Epoch:  60 , loss:  2.3661508560180664 , count accuracy:  0.376 , edge accuracy:  0.9301341721769275\n",
      "Epoch:  61 , loss:  2.4601023197174072 , count accuracy:  0.33 , edge accuracy:  0.9298838030429479\n",
      "Epoch:  62 , loss:  2.3030624389648438 , count accuracy:  0.322 , edge accuracy:  0.9283880079604545\n",
      "Epoch:  63 , loss:  2.2585561275482178 , count accuracy:  0.346 , edge accuracy:  0.9281183796623227\n",
      "Epoch:  64 , loss:  2.3640875816345215 , count accuracy:  0.367 , edge accuracy:  0.9275983822302112\n",
      "Epoch:  65 , loss:  2.283921241760254 , count accuracy:  0.363 , edge accuracy:  0.9294151633819092\n",
      "Epoch:  66 , loss:  2.2880241870880127 , count accuracy:  0.399 , edge accuracy:  0.9302433074404571\n",
      "Epoch:  67 , loss:  2.1699166297912598 , count accuracy:  0.393 , edge accuracy:  0.9289401039994865\n",
      "Epoch:  68 , loss:  2.3117504119873047 , count accuracy:  0.404 , edge accuracy:  0.9309687359568595\n",
      "Epoch:  69 , loss:  2.1328814029693604 , count accuracy:  0.402 , edge accuracy:  0.9310842909417731\n",
      "Epoch:  70 , loss:  2.395967483520508 , count accuracy:  0.407 , edge accuracy:  0.9302176285549207\n",
      "Epoch:  71 , loss:  2.3635895252227783 , count accuracy:  0.381 , edge accuracy:  0.930378121589523\n",
      "Epoch:  72 , loss:  2.29846453666687 , count accuracy:  0.371 , edge accuracy:  0.9311549078769982\n",
      "Epoch:  73 , loss:  2.1668996810913086 , count accuracy:  0.382 , edge accuracy:  0.932047249149387\n",
      "Epoch:  74 , loss:  2.2934577465057373 , count accuracy:  0.398 , edge accuracy:  0.9325800860242666\n",
      "Epoch:  75 , loss:  2.3736393451690674 , count accuracy:  0.395 , edge accuracy:  0.9321949027412211\n",
      "Epoch:  76 , loss:  2.371438980102539 , count accuracy:  0.382 , edge accuracy:  0.9291326956410092\n",
      "Epoch:  77 , loss:  2.2368662357330322 , count accuracy:  0.374 , edge accuracy:  0.9309430570713231\n",
      "Epoch:  78 , loss:  2.23089337348938 , count accuracy:  0.367 , edge accuracy:  0.931077871220389\n",
      "Epoch:  79 , loss:  2.2200896739959717 , count accuracy:  0.407 , edge accuracy:  0.930654169609039\n",
      "Epoch:  80 , loss:  2.272797107696533 , count accuracy:  0.41 , edge accuracy:  0.9314694742248186\n",
      "Epoch:  81 , loss:  2.177095651626587 , count accuracy:  0.41 , edge accuracy:  0.9321499646915324\n",
      "Epoch:  82 , loss:  2.1739630699157715 , count accuracy:  0.406 , edge accuracy:  0.9331257623419144\n",
      "Epoch:  83 , loss:  2.115454912185669 , count accuracy:  0.4 , edge accuracy:  0.9315272517172755\n",
      "Epoch:  84 , loss:  2.3608763217926025 , count accuracy:  0.397 , edge accuracy:  0.9334210695255826\n",
      "Epoch:  85 , loss:  2.078286647796631 , count accuracy:  0.402 , edge accuracy:  0.9339731655646145\n",
      "Epoch:  86 , loss:  2.271789312362671 , count accuracy:  0.407 , edge accuracy:  0.9319445336072415\n",
      "Epoch:  87 , loss:  2.3249642848968506 , count accuracy:  0.393 , edge accuracy:  0.9322270013481415\n",
      "Epoch:  88 , loss:  2.2421343326568604 , count accuracy:  0.397 , edge accuracy:  0.9326763818450279\n",
      "Epoch:  89 , loss:  2.205183744430542 , count accuracy:  0.405 , edge accuracy:  0.9325800860242666\n",
      "Epoch:  90 , loss:  2.22875714302063 , count accuracy:  0.408 , edge accuracy:  0.9313346600757527\n",
      "Epoch:  91 , loss:  2.149848699569702 , count accuracy:  0.405 , edge accuracy:  0.9319573730500096\n",
      "Epoch:  92 , loss:  2.1380088329315186 , count accuracy:  0.402 , edge accuracy:  0.9338897091866213\n",
      "Epoch:  93 , loss:  2.304644823074341 , count accuracy:  0.402 , edge accuracy:  0.9320729280349233\n",
      "Epoch:  94 , loss:  2.3695461750030518 , count accuracy:  0.408 , edge accuracy:  0.9317391025229506\n",
      "Epoch:  95 , loss:  2.2972190380096436 , count accuracy:  0.406 , edge accuracy:  0.9335623033960326\n",
      "Epoch:  96 , loss:  2.261439800262451 , count accuracy:  0.402 , edge accuracy:  0.9329524298645439\n",
      "Epoch:  97 , loss:  2.201672077178955 , count accuracy:  0.415 , edge accuracy:  0.9345830390961032\n",
      "Epoch:  98 , loss:  2.2863404750823975 , count accuracy:  0.412 , edge accuracy:  0.9342106952558259\n",
      "Epoch:  99 , loss:  2.221977710723877 , count accuracy:  0.413 , edge accuracy:  0.9334916864608076\n",
      "Epoch:  100 , loss:  2.222644329071045 , count accuracy:  0.412 , edge accuracy:  0.9339218077935417\n",
      "Epoch:  101 , loss:  2.3099451065063477 , count accuracy:  0.419 , edge accuracy:  0.9340309430570714\n",
      "Epoch:  102 , loss:  2.3079631328582764 , count accuracy:  0.409 , edge accuracy:  0.9325030493676575\n",
      "Epoch:  103 , loss:  2.1578786373138428 , count accuracy:  0.395 , edge accuracy:  0.9344161263401168\n",
      "Epoch:  104 , loss:  2.235250234603882 , count accuracy:  0.412 , edge accuracy:  0.9348205687873147\n",
      "Epoch:  105 , loss:  2.147027015686035 , count accuracy:  0.418 , edge accuracy:  0.9348783462797715\n",
      "Epoch:  106 , loss:  2.2201507091522217 , count accuracy:  0.419 , edge accuracy:  0.9355138986967966\n",
      "Epoch:  107 , loss:  2.1187169551849365 , count accuracy:  0.411 , edge accuracy:  0.9336329203312577\n",
      "Epoch:  108 , loss:  2.2093658447265625 , count accuracy:  0.411 , edge accuracy:  0.93379341336586\n",
      "Epoch:  109 , loss:  2.1756436824798584 , count accuracy:  0.405 , edge accuracy:  0.9343711882904282\n",
      "Epoch:  110 , loss:  2.1418650150299072 , count accuracy:  0.414 , edge accuracy:  0.9358413044873852\n",
      "Epoch:  111 , loss:  2.1606314182281494 , count accuracy:  0.414 , edge accuracy:  0.9356615522886307\n",
      "Epoch:  112 , loss:  2.1200220584869385 , count accuracy:  0.406 , edge accuracy:  0.934351929126276\n",
      "Epoch:  113 , loss:  2.2652487754821777 , count accuracy:  0.421 , edge accuracy:  0.935822045323233\n",
      "Epoch:  114 , loss:  2.0983119010925293 , count accuracy:  0.425 , edge accuracy:  0.9338383514155486\n",
      "Epoch:  115 , loss:  2.0581417083740234 , count accuracy:  0.429 , edge accuracy:  0.9341721769275213\n",
      "Epoch:  116 , loss:  2.2800710201263428 , count accuracy:  0.428 , edge accuracy:  0.935822045323233\n",
      "Epoch:  117 , loss:  2.1589226722717285 , count accuracy:  0.43 , edge accuracy:  0.9354689606471079\n",
      "Epoch:  118 , loss:  2.2353904247283936 , count accuracy:  0.429 , edge accuracy:  0.9372022854208127\n",
      "Epoch:  119 , loss:  2.226597547531128 , count accuracy:  0.403 , edge accuracy:  0.935828465044617\n",
      "Epoch:  120 , loss:  2.053783416748047 , count accuracy:  0.416 , edge accuracy:  0.9358156256018488\n",
      "Epoch:  121 , loss:  2.3179473876953125 , count accuracy:  0.407 , edge accuracy:  0.9352956281697374\n",
      "Epoch:  122 , loss:  2.0529134273529053 , count accuracy:  0.414 , edge accuracy:  0.9362906849842717\n",
      "Epoch:  123 , loss:  2.335205554962158 , count accuracy:  0.427 , edge accuracy:  0.9383257366630289\n",
      "Epoch:  124 , loss:  2.206385374069214 , count accuracy:  0.427 , edge accuracy:  0.9374141362264877\n",
      "Epoch:  125 , loss:  2.0820634365081787 , count accuracy:  0.429 , edge accuracy:  0.9370610515503627\n",
      "Epoch:  126 , loss:  1.9886621236801147 , count accuracy:  0.432 , edge accuracy:  0.9374012967837196\n",
      "Epoch:  127 , loss:  2.1789045333862305 , count accuracy:  0.416 , edge accuracy:  0.9378121589523015\n",
      "Epoch:  128 , loss:  2.05041766166687 , count accuracy:  0.427 , edge accuracy:  0.935269949284201\n",
      "Epoch:  129 , loss:  2.181492328643799 , count accuracy:  0.434 , edge accuracy:  0.936386980805033\n",
      "Epoch:  130 , loss:  2.1278584003448486 , count accuracy:  0.416 , edge accuracy:  0.9367079668742376\n",
      "Epoch:  131 , loss:  2.1479368209838867 , count accuracy:  0.416 , edge accuracy:  0.9355652564678693\n",
      "Epoch:  132 , loss:  2.1656486988067627 , count accuracy:  0.421 , edge accuracy:  0.9355780959106375\n",
      "Epoch:  133 , loss:  2.199862003326416 , count accuracy:  0.425 , edge accuracy:  0.9360659947358284\n",
      "Epoch:  134 , loss:  2.10709285736084 , count accuracy:  0.427 , edge accuracy:  0.9364704371830262\n",
      "Epoch:  135 , loss:  2.0422310829162598 , count accuracy:  0.434 , edge accuracy:  0.9368042626949991\n",
      "Epoch:  136 , loss:  2.1500422954559326 , count accuracy:  0.428 , edge accuracy:  0.9384605508120948\n",
      "Epoch:  137 , loss:  2.084538698196411 , count accuracy:  0.424 , edge accuracy:  0.9367143865956218\n",
      "Epoch:  138 , loss:  2.2892906665802 , count accuracy:  0.431 , edge accuracy:  0.9367850035308468\n",
      "Epoch:  139 , loss:  2.1157445907592773 , count accuracy:  0.431 , edge accuracy:  0.9348398279514669\n",
      "Epoch:  140 , loss:  2.2012758255004883 , count accuracy:  0.426 , edge accuracy:  0.9361815497207421\n",
      "Epoch:  141 , loss:  2.0916194915771484 , count accuracy:  0.435 , edge accuracy:  0.9329845284714643\n",
      "Epoch:  142 , loss:  1.9550838470458984 , count accuracy:  0.427 , edge accuracy:  0.9348398279514669\n",
      "Epoch:  143 , loss:  2.240842342376709 , count accuracy:  0.432 , edge accuracy:  0.9371124093214355\n",
      "Epoch:  144 , loss:  2.1204588413238525 , count accuracy:  0.431 , edge accuracy:  0.9379726519869037\n",
      "Epoch:  145 , loss:  2.136545419692993 , count accuracy:  0.434 , edge accuracy:  0.9362200680490467\n",
      "Epoch:  146 , loss:  2.195040702819824 , count accuracy:  0.439 , edge accuracy:  0.9365346343968671\n",
      "Epoch:  147 , loss:  2.142554759979248 , count accuracy:  0.439 , edge accuracy:  0.9371701868138923\n",
      "Epoch:  148 , loss:  2.1372339725494385 , count accuracy:  0.429 , edge accuracy:  0.9364704371830262\n",
      "Epoch:  149 , loss:  1.9903781414031982 , count accuracy:  0.431 , edge accuracy:  0.9381716633498106\n",
      "Epoch:  150 , loss:  2.008729934692383 , count accuracy:  0.429 , edge accuracy:  0.9383000577774925\n",
      "Epoch:  151 , loss:  2.160226821899414 , count accuracy:  0.436 , edge accuracy:  0.9382615394491879\n",
      "Epoch:  152 , loss:  2.074380874633789 , count accuracy:  0.445 , edge accuracy:  0.9368235218591513\n",
      "Epoch:  153 , loss:  2.027723789215088 , count accuracy:  0.436 , edge accuracy:  0.9385953649611607\n",
      "Epoch:  154 , loss:  2.1855876445770264 , count accuracy:  0.441 , edge accuracy:  0.9384220324837902\n",
      "Epoch:  155 , loss:  2.1038031578063965 , count accuracy:  0.438 , edge accuracy:  0.9373306798484946\n",
      "Epoch:  156 , loss:  2.154909610748291 , count accuracy:  0.435 , edge accuracy:  0.9362906849842717\n",
      "Epoch:  157 , loss:  2.0912325382232666 , count accuracy:  0.422 , edge accuracy:  0.9384926494190152\n",
      "Epoch:  158 , loss:  2.0611534118652344 , count accuracy:  0.432 , edge accuracy:  0.9382101816781152\n",
      "Epoch:  159 , loss:  2.0063302516937256 , count accuracy:  0.444 , edge accuracy:  0.9389548693586698\n",
      "Epoch:  160 , loss:  1.9991614818572998 , count accuracy:  0.443 , edge accuracy:  0.9373114206843423\n",
      "Epoch:  161 , loss:  1.958442211151123 , count accuracy:  0.444 , edge accuracy:  0.9383835141554856\n",
      "Epoch:  162 , loss:  2.21334171295166 , count accuracy:  0.436 , edge accuracy:  0.938691660781922\n",
      "Epoch:  163 , loss:  2.0490927696228027 , count accuracy:  0.446 , edge accuracy:  0.9391153623932721\n",
      "Epoch:  164 , loss:  2.175071954727173 , count accuracy:  0.444 , edge accuracy:  0.938897091866213\n",
      "Epoch:  165 , loss:  2.1463544368743896 , count accuracy:  0.448 , edge accuracy:  0.9385119085831675\n",
      "Epoch:  166 , loss:  2.122861623764038 , count accuracy:  0.445 , edge accuracy:  0.9366501893817808\n",
      "Epoch:  167 , loss:  2.05952525138855 , count accuracy:  0.448 , edge accuracy:  0.9378249983950696\n",
      "Epoch:  168 , loss:  2.1320407390594482 , count accuracy:  0.442 , edge accuracy:  0.9380753675290492\n",
      "Epoch:  169 , loss:  2.0140438079833984 , count accuracy:  0.445 , edge accuracy:  0.9368812993516081\n",
      "Epoch:  170 , loss:  2.022045135498047 , count accuracy:  0.446 , edge accuracy:  0.9374269756692559\n",
      "Epoch:  171 , loss:  1.9167137145996094 , count accuracy:  0.444 , edge accuracy:  0.9384220324837902\n",
      "Epoch:  172 , loss:  2.0613515377044678 , count accuracy:  0.448 , edge accuracy:  0.9379405533799833\n",
      "Epoch:  173 , loss:  2.018104076385498 , count accuracy:  0.451 , edge accuracy:  0.9382615394491879\n",
      "Epoch:  174 , loss:  1.9494966268539429 , count accuracy:  0.454 , edge accuracy:  0.9382422802850356\n",
      "Epoch:  175 , loss:  1.7587087154388428 , count accuracy:  0.446 , edge accuracy:  0.9383449958271811\n",
      "Epoch:  176 , loss:  1.8550444841384888 , count accuracy:  0.458 , edge accuracy:  0.9371830262566605\n",
      "Epoch:  177 , loss:  2.022266387939453 , count accuracy:  0.456 , edge accuracy:  0.9381716633498106\n",
      "Epoch:  178 , loss:  2.0113096237182617 , count accuracy:  0.464 , edge accuracy:  0.9381010464145856\n",
      "Epoch:  179 , loss:  1.8105573654174805 , count accuracy:  0.478 , edge accuracy:  0.9376324067535469\n",
      "Epoch:  180 , loss:  1.9163634777069092 , count accuracy:  0.488 , edge accuracy:  0.9385568466328561\n",
      "Epoch:  181 , loss:  1.863350510597229 , count accuracy:  0.501 , edge accuracy:  0.9364704371830262\n",
      "Epoch:  182 , loss:  1.6614629030227661 , count accuracy:  0.498 , edge accuracy:  0.938685241060538\n",
      "Epoch:  183 , loss:  1.807140588760376 , count accuracy:  0.493 , edge accuracy:  0.9379533928227515\n",
      "Epoch:  184 , loss:  1.8507134914398193 , count accuracy:  0.503 , edge accuracy:  0.9382936380561083\n",
      "Epoch:  185 , loss:  1.717226266860962 , count accuracy:  0.507 , edge accuracy:  0.9382807986133401\n",
      "Epoch:  186 , loss:  1.9944990873336792 , count accuracy:  0.489 , edge accuracy:  0.9387365988316108\n",
      "Epoch:  187 , loss:  1.9143891334533691 , count accuracy:  0.51 , edge accuracy:  0.9357257495024716\n",
      "Epoch:  188 , loss:  1.8687174320220947 , count accuracy:  0.491 , edge accuracy:  0.9355973550747898\n",
      "Epoch:  189 , loss:  1.9194934368133545 , count accuracy:  0.492 , edge accuracy:  0.9359632791936829\n",
      "Epoch:  190 , loss:  2.0154356956481934 , count accuracy:  0.51 , edge accuracy:  0.9353469859408101\n",
      "Epoch:  191 , loss:  1.9457921981811523 , count accuracy:  0.496 , edge accuracy:  0.9377543814598447\n",
      "Epoch:  192 , loss:  1.8166245222091675 , count accuracy:  0.526 , edge accuracy:  0.9372472234705014\n",
      "Epoch:  193 , loss:  1.979361891746521 , count accuracy:  0.516 , edge accuracy:  0.9381010464145856\n",
      "Epoch:  194 , loss:  1.8314417600631714 , count accuracy:  0.52 , edge accuracy:  0.9396738781536881\n",
      "Epoch:  195 , loss:  1.827699899673462 , count accuracy:  0.521 , edge accuracy:  0.9390447454580472\n",
      "Epoch:  196 , loss:  1.8227808475494385 , count accuracy:  0.518 , edge accuracy:  0.9363163638698081\n",
      "Epoch:  197 , loss:  1.7523926496505737 , count accuracy:  0.521 , edge accuracy:  0.935475380368492\n",
      "Epoch:  198 , loss:  1.9599902629852295 , count accuracy:  0.495 , edge accuracy:  0.937080310714515\n",
      "Epoch:  199 , loss:  2.0010786056518555 , count accuracy:  0.469 , edge accuracy:  0.9353213070552738\n",
      "Epoch:  200 , loss:  1.863943099975586 , count accuracy:  0.514 , edge accuracy:  0.9339731655646145\n",
      "Epoch:  201 , loss:  1.879685640335083 , count accuracy:  0.504 , edge accuracy:  0.9360788341785966\n",
      "Epoch:  202 , loss:  1.9052863121032715 , count accuracy:  0.519 , edge accuracy:  0.9384862296976311\n",
      "Epoch:  203 , loss:  1.8513412475585938 , count accuracy:  0.52 , edge accuracy:  0.9362457469345831\n",
      "Epoch:  204 , loss:  2.059642791748047 , count accuracy:  0.537 , edge accuracy:  0.9356487128458625\n",
      "Epoch:  205 , loss:  1.7278437614440918 , count accuracy:  0.514 , edge accuracy:  0.9382487000064197\n",
      "Epoch:  206 , loss:  1.863663673400879 , count accuracy:  0.507 , edge accuracy:  0.9374911728830969\n",
      "Epoch:  207 , loss:  1.857136607170105 , count accuracy:  0.471 , edge accuracy:  0.9354625409257238\n",
      "Epoch:  208 , loss:  2.0660808086395264 , count accuracy:  0.498 , edge accuracy:  0.9337227964306349\n",
      "Epoch:  209 , loss:  1.7690074443817139 , count accuracy:  0.519 , edge accuracy:  0.935545997303717\n",
      "Epoch:  210 , loss:  1.7688298225402832 , count accuracy:  0.516 , edge accuracy:  0.9378763561661424\n",
      "Epoch:  211 , loss:  1.742173433303833 , count accuracy:  0.543 , edge accuracy:  0.9393914104127881\n",
      "Epoch:  212 , loss:  1.870680570602417 , count accuracy:  0.531 , edge accuracy:  0.9386595621750016\n",
      "Epoch:  213 , loss:  1.8515676259994507 , count accuracy:  0.518 , edge accuracy:  0.9384605508120948\n",
      "Epoch:  214 , loss:  1.7366515398025513 , count accuracy:  0.542 , edge accuracy:  0.9385311677473198\n",
      "Epoch:  215 , loss:  1.8430802822113037 , count accuracy:  0.533 , edge accuracy:  0.9387879566026834\n",
      "Epoch:  216 , loss:  1.6865381002426147 , count accuracy:  0.54 , edge accuracy:  0.9396353598253836\n",
      "Epoch:  217 , loss:  1.8010212182998657 , count accuracy:  0.539 , edge accuracy:  0.9392244976568017\n",
      "Epoch:  218 , loss:  1.9431835412979126 , count accuracy:  0.551 , edge accuracy:  0.939314373756179\n",
      "Epoch:  219 , loss:  1.7670519351959229 , count accuracy:  0.544 , edge accuracy:  0.9393785709700199\n",
      "Epoch:  220 , loss:  1.75729238986969 , count accuracy:  0.535 , edge accuracy:  0.938126725300122\n",
      "Epoch:  221 , loss:  1.857451319694519 , count accuracy:  0.503 , edge accuracy:  0.9373884573409514\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-16cb4621fbe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcount_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0medge_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#         print(batch.x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(data_list)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             collate_fn=lambda data_list: Batch.from_data_list(\n\u001b[0;32m---> 32\u001b[0;31m                 data_list, follow_batch),\n\u001b[0m\u001b[1;32m     33\u001b[0m             **kwargs)\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(data_list, follow_batch)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0mcumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_v = []\n",
    "acc_v_count = []\n",
    "acc_v_edge = []\n",
    "ep = 0\n",
    "for epoch in range(500):\n",
    "    ep += 1\n",
    "    count_correct = 0\n",
    "    edge_correct = 0\n",
    "    count_total = 0\n",
    "    edge_total = 0 \n",
    "    for batch in train_loader:\n",
    "#         print(batch.x)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        edge_pred, graph_pred = model(data)\n",
    "        _, graph_pred_max = graph_pred.max(dim=1)\n",
    "        losses = [F.binary_cross_entropy_with_logits(edge_pred.float(), data.y.float()), F.cross_entropy(graph_pred, data.y_graph)]\n",
    "#         print(losses[0].item(), losses[1].item())\n",
    "        loss = sum(losses)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        edge_correct += ((edge_pred > 0.5) == (data.y > 0.5)).sum().item()\n",
    "        count_correct += float(graph_pred_max.eq(data.y_graph).sum().item())\n",
    "#         print(correct, pred, data.y)\n",
    "        count_total += len(graph_pred_max)\n",
    "        edge_total += len(edge_pred)\n",
    "#         print(out, data.y, )\n",
    "    count_acc = count_correct/count_total\n",
    "    edge_acc = edge_correct / edge_total\n",
    "    print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", count accuracy: \", count_acc, \", edge accuracy: \", edge_acc)\n",
    "    loss_v.append(loss)\n",
    "    acc_v_count.append(count_acc)\n",
    "    acc_v_edge.append(edge_acc)\n",
    "plt.plot(np.arange(len(loss_v)), loss_v)\n",
    "plt.plot(np.arange(len(acc_v_count)), acc_v_count)\n",
    "plt.plot(np.arange(len(acc_v_edge)), acc_v_edge)\n",
    "plt.ylim(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[5910], edge_index=[2, 14768], x=[5910, 2], y=[14768], y_graph=[100])\n",
      "Accuracy: 0.6900\n",
      "Batch(batch=[6130], edge_index=[2, 15735], x=[6130, 2], y=[15735], y_graph=[100])\n",
      "Accuracy: 0.7000\n",
      "Batch(batch=[6460], edge_index=[2, 17175], x=[6460, 2], y=[17175], y_graph=[100])\n",
      "Accuracy: 0.6700\n",
      "Batch(batch=[6180], edge_index=[2, 15944], x=[6180, 2], y=[15944], y_graph=[100])\n",
      "Accuracy: 0.6800\n",
      "Batch(batch=[6110], edge_index=[2, 15557], x=[6110, 2], y=[15557], y_graph=[100])\n",
      "Accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    data = batch.to(device)\n",
    "    edge_pred, graph_pred = model(data)\n",
    "    _, graph_pred_max = graph_pred.max(dim=1)\n",
    "    correct = float(graph_pred_max.eq(data.y_graph).sum().item())\n",
    "    acc = correct / len(graph_pred_max)\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Edge & Track Param Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to do a double scatter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     52
    ]
   },
   "outputs": [],
   "source": [
    "class TwoHopAttNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    A module which computes new node features on the graph.\n",
    "    For each node, it aggregates the neighbor node features\n",
    "    (separately on the input and output side), and combines\n",
    "    them with the node's previous features in a fully-connected\n",
    "    network to compute the new features.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
    "                 layer_norm=True):\n",
    "        super(TwoHopAttNetwork, self).__init__()\n",
    "        self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
    "                                hidden_activation=hidden_activation,\n",
    "                                output_activation=hidden_activation,\n",
    "                                layer_norm=layer_norm)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        start, end = edge_index\n",
    "        # Aggregate edge-weighted incoming/outgoing features\n",
    "        mi = scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])\n",
    "        mi2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
    "        mo = scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])\n",
    "        mo2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
    "        node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
    "        return self.network(node_inputs)\n",
    "\n",
    "class TwoHopNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    A module which computes new node features on the graph.\n",
    "    For each node, it aggregates the neighbor node features\n",
    "    (separately on the input and output side), and combines\n",
    "    them with the node's previous features in a fully-connected\n",
    "    network to compute the new features.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
    "                 layer_norm=True):\n",
    "        super(TwoHopNetwork, self).__init__()\n",
    "        self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
    "                                hidden_activation=hidden_activation,\n",
    "                                output_activation=hidden_activation,\n",
    "                                layer_norm=layer_norm)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        start, end = edge_index\n",
    "        # Aggregate edge-weighted incoming/outgoing features\n",
    "        mi = scatter_add(x[start], end, dim=0, dim_size=x.shape[0])\n",
    "        mi2 = scatter_add(scatter_add(x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
    "        mo = scatter_add(x[end], start, dim=0, dim_size=x.shape[0])\n",
    "        mo2 = scatter_add(scatter_add(x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
    "        node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
    "        return self.network(node_inputs)\n",
    "\n",
    "class Edge_Track_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Segment classification graph neural network model.\n",
    "    Consists of an input network, an edge network, and a node network.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
    "                 output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
    "        super(Edge_Track_Net, self).__init__()\n",
    "        self.n_graph_iters = n_graph_iters\n",
    "        # Setup the input network\n",
    "        self.input_network = make_mlp(input_dim, [hidden_dim],\n",
    "                                      hidden_activation=nn.ReLU,\n",
    "                                      layer_norm=False)\n",
    "        # Setup the edge network\n",
    "        self.edge_network = EdgeNetwork(input_dim+hidden_dim, hidden_dim,\n",
    "                                        hidden_activation, layer_norm=layer_norm)\n",
    "        # Setup the node layers\n",
    "        self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
    "                                        hidden_activation=nn.ReLU, layer_norm=False)\n",
    "        \n",
    "#         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
    "#                                         layer_norm=False)\n",
    "        self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, output_dim],\n",
    "                                       hidden_activation=nn.ReLU,\n",
    "                                      output_activation=None,\n",
    "                                      layer_norm=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Apply forward pass of the model\"\"\"\n",
    "        # Apply input network to get hidden representation\n",
    "        x = self.input_network(inputs.x)\n",
    "        # Shortcut connect the inputs onto the hidden representation\n",
    "        x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Loop over iterations of edge and node networks\n",
    "        for i in range(self.n_graph_iters):\n",
    "            # Apply edge network\n",
    "            e = torch.sigmoid(self.edge_network(x, inputs.edge_index))\n",
    "            # Apply node network\n",
    "            x = self.node_network(x, e, inputs.edge_index)\n",
    "            # Shortcut connect the inputs onto the hidden representation\n",
    "            x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Apply final edge network\n",
    "        e = self.edge_network(x, inputs.edge_index)\n",
    "        return e, self.output_network(x)\n",
    "    \n",
    "class Edge_Track_Truth_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Segment classification graph neural network model.\n",
    "    Consists of an input network, an edge network, and a node network.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
    "                 output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
    "        super(Edge_Track_Truth_Net, self).__init__()\n",
    "        self.n_graph_iters = n_graph_iters\n",
    "        # Setup the input network\n",
    "        self.input_network = make_mlp(input_dim, [hidden_dim],\n",
    "                                      hidden_activation=nn.ReLU,\n",
    "                                      layer_norm=False)\n",
    "        # Setup the node layers\n",
    "        self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
    "                                        hidden_activation=nn.ReLU, layer_norm=False)\n",
    "        \n",
    "#         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
    "#                                         layer_norm=False)\n",
    "        self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, output_dim],\n",
    "                                       hidden_activation=nn.ReLU,\n",
    "                                      output_activation=None,\n",
    "                                      layer_norm=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Apply forward pass of the model\"\"\"\n",
    "        # Apply input network to get hidden representation\n",
    "        x = self.input_network(inputs.x)\n",
    "        # Shortcut connect the inputs onto the hidden representation\n",
    "        x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Loop over iterations of edge and node networks\n",
    "        for i in range(self.n_graph_iters):\n",
    "            # Apply edge network\n",
    "            e = inputs.y_edges\n",
    "            # Apply node network\n",
    "            x = self.node_network(x, e, inputs.edge_index)\n",
    "            # Shortcut connect the inputs onto the hidden representation\n",
    "            x = torch.cat([x, inputs.x], dim=-1)\n",
    "        # Apply final edge network\n",
    "        return self.output_network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.5 * len(cut_full_dataset))\n",
    "test_size = int(0.1 * len(cut_full_dataset))\n",
    "train_dataset = cut_full_dataset[:train_size]\n",
    "test_dataset = cut_full_dataset[-test_size:]\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "t_configs = {'train_size': train_size, 'test_size': test_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using \", device)\n",
    "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
    "m_configs = {'input_dim': 3, 'hidden_dim': 16, 'n_graph_iters': 3, 'output_dim': 1}\n",
    "model = Edge_Track_Truth_Net(**m_configs).to(device)\n",
    "# data = dataset[0].to(device)\n",
    "o_configs = {'lr': 0.001, 'weight_decay': 1e-4}\n",
    "# optimizer = torch.optim.SGD([\n",
    "#                                 {'params': model.input_network.parameters()},\n",
    "#                                 {'params': model.edge_network.parameters()},\n",
    "#                                 {'params': model.node_network.parameters()},\n",
    "#                                 {'params': model.output_network.parameters(), 'lr': learning_rate*10}], lr=learning_rate, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam([\n",
    "#                                 {'params': model.input_network.parameters()},\n",
    "#                                 {'params': model.edge_network.parameters()},\n",
    "#                                 {'params': model.node_network.parameters(), 'lr': learning_rate*10},\n",
    "#                                 {'params': model.output_network.parameters(), 'lr': learning_rate*10}], lr=learning_rate, weight_decay=1e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), **o_configs)\n",
    "s_configs = {'step_size': 20, 'gamma': 0.9}\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, **s_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression/runs/fwpw76ra\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression/runs/fwpw76ra</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error resolved after 0:00:23.785435, resuming normal operation.\n",
      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x2aab57ea34a8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error resolved after 0:00:11.332204, resuming normal operation.\n",
      "wandb: Network error resolved after 0:00:23.334204, resuming normal operation.\n",
      "wandb: Network error resolved after 0:00:37.807275, resuming normal operation.\n",
      "wandb: Network error resolved after 0:00:38.484777, resuming normal operation.\n"
     ]
    }
   ],
   "source": [
    "hyperconfig = {**m_configs, **t_configs, **s_configs, **o_configs}\n",
    "wandb.init(project=\"node_regression\", config=hyperconfig)\n",
    "wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/global/homes/d/danieltm/.local/bin/wandb\", line 6, in <module>\r\n",
      "    from wandb.cli import cli\r\n",
      "ModuleNotFoundError: No module named 'wandb'\r\n"
     ]
    }
   ],
   "source": [
    "!wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aab7fcdaf60>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "fig.set_size_inches(16,4)\n",
    "axs[0].plot(np.arange(len(loss_v_node)), loss_v_node)\n",
    "# axs[1].plot(np.arange(len(loss_v_edge)), loss_v_edge)\n",
    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
    "# axs[3].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Network error resolved after 0:00:11.345432, resuming normal operation.\n",
      "Failed to connect to W&B servers after 10 seconds.                    Letting user process proceed while attempting to reconnect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , loss:  0.6007898449897766 , node accuracy:  10.242046834801204 %, lr:  [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retry attempt failed:\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 164, in _new_conn\n",
      "    % (self.host, self.timeout),\n",
      "urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fab8d0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fab8d0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 103, in execute\n",
      "    return self.client.execute(*args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 50, in execute\n",
      "    result = self._get_result(document, *args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 58, in _get_result\n",
      "    return self.transport.execute(document, *args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/transport/requests.py\", line 37, in execute\n",
      "    request = requests.post(self.url, **post_args)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 116, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 504, in send\n",
      "    raise ConnectTimeout(e, request=request)\n",
      "requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fab8d0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
      "wandb: Network error (ConnectTimeout), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 , loss:  0.817642867565155 , node accuracy:  10.806555227684166 %, lr:  [0.001]\n",
      "Epoch:  3 , loss:  0.9038619995117188 , node accuracy:  11.966084468880512 %, lr:  [0.001]\n",
      "Epoch:  4 , loss:  2.6982123851776123 , node accuracy:  12.011629412664599 %, lr:  [0.001]\n",
      "Epoch:  5 , loss:  2.588160753250122 , node accuracy:  11.906975326302884 %, lr:  [0.001]\n",
      "Epoch:  6 , loss:  1.5540924072265625 , node accuracy:  11.722250515928984 %, lr:  [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error resolved after 0:00:58.266933, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7 , loss:  8.183475494384766 , node accuracy:  11.767347980989985 %, lr:  [0.001]\n",
      "Epoch:  8 , loss:  1.7046161890029907 , node accuracy:  11.827561836665232 %, lr:  [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error resolved after 0:00:11.470606, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9 , loss:  0.42751920223236084 , node accuracy:  11.777570073070478 %, lr:  [0.001]\n",
      "Epoch:  10 , loss:  2.032323122024536 , node accuracy:  11.7880718393529 %, lr:  [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error uploading \"config.yaml\": CommError, <Response [400]>\n",
      "Retry attempt failed:\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 164, in _new_conn\n",
      "    % (self.host, self.timeout),\n",
      "urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57f7def0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57f7def0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 103, in execute\n",
      "    return self.client.execute(*args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 50, in execute\n",
      "    result = self._get_result(document, *args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 58, in _get_result\n",
      "    return self.transport.execute(document, *args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/transport/requests.py\", line 37, in execute\n",
      "    request = requests.post(self.url, **post_args)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 116, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 504, in send\n",
      "    raise ConnectTimeout(e, request=request)\n",
      "requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57f7def0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
      "wandb: Network error (ConnectTimeout), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 , loss:  0.9068647623062134 , node accuracy:  11.77572422333775 %, lr:  [0.001]\n",
      "Epoch:  12 , loss:  3.974558115005493 , node accuracy:  11.754566869961844 %, lr:  [0.001]\n",
      "Epoch:  13 , loss:  0.7298269271850586 , node accuracy:  11.784953472001396 %, lr:  [0.001]\n",
      "Epoch:  14 , loss:  0.7682395577430725 , node accuracy:  11.689500666883134 %, lr:  [0.001]\n",
      "Epoch:  15 , loss:  5.155138969421387 , node accuracy:  11.852173166434957 %, lr:  [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error resolved after 0:00:56.379144, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16 , loss:  2.4475228786468506 , node accuracy:  11.88984528143475 %, lr:  [0.001]\n",
      "Epoch:  17 , loss:  8.945351600646973 , node accuracy:  11.948003531725822 %, lr:  [0.001]\n",
      "Epoch:  18 , loss:  0.800361692905426 , node accuracy:  11.82655500953829 %, lr:  [0.001]\n",
      "Epoch:  19 , loss:  4.170938968658447 , node accuracy:  12.117542032934994 %, lr:  [0.001]\n",
      "Epoch:  20 , loss:  13.88068675994873 , node accuracy:  11.96797226974353 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  21 , loss:  9.681962013244629 , node accuracy:  12.113640577818089 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  22 , loss:  4.359136581420898 , node accuracy:  12.098664024304808 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  23 , loss:  0.9145486354827881 , node accuracy:  12.054405581849592 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  24 , loss:  1.0942814350128174 , node accuracy:  12.114088056541174 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  25 , loss:  1.8272830247879028 , node accuracy:  12.160220316149312 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  26 , loss:  1.0419292449951172 , node accuracy:  12.065564582506546 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  27 , loss:  1.8605482578277588 , node accuracy:  12.224559366303007 %, lr:  [0.0009000000000000001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error uploading \"diff.patch\": CommError, <Response [400]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  28 , loss:  1.0357260704040527 , node accuracy:  12.188509361674399 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  29 , loss:  5.578948974609375 , node accuracy:  12.176371501310692 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  30 , loss:  7.798847675323486 , node accuracy:  12.258595716677728 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  31 , loss:  6.776310920715332 , node accuracy:  12.162583563155609 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  32 , loss:  0.6156641840934753 , node accuracy:  12.182356529231967 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  33 , loss:  0.6728848814964294 , node accuracy:  12.12583437302218 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  34 , loss:  3.6187450885772705 , node accuracy:  12.225244568097732 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  35 , loss:  3.693549633026123 , node accuracy:  12.218280680469707 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  36 , loss:  2.0439088344573975 , node accuracy:  12.09069330954984 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  37 , loss:  2.4835045337677 , node accuracy:  12.212533375620072 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  38 , loss:  0.6139274835586548 , node accuracy:  12.270803495591915 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  39 , loss:  1.7037460803985596 , node accuracy:  12.20246510435064 %, lr:  [0.0009000000000000001]\n",
      "Epoch:  40 , loss:  2.4318125247955322 , node accuracy:  12.192159110009568 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  41 , loss:  0.7220551371574402 , node accuracy:  12.29498133034865 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  42 , loss:  1.5551996231079102 , node accuracy:  12.163674292543131 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  43 , loss:  1.789021372795105 , node accuracy:  12.291037924101456 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  44 , loss:  1.3258136510849 , node accuracy:  12.261140751915278 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  45 , loss:  9.340996742248535 , node accuracy:  12.195263493650977 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  46 , loss:  1.5705657005310059 , node accuracy:  12.157493492680507 %, lr:  [0.0008100000000000001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retry attempt failed:\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 169, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9dd8>: Failed to establish a new connection: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576270804&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=hOWZqur9%2FE%2B63Tc6ZLj%2BSd3y2tX%2BgKVvtLWi%2F%2FMYrPOhGJNdbcjIzm2AycX83SiOXjK8%2FnFTHL06nfSMiGX138tS3JjMTVQXFJSfQ34KfGCe%2FDmN2hRZOv6RI46nJ7oC4bW4XuPL6r7%2F%2Fi3ifrnD6Bsn7ieg5wEntYKQuFmCSVGENS78lGvvF6OA4btweX2muj2fY83GxbrFx7QKltvImU4pWsYeYU4RMMqOoggZUQ9QpWWPXEWcwjAGZZrLnjghaX5hrWRAmAPsDApbsQpN7Xm7immu7hxXIJUq18t98MGmdiXGz9eIhQiEd3Mwk3RogxGGkN9eE52xf1WIcagLtA%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9dd8>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
      "    url, data=progress, headers=extra_headers)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
      "    return request('put', url, data=data, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576270804&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=hOWZqur9%2FE%2B63Tc6ZLj%2BSd3y2tX%2BgKVvtLWi%2F%2FMYrPOhGJNdbcjIzm2AycX83SiOXjK8%2FnFTHL06nfSMiGX138tS3JjMTVQXFJSfQ34KfGCe%2FDmN2hRZOv6RI46nJ7oC4bW4XuPL6r7%2F%2Fi3ifrnD6Bsn7ieg5wEntYKQuFmCSVGENS78lGvvF6OA4btweX2muj2fY83GxbrFx7QKltvImU4pWsYeYU4RMMqOoggZUQ9QpWWPXEWcwjAGZZrLnjghaX5hrWRAmAPsDApbsQpN7Xm7immu7hxXIJUq18t98MGmdiXGz9eIhQiEd3Mwk3RogxGGkN9eE52xf1WIcagLtA%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9dd8>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 980, in upload_file\n",
      "    util.sentry_reraise(retry.TransientException(exc=e))\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/util.py\", line 92, in sentry_reraise\n",
      "    six.reraise(type(exc), exc, sys.exc_info()[2])\n",
      "  File \"/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/six.py\", line 692, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
      "    url, data=progress, headers=extra_headers)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
      "    return request('put', url, data=data, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "wandb.retry.TransientException: None\n",
      "wandb: Network error (TransientException), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n",
      "wandb: ERROR Error uploading \"wandb-metadata.json\": CommError, <Response [400]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  47 , loss:  1.369815468788147 , node accuracy:  12.232641950738746 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  48 , loss:  29.94580841064453 , node accuracy:  12.380771391790276 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  49 , loss:  18.640899658203125 , node accuracy:  14.612893148513434 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  50 , loss:  2.596501350402832 , node accuracy:  10.714682252350592 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  51 , loss:  2.0275228023529053 , node accuracy:  11.03620969859791 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  52 , loss:  3.6572177410125732 , node accuracy:  11.914134985872257 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  53 , loss:  0.4805273115634918 , node accuracy:  12.153172526260708 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  54 , loss:  3.2910521030426025 , node accuracy:  12.409647753139414 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  55 , loss:  1.5877015590667725 , node accuracy:  13.966789807217776 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  56 , loss:  0.7358959913253784 , node accuracy:  14.979811717733776 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  57 , loss:  1.8266561031341553 , node accuracy:  10.73860838032559 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  58 , loss:  0.43270111083984375 , node accuracy:  11.64315865162355 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  59 , loss:  1.9536621570587158 , node accuracy:  15.584453358593509 %, lr:  [0.0008100000000000001]\n",
      "Epoch:  60 , loss:  2.093195915222168 , node accuracy:  10.692825713469865 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  61 , loss:  0.814365565776825 , node accuracy:  11.901745418726817 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  62 , loss:  31.9005126953125 , node accuracy:  18.31162642015064 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  63 , loss:  0.4563229978084564 , node accuracy:  19.494844066250344 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  64 , loss:  0.7945733070373535 , node accuracy:  15.855052132669611 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  65 , loss:  1.1281858682632446 , node accuracy:  14.559545294495535 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  66 , loss:  0.7465262413024902 , node accuracy:  13.159398353669843 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  67 , loss:  2.0372366905212402 , node accuracy:  11.426355210288431 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  68 , loss:  8.939661979675293 , node accuracy:  13.123586072112875 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  69 , loss:  0.4237460196018219 , node accuracy:  12.844974632151516 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  70 , loss:  0.5248408913612366 , node accuracy:  12.198731453754892 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  71 , loss:  0.8191898465156555 , node accuracy:  10.694475791261244 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  72 , loss:  0.9275200366973877 , node accuracy:  11.33827182039099 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  73 , loss:  1.2797634601593018 , node accuracy:  14.771706144078639 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  74 , loss:  10.561777114868164 , node accuracy:  16.505462456674973 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  75 , loss:  2.1823747158050537 , node accuracy:  22.458146056495867 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  76 , loss:  0.9706612229347229 , node accuracy:  21.41686306787497 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  77 , loss:  0.5489035844802856 , node accuracy:  24.637744998096817 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  78 , loss:  0.23864111304283142 , node accuracy:  21.300770306654375 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  79 , loss:  0.24089452624320984 , node accuracy:  26.019265637074056 %, lr:  [0.0007290000000000002]\n",
      "Epoch:  80 , loss:  3.169557809829712 , node accuracy:  22.959755721365067 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  81 , loss:  25.155071258544922 , node accuracy:  11.18468873240185 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  82 , loss:  0.4444100260734558 , node accuracy:  18.682824004660493 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  83 , loss:  0.6307412385940552 , node accuracy:  23.607872716914613 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  84 , loss:  0.44871583580970764 , node accuracy:  26.412082037393 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  85 , loss:  2.9424526691436768 , node accuracy:  26.181966104046072 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  86 , loss:  0.749906063079834 , node accuracy:  25.233884543217915 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  87 , loss:  0.8655756115913391 , node accuracy:  27.588335795864683 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  88 , loss:  0.6294488310813904 , node accuracy:  29.389437656285438 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  89 , loss:  0.7006829977035522 , node accuracy:  30.015194699390786 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  90 , loss:  3.337183952331543 , node accuracy:  29.120223269508884 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  91 , loss:  1.1927621364593506 , node accuracy:  28.581990267897122 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  92 , loss:  0.8216007351875305 , node accuracy:  27.44835885779937 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  93 , loss:  1.9755046367645264 , node accuracy:  28.335289654375824 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  94 , loss:  0.5349218249320984 , node accuracy:  19.199410223042975 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  95 , loss:  7.208506107330322 , node accuracy:  19.29010856672845 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  96 , loss:  2.0792455673217773 , node accuracy:  25.51820133689862 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  97 , loss:  2.0596158504486084 , node accuracy:  12.411269863510599 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  98 , loss:  3.1164815425872803 , node accuracy:  22.995064589358563 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  99 , loss:  0.15878534317016602 , node accuracy:  26.6925113596669 %, lr:  [0.0006561000000000001]\n",
      "Epoch:  100 , loss:  0.3312382102012634 , node accuracy:  27.46971198311663 %, lr:  [0.00059049]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aab57fab198>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error resolved after 0:00:23.512588, resuming normal operation.\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_v_node = []\n",
    "# loss_v_edge = []\n",
    "acc_v_node = []\n",
    "# acc_v_edge = []\n",
    "ep = 0\n",
    "for epoch in range(100):\n",
    "    ep += 1\n",
    "    node_correct = 0\n",
    "#     edge_correct = 0\n",
    "    node_total = 0\n",
    "#     edge_total = 0 \n",
    "    for batch in train_loader:\n",
    "#         print(batch)\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        node_pred = model(data)\n",
    "#         print(edge_pred.shape, data.y_edges.shape, node_pred.shape, data.y_params.shape)\n",
    "#         print(edge_pred, data.y_edges, node_pred, data.y_params)\n",
    "#         losses = [F.binary_cross_entropy_with_logits(edge_pred.float(), data.y_edges.float()), F.mse_loss(node_pred.float(), data.y_params.float())]\n",
    "#         print(node_pred, data.y_nodes)\n",
    "#         print(\"Losses: \", losses[0].item(), losses[1].item())\n",
    "        loss = F.mse_loss(node_pred, data.y_params)\n",
    "#         loss = sum(losses)\n",
    "#         loss_v_edge.append(losses[0])\n",
    "        loss_v_node.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         edge_pred = torch.sigmoid(edge_pred)\n",
    "#         edge_correct += ((edge_pred > 0.5) == (data.y_edges > 0.5)).sum().item()\n",
    "        # A \"correct\" track parameter is one where the pred. is within 5% of the truth\n",
    "#         print(node_pred, data.y_nodes)\n",
    "#         print((((node_pred - data.y_nodes)/data.y_nodes)**2 < 0.05**2).sum().item())\n",
    "        node_correct += (((node_pred - data.y_params)/data.y_params)**2 < 0.1**2).sum().item()\n",
    "        node_total += len(node_pred)\n",
    "#         edge_total += len(edge_pred)\n",
    "#         print(out, data.y, )\n",
    "    node_acc = node_correct/node_total\n",
    "#     edge_acc = edge_correct / edge_total\n",
    "    scheduler.step()\n",
    "#     print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", node accuracy: \", node_acc*100, \"%, edge accuracy: \", edge_acc*100, \"%, lr: \", scheduler.get_lr())\n",
    "    print(\"Epoch: \" , ep, \", loss: \", loss.item(), \", node accuracy: \", node_acc*100, \"%, lr: \", scheduler.get_lr())\n",
    "    acc_v_node.append(node_acc)\n",
    "    wandb.log({\"Test Accuracy\": node_acc, \"Test Loss\": loss.item(), \"Learning Rate\": scheduler.get_lr()[0]})\n",
    "#     acc_v_edge.append(edge_acc)\n",
    "\n",
    "#     if node_acc > 0.5:\n",
    "#         break\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.set_size_inches(16,4)\n",
    "axs[0].plot(np.arange(len(loss_v_node)-10), loss_v_node[10:])\n",
    "# axs[1].plot(np.arange(len(loss_v_edge)-10), loss_v_edge[10:])\n",
    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
    "# axs[3].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.9318],\n",
      "        [11.8650],\n",
      "        [11.2290],\n",
      "        ...,\n",
      "        [ 0.7272],\n",
      "        [ 0.6703],\n",
      "        [ 0.7702]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[15.2125],\n",
      "        [15.2125],\n",
      "        [15.2125],\n",
      "        ...,\n",
      "        [ 0.5958],\n",
      "        [ 0.5958],\n",
      "        [ 0.5958]], device='cuda:0')\n",
      "Accuracy: 39.7417%\n",
      "tensor([[13.8930],\n",
      "        [14.0282],\n",
      "        [17.2821],\n",
      "        ...,\n",
      "        [ 1.9400],\n",
      "        [ 1.5565],\n",
      "        [ 1.8785]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[40.8148],\n",
      "        [40.8148],\n",
      "        [40.8148],\n",
      "        ...,\n",
      "        [ 1.7936],\n",
      "        [ 1.7936],\n",
      "        [ 1.7936]], device='cuda:0')\n",
      "Accuracy: 40.2185%\n",
      "tensor([[0.6895],\n",
      "        [0.6651],\n",
      "        [0.6577],\n",
      "        ...,\n",
      "        [1.0724],\n",
      "        [1.4556],\n",
      "        [1.4310]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.9864],\n",
      "        [18.9864],\n",
      "        [18.9864],\n",
      "        ...,\n",
      "        [ 0.6766],\n",
      "        [ 0.6766],\n",
      "        [ 0.6766]], device='cuda:0')\n",
      "Accuracy: 40.0350%\n",
      "tensor([[1.1658],\n",
      "        [1.1077],\n",
      "        [0.6554],\n",
      "        ...,\n",
      "        [0.8939],\n",
      "        [0.8615],\n",
      "        [0.7666]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.9864],\n",
      "        [18.9864],\n",
      "        [18.9864],\n",
      "        ...,\n",
      "        [ 0.6721],\n",
      "        [ 0.6721],\n",
      "        [ 0.6721]], device='cuda:0')\n",
      "Accuracy: 40.3253%\n",
      "tensor([[2.3222],\n",
      "        [2.5033],\n",
      "        [2.3553],\n",
      "        ...,\n",
      "        [0.9325],\n",
      "        [0.8848],\n",
      "        [0.8664]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[2.8667],\n",
      "        [2.8667],\n",
      "        [2.8667],\n",
      "        ...,\n",
      "        [0.8440],\n",
      "        [0.8440],\n",
      "        [0.8440]], device='cuda:0')\n",
      "Accuracy: 40.4110%\n",
      "tensor([[12.1352],\n",
      "        [14.0357],\n",
      "        [17.5757],\n",
      "        ...,\n",
      "        [ 0.7509],\n",
      "        [ 0.8472],\n",
      "        [ 0.9719]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[15.9097],\n",
      "        [15.9097],\n",
      "        [15.9097],\n",
      "        ...,\n",
      "        [ 0.8866],\n",
      "        [ 0.8866],\n",
      "        [ 0.8866]], device='cuda:0')\n",
      "Accuracy: 40.0428%\n",
      "tensor([[0.9942],\n",
      "        [1.1208],\n",
      "        [1.1194],\n",
      "        ...,\n",
      "        [0.9826],\n",
      "        [0.8489],\n",
      "        [0.9707]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.6542],\n",
      "        [1.6542],\n",
      "        [1.6542],\n",
      "        ...,\n",
      "        [1.2293],\n",
      "        [1.2293],\n",
      "        [1.2293]], device='cuda:0')\n",
      "Accuracy: 38.8717%\n",
      "tensor([[ 3.4424],\n",
      "        [ 5.2534],\n",
      "        [23.1656],\n",
      "        ...,\n",
      "        [ 0.8685],\n",
      "        [ 0.5717],\n",
      "        [ 0.5412]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[45.7979],\n",
      "        [45.7979],\n",
      "        [45.7979],\n",
      "        ...,\n",
      "        [ 0.5170],\n",
      "        [ 0.5170],\n",
      "        [ 0.5170]], device='cuda:0')\n",
      "Accuracy: 39.7613%\n",
      "tensor([[ 9.1288],\n",
      "        [11.8913],\n",
      "        [11.2297],\n",
      "        ...,\n",
      "        [ 0.7391],\n",
      "        [ 0.9998],\n",
      "        [ 0.6972]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[15.2125],\n",
      "        [15.2125],\n",
      "        [15.2125],\n",
      "        ...,\n",
      "        [ 1.6608],\n",
      "        [ 1.6608],\n",
      "        [ 1.6608]], device='cuda:0')\n",
      "Accuracy: 40.3495%\n",
      "tensor([[ 9.4903],\n",
      "        [ 8.7859],\n",
      "        [10.1595],\n",
      "        ...,\n",
      "        [ 1.2201],\n",
      "        [ 1.3347],\n",
      "        [ 1.2632]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[12.6091],\n",
      "        [12.6091],\n",
      "        [12.6091],\n",
      "        ...,\n",
      "        [ 1.7351],\n",
      "        [ 1.7351],\n",
      "        [ 1.7351]], device='cuda:0')\n",
      "Accuracy: 39.1402%\n",
      "tensor([[28.3547],\n",
      "        [63.4533],\n",
      "        [81.7252],\n",
      "        ...,\n",
      "        [ 0.7373],\n",
      "        [ 0.6272],\n",
      "        [ 0.6428]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[214.2887],\n",
      "        [214.2887],\n",
      "        [214.2887],\n",
      "        ...,\n",
      "        [  0.6889],\n",
      "        [  0.6889],\n",
      "        [  0.6889]], device='cuda:0')\n",
      "Accuracy: 38.7976%\n",
      "tensor([[1.1035],\n",
      "        [1.3030],\n",
      "        [2.1136],\n",
      "        ...,\n",
      "        [0.5246],\n",
      "        [0.5279],\n",
      "        [0.5917]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[77.3769],\n",
      "        [77.3769],\n",
      "        [77.3769],\n",
      "        ...,\n",
      "        [ 0.5297],\n",
      "        [ 0.5297],\n",
      "        [ 0.5297]], device='cuda:0')\n",
      "Accuracy: 39.7328%\n",
      "tensor([[0.9875],\n",
      "        [0.9888],\n",
      "        [0.9942],\n",
      "        ...,\n",
      "        [1.1358],\n",
      "        [0.9484],\n",
      "        [1.0132]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0031],\n",
      "        [1.0031],\n",
      "        [1.0031],\n",
      "        ...,\n",
      "        [1.0928],\n",
      "        [1.0928],\n",
      "        [1.0928]], device='cuda:0')\n",
      "Accuracy: 39.4175%\n",
      "tensor([[14.6370],\n",
      "        [19.4894],\n",
      "        [18.1789],\n",
      "        ...,\n",
      "        [ 0.9971],\n",
      "        [ 0.8656],\n",
      "        [ 0.9496]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[10.8352],\n",
      "        [10.8352],\n",
      "        [10.8352],\n",
      "        ...,\n",
      "        [ 0.6337],\n",
      "        [ 0.6337],\n",
      "        [ 0.6337]], device='cuda:0')\n",
      "Accuracy: 39.8321%\n",
      "tensor([[2.1587],\n",
      "        [2.2499],\n",
      "        [2.0766],\n",
      "        ...,\n",
      "        [0.8286],\n",
      "        [1.1595],\n",
      "        [1.3049]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.9701],\n",
      "        [1.9701],\n",
      "        [1.9701],\n",
      "        ...,\n",
      "        [0.6973],\n",
      "        [0.6973],\n",
      "        [0.6973]], device='cuda:0')\n",
      "Accuracy: 39.2101%\n",
      "tensor([[1.1895],\n",
      "        [1.2553],\n",
      "        [1.3382],\n",
      "        ...,\n",
      "        [0.6514],\n",
      "        [0.6962],\n",
      "        [0.6892]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.6419],\n",
      "        [1.6419],\n",
      "        [1.6419],\n",
      "        ...,\n",
      "        [0.7746],\n",
      "        [0.7746],\n",
      "        [0.7746]], device='cuda:0')\n",
      "Accuracy: 39.8810%\n",
      "tensor([[0.6917],\n",
      "        [0.6471],\n",
      "        [0.6083],\n",
      "        ...,\n",
      "        [0.9881],\n",
      "        [0.6713],\n",
      "        [0.7153]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[9.5957],\n",
      "        [9.5957],\n",
      "        [9.5957],\n",
      "        ...,\n",
      "        [0.5030],\n",
      "        [0.5053],\n",
      "        [0.5053]], device='cuda:0')\n",
      "Accuracy: 39.1109%\n",
      "tensor([[ 7.0304],\n",
      "        [20.3012],\n",
      "        [30.0342],\n",
      "        ...,\n",
      "        [ 0.7923],\n",
      "        [ 1.3118],\n",
      "        [ 1.0547]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[103.9713],\n",
      "        [103.9713],\n",
      "        [103.9713],\n",
      "        ...,\n",
      "        [  0.5964],\n",
      "        [  0.5964],\n",
      "        [  0.5964]], device='cuda:0')\n",
      "Accuracy: 39.0858%\n",
      "tensor([[ 9.0399],\n",
      "        [11.7952],\n",
      "        [11.1465],\n",
      "        ...,\n",
      "        [ 0.6030],\n",
      "        [ 0.7784],\n",
      "        [ 0.8715]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[15.2125],\n",
      "        [15.2125],\n",
      "        [15.2125],\n",
      "        ...,\n",
      "        [ 0.8757],\n",
      "        [ 0.8757],\n",
      "        [ 0.8757]], device='cuda:0')\n",
      "Accuracy: 39.4866%\n",
      "tensor([[0.9135],\n",
      "        [1.0143],\n",
      "        [1.2914],\n",
      "        ...,\n",
      "        [0.8385],\n",
      "        [0.8471],\n",
      "        [0.7578]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0432],\n",
      "        [1.0432],\n",
      "        [1.0432],\n",
      "        ...,\n",
      "        [0.5182],\n",
      "        [0.5182],\n",
      "        [0.5182]], device='cuda:0')\n",
      "Accuracy: 40.1606%\n",
      "tensor([[1.6345],\n",
      "        [1.6915],\n",
      "        [1.5431],\n",
      "        ...,\n",
      "        [0.6044],\n",
      "        [0.7311],\n",
      "        [0.9333]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.9438],\n",
      "        [1.9438],\n",
      "        [1.9438],\n",
      "        ...,\n",
      "        [0.5980],\n",
      "        [0.5980],\n",
      "        [0.5980]], device='cuda:0')\n",
      "Accuracy: 39.1989%\n",
      "tensor([[10.2383],\n",
      "        [ 8.0740],\n",
      "        [ 7.1587],\n",
      "        ...,\n",
      "        [ 1.0393],\n",
      "        [ 1.1273],\n",
      "        [ 1.0783]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[7.2037],\n",
      "        [7.2037],\n",
      "        [7.2037],\n",
      "        ...,\n",
      "        [1.1689],\n",
      "        [1.1689],\n",
      "        [1.1689]], device='cuda:0')\n",
      "Accuracy: 39.5244%\n",
      "tensor([[0.7564],\n",
      "        [0.7558],\n",
      "        [0.6647],\n",
      "        ...,\n",
      "        [0.6475],\n",
      "        [0.6273],\n",
      "        [0.6765]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.7752],\n",
      "        [0.7752],\n",
      "        [0.7752],\n",
      "        ...,\n",
      "        [0.5488],\n",
      "        [0.5488],\n",
      "        [0.5488]], device='cuda:0')\n",
      "Accuracy: 40.0390%\n",
      "tensor([[ 2.1219],\n",
      "        [ 4.1635],\n",
      "        [31.8953],\n",
      "        ...,\n",
      "        [ 0.7448],\n",
      "        [ 0.6810],\n",
      "        [ 0.6063]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[103.9713],\n",
      "        [103.9713],\n",
      "        [103.9713],\n",
      "        ...,\n",
      "        [  0.6936],\n",
      "        [  0.6936],\n",
      "        [  0.6936]], device='cuda:0')\n",
      "Accuracy: 40.3640%\n",
      "tensor([[5.5135],\n",
      "        [4.3961],\n",
      "        [4.6118],\n",
      "        ...,\n",
      "        [0.6515],\n",
      "        [0.7172],\n",
      "        [0.7335]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[4.7416],\n",
      "        [4.7416],\n",
      "        [4.7416],\n",
      "        ...,\n",
      "        [0.5174],\n",
      "        [0.5174],\n",
      "        [0.5174]], device='cuda:0')\n",
      "Accuracy: 41.8565%\n",
      "tensor([[0.7226],\n",
      "        [0.8478],\n",
      "        [0.6117],\n",
      "        ...,\n",
      "        [0.7012],\n",
      "        [0.7081],\n",
      "        [0.6395]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.2959],\n",
      "        [18.2959],\n",
      "        [18.2959],\n",
      "        ...,\n",
      "        [ 0.5716],\n",
      "        [ 0.5716],\n",
      "        [ 0.5716]], device='cuda:0')\n",
      "Accuracy: 39.6079%\n",
      "tensor([[0.7796],\n",
      "        [0.8318],\n",
      "        [0.7697],\n",
      "        ...,\n",
      "        [0.9296],\n",
      "        [0.9273],\n",
      "        [1.0580]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.8145],\n",
      "        [0.8145],\n",
      "        [0.5644],\n",
      "        ...,\n",
      "        [1.2768],\n",
      "        [1.2768],\n",
      "        [1.2768]], device='cuda:0')\n",
      "Accuracy: 39.3381%\n",
      "tensor([[10.2519],\n",
      "        [ 8.6586],\n",
      "        [ 7.7297],\n",
      "        ...,\n",
      "        [ 1.2707],\n",
      "        [ 1.0032],\n",
      "        [ 0.6826]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[12.3305],\n",
      "        [12.3305],\n",
      "        [12.3305],\n",
      "        ...,\n",
      "        [ 0.6648],\n",
      "        [ 0.6648],\n",
      "        [ 0.6648]], device='cuda:0')\n",
      "Accuracy: 38.8127%\n",
      "tensor([[0.9996],\n",
      "        [0.8601],\n",
      "        [0.9708],\n",
      "        ...,\n",
      "        [0.6847],\n",
      "        [0.6144],\n",
      "        [0.5791]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.2671],\n",
      "        [1.2671],\n",
      "        [1.2671],\n",
      "        ...,\n",
      "        [0.6528],\n",
      "        [0.6528],\n",
      "        [0.6528]], device='cuda:0')\n",
      "Accuracy: 40.3468%\n",
      "tensor([[19.1213],\n",
      "        [16.8965],\n",
      "        [17.0006],\n",
      "        ...,\n",
      "        [ 1.2032],\n",
      "        [ 1.2859],\n",
      "        [ 1.1205]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[11.3675],\n",
      "        [11.3675],\n",
      "        [11.3675],\n",
      "        ...,\n",
      "        [ 1.1216],\n",
      "        [ 1.1216],\n",
      "        [ 1.1216]], device='cuda:0')\n",
      "Accuracy: 40.6948%\n",
      "tensor([[3.6168],\n",
      "        [5.2099],\n",
      "        [5.1324],\n",
      "        ...,\n",
      "        [2.8753],\n",
      "        [3.4861],\n",
      "        [2.0596]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[5.4117],\n",
      "        [5.4117],\n",
      "        [5.4117],\n",
      "        ...,\n",
      "        [1.7091],\n",
      "        [1.7091],\n",
      "        [1.7091]], device='cuda:0')\n",
      "Accuracy: 40.0502%\n",
      "tensor([[10.3463],\n",
      "        [ 8.6515],\n",
      "        [ 7.7605],\n",
      "        ...,\n",
      "        [ 0.6446],\n",
      "        [ 0.6453],\n",
      "        [ 0.7479]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[12.3305],\n",
      "        [12.3305],\n",
      "        [12.3305],\n",
      "        ...,\n",
      "        [ 0.5811],\n",
      "        [ 0.5811],\n",
      "        [ 0.5811]], device='cuda:0')\n",
      "Accuracy: 39.0119%\n",
      "tensor([[0.9783],\n",
      "        [1.0397],\n",
      "        [1.0651],\n",
      "        ...,\n",
      "        [0.6647],\n",
      "        [0.7699],\n",
      "        [0.8835]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[41.3389],\n",
      "        [41.3389],\n",
      "        [41.3389],\n",
      "        ...,\n",
      "        [ 2.3012],\n",
      "        [ 2.3012],\n",
      "        [ 2.3012]], device='cuda:0')\n",
      "Accuracy: 40.6840%\n",
      "tensor([[0.6630],\n",
      "        [0.6878],\n",
      "        [0.6975],\n",
      "        ...,\n",
      "        [0.8447],\n",
      "        [0.8768],\n",
      "        [1.0330]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.7537],\n",
      "        [0.7537],\n",
      "        [0.7537],\n",
      "        ...,\n",
      "        [0.7055],\n",
      "        [0.7055],\n",
      "        [0.7055]], device='cuda:0')\n",
      "Accuracy: 39.3853%\n",
      "tensor([[3.9761],\n",
      "        [4.5978],\n",
      "        [6.2752],\n",
      "        ...,\n",
      "        [0.6555],\n",
      "        [0.9929],\n",
      "        [0.9387]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[114.3767],\n",
      "        [114.3767],\n",
      "        [114.3767],\n",
      "        ...,\n",
      "        [  0.5394],\n",
      "        [  0.5394],\n",
      "        [  0.5394]], device='cuda:0')\n",
      "Accuracy: 40.5195%\n",
      "tensor([[0.9683],\n",
      "        [1.0184],\n",
      "        [1.0687],\n",
      "        ...,\n",
      "        [2.1319],\n",
      "        [2.1325],\n",
      "        [2.3955]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[2.1535],\n",
      "        [2.1535],\n",
      "        [2.1535],\n",
      "        ...,\n",
      "        [2.0440],\n",
      "        [2.0440],\n",
      "        [2.0440]], device='cuda:0')\n",
      "Accuracy: 40.0183%\n",
      "tensor([[1.0741],\n",
      "        [1.1577],\n",
      "        [1.1884],\n",
      "        ...,\n",
      "        [0.7665],\n",
      "        [0.7874],\n",
      "        [0.8470]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0568],\n",
      "        [1.0568],\n",
      "        [1.0568],\n",
      "        ...,\n",
      "        [0.5111],\n",
      "        [0.5111],\n",
      "        [0.5111]], device='cuda:0')\n",
      "Accuracy: 38.4389%\n",
      "tensor([[1.6255],\n",
      "        [1.6056],\n",
      "        [1.8206],\n",
      "        ...,\n",
      "        [0.7076],\n",
      "        [0.8283],\n",
      "        [0.8569]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.5487],\n",
      "        [1.5487],\n",
      "        [1.5487],\n",
      "        ...,\n",
      "        [0.8363],\n",
      "        [0.8363],\n",
      "        [0.8363]], device='cuda:0')\n",
      "Accuracy: 39.5117%\n",
      "tensor([[0.6603],\n",
      "        [1.6645],\n",
      "        [4.5902],\n",
      "        ...,\n",
      "        [0.7540],\n",
      "        [0.7077],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [0.6972]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[34.2068],\n",
      "        [34.2068],\n",
      "        [34.2068],\n",
      "        ...,\n",
      "        [ 0.5591],\n",
      "        [ 0.5591],\n",
      "        [ 0.5591]], device='cuda:0')\n",
      "Accuracy: 40.2999%\n",
      "tensor([[10.2161],\n",
      "        [ 8.5189],\n",
      "        [ 7.6812],\n",
      "        ...,\n",
      "        [ 0.6470],\n",
      "        [ 0.6614],\n",
      "        [ 0.5862]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[12.3305],\n",
      "        [12.3305],\n",
      "        [12.3305],\n",
      "        ...,\n",
      "        [ 0.5768],\n",
      "        [ 0.5768],\n",
      "        [ 0.5768]], device='cuda:0')\n",
      "Accuracy: 40.0605%\n",
      "tensor([[0.9681],\n",
      "        [1.0175],\n",
      "        [1.0679],\n",
      "        ...,\n",
      "        [0.6423],\n",
      "        [0.6531],\n",
      "        [0.6582]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[2.1535],\n",
      "        [2.1535],\n",
      "        [2.1535],\n",
      "        ...,\n",
      "        [0.5419],\n",
      "        [0.5419],\n",
      "        [0.5419]], device='cuda:0')\n",
      "Accuracy: 39.3605%\n",
      "tensor([[0.9883],\n",
      "        [0.9892],\n",
      "        [0.9956],\n",
      "        ...,\n",
      "        [0.7058],\n",
      "        [0.7919],\n",
      "        [0.9199]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0031],\n",
      "        [1.0031],\n",
      "        [1.0031],\n",
      "        ...,\n",
      "        [0.7900],\n",
      "        [0.7900],\n",
      "        [0.7900]], device='cuda:0')\n",
      "Accuracy: 39.9850%\n",
      "tensor([[1.4345],\n",
      "        [1.4077],\n",
      "        [1.2925],\n",
      "        ...,\n",
      "        [1.1382],\n",
      "        [1.3562],\n",
      "        [1.0842]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.5719],\n",
      "        [1.5719],\n",
      "        [1.5719],\n",
      "        ...,\n",
      "        [1.4316],\n",
      "        [1.4316],\n",
      "        [1.4316]], device='cuda:0')\n",
      "Accuracy: 39.1546%\n",
      "tensor([[3.0630],\n",
      "        [2.7623],\n",
      "        [3.2913],\n",
      "        ...,\n",
      "        [0.6739],\n",
      "        [0.5828],\n",
      "        [0.6157]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[49.4070],\n",
      "        [49.4070],\n",
      "        [49.4070],\n",
      "        ...,\n",
      "        [ 0.5294],\n",
      "        [ 0.5294],\n",
      "        [ 0.5294]], device='cuda:0')\n",
      "Accuracy: 40.2626%\n",
      "tensor([[11.9847],\n",
      "        [13.2803],\n",
      "        [10.4962],\n",
      "        ...,\n",
      "        [ 0.7002],\n",
      "        [ 0.5775],\n",
      "        [ 0.5533]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[103.9713],\n",
      "        [103.9713],\n",
      "        [103.9713],\n",
      "        ...,\n",
      "        [  0.5163],\n",
      "        [  0.5163],\n",
      "        [  0.5163]], device='cuda:0')\n",
      "Accuracy: 40.2963%\n",
      "tensor([[1.0355],\n",
      "        [0.8637],\n",
      "        [0.8407],\n",
      "        ...,\n",
      "        [1.0183],\n",
      "        [0.8709],\n",
      "        [0.9781]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[7.4545],\n",
      "        [7.4545],\n",
      "        [7.4545],\n",
      "        ...,\n",
      "        [0.5515],\n",
      "        [0.5515],\n",
      "        [0.5515]], device='cuda:0')\n",
      "Accuracy: 39.2724%\n",
      "tensor([[1.6573],\n",
      "        [1.7834],\n",
      "        [1.5776],\n",
      "        ...,\n",
      "        [0.7427],\n",
      "        [0.7284],\n",
      "        [0.8567]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.6736],\n",
      "        [1.6736],\n",
      "        [1.6736],\n",
      "        ...,\n",
      "        [0.5688],\n",
      "        [0.5688],\n",
      "        [0.5688]], device='cuda:0')\n",
      "Accuracy: 40.3407%\n",
      "tensor([[11.2320],\n",
      "        [13.0427],\n",
      "        [16.5677],\n",
      "        ...,\n",
      "        [ 0.6959],\n",
      "        [ 0.6481],\n",
      "        [ 0.7528]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[15.9097],\n",
      "        [15.9097],\n",
      "        [15.9097],\n",
      "        ...,\n",
      "        [ 0.5118],\n",
      "        [ 0.5118],\n",
      "        [ 0.5118]], device='cuda:0')\n",
      "Accuracy: 39.8308%\n",
      "tensor([[3.6314],\n",
      "        [5.2184],\n",
      "        [5.1166],\n",
      "        ...,\n",
      "        [0.6317],\n",
      "        [0.6797],\n",
      "        [0.5500]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[5.4117],\n",
      "        [5.4117],\n",
      "        [5.4117],\n",
      "        ...,\n",
      "        [0.5336],\n",
      "        [0.5336],\n",
      "        [0.5336]], device='cuda:0')\n",
      "Accuracy: 39.5466%\n",
      "tensor([[ 0.6881],\n",
      "        [11.6658],\n",
      "        [ 6.5289],\n",
      "        ...,\n",
      "        [ 0.6949],\n",
      "        [ 0.7447],\n",
      "        [ 0.8752]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.9864],\n",
      "        [18.9864],\n",
      "        [18.9864],\n",
      "        ...,\n",
      "        [ 0.5053],\n",
      "        [ 0.5053],\n",
      "        [ 0.5053]], device='cuda:0')\n",
      "Accuracy: 39.3142%\n",
      "tensor([[8.2489],\n",
      "        [7.2578],\n",
      "        [7.3865],\n",
      "        ...,\n",
      "        [0.6723],\n",
      "        [0.6653],\n",
      "        [0.6261]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[7.0816],\n",
      "        [7.0816],\n",
      "        [7.0816],\n",
      "        ...,\n",
      "        [0.6795],\n",
      "        [0.6795],\n",
      "        [0.6795]], device='cuda:0')\n",
      "Accuracy: 39.4279%\n",
      "tensor([[42.7952],\n",
      "        [48.9230],\n",
      "        [46.6251],\n",
      "        ...,\n",
      "        [ 0.6276],\n",
      "        [ 0.6505],\n",
      "        [ 0.5349]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[214.2887],\n",
      "        [214.2887],\n",
      "        [214.2887],\n",
      "        ...,\n",
      "        [  0.5513],\n",
      "        [  0.5513],\n",
      "        [  0.5513]], device='cuda:0')\n",
      "Accuracy: 40.1457%\n",
      "tensor([[1.6206],\n",
      "        [1.4773],\n",
      "        [2.0015],\n",
      "        ...,\n",
      "        [0.8882],\n",
      "        [0.9505],\n",
      "        [0.8475]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[2.0819],\n",
      "        [2.0819],\n",
      "        [2.0819],\n",
      "        ...,\n",
      "        [0.9285],\n",
      "        [0.9285],\n",
      "        [0.9285]], device='cuda:0')\n",
      "Accuracy: 40.2122%\n",
      "tensor([[1.3236],\n",
      "        [1.3064],\n",
      "        [1.1554],\n",
      "        ...,\n",
      "        [0.6435],\n",
      "        [0.6298],\n",
      "        [0.6163]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.2227],\n",
      "        [1.2227],\n",
      "        [1.2227],\n",
      "        ...,\n",
      "        [0.5580],\n",
      "        [0.5580],\n",
      "        [0.5580]], device='cuda:0')\n",
      "Accuracy: 39.8365%\n",
      "tensor([[0.6796],\n",
      "        [0.7947],\n",
      "        [0.8771],\n",
      "        ...,\n",
      "        [0.7633],\n",
      "        [0.9490],\n",
      "        [1.0927]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.4249],\n",
      "        [18.4249],\n",
      "        [18.4249],\n",
      "        ...,\n",
      "        [ 0.8176],\n",
      "        [ 0.8176],\n",
      "        [ 0.8176]], device='cuda:0')\n",
      "Accuracy: 37.5792%\n",
      "tensor([[1.0066],\n",
      "        [0.8420],\n",
      "        [0.9938],\n",
      "        ...,\n",
      "        [0.7329],\n",
      "        [0.8331],\n",
      "        [0.7742]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.7756],\n",
      "        [1.7756],\n",
      "        [1.7756],\n",
      "        ...,\n",
      "        [0.8164],\n",
      "        [0.8164],\n",
      "        [0.8164]], device='cuda:0')\n",
      "Accuracy: 40.5097%\n",
      "tensor([[0.7226],\n",
      "        [0.8432],\n",
      "        [0.6172],\n",
      "        ...,\n",
      "        [1.5072],\n",
      "        [1.1013],\n",
      "        [1.3276]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[9.5957],\n",
      "        [9.5957],\n",
      "        [9.5957],\n",
      "        ...,\n",
      "        [1.1248],\n",
      "        [1.1248],\n",
      "        [1.1248]], device='cuda:0')\n",
      "Accuracy: 39.2459%\n",
      "tensor([[1.1484],\n",
      "        [1.2153],\n",
      "        [1.1721],\n",
      "        ...,\n",
      "        [0.6316],\n",
      "        [0.6301],\n",
      "        [0.6537]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.7752],\n",
      "        [0.7752],\n",
      "        [0.7752],\n",
      "        ...,\n",
      "        [0.5931],\n",
      "        [0.5931],\n",
      "        [0.5931]], device='cuda:0')\n",
      "Accuracy: 40.2219%\n",
      "tensor([[2.6271],\n",
      "        [2.6988],\n",
      "        [3.3629],\n",
      "        ...,\n",
      "        [0.6870],\n",
      "        [0.6212],\n",
      "        [0.6703]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[3.5017],\n",
      "        [3.5017],\n",
      "        [3.5017],\n",
      "        ...,\n",
      "        [0.6006],\n",
      "        [0.6006],\n",
      "        [0.6006]], device='cuda:0')\n",
      "Accuracy: 39.0849%\n",
      "tensor([[0.6733],\n",
      "        [0.6504],\n",
      "        [0.6597],\n",
      "        ...,\n",
      "        [1.0149],\n",
      "        [1.2987],\n",
      "        [0.9066]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6718],\n",
      "        [0.6718],\n",
      "        [0.6718],\n",
      "        ...,\n",
      "        [0.6416],\n",
      "        [0.6416],\n",
      "        [0.6416]], device='cuda:0')\n",
      "Accuracy: 40.3180%\n",
      "tensor([[0.9803],\n",
      "        [0.9679],\n",
      "        [0.9910],\n",
      "        ...,\n",
      "        [0.6828],\n",
      "        [0.6682],\n",
      "        [0.6200]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[5.4676],\n",
      "        [5.4676],\n",
      "        [5.4676],\n",
      "        ...,\n",
      "        [0.7276],\n",
      "        [0.7276],\n",
      "        [0.7276]], device='cuda:0')\n",
      "Accuracy: 40.6631%\n",
      "tensor([[14.7487],\n",
      "        [19.8781],\n",
      "        [18.3167],\n",
      "        ...,\n",
      "        [ 0.6486],\n",
      "        [ 0.6342],\n",
      "        [ 0.6402]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[10.8352],\n",
      "        [10.8352],\n",
      "        [10.8352],\n",
      "        ...,\n",
      "        [ 0.6237],\n",
      "        [ 0.6237],\n",
      "        [ 0.6237]], device='cuda:0')\n",
      "Accuracy: 39.3348%\n",
      "tensor([[1.0005],\n",
      "        [1.1341],\n",
      "        [1.1276],\n",
      "        ...,\n",
      "        [0.6037],\n",
      "        [0.6033],\n",
      "        [0.5284]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6658],\n",
      "        [0.6658],\n",
      "        [0.6658],\n",
      "        ...,\n",
      "        [0.5664],\n",
      "        [0.5664],\n",
      "        [0.5664]], device='cuda:0')\n",
      "Accuracy: 40.1885%\n",
      "tensor([[16.8904],\n",
      "        [20.8417],\n",
      "        [20.3371],\n",
      "        ...,\n",
      "        [ 0.7235],\n",
      "        [ 0.6742],\n",
      "        [ 0.7453]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[62.8775],\n",
      "        [62.8775],\n",
      "        [62.8775],\n",
      "        ...,\n",
      "        [ 0.7276],\n",
      "        [ 0.7276],\n",
      "        [ 0.7276]], device='cuda:0')\n",
      "Accuracy: 39.7209%\n",
      "tensor([[0.8520],\n",
      "        [0.8058],\n",
      "        [1.3407],\n",
      "        ...,\n",
      "        [0.8619],\n",
      "        [0.9751],\n",
      "        [0.8014]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.1269],\n",
      "        [1.1269],\n",
      "        [1.1269],\n",
      "        ...,\n",
      "        [0.7729],\n",
      "        [0.7729],\n",
      "        [0.7729]], device='cuda:0')\n",
      "Accuracy: 40.4717%\n",
      "tensor([[0.6712],\n",
      "        [0.6263],\n",
      "        [0.5953],\n",
      "        ...,\n",
      "        [0.5279],\n",
      "        [0.5198],\n",
      "        [0.5139]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[9.9181],\n",
      "        [9.9181],\n",
      "        [9.9181],\n",
      "        ...,\n",
      "        [0.5163],\n",
      "        [0.5163],\n",
      "        [0.5163]], device='cuda:0')\n",
      "Accuracy: 39.5578%\n",
      "tensor([[0.8464],\n",
      "        [0.8655],\n",
      "        [0.9052],\n",
      "        ...,\n",
      "        [0.8541],\n",
      "        [0.9607],\n",
      "        [0.9901]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[28.2485],\n",
      "        [28.2485],\n",
      "        [28.2485],\n",
      "        ...,\n",
      "        [ 0.5693],\n",
      "        [ 0.5693],\n",
      "        [ 0.5693]], device='cuda:0')\n",
      "Accuracy: 38.7823%\n",
      "tensor([[0.9980],\n",
      "        [0.8870],\n",
      "        [0.9275],\n",
      "        ...,\n",
      "        [1.7981],\n",
      "        [1.4017],\n",
      "        [1.2597]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.8174],\n",
      "        [1.8174],\n",
      "        [1.8174],\n",
      "        ...,\n",
      "        [1.5891],\n",
      "        [1.5891],\n",
      "        [1.5891]], device='cuda:0')\n",
      "Accuracy: 39.9508%\n",
      "tensor([[0.9969],\n",
      "        [0.9015],\n",
      "        [0.9987],\n",
      "        ...,\n",
      "        [0.6854],\n",
      "        [0.7988],\n",
      "        [0.6971]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6272],\n",
      "        [0.6272],\n",
      "        [0.6272],\n",
      "        ...,\n",
      "        [0.5574],\n",
      "        [0.5574],\n",
      "        [0.5574]], device='cuda:0')\n",
      "Accuracy: 39.1757%\n",
      "tensor([[5.6407],\n",
      "        [5.8813],\n",
      "        [5.0981],\n",
      "        ...,\n",
      "        [0.6493],\n",
      "        [0.5865],\n",
      "        [0.6767]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[4.2333],\n",
      "        [4.2333],\n",
      "        [4.2333],\n",
      "        ...,\n",
      "        [0.6468],\n",
      "        [0.6468],\n",
      "        [0.6468]], device='cuda:0')\n",
      "Accuracy: 39.7403%\n",
      "tensor([[2.6274],\n",
      "        [2.7943],\n",
      "        [3.6031],\n",
      "        ...,\n",
      "        [1.1684],\n",
      "        [1.0011],\n",
      "        [1.0178]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[3.5017],\n",
      "        [3.5017],\n",
      "        [3.5017],\n",
      "        ...,\n",
      "        [1.0661],\n",
      "        [1.0661],\n",
      "        [1.0661]], device='cuda:0')\n",
      "Accuracy: 38.7006%\n",
      "tensor([[3.1372],\n",
      "        [4.5701],\n",
      "        [7.6276],\n",
      "        ...,\n",
      "        [0.5648],\n",
      "        [0.6136],\n",
      "        [0.7399]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.9803],\n",
      "        [18.9803],\n",
      "        [18.9803],\n",
      "        ...,\n",
      "        [ 0.7229],\n",
      "        [ 0.7229],\n",
      "        [ 0.7229]], device='cuda:0')\n",
      "Accuracy: 39.4491%\n",
      "tensor([[12.9539],\n",
      "        [12.2334],\n",
      "        [11.3214],\n",
      "        ...,\n",
      "        [ 0.6566],\n",
      "        [ 0.5275],\n",
      "        [ 0.5185]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[10.0892],\n",
      "        [10.0892],\n",
      "        [10.0892],\n",
      "        ...,\n",
      "        [ 0.5517],\n",
      "        [ 0.5517],\n",
      "        [ 0.5517]], device='cuda:0')\n",
      "Accuracy: 40.2761%\n",
      "tensor([[3.6755],\n",
      "        [3.6912],\n",
      "        [4.2473],\n",
      "        ...,\n",
      "        [0.8420],\n",
      "        [0.9263],\n",
      "        [0.8659]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[4.1409],\n",
      "        [4.1409],\n",
      "        [4.1409],\n",
      "        ...,\n",
      "        [0.6053],\n",
      "        [0.6053],\n",
      "        [0.6053]], device='cuda:0')\n",
      "Accuracy: 39.6207%\n",
      "tensor([[0.9930],\n",
      "        [1.1189],\n",
      "        [1.1182],\n",
      "        ...,\n",
      "        [1.0980],\n",
      "        [0.9079],\n",
      "        [0.9797]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.6542],\n",
      "        [1.6542],\n",
      "        [1.6542],\n",
      "        ...,\n",
      "        [1.0477],\n",
      "        [1.0477],\n",
      "        [1.0477]], device='cuda:0')\n",
      "Accuracy: 40.8742%\n",
      "tensor([[2.3119],\n",
      "        [3.0012],\n",
      "        [3.4853],\n",
      "        ...,\n",
      "        [0.7756],\n",
      "        [0.8348],\n",
      "        [0.7605]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[4.2260],\n",
      "        [4.2260],\n",
      "        [4.2260],\n",
      "        ...,\n",
      "        [0.8264],\n",
      "        [0.8264],\n",
      "        [0.8264]], device='cuda:0')\n",
      "Accuracy: 39.4977%\n",
      "tensor([[0.9552],\n",
      "        [0.9512],\n",
      "        [1.1259],\n",
      "        ...,\n",
      "        [0.7132],\n",
      "        [0.8764],\n",
      "        [0.7109]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[18.9803],\n",
      "        [18.9803],\n",
      "        [18.9803],\n",
      "        ...,\n",
      "        [ 0.5077],\n",
      "        [ 0.5077],\n",
      "        [ 0.5077]], device='cuda:0')\n",
      "Accuracy: 40.1390%\n",
      "tensor([[1.0961],\n",
      "        [1.0131],\n",
      "        [0.9886],\n",
      "        ...,\n",
      "        [0.9215],\n",
      "        [0.8816],\n",
      "        [1.0348]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6300],\n",
      "        [0.6300],\n",
      "        [0.6300],\n",
      "        ...,\n",
      "        [0.6538],\n",
      "        [0.6538],\n",
      "        [0.6538]], device='cuda:0')\n",
      "Accuracy: 39.7940%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9016],\n",
      "        [1.0014],\n",
      "        [1.2399],\n",
      "        ...,\n",
      "        [0.6275],\n",
      "        [0.6268],\n",
      "        [0.6755]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0432],\n",
      "        [1.0432],\n",
      "        [1.0432],\n",
      "        ...,\n",
      "        [0.6954],\n",
      "        [0.6954],\n",
      "        [0.6954]], device='cuda:0')\n",
      "Accuracy: 39.1318%\n",
      "tensor([[0.9803],\n",
      "        [0.9692],\n",
      "        [0.9925],\n",
      "        ...,\n",
      "        [0.5200],\n",
      "        [0.5255],\n",
      "        [0.5377]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[5.4676],\n",
      "        [5.4676],\n",
      "        [5.4676],\n",
      "        ...,\n",
      "        [0.5036],\n",
      "        [0.5036],\n",
      "        [0.5036]], device='cuda:0')\n",
      "Accuracy: 39.6506%\n",
      "tensor([[19.0480],\n",
      "        [23.0835],\n",
      "        [21.6653],\n",
      "        ...,\n",
      "        [ 1.5495],\n",
      "        [ 1.5566],\n",
      "        [ 1.3213]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[66.0761],\n",
      "        [66.0761],\n",
      "        [66.0761],\n",
      "        ...,\n",
      "        [ 1.1489],\n",
      "        [ 1.1489],\n",
      "        [ 1.1489]], device='cuda:0')\n",
      "Accuracy: 39.7656%\n",
      "tensor([[10.7145],\n",
      "        [ 6.7402],\n",
      "        [ 8.7517],\n",
      "        ...,\n",
      "        [ 0.8141],\n",
      "        [ 0.7114],\n",
      "        [ 0.8462]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[9.6110],\n",
      "        [9.6110],\n",
      "        [9.6110],\n",
      "        ...,\n",
      "        [0.7663],\n",
      "        [0.7663],\n",
      "        [0.7663]], device='cuda:0')\n",
      "Accuracy: 38.7527%\n",
      "tensor([[10.4775],\n",
      "        [ 8.1635],\n",
      "        [ 6.9152],\n",
      "        ...,\n",
      "        [ 0.8971],\n",
      "        [ 1.0843],\n",
      "        [ 0.8726]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[7.2037],\n",
      "        [7.2037],\n",
      "        [7.2037],\n",
      "        ...,\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917]], device='cuda:0')\n",
      "Accuracy: 38.9668%\n",
      "tensor([[32.4640],\n",
      "        [32.3690],\n",
      "        [43.8462],\n",
      "        ...,\n",
      "        [ 1.8761],\n",
      "        [ 1.6347],\n",
      "        [ 1.5169]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[77.1132],\n",
      "        [77.1132],\n",
      "        [77.1132],\n",
      "        ...,\n",
      "        [ 1.6917],\n",
      "        [ 1.6917],\n",
      "        [ 1.6917]], device='cuda:0')\n",
      "Accuracy: 39.9223%\n",
      "tensor([[0.9733],\n",
      "        [0.9466],\n",
      "        [0.9591],\n",
      "        ...,\n",
      "        [0.5838],\n",
      "        [0.5999],\n",
      "        [0.7291]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.9247],\n",
      "        [0.9247],\n",
      "        [0.9247],\n",
      "        ...,\n",
      "        [0.5667],\n",
      "        [0.5667],\n",
      "        [0.5667]], device='cuda:0')\n",
      "Accuracy: 39.6083%\n",
      "tensor([[1.0348],\n",
      "        [0.8618],\n",
      "        [0.8457],\n",
      "        ...,\n",
      "        [0.8780],\n",
      "        [0.9837],\n",
      "        [0.5215]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[7.4545],\n",
      "        [7.4545],\n",
      "        [7.4545],\n",
      "        ...,\n",
      "        [1.2338],\n",
      "        [1.2338],\n",
      "        [1.2338]], device='cuda:0')\n",
      "Accuracy: 39.0186%\n",
      "tensor([[1.0539],\n",
      "        [1.0836],\n",
      "        [1.0144],\n",
      "        ...,\n",
      "        [0.9879],\n",
      "        [0.8594],\n",
      "        [0.7651]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6624],\n",
      "        [0.6624],\n",
      "        [0.6624],\n",
      "        ...,\n",
      "        [1.0003],\n",
      "        [1.0003],\n",
      "        [1.0003]], device='cuda:0')\n",
      "Accuracy: 40.4452%\n",
      "tensor([[0.6560],\n",
      "        [0.7484],\n",
      "        [0.8034],\n",
      "        ...,\n",
      "        [0.8664],\n",
      "        [0.8966],\n",
      "        [0.7544]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.5559],\n",
      "        [0.5559],\n",
      "        [0.5559],\n",
      "        ...,\n",
      "        [1.0908],\n",
      "        [1.0908],\n",
      "        [1.1814]], device='cuda:0')\n",
      "Accuracy: 39.5069%\n",
      "tensor([[0.6713],\n",
      "        [0.6502],\n",
      "        [0.6608],\n",
      "        ...,\n",
      "        [1.1412],\n",
      "        [1.2072],\n",
      "        [0.9134]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.6718],\n",
      "        [0.6718],\n",
      "        [0.6718],\n",
      "        ...,\n",
      "        [1.1390],\n",
      "        [1.1390],\n",
      "        [1.1390]], device='cuda:0')\n",
      "Accuracy: 39.1823%\n",
      "tensor([[1.6302],\n",
      "        [1.2663],\n",
      "        [1.7483],\n",
      "        ...,\n",
      "        [0.7675],\n",
      "        [0.7321],\n",
      "        [0.6926]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.7191],\n",
      "        [1.7191],\n",
      "        [1.7191],\n",
      "        ...,\n",
      "        [0.7097],\n",
      "        [0.7097],\n",
      "        [0.7097]], device='cuda:0')\n",
      "Accuracy: 40.5287%\n",
      "tensor([[0.9975],\n",
      "        [0.9531],\n",
      "        [0.9131],\n",
      "        ...,\n",
      "        [1.1248],\n",
      "        [0.7863],\n",
      "        [1.0304]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[3.8672],\n",
      "        [3.8672],\n",
      "        [3.8672],\n",
      "        ...,\n",
      "        [0.5144],\n",
      "        [0.5074],\n",
      "        [0.5074]], device='cuda:0')\n",
      "Accuracy: 40.6298%\n",
      "tensor([[0.8473],\n",
      "        [0.8746],\n",
      "        [0.7258],\n",
      "        ...,\n",
      "        [0.6936],\n",
      "        [0.7743],\n",
      "        [0.7342]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0484],\n",
      "        [1.0484],\n",
      "        [1.0484],\n",
      "        ...,\n",
      "        [0.7965],\n",
      "        [0.7965],\n",
      "        [0.7965]], device='cuda:0')\n",
      "Accuracy: 39.0264%\n",
      "tensor([[8.5380],\n",
      "        [7.4409],\n",
      "        [8.9080],\n",
      "        ...,\n",
      "        [0.9483],\n",
      "        [0.8375],\n",
      "        [0.7380]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[6.1454],\n",
      "        [6.1454],\n",
      "        [6.1454],\n",
      "        ...,\n",
      "        [0.8144],\n",
      "        [0.8144],\n",
      "        [0.8144]], device='cuda:0')\n",
      "Accuracy: 39.3465%\n",
      "tensor([[0.9399],\n",
      "        [0.9246],\n",
      "        [0.9130],\n",
      "        ...,\n",
      "        [0.6532],\n",
      "        [0.6188],\n",
      "        [0.6643]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.7312],\n",
      "        [0.7312],\n",
      "        [0.7312],\n",
      "        ...,\n",
      "        [0.6452],\n",
      "        [0.6452],\n",
      "        [0.6452]], device='cuda:0')\n",
      "Accuracy: 38.6133%\n",
      "tensor([[17.3492],\n",
      "        [21.3735],\n",
      "        [20.9378],\n",
      "        ...,\n",
      "        [ 0.7750],\n",
      "        [ 0.7245],\n",
      "        [ 0.8494]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[62.8775],\n",
      "        [62.8775],\n",
      "        [62.8775],\n",
      "        ...,\n",
      "        [ 1.1988],\n",
      "        [ 0.5820],\n",
      "        [ 0.5820]], device='cuda:0')\n",
      "Accuracy: 40.3640%\n",
      "tensor([[0.7486],\n",
      "        [0.7896],\n",
      "        [0.9446],\n",
      "        ...,\n",
      "        [0.9740],\n",
      "        [0.8918],\n",
      "        [0.8121]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.9247],\n",
      "        [0.9247],\n",
      "        [0.9247],\n",
      "        ...,\n",
      "        [0.6448],\n",
      "        [0.6448],\n",
      "        [0.6448]], device='cuda:0')\n",
      "Accuracy: 38.9745%\n",
      "tensor([[0.7439],\n",
      "        [0.7359],\n",
      "        [0.6380],\n",
      "        ...,\n",
      "        [0.5949],\n",
      "        [0.8614],\n",
      "        [0.9297]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.7752],\n",
      "        [0.7752],\n",
      "        [0.7752],\n",
      "        ...,\n",
      "        [0.6405],\n",
      "        [0.6405],\n",
      "        [0.6405]], device='cuda:0')\n",
      "Accuracy: 40.1297%\n",
      "tensor([[1.0853],\n",
      "        [1.0139],\n",
      "        [1.0190],\n",
      "        ...,\n",
      "        [1.0269],\n",
      "        [1.0126],\n",
      "        [0.8494]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0948],\n",
      "        [1.0948],\n",
      "        [1.0948],\n",
      "        ...,\n",
      "        [0.8433],\n",
      "        [0.8433],\n",
      "        [0.8433]], device='cuda:0')\n",
      "Accuracy: 39.8106%\n",
      "tensor([[0.7379],\n",
      "        [0.7385],\n",
      "        [0.6666],\n",
      "        ...,\n",
      "        [0.7068],\n",
      "        [0.8132],\n",
      "        [0.8594]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[0.9289],\n",
      "        [0.9289],\n",
      "        [0.9289],\n",
      "        ...,\n",
      "        [0.5385],\n",
      "        [0.5385],\n",
      "        [0.5385]], device='cuda:0')\n",
      "Accuracy: 40.2084%\n",
      "tensor([[35.6363],\n",
      "        [40.4104],\n",
      "        [31.6950],\n",
      "        ...,\n",
      "        [ 0.9692],\n",
      "        [ 1.0891],\n",
      "        [ 1.0799]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[81.0337],\n",
      "        [81.0337],\n",
      "        [81.0337],\n",
      "        ...,\n",
      "        [ 0.7141],\n",
      "        [ 0.7141],\n",
      "        [ 0.7141]], device='cuda:0')\n",
      "Accuracy: 39.1416%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "#     print(batch)\n",
    "    data = batch.to(device)\n",
    "    node_pred = model(data)\n",
    "#     edge_pred = torch.sigmoid(edge_pred)\n",
    "#     print(edge_pred, data.y_edges, node_pred, data.y_params)\n",
    "    print(node_pred, data.y_params)\n",
    "#     edge_correct = ((edge_pred > 0.5) == (data.y_edges > 0.5)).sum().item()\n",
    "    correct = (((node_pred - data.y_params)/data.y_params)**2 < 0.1**2).sum().item()\n",
    "    acc = correct / (len(node_pred))*100\n",
    "#     edge_acc = edge_correct / len(edge_pred)*100\n",
    "#     print('Accuracy: {:.4f}%'.format(acc), ', edge accuracy: {:.4f}%'.format(edge_acc))\n",
    "    print('Accuracy: {:.4f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.484405994415283 13.484405994415283\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()\n",
    "print(torch.cuda.memory_allocated(0)/1024**3, torch.cuda.max_memory_allocated(0)/1024**3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Weights & Bias to Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=19, out_features=16, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retry attempt failed:\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 169, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576271582&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=MmIGu%2F4ONY2zZtXV60r4n2VtQ%2F7%2BfOmVBHMam3wT3aKVoHGK84OediGBAASfRnCU%2ByxJnJoe6wgqBm8OA4RFnwbWS%2BT1gP1VBHVekU3e0%2FBjKnK8lLsunIwyrwC9DhNkHSaiPTduRingNiJZ1K096%2BHtW8DSs%2BVkivZt%2FHH4Sh24d1JcpFjjkb8GUWGOc2XuFhCKq%2FQ6v7cIiQPmaCfZ7tIsPYZNaEJ5WnLcgsMIcUFlMpayxtmovih59VHK9%2Bu7pLnnEIleq%2FVVwSp1Nxn3Cuvyf%2FefL9nIOD9RrfbYHqTIWZB2cEMVI4XuNkEPrYUuV5aNadYZ%2BXP1VYzyt%2BGgVQ%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
      "    url, data=progress, headers=extra_headers)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
      "    return request('put', url, data=data, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576271582&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=MmIGu%2F4ONY2zZtXV60r4n2VtQ%2F7%2BfOmVBHMam3wT3aKVoHGK84OediGBAASfRnCU%2ByxJnJoe6wgqBm8OA4RFnwbWS%2BT1gP1VBHVekU3e0%2FBjKnK8lLsunIwyrwC9DhNkHSaiPTduRingNiJZ1K096%2BHtW8DSs%2BVkivZt%2FHH4Sh24d1JcpFjjkb8GUWGOc2XuFhCKq%2FQ6v7cIiQPmaCfZ7tIsPYZNaEJ5WnLcgsMIcUFlMpayxtmovih59VHK9%2Bu7pLnnEIleq%2FVVwSp1Nxn3Cuvyf%2FefL9nIOD9RrfbYHqTIWZB2cEMVI4XuNkEPrYUuV5aNadYZ%2BXP1VYzyt%2BGgVQ%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 980, in upload_file\n",
      "    util.sentry_reraise(retry.TransientException(exc=e))\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/util.py\", line 92, in sentry_reraise\n",
      "    six.reraise(type(exc), exc, sys.exc_info()[2])\n",
      "  File \"/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/six.py\", line 692, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
      "    url, data=progress, headers=extra_headers)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
      "    return request('put', url, data=data, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "wandb.retry.TransientException: None\n",
      "wandb: Network error (TransientException), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n",
      "wandb: ERROR Error uploading \"wandb-metadata.json\": CommError, None\n"
     ]
    }
   ],
   "source": [
    "model.output_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-v1.2.0-gpu [conda env:root] *",
   "language": "python",
   "name": "conda-root-pytorch-v1.2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
