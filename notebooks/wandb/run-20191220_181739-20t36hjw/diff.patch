diff --git a/notebooks/.ipynb_checkpoints/ToyModelTrackML-checkpoint.ipynb b/notebooks/.ipynb_checkpoints/ToyModelTrackML-checkpoint.ipynb
index c1ebb79..396f68c 100644
--- a/notebooks/.ipynb_checkpoints/ToyModelTrackML-checkpoint.ipynb
+++ b/notebooks/.ipynb_checkpoints/ToyModelTrackML-checkpoint.ipynb
@@ -11,7 +11,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 17,
+   "execution_count": 3,
    "metadata": {
     "cell_style": "center",
     "code_folding": []
@@ -33,28 +33,31 @@
     "import matplotlib.colors\n",
     "import numpy as np\n",
     "import torch\n",
+    "import torch.multiprocessing as mp\n",
+    "import torch.nn as nn\n",
+    "# mp.set_start_method(\"forkserver\", force=True)\n",
     "from torch_geometric.data import Data\n",
     "from torch_geometric.data import DataLoader\n",
     "import seaborn as sns\n",
     "import wandb\n",
     "# os.environ['WANDB_MODE'] = 'dryrun'\n",
-    "from numba import jit, njit, prange, float32\n",
     "\n",
     "import ipywidgets as widgets\n",
     "from ipywidgets import interact, interact_manual\n",
     "\n",
     "# Limit CPU usage on Jupyter\n",
-    "os.environ['OMP_NUM_THREADS'] = '4'\n",
+    "os.environ['OMP_NUM_THREADS'] = '1'\n",
     "\n",
     "# Local imports\n",
-    "from utils.toy_utils import *\n",
-    "from datasets.hitgraphs_params import *\n",
+    "from utils.toy_utils import load_data, make_mlp\n",
     "%matplotlib inline"
    ]
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "## Loading TrackML Dataset"
    ]
@@ -62,7 +65,9 @@
   {
    "cell_type": "code",
    "execution_count": 6,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -79,8 +84,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 20,
-   "metadata": {},
+   "execution_count": 2,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "input_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/\"\n",
@@ -90,8 +97,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 21,
-   "metadata": {},
+   "execution_count": 3,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "full_graphs = [load_graph(fi) for fi in filenames]"
@@ -100,7 +109,9 @@
   {
    "cell_type": "code",
    "execution_count": 5,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "cut_mask = [~(np.isnan(g[3]).any()) for g in full_graphs]\n",
@@ -109,8 +120,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 22,
-   "metadata": {},
+   "execution_count": 4,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "cut_full_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),\n",
@@ -118,6 +131,15 @@
     "                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in full_graphs]"
    ]
   },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "metadata": {
+    "hidden": true
+   },
+   "outputs": [],
+   "source": []
+  },
   {
    "cell_type": "markdown",
    "metadata": {
@@ -1441,19 +1463,15 @@
     "## Combined Edge & Track Param Classifier"
    ]
   },
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "How to do a double scatter..."
-   ]
-  },
   {
    "cell_type": "code",
-   "execution_count": 26,
+   "execution_count": 4,
    "metadata": {
     "code_folding": [
-     52
+     0,
+     26,
+     52,
+     97
     ]
    },
    "outputs": [],
@@ -1599,37 +1617,43 @@
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "#### Generate data"
    ]
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "#### Load data"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 37,
-   "metadata": {},
+   "execution_count": 3,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
-    "train_size = int(0.5 * len(cut_full_dataset))\n",
-    "test_size = int(0.1 * len(cut_full_dataset))\n",
-    "train_dataset = cut_full_dataset[:train_size]\n",
-    "test_dataset = cut_full_dataset[-test_size:]\n",
-    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
+    "train_size, test_size = 300, 50\n",
+    "train_dataset, test_dataset = load_data(train_size, test_size)\n",
+    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
     "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
     "t_configs = {'train_size': train_size, 'test_size': test_size}"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 28,
-   "metadata": {},
+   "execution_count": 4,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -1643,7 +1667,8 @@
     "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
     "print(\"Using \", device)\n",
     "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
-    "m_configs = {'input_dim': 3, 'hidden_dim': 16, 'n_graph_iters': 3, 'output_dim': 1}\n",
+    "m_configs = {'hidden_dim': 16, 'n_graph_iters': 3}\n",
+    "m_configs = {'input_dim': 3, **m_configs, 'output_dim': 1}\n",
     "model = Edge_Track_Truth_Net(**m_configs).to(device)\n",
     "# data = dataset[0].to(device)\n",
     "o_configs = {'lr': 0.001, 'weight_decay': 1e-4}\n",
@@ -1664,16 +1689,19 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 29,
-   "metadata": {},
+   "execution_count": 9,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "data": {
       "text/html": [
        "\n",
-       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
-       "            Call wandb.login() to authenticate this machine.<br/>\n",
-       "        "
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression/runs/fwpw76ra\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression/runs/fwpw76ra</a><br/>\n",
+       "            "
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -1686,6 +1714,7 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
+      "wandb: Network error resolved after 0:00:23.785435, resuming normal operation.\n",
       "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
       "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
      ]
@@ -1693,12 +1722,22 @@
     {
      "data": {
       "text/plain": [
-       "[<wandb.wandb_torch.TorchGraph at 0x2aab86bb2710>]"
+       "[<wandb.wandb_torch.TorchGraph at 0x2aab57ea34a8>]"
       ]
      },
-     "execution_count": 29,
+     "execution_count": 9,
      "metadata": {},
      "output_type": "execute_result"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:11.332204, resuming normal operation.\n",
+      "wandb: Network error resolved after 0:00:23.334204, resuming normal operation.\n",
+      "wandb: Network error resolved after 0:00:37.807275, resuming normal operation.\n",
+      "wandb: Network error resolved after 0:00:38.484777, resuming normal operation.\n"
+     ]
     }
    ],
    "source": [
@@ -1707,158 +1746,442 @@
     "wandb.watch(model, log='all')"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "metadata": {
+    "heading_collapsed": true
+   },
+   "source": [
+    "### Training and Validation"
+   ]
+  },
   {
    "cell_type": "code",
-   "execution_count": 16,
-   "metadata": {},
+   "execution_count": 10,
+   "metadata": {
+    "code_folding": [],
+    "hidden": true
+   },
    "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Network error resolved after 0:00:11.345432, resuming normal operation.\n",
+      "Failed to connect to W&B servers after 10 seconds.                    Letting user process proceed while attempting to reconnect.\n"
+     ]
+    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Traceback (most recent call last):\r\n",
-      "  File \"/global/homes/d/danieltm/.local/bin/wandb\", line 6, in <module>\r\n",
-      "    from wandb.cli import cli\r\n",
-      "ModuleNotFoundError: No module named 'wandb'\r\n"
+      "Epoch:  1 , loss:  0.6007898449897766 , node accuracy:  10.242046834801204 %, lr:  [0.001]\n"
      ]
-    }
-   ],
-   "source": [
-    "!wandb"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 47,
-   "metadata": {},
-   "outputs": [
+    },
     {
-     "data": {
-      "text/plain": [
-       "[<matplotlib.lines.Line2D at 0x2aab7fcdaf60>]"
-      ]
-     },
-     "execution_count": 47,
-     "metadata": {},
-     "output_type": "execute_result"
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "Retry attempt failed:\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
+      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
+      "    raise err\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
+      "    sock.connect(sa)\n",
+      "socket.timeout: timed out\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
+      "    chunked=chunked,\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
+      "    self._validate_conn(conn)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
+      "    conn.connect()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
+      "    conn = self._new_conn()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 164, in _new_conn\n",
+      "    % (self.host, self.timeout),\n",
+      "urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fab8d0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)')\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
+      "    timeout=timeout\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
+      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
+      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
+      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fab8d0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
+      "    result = self._call_fn(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 103, in execute\n",
+      "    return self.client.execute(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 50, in execute\n",
+      "    result = self._get_result(document, *args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 58, in _get_result\n",
+      "    return self.transport.execute(document, *args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/transport/requests.py\", line 37, in execute\n",
+      "    request = requests.post(self.url, **post_args)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 116, in post\n",
+      "    return request('post', url, data=data, json=json, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 504, in send\n",
+      "    raise ConnectTimeout(e, request=request)\n",
+      "requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fab8d0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
+      "wandb: Network error (ConnectTimeout), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n"
+     ]
     },
     {
-     "data": {
-      "image/png": "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\n",
-      "text/plain": [
-       "<Figure size 1152x288 with 2 Axes>"
-      ]
-     },
-     "metadata": {
-      "needs_background": "light"
-     },
-     "output_type": "display_data"
-    }
-   ],
-   "source": [
-    "fig, axs = plt.subplots(1,2)\n",
-    "fig.set_size_inches(16,4)\n",
-    "axs[0].plot(np.arange(len(loss_v_node)), loss_v_node)\n",
-    "# axs[1].plot(np.arange(len(loss_v_edge)), loss_v_edge)\n",
-    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
-    "# axs[3].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 39,
-   "metadata": {},
-   "outputs": [
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  2 , loss:  0.817642867565155 , node accuracy:  10.806555227684166 %, lr:  [0.001]\n",
+      "Epoch:  3 , loss:  0.9038619995117188 , node accuracy:  11.966084468880512 %, lr:  [0.001]\n",
+      "Epoch:  4 , loss:  2.6982123851776123 , node accuracy:  12.011629412664599 %, lr:  [0.001]\n",
+      "Epoch:  5 , loss:  2.588160753250122 , node accuracy:  11.906975326302884 %, lr:  [0.001]\n",
+      "Epoch:  6 , loss:  1.5540924072265625 , node accuracy:  11.722250515928984 %, lr:  [0.001]\n"
+     ]
+    },
     {
-     "data": {
-      "text/html": [
-       "<iframe src=\"https://app.wandb.ai/murnanedaniel/node_regression/runs/xrckpu24?jupyter=true&state=paused\" style=\"border:none;width:100%;height:420px\">\n",
-       "                </iframe>"
-      ],
-      "text/plain": [
-       "<wandb.jupyter.Run at 0x2aab86b7af60>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:58.266933, resuming normal operation.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  7 , loss:  8.183475494384766 , node accuracy:  11.767347980989985 %, lr:  [0.001]\n",
+      "Epoch:  8 , loss:  1.7046161890029907 , node accuracy:  11.827561836665232 %, lr:  [0.001]\n"
+     ]
     },
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
-      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
+      "wandb: Network error resolved after 0:00:11.470606, resuming normal operation.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  9 , loss:  0.42751920223236084 , node accuracy:  11.777570073070478 %, lr:  [0.001]\n",
+      "Epoch:  10 , loss:  2.032323122024536 , node accuracy:  11.7880718393529 %, lr:  [0.001]\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: ERROR Error uploading \"config.yaml\": CommError, <Response [400]>\n",
+      "Retry attempt failed:\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
+      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
+      "    raise err\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
+      "    sock.connect(sa)\n",
+      "socket.timeout: timed out\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
+      "    chunked=chunked,\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
+      "    self._validate_conn(conn)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
+      "    conn.connect()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
+      "    conn = self._new_conn()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 164, in _new_conn\n",
+      "    % (self.host, self.timeout),\n",
+      "urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57f7def0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)')\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
+      "    timeout=timeout\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
+      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
+      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
+      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57f7def0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
+      "    result = self._call_fn(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 103, in execute\n",
+      "    return self.client.execute(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 50, in execute\n",
+      "    result = self._get_result(document, *args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/client.py\", line 58, in _get_result\n",
+      "    return self.transport.execute(document, *args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/gql/transport/requests.py\", line 37, in execute\n",
+      "    request = requests.post(self.url, **post_args)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 116, in post\n",
+      "    return request('post', url, data=data, json=json, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 504, in send\n",
+      "    raise ConnectTimeout(e, request=request)\n",
+      "requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57f7def0>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))\n",
+      "wandb: Network error (ConnectTimeout), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  11 , loss:  0.9068647623062134 , node accuracy:  11.77572422333775 %, lr:  [0.001]\n",
+      "Epoch:  12 , loss:  3.974558115005493 , node accuracy:  11.754566869961844 %, lr:  [0.001]\n",
+      "Epoch:  13 , loss:  0.7298269271850586 , node accuracy:  11.784953472001396 %, lr:  [0.001]\n",
+      "Epoch:  14 , loss:  0.7682395577430725 , node accuracy:  11.689500666883134 %, lr:  [0.001]\n",
+      "Epoch:  15 , loss:  5.155138969421387 , node accuracy:  11.852173166434957 %, lr:  [0.001]\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:56.379144, resuming normal operation.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  16 , loss:  2.4475228786468506 , node accuracy:  11.88984528143475 %, lr:  [0.001]\n",
+      "Epoch:  17 , loss:  8.945351600646973 , node accuracy:  11.948003531725822 %, lr:  [0.001]\n",
+      "Epoch:  18 , loss:  0.800361692905426 , node accuracy:  11.82655500953829 %, lr:  [0.001]\n",
+      "Epoch:  19 , loss:  4.170938968658447 , node accuracy:  12.117542032934994 %, lr:  [0.001]\n",
+      "Epoch:  20 , loss:  13.88068675994873 , node accuracy:  11.96797226974353 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  21 , loss:  9.681962013244629 , node accuracy:  12.113640577818089 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  22 , loss:  4.359136581420898 , node accuracy:  12.098664024304808 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  23 , loss:  0.9145486354827881 , node accuracy:  12.054405581849592 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  24 , loss:  1.0942814350128174 , node accuracy:  12.114088056541174 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  25 , loss:  1.8272830247879028 , node accuracy:  12.160220316149312 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  26 , loss:  1.0419292449951172 , node accuracy:  12.065564582506546 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  27 , loss:  1.8605482578277588 , node accuracy:  12.224559366303007 %, lr:  [0.0009000000000000001]\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: ERROR Error uploading \"diff.patch\": CommError, <Response [400]>\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  28 , loss:  1.0357260704040527 , node accuracy:  12.188509361674399 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  29 , loss:  5.578948974609375 , node accuracy:  12.176371501310692 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  30 , loss:  7.798847675323486 , node accuracy:  12.258595716677728 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  31 , loss:  6.776310920715332 , node accuracy:  12.162583563155609 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  32 , loss:  0.6156641840934753 , node accuracy:  12.182356529231967 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  33 , loss:  0.6728848814964294 , node accuracy:  12.12583437302218 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  34 , loss:  3.6187450885772705 , node accuracy:  12.225244568097732 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  35 , loss:  3.693549633026123 , node accuracy:  12.218280680469707 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  36 , loss:  2.0439088344573975 , node accuracy:  12.09069330954984 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  37 , loss:  2.4835045337677 , node accuracy:  12.212533375620072 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  38 , loss:  0.6139274835586548 , node accuracy:  12.270803495591915 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  39 , loss:  1.7037460803985596 , node accuracy:  12.20246510435064 %, lr:  [0.0009000000000000001]\n",
+      "Epoch:  40 , loss:  2.4318125247955322 , node accuracy:  12.192159110009568 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  41 , loss:  0.7220551371574402 , node accuracy:  12.29498133034865 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  42 , loss:  1.5551996231079102 , node accuracy:  12.163674292543131 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  43 , loss:  1.789021372795105 , node accuracy:  12.291037924101456 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  44 , loss:  1.3258136510849 , node accuracy:  12.261140751915278 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  45 , loss:  9.340996742248535 , node accuracy:  12.195263493650977 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  46 , loss:  1.5705657005310059 , node accuracy:  12.157493492680507 %, lr:  [0.0008100000000000001]\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "Retry attempt failed:\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
+      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
+      "    raise err\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
+      "    sock.connect(sa)\n",
+      "OSError: [Errno 101] Network is unreachable\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
+      "    chunked=chunked,\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
+      "    self._validate_conn(conn)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
+      "    conn.connect()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
+      "    conn = self._new_conn()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 169, in _new_conn\n",
+      "    self, \"Failed to establish a new connection: %s\" % e\n",
+      "urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9dd8>: Failed to establish a new connection: [Errno 101] Network is unreachable\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
+      "    timeout=timeout\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
+      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
+      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
+      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576270804&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=hOWZqur9%2FE%2B63Tc6ZLj%2BSd3y2tX%2BgKVvtLWi%2F%2FMYrPOhGJNdbcjIzm2AycX83SiOXjK8%2FnFTHL06nfSMiGX138tS3JjMTVQXFJSfQ34KfGCe%2FDmN2hRZOv6RI46nJ7oC4bW4XuPL6r7%2F%2Fi3ifrnD6Bsn7ieg5wEntYKQuFmCSVGENS78lGvvF6OA4btweX2muj2fY83GxbrFx7QKltvImU4pWsYeYU4RMMqOoggZUQ9QpWWPXEWcwjAGZZrLnjghaX5hrWRAmAPsDApbsQpN7Xm7immu7hxXIJUq18t98MGmdiXGz9eIhQiEd3Mwk3RogxGGkN9eE52xf1WIcagLtA%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9dd8>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
+      "    url, data=progress, headers=extra_headers)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
+      "    return request('put', url, data=data, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
+      "    raise ConnectionError(e, request=request)\n",
+      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576270804&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=hOWZqur9%2FE%2B63Tc6ZLj%2BSd3y2tX%2BgKVvtLWi%2F%2FMYrPOhGJNdbcjIzm2AycX83SiOXjK8%2FnFTHL06nfSMiGX138tS3JjMTVQXFJSfQ34KfGCe%2FDmN2hRZOv6RI46nJ7oC4bW4XuPL6r7%2F%2Fi3ifrnD6Bsn7ieg5wEntYKQuFmCSVGENS78lGvvF6OA4btweX2muj2fY83GxbrFx7QKltvImU4pWsYeYU4RMMqOoggZUQ9QpWWPXEWcwjAGZZrLnjghaX5hrWRAmAPsDApbsQpN7Xm7immu7hxXIJUq18t98MGmdiXGz9eIhQiEd3Mwk3RogxGGkN9eE52xf1WIcagLtA%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9dd8>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
+      "    result = self._call_fn(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 980, in upload_file\n",
+      "    util.sentry_reraise(retry.TransientException(exc=e))\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/util.py\", line 92, in sentry_reraise\n",
+      "    six.reraise(type(exc), exc, sys.exc_info()[2])\n",
+      "  File \"/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/six.py\", line 692, in reraise\n",
+      "    raise value.with_traceback(tb)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
+      "    url, data=progress, headers=extra_headers)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
+      "    return request('put', url, data=data, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
+      "    raise ConnectionError(e, request=request)\n",
+      "wandb.retry.TransientException: None\n",
+      "wandb: Network error (TransientException), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n",
+      "wandb: ERROR Error uploading \"wandb-metadata.json\": CommError, <Response [400]>\n"
      ]
     },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Epoch:  51 , loss:  1.0130443572998047 , node accuracy:  17.62983665068888 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  52 , loss:  1.304320216178894 , node accuracy:  17.497257095264583 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  53 , loss:  0.2536078691482544 , node accuracy:  17.806618713728003 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  54 , loss:  0.5005673766136169 , node accuracy:  16.359346669877326 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  55 , loss:  0.7102632522583008 , node accuracy:  18.416588148134476 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  56 , loss:  0.44991207122802734 , node accuracy:  19.216805958402936 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  57 , loss:  1.6711790561676025 , node accuracy:  19.13799376829943 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  58 , loss:  1.8175777196884155 , node accuracy:  16.412596637924548 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  59 , loss:  0.5086053609848022 , node accuracy:  20.52232513300606 %, lr:  [0.0008100000000000001]\n",
-      "Epoch:  60 , loss:  1.4643304347991943 , node accuracy:  16.340916139970226 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  61 , loss:  10.858916282653809 , node accuracy:  20.98266886938068 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  62 , loss:  1.1947903633117676 , node accuracy:  22.18321233228987 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  63 , loss:  0.5516257882118225 , node accuracy:  22.195671817985794 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  64 , loss:  0.5449832081794739 , node accuracy:  22.43950577093732 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  65 , loss:  4.906266689300537 , node accuracy:  22.502824010253974 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  66 , loss:  0.8653304576873779 , node accuracy:  22.80020158916475 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  67 , loss:  3.713456630706787 , node accuracy:  24.615790573245416 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  68 , loss:  0.15667743980884552 , node accuracy:  25.90436149121166 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  69 , loss:  0.8753616809844971 , node accuracy:  27.252992444042086 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  70 , loss:  0.30628612637519836 , node accuracy:  27.26599729443177 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  71 , loss:  1.2008047103881836 , node accuracy:  29.070189554783845 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  72 , loss:  8.908965110778809 , node accuracy:  27.333216988865335 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  73 , loss:  0.3511810600757599 , node accuracy:  27.442555618109353 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  74 , loss:  30.64867401123047 , node accuracy:  30.093783150132747 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  75 , loss:  0.4458775222301483 , node accuracy:  19.537983811897845 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  76 , loss:  0.2321305274963379 , node accuracy:  27.016318150659934 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  77 , loss:  1.303676962852478 , node accuracy:  25.187612446508812 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  78 , loss:  0.2609845995903015 , node accuracy:  17.050953003826784 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  79 , loss:  0.5831493139266968 , node accuracy:  25.560823685272556 %, lr:  [0.0007290000000000002]\n",
-      "Epoch:  80 , loss:  0.5291023254394531 , node accuracy:  29.28110585416836 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  81 , loss:  0.693770706653595 , node accuracy:  29.831980129707304 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  82 , loss:  3.381126880645752 , node accuracy:  30.931029824736566 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  83 , loss:  1.255566120147705 , node accuracy:  28.218665512171558 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  84 , loss:  3.4112496376037598 , node accuracy:  31.34714308607617 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  85 , loss:  0.9732820391654968 , node accuracy:  27.529170718446665 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  86 , loss:  0.8045064806938171 , node accuracy:  28.596603244947893 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  87 , loss:  2.2349295616149902 , node accuracy:  33.107188773653796 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  88 , loss:  0.44516462087631226 , node accuracy:  32.64589414499262 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  89 , loss:  0.9409404993057251 , node accuracy:  34.64910256743714 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  90 , loss:  0.8439923524856567 , node accuracy:  30.35480308279279 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  91 , loss:  0.6240589618682861 , node accuracy:  32.98351684156093 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  92 , loss:  1.0759775638580322 , node accuracy:  32.821641413484606 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  93 , loss:  0.2878401577472687 , node accuracy:  33.36514627380272 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  94 , loss:  0.7029196619987488 , node accuracy:  30.96589121400698 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  95 , loss:  0.1989344358444214 , node accuracy:  32.94222294564616 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  96 , loss:  0.2367507964372635 , node accuracy:  28.472176192509824 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  97 , loss:  2.6421658992767334 , node accuracy:  33.324537579682676 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  98 , loss:  3.5272955894470215 , node accuracy:  31.251816134348775 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  99 , loss:  19.012252807617188 , node accuracy:  31.749006946827503 %, lr:  [0.0006561000000000001]\n",
-      "Epoch:  100 , loss:  1.5425626039505005 , node accuracy:  34.279778800080216 %, lr:  [0.00059049]\n"
+      "Epoch:  47 , loss:  1.369815468788147 , node accuracy:  12.232641950738746 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  48 , loss:  29.94580841064453 , node accuracy:  12.380771391790276 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  49 , loss:  18.640899658203125 , node accuracy:  14.612893148513434 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  50 , loss:  2.596501350402832 , node accuracy:  10.714682252350592 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  51 , loss:  2.0275228023529053 , node accuracy:  11.03620969859791 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  52 , loss:  3.6572177410125732 , node accuracy:  11.914134985872257 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  53 , loss:  0.4805273115634918 , node accuracy:  12.153172526260708 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  54 , loss:  3.2910521030426025 , node accuracy:  12.409647753139414 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  55 , loss:  1.5877015590667725 , node accuracy:  13.966789807217776 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  56 , loss:  0.7358959913253784 , node accuracy:  14.979811717733776 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  57 , loss:  1.8266561031341553 , node accuracy:  10.73860838032559 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  58 , loss:  0.43270111083984375 , node accuracy:  11.64315865162355 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  59 , loss:  1.9536621570587158 , node accuracy:  15.584453358593509 %, lr:  [0.0008100000000000001]\n",
+      "Epoch:  60 , loss:  2.093195915222168 , node accuracy:  10.692825713469865 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  61 , loss:  0.814365565776825 , node accuracy:  11.901745418726817 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  62 , loss:  31.9005126953125 , node accuracy:  18.31162642015064 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  63 , loss:  0.4563229978084564 , node accuracy:  19.494844066250344 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  64 , loss:  0.7945733070373535 , node accuracy:  15.855052132669611 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  65 , loss:  1.1281858682632446 , node accuracy:  14.559545294495535 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  66 , loss:  0.7465262413024902 , node accuracy:  13.159398353669843 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  67 , loss:  2.0372366905212402 , node accuracy:  11.426355210288431 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  68 , loss:  8.939661979675293 , node accuracy:  13.123586072112875 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  69 , loss:  0.4237460196018219 , node accuracy:  12.844974632151516 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  70 , loss:  0.5248408913612366 , node accuracy:  12.198731453754892 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  71 , loss:  0.8191898465156555 , node accuracy:  10.694475791261244 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  72 , loss:  0.9275200366973877 , node accuracy:  11.33827182039099 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  73 , loss:  1.2797634601593018 , node accuracy:  14.771706144078639 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  74 , loss:  10.561777114868164 , node accuracy:  16.505462456674973 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  75 , loss:  2.1823747158050537 , node accuracy:  22.458146056495867 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  76 , loss:  0.9706612229347229 , node accuracy:  21.41686306787497 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  77 , loss:  0.5489035844802856 , node accuracy:  24.637744998096817 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  78 , loss:  0.23864111304283142 , node accuracy:  21.300770306654375 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  79 , loss:  0.24089452624320984 , node accuracy:  26.019265637074056 %, lr:  [0.0007290000000000002]\n",
+      "Epoch:  80 , loss:  3.169557809829712 , node accuracy:  22.959755721365067 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  81 , loss:  25.155071258544922 , node accuracy:  11.18468873240185 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  82 , loss:  0.4444100260734558 , node accuracy:  18.682824004660493 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  83 , loss:  0.6307412385940552 , node accuracy:  23.607872716914613 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  84 , loss:  0.44871583580970764 , node accuracy:  26.412082037393 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  85 , loss:  2.9424526691436768 , node accuracy:  26.181966104046072 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  86 , loss:  0.749906063079834 , node accuracy:  25.233884543217915 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  87 , loss:  0.8655756115913391 , node accuracy:  27.588335795864683 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  88 , loss:  0.6294488310813904 , node accuracy:  29.389437656285438 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  89 , loss:  0.7006829977035522 , node accuracy:  30.015194699390786 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  90 , loss:  3.337183952331543 , node accuracy:  29.120223269508884 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  91 , loss:  1.1927621364593506 , node accuracy:  28.581990267897122 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  92 , loss:  0.8216007351875305 , node accuracy:  27.44835885779937 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  93 , loss:  1.9755046367645264 , node accuracy:  28.335289654375824 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  94 , loss:  0.5349218249320984 , node accuracy:  19.199410223042975 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  95 , loss:  7.208506107330322 , node accuracy:  19.29010856672845 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  96 , loss:  2.0792455673217773 , node accuracy:  25.51820133689862 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  97 , loss:  2.0596158504486084 , node accuracy:  12.411269863510599 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  98 , loss:  3.1164815425872803 , node accuracy:  22.995064589358563 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  99 , loss:  0.15878534317016602 , node accuracy:  26.6925113596669 %, lr:  [0.0006561000000000001]\n",
+      "Epoch:  100 , loss:  0.3312382102012634 , node accuracy:  27.46971198311663 %, lr:  [0.00059049]\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "[<matplotlib.lines.Line2D at 0x2aab56a34ba8>]"
+       "[<matplotlib.lines.Line2D at 0x2aab57fab198>]"
       ]
      },
-     "execution_count": 39,
+     "execution_count": 10,
      "metadata": {},
      "output_type": "execute_result"
     },
     {
      "data": {
-      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA54AAAD4CAYAAACEyjk9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdeXzcdbU//tc7M5nJnm7ZupG2tJS2LIWyK6iAFr0iXpeLXL2g3h9ylXvx4r1X1HtFES4KCl6+IotCQZRNQVlaKKW0dF/SNm2TpkmTNGm2yZ7MTGafef/+mPlMZl+S2fN6Ph59kPnMZ+bzbiYlc+ac9zlCSgkiIiIiIiKiZMlL9wKIiIiIiIgotzHwJCIiIiIioqRi4ElERERERERJxcCTiIiIiIiIkoqBJxERERERESWVOpUXmzdvnqytrU3lJYmIKIcdOnRoSEpZke51ZDP+biYiokQK97s5pYFnbW0t6urqUnlJIiLKYUKIznSvIdvxdzMRESVSuN/NLLUlIiIiIiKipGLgSUREREREREnFwJOIiCiDCCHWCyGahRCtQoh7Qtx/hxDiuBCiXgixSwixynO8Vghh9hyvF0I8mfrVExERhZbSPZ5EREQUnhBCBeBxANcD6AZwUAjxppTyhM9pL0opn/ScfyOARwCs99zXJqW8MJVrJiIiigUznkRERJnjUgCtUsp2KaUNwMsAPud7gpRS73OzGIBM4fqIiIimhIEnERFR5lgAoMvndrfnmB8hxHeEEG0AHgLwbz53LRFCHBFCfCiE+Gi4iwghbhdC1Akh6gYHBxO1diIiorAYeBIREWUOEeJYUEZTSvm4lHIZgO8D+G/P4T4Ai6WUawHcDeBFIURZqItIKZ+WUq6TUq6rqOAYVCIiSr6sDDz/dqQHRqsj3cvICmabE7pxS7qXQUREsekGsMjn9kIAvRHOfxnATQAgpbRKKYc9Xx8C0AZgRZLWSUREMRiZsOGN+p50LyMjRA08hRAFQogDQoijQohGIcRPPcefE0Kc9umel5JmBke7xvDdV+qx5t7N0I1bUN81hneO9/mds7WpH2Mmm9+xvW3DaNYZvLc7hycwYLBAN25B14gJAHBSp8eB0yNB1zRaHTipc2+p+bBlECZbcNC75UQ/jpwZ9Tu2vXkAR7vGAACDBite2OeepSqlxN+O9MDhdEFK6T0n0EmdHv16C1r6Dd41htM9asKuU0PYdnLA7/hXn9mPyx/cGvIxNocLrQOGkPdFIqXE83s6MJFBwf89rx3DvvZh7+3XD3f7fS/ebdChpd/9d33tUDeGjdaQz/NuQx+sDifqOkYwbLRiwurAjpbJMrQjZ0YhpTv50DpgwIA+dFA/braja8QEl4tbr4goLgcBLBdCLBFCaADcDOBN3xOEEMt9bn4GwCnP8QpPcyIIIZYCWA6gPSWrJiKikJ7ddRp3vVyPQUPo954zSSxdba0APiGlNAoh8gHsEkK847nvP6WUf0ne8oJN+AR93/7TIRw+4w7aOn7+GQDuTxW++XwdLl0yB69+6wrvuV/53T6/8655eLvf83b8/DNY/+udfucovvncQew/PYIPvncNbn32AD57wXz8v6+sBeAOwh7e3Izfbm8LeuxtGw56j33nxcM4cHoEVy2bi+M94/juK/XoHjWhqqwA//mXY3jyqxdh/Zoav+uu//VOqPMEHJ7gJXBdvj7yi23er9/796uxoqoUAHCoczTcQ3Dvmw146UAXDvzoWlSWFoQ9L9D25kHc+2YjTuoMePDvz4v5ccngcklYHS68fLALLx/s8n6P7n71KIDJ79kdfzwEANj1/Y/je38+iktr5+DVO67we6597cO444+H8fWrarFhdwdq5xZh1fwybDquw47//Dgae8fxL386jIe+cD6+fMkiXPfIDuQJoP3B4Nflgp++BwD49+tW4K7rJt8jnujVY2lFMR7begr5qjz8+/VMRhDRJCmlQwhxJ4DNAFQAnpVSNgoh7gNQJ6V8E8CdQojrANgBjAK41fPwqwHcJ4RwAHACuENKGfxpKhERpczBDvf/hvvGzago1aZ5NekVNfCU7vSO0XMz3/MnI9I4Jpsz6Jjd6QIAdAxNJOw6+z1ZUKW89/SQ0Xtf64DRG3RGMjrhzsA6XNL79aDBCoPF/Zwdw6Ezmo4pZMxClSE/vPkkPrGyEhefNcd7bH+7++9lsDhQWRr78yvf93GzLcqZyfeLzSfx1Iexf6Bvd7q/nwOG4EzlmMkOAOgZNQNwvyZatQoAYLI7vK9Rm8/rH+3l2dU66A08h41WfPqxnbjxgvl486i7co6BJxEFklJuArAp4NiPfb6+K8zjXgPwWnJXR0REsbI5XKj3VDbqxi04f2GaFxTGwY4RbDs5gDs+tgxlBflJu05MezyFECohRD2AAQBbpJT7PXc9IIQ4JoR4VAgRMoRPdee8IU8Jpd3pClkGaXU4vaWSiRAu8BjyKeU025zo9gQz07qWS/qVxm5vHghZgusMsajHt7XhC0/sjXoNvcWOCasDUkqcCQiGBwwWPLf7tN8xc4jgf9hoTVmJ6WuH/GvmDRa73+3An4FQZQ7DRmtCfybCUQL2w2fCZ6FnEovdice2noLN4Ur3UmKyrXkAt/xuX0J+tlv6DfjPPx8N+W+ViIiIckNj7zisnvc5ujDbszLBh82DeGpHOzSq5Lb/ienZpZROz0DqhQAuFUKsAfADACsBXAJgDtyd9UI9NmWd89462ovPPLYLADBqsuPS/93qzYAqzvnvd/HigTMRn+drz+zHFZ59kR//5fag+xt63Ps9H9nSgk/9ekfI51h3//ver2/bcABme3CABgBP7fDP1v3g9WOovWdjyHN/t7Md1z2yA8e6xzzPexDXPvJh0HlfejJ6gBnO+T95DxffvwUbdnfg6oe3oaFn3HvfpQ9sxU/eOoH2QXfGr/7MGM798buovWejN0jtHTPj4vvfx2+3t055DdNx54tH/G5f+r/++1u//JT7e6NkL7tGTLj4/vfx9I52b6b4vRP9Qc+7/tc7vR8mPPVhO37zwSnvfZ/w/IxIKbHiR+/ghb0dfo/ddLwPfwg4FsqZYRNq79mIPW1DUc9VSCmj7v/NVM/sOo1HtrTE9L3JBHe8cAh72oZhc04/UP6XPx7Cnw91e6snnC6JU/3x77cmIiKizKVseRMC6MvgZp9NfXosqyhGQb4qqdeJK6yVUo4B2A5gvZSyT7pZAWyAe+h1WoVqDBQqo7DxWF/QMV87Tw15fzhORyjZfWzrqbD3+dofYl3hvHSgK+x9SqreN3uajGyRxe5CXad7zZ0hSoCV8t9en39AH55yZ7OV79vWgCZHqdI6YIx+kg8laNvePBiy/NbXKZ/n/uV7Ld6v2z0/Iw6XhM3pwk/fOuH3uG//6TB+/EZj1LXsO+1ujvT64dg7nz2/pwMffWgbjnePRz/Zx6l+A7778hE4EhBETZXSpMsS5kOZTPHjNxrwl0PdcT9ue/MA9AEZ+HB+9V4zrn90B9oG4/v5JSIiosx1sGMEi+cUYX55IfozPPA8tybk9K2EiqWrbYUQYpbn60IA1wE4KYSo8RwTcLdyb0jmQim1Mq0EcHTClpJy2FTQm2MLRmJx0PNJWsdwfHua73q5Hn+r78VJXegsm8sl8dXf78f25vR8gJBJ/rC3E//x56NxPUY3bsFtGw7irpeORD8ZQJ3ndWTHOyIiotwgpcShzlGsO2s2qssLMjbjOWayoXfckhmBJ4AaANuEEMfgbvO+RUr5NoA/CSGOAzgOYB6A+5O3zNB83zT/7UjoLFGojF1diE6voQKtqWQffr8z9kY3x3vCZ6kCR8QAwDsNOgDuwOWHfz0e99qi8S3Z3Nw4WW761tFeb0MkIHTzIiWYeuVg5DLmqWjWGbD2Z1vw8sHw2WBFz1jse2n3tw97M7XOGILagxEy13UdI9h1KrhEtn0wOCDUW+IbQyOl9BsVk2ivH+7GRT/b4vdvwOJwYlfrEP7lj4eTdt1cppTWR6qYICIiotzVOWzCkNGGdbVzUF1ekLF7PJv63PFURgSeUspjUsq1UsrzpZRrpJT3eY5/Qkp5nufYV6WUaa0R++4r9SGP3/T47qBjocpTXz8cXEp37a+C909Gc//GppibjyijYEL5lz+Ff8P/f1tP4cX9UwvwXC6Jpz5sCzmD85bf7ws61jduxr++dMQ7jgRw780L9PDmZgDAq3XxlyRGo5TP7jzl35zK4XTFXMoYyj88vc/bETdUmXagcPt0AeCLT+7F1587GHR8eGL6nX9f2NeJm5/eh089Gno/8XT9+I1GjEzYQs6nJSIiIqL4KWNU1tXORk1ZAXTjloys3mvqc/euObcmjhEXUxTLHM+sFilYmMp5sRAiYU8V0nTKYN87ocOD75zEmRANaQwhMnFKI5VMLA/4r9eOZU1H1OlQsqbNCWg+Y3e6kJ/kjmUU2bHuMbSFyIQTERFR7jjUOYqyAjXOrihBdXkBzHYn9GYHyotiH1ficLowYrKhsrQgaets6tNjXokmqddQ8B3oDGOxuwO1UOWy2eavYcqrp0ogyZ8YpFnH0ASW/+idkNl9Sp0bfxNchUFERES5pa5zFOtq5yAvT6C63B3U9elj3xLmcLrwzefr8MlHd0wp6fTqwS78KIateU261DQWAhh4ZozcDnmyV7Kz133j05/vGislY6rsFc4U6ag6Odgxgg27g0vGc4XF7sTDm09mfMdgIiKiXGC2Of222o1O2NA6YMTFZ80GANQogWeMFYRSSvzkrUZ82DKIMZPdO8owHu+d6MdLB86E3F6ncDhdaOk3MvDMVRlY2k0JFs9LPJ2Zq76OdY9hyQ82oj/OjetdI6YpZb9fP9yNE736uB/nK50Z5i89uTdo7E0ueXb3aTy+rS3kfmwiIiJKrM//djdu/t0+b5CnzO9c5wk8q8sLASDkSBWTzRE03u6ZXafxx31n8MlVVQCAht74xuYBwKDRCpcEjnaH7ynTPjQBm8OVkv2dAAPPuORSKeaElZmQTDCQoPEZG3Z3QEpgd+sQnC4Zc4OrSE2sIrn71aP49GM7p/TYVDrRq8dAhnaRA5L3QZSy99k6A/ZAExERpZPLJXFqwIgDp0dw24YDMFodqOscRb5K4IJFswAAlaVaCBGc8XQ4Xbj6oe247H+34n/+1oCDHSPY3KjDA5uasH51NX5zy0XQqvPQ2BP8Yb/N4cKdLx5GQ5gpGYOe9z+HQ0zzUCiNhVZWpybjmfPNhWI10zKR7zf1Y16JJt3LmJLXDnXjimVz072MxJvCz2Coj0KW/XAT1i6ehb9++6ppLymRXC4Js92JYm3q/rfz6cd2QqPKQ8sDN6TsmplqQG+BzenCwtlF6V4KERFRzhiesMHpkrhmRQV2tQ7h1mcPwOpwYs2CchTkqwAA+ao8zCvRQhcQeHYMmzBktGJVTRn+fKgLL+zrBABcsLAcj/7DhdCo87CypixkxvNo9xjePtaHc6pKsWZBud99UkoMGt3JjUhTNE706ZGvElhWUTKt70GsGHjOYKOmqY8iSYS6jhFIAJfUzonpfCnde9e+9+ejWDSnMLmLS6NE5NWPRPifTDhfeGIP7E6Jbf/xsQSsINhP32rE83s70XL/DdCoU1dsYXOmPuu3yzP6pyPEHOGQUvDB16X/uxUA0PHzzyT/YkRERDOEss3pK5cuxs2XLMK/vnQEDpfE7Vcv9TuvJsQsz2adu//GQ188H7XzivH+iX7UdY7g365djkKNO2hdM78Mbx7thZQSwqf5iDKupd8QXNk1ZrLD7pRQ5wkcPjMa9FhFU58BZ1eWpux9WU6V2ia7EUymyIbk7JEzYxgyWvHqwS4c6gw9I/OLT+6NaY+j7+vq8qSmhwzTn48Z6TqZJFXrauk34vRQ8sZ8/OWQu5tuOgLBVJtqx+VYX+qnPmzD28d6p3SNRDjUOYLesdQ1xiIiIspUSuBZVabFDefV4De3rEVZgRrXe/ZnKqo8szx9Nev0yBPA2ZUlKNGqcdPaBbj/pvP8Rpusnl8Og8WBrhH/37t1He4SWt148LYtJdt5xbK57uZEYd7fNfXpU7a/E8ixwDObZWrQE08J8q5TQ363b9twAP/12jF84YnENNChxIj2mr504AwOdoTfD0Dp9+A7J3Hni0eSfp1dp4Zw1c8/COqO+4Un9uLqh7Yl/fpERESZrl/vDvKUkSnr19Tg6L2fDKroqykvCJpm0KQzYMm8Ym9JbihrFrj3Xzb6lNu6XBJ1noznQIiM54BnTZ9aXQ0g9D7PIaMVgwZ3mW+qMPBMg1Cp7lzw1Wf2+93uHcvcpi6hJPtVCfeyWx1O3PXyEXQnOYMU69/vB68fx63PHkjqWnxlQwY/WQYMVrxa15XuZYR1/8YT6Bkzh8yEO6YwU4yIiCjX6PQWCAHMK9F6j4V6r19dXgC9xQGTbXKaQLPOELWxz4qqUqjyhN8+z1MDRugtDhRrVEFZVAAYNLqPXbFsLsoK1Dh8JjjwVBoLpWqUCsA9nkkxlUZFqeqY2xnrnjOaMhnnD8COliG8Ue9fNimlxNvH+vDJ1VVhHpUaMolhYY5+/hKXrz93EDaHC0vnFad7KURERDQFA3oL5pVoka+KnM+rLnNnRHXjFiytKMGE1YEzIyZ88eKFER9XkK/C8soSNPqMsVP2d163qgpvHe2Fw+mC2uf6SsazqqwAaxfPxuHO4N4f6Qg8mfGcYZ7dPTnXz5nlGYuciFvCvAQ7Tw3hX186gn976UhMIzHieyUT+7qbbU7U3rMRz86QmZG/3daasOdSxp44Z1pbbSIiohyh01tQVaaNep5SiqtkKFv63Y2FVlZH32O5en45GnrGvcmNuo4RVJZqcUntHLgkMGT0730yaLCiMF+FYo0KFy2ejZYBA/QW/6aiTX0GVJVpMac4dVMuGHh6xJulykWRArlkZr4o2LjZ/T+HzY39eHH/majnKz+/kbKIySrxHjG5/2f3+53tSXn+cFoHjLCnoVHRYx8kLvBMOv5/jYiIKKn69VZU+TQDCqem3D2RQelsq3S0jWWG5poFZRgy2rzz3w92jOKS2jmTWdSAbrkDBisqy7QQQuCis2ZBSqA+YOKBu7FQ6rKdAANPQuT3ptOJVZIRzGfz++hkrD1X9wtHoxu34LpHPsR9b51I2TV9v9XvHO9L2XWnIlWl+0RERDPdgN6CqvLogacSJPZ5Mp4ndQYUaVRYODv6iMDV891zOht7x9EzZkbPmBnramejyvOc/QGB56DBigrPntMLF82CEPDb52l1ONE6YGTgSdFlS/CV6Dmhvn/vGRpvkceY2Z1lPXA69KieZHu3UZeW6xIREVHmsDqcGJ6wxZTxLNSoUF6Y7y21PanTY0VVKfLyor+pXTXfHSA29Oi93WwvqZ2DqnJ3cBkYeA4YLKj0lP+WFuTjnKpSHPLpbPuHPZ1wuCTOX1Aew98ycRh4xiERwQ5LVt3/SOMpy8yWQDsXhcqcdY2wQVUusTqc3r2mREREFLtBg9LEJ/oeT8A9UkWnt0BKiWadIeYZmiVaNZbOK0Zj7zjqOkZRolVjZXUp5hZrocoTQZ1tfTOeALB28WzUnxmDyyXxal0XHtjUhBvWVAfNGk02Bp7klar47snt7bh/Y1PM5z/6fgsABM0+ylXJyuYOeYYJ682OKGdGdtuG1I1ayVbpLoF2umIPJM+79z1cfP+WKV1n2Q83TelxREREuUCZ4RlLqS3g7jKrG7dg0GDFqMmOc6piCzwBd9azoUePgx0jWLt4FtSqPKjyBCpLtd51AIDF7oTe4kBl2eSaLj5rNgxWB36zrRX3vHYMH10+D7+++UK/TripwMAzK2V3CtBgia8Et3XACGDyU6VkSVSsEO7VCfX84TLg//rSkcQsxsdvt7ub4hzomF55qtE6vcA1UKiMttMlsel4X1L2CbsyuJtzIgJWm8PlbYA0EMO/GZvTBYMl8msa7mUI1RnbaHXAkYamT0RERIlitjnxiV9ux7aTAxHPU0pcYym1BdwZz75xC5o8jYXOiaGxkGLNgnL0jJnR3G/AJbVzvMerygr8Sm2V98u+Gc+LFs8CADyypQUXLpqFp752MbRqVczXTpScCjyn85Ytc9+KUq6LN7jSjVvQOTzh/xyJXFAIbx/rxd//dndCnzPSv9dndrXj2386jDeP9kY4yx24b28eCBlMXvng1pCPeeyDU/EsM+u80zDZ+GhkwhbhzMT7zouHsebezbjzxcR/cEJERJQqbYNGtA9NRP2w3ht4xlhqW11egCGjFQ094wBiG6WiWO3Z5yklsK52tvd4VZnWL/BUPnSu8FnTknnFqCzVYmV1KTbcdimKNOqYr5tIUQNPIUSBEOKAEOKoEKJRCPFTz/ElQoj9QohTQohXhBCpGwITRrhP93vHUlui2TZoDHufxe7CsDF4nfEkOgJn9YTbnxXvnM6xBDcDyhR7WodiOi9U/GexOxO8mum7/MGtuObh7SHvS1Y30ztfPILDZ4KHDyfL49vaAIT+WX+3oc/7WrX0G3HbhoN+82kVvQH7HRT72oenvb5onxWks9A2nXuiNx5zB71svkRERNmsfcj9AX/PaOQYol9vRb5KxDwLU+lsu6NlEJWlWsyOY4am0tlWnSdw4aJZfs+p88t4ur/2zXgKIfDX71yF1/7lSpQX5cd8zUSLJeNpBfAJKeUFAC4EsF4IcTmAXwB4VEq5HMAogG8mb5mxeach9JudK3/+QcKvVXvPxrD3Xf/ojrD33fT47rBzAKfatOX/+0NdyON3v1ofdCzeSr5Ma+zju5xYyxJv+f3+mM578sO2oGMdw/G/JuG+Z68d6on7uaZ7zUOdI/jK0/umPO/SbHfic7/ZFeXaif8hUeaYBnr0/Rbc8cfD2NEy6HecDY/cTg9N4LuvBP+7JyIiIn9Hu8bw+LbQ78lPD7oDz+7RyO8v+vUWVJYWxPyetNqzF/RQ5yhWxjnKZE6xBgtmFWL1/DK/jGVVeQEMFgdMNve2GaXUtjIgC7tgViGKtenJdCqiBp7STUnh5Xv+SACfAPAXz/HnAdyUlBVmECUtnixnpvjm+cOAN+GAu4b7jfrIZYq+/udvDRHv7xpJf2Mficnht8nIKCV6/EsgpUlSoKmGbeNme8Tvw4TVgf/48zHsbR8OCszi+QDiaLf/z324OHOq+xM/ONnvbXwUjfLJ41iYwBRw/71napfWo13+WekM+9yIiIgoY9z39gk8vLk55Ifdp4fcoU9PlKrJfr0l5jJbAKgpd8/sdLhkXGW2igf//jzce+Nqv2PK/lKlwdCAwYo8Acwtjn1dqRLTHk8hhEoIUQ9gAMAWAG0AxqSUSkeKbgALwjz2diFEnRCibnAwOEDKJve8fjzdS4jZY1vj28f2wr7OJK0kcfrGLfjqM7FlL2eCC376XsRM5ndePOx3O1FluNEa1rT0G/D53+7GRJgmRIEZ0qPd4/hqjFnpyecIf9/qezfjS0/uiev5kum//nI06jmRXpk9bUP42jP74y6d92W2xVcyrrfYvXPCiIiIck1Dz7h3rmXrgCHo/tOeUtsBgzXih9n9eos3ixmLap9Os/F0tFVcvaICFy2e7XdMub4yUmXQYMXcEveYlUwTU+AppXRKKS8EsBDApQDODXVamMc+LaVcJ6VcV1FRMfWVElEQu9P/n92AYbLG/7DPoOBUUD4V/MU7J3HkzBj2tvnvpYyUEe2cQklzoB0tg941BGZpw/ndDvc82UOdo3gqRKl1JOMmO96oj14+/Wpdd1zPG+jOF49g56khjJmCGwX95oNTMe1D/vpz8Y3Auf0Pdfjik3thzsA9zkRERNP1h70dUHsCs2adf28WKSXahyZQolVDysjj/Pr1VlTG2NEWAMoK1SjMd3eTPWcKGc9QlIyr8h5wIGCGZyaJq6utlHIMwHYAlwOYJYRQCoUXAoi9rpMohEOdo/jUozu82ZnO4QlsOt4X5VHk6383nQx7XyLGxUTa2xzNdPaCBo7S2d4c3N78n549gOsf+TCu531gk3ue7Bee2IMH3wn/vQvl31+tx10v10dsJharqZYp//K9Fjz1YXv45/X8d197fNnLhh49AMDhZLEuERHlltEJG96o78WX1i1EsUaFln7/jOfwhA0GiwOXL50LIHyDIaPVAaPVEVfGUwiBmvICqPIEzq4smfpfwkdVWXDGM3B/Z6aIpatthRBilufrQgDXAWgCsA3AFz2n3QrgjWQtMhUyrYnOTKIEJPdvPIHmfgNO9Lnf9F7/6A58+0+HIz2UspA3yIoh2BIA3jzai0seeB8HfUo/T+r8f0ko/3xNcZaUTofSLdtqd5fgfOO5g97APFEzYWORjKykMqtVySCHmzcbiZQSv9/ZDn2cc3vJTQixXgjRLIRoFULcE+L+O4QQx4UQ9UKIXUKIVT73/cDzuGYhxKdSu3Iiosz2al0XrA4Xbr2yFsurStEc8J5CKbP96PJ5AIDuMPs8B+IcpaJYMLsQyyqKUZCfmDmapQX5KNaofPZ4WrI641kDYJsQ4hiAgwC2SCnfBvB9AHcLIVoBzAXwTPKWSemSijfQ25tD7/2dKQ1iAj/0mG5pZqqd7AveGwEA7UOhM4Fr7t0c157DA6fdJbtfenJv2PDn9cOxdQze3KiLO/sXiu86Nh3vw5MftuGDKEOmY+FK0Sdgj29rxYOebG8sprKsXa1DuH9jE+59ozH+B89wQggVgMcB3ABgFYCv+AaWHi9KKc/zbIN5CMAjnseuAnAzgNUA1gP4ref5iIhmPKdL4oV9nbhsyRysrC7DOVWlQRlPpaPtVWfPhRDhM57KCJOqOEptAeDHf7cKj3z5wimsPryqsgL06y1wuSSGjLbszXhKKY9JKddKKc+XUq6RUt7nOd4upbxUSnm2lPJLUsrY2lLSjBcYzA4HDLl/v6kfjb3J7SA800gkb7bkP4cZ5xOp7NcQkAVzTjPgMoZpZBToWy8cmtZ1QvnNtlb8PM4y3UDKp6vh2roD7r9jfVfoWaqHOkfwz8/XxdSA6PTQBB7e3IyndoQv0U2E/+cZG9Uzag7ZuIEiuhRAq+f3rA3AywA+53uClFLvc7MYk5+HfA7Ay1JKq5TyNFFFfhMAACAASURBVIBWz/MREWWkxt5xfOrRHWFHqSXSBycH0D1qxm1X1gIAVlSXYnjC5tddv31oAvkqgdq5xags1YbtbDvgyTBWxVFqCwDLq0qxZkH51P4CYVR5ZnmOmGxwumRWZzwpBaa6xysXPbG9DZ95LPLsSH6/YqN8l9JZSu50yagNcGLNbidjZmgm2X86fDb2m8/X4abHd8PqCP5efvtPh/F+Uz8GA8bShPpn8vFfbo+4hliD+GgOeP4uBzpGcN0jO7C1qT8hzztDLADQ5XM7ZOd4IcR3hBBtcGc8/y2exxIRZYrtzYNo7jekZCb3H/Z2oKa8ANevqgIw2VnWN+t5esiIxXOKoFblYcGswugZz7L4As9kqCrTol9v8Znhmf41hcLAk7JWLoSe042josbfnvuve+RDdCSgc+xU3P6HOqz8n3fTcu3pqOsYweuHw5c9J/vDj20nB/D8ng7v7dYBd+lypJ+ZRMTla+7dPP0nCaGl373+hp5x/PCvx3P+Q4RpCvXDFfQNk1I+LqVcBvfWl/+O57G5NOqMiLKbsscy2X0ajnaNYeepIfzjZYuhVrlDoBVV7gY/LTrfwHMCS+a5jy+cXYTusdDvn/r1FhRrVCjRqkPen0pV5QUY0FvR7wmGK0ozM+OZ/u8UzRiDBit++lYjygrz/Y73RhnOS9lta4x7HzuGJlA7rzjJq4ndF5/c63c7UXNQY/X15w4CAOYUa6b8HJkY2/3TswcwMmHD965fgbkZWgqUAboBLPK5Ha1z/MsAnojnsVLKpwE8DQDr1q3LwJ8UIpoplMBzwpaYiptQ+vUWfOuFQ5hfXoB/vOws7/GKUi1mFeWj2fPhqNMl0TFswsfOqQTgbgS06XgfnC4ZNBdzQG+Nu8w2WarLCmBzunDK8/eozNDAkxlPD/7WTb5LHngfbx/rw4v7z/gdf2RLCzo8e9xmmlz8uYs10Ax0rCd4X69LSvxx35kQZ8eHewyTx7fbMCXMQQDLhRBLhBAauJsFvel7ghBiuc/NzwA45fn6TQA3CyG0QoglAJYDiG+QKxFRitgcLu9YsngaD8bDbHPin5+vg95ixzO3XYLZPh/oCiGwwqfBUO+YGTaHC0s8H4QvmFUIh0v6zUlX6PSWuBsLJYtS7nvc814qUzOeDDwpI+j0lozMzlB6HT4z6nd7qj8iE9bwv8x2tw7F/XyZVCaa7u7PXwrIDNP0SSkdAO4EsBnu8WWvSikbhRD3CSFu9Jx2pxCiUQhRD+BuuMeaQUrZCOBVACcAvAvgO1LK1M0ZIiKKw+mhCTg8jfGSUWrrcknc/Wo9GnrH8djNa3FuTVnQOedUlaJFZ4CU0tvszxt4zi4EELqzbb/eEvcolWTxDTxLtGoUaTKzqDUzV0U0o2ROEJNKsRSuulIQUz20uTmm8wLnZaZrj/G7DTq/28/uPp0xv/gocaSUmwBsCjj2Y5+v74rw2AcAPJC81RERJcZJ3WSDbnMSSm0ffb8F7zTo8N+fORfXeRoKBVpRXQqD1QGd3uINPJd6As+FszyB55gZ63weI6XMqFJb5X2Ae39q5mxbCsTAkyiNnC6JO/54OGnPn+4GTK4Yxnv4evnAmZR3h7Mk4RPWqe4HjSV7+d1X6qf03ERERJmmWWeAEO6eBBMJ/n1sd7rwxPY2fPaC+fjmR5aEPU/pbNusM+D00ASKNSpvqaqS8ewOyHiOmuywOV0ZU2pb6bOOTC2zBVhqO+OMmULNSMq+jFu6AyqKzYctk90yA3+h+N6nuOf1496mOqnS3B+8/7MhxH7TeBzI0X2P8X6QQEREM9PBjhE8sPFE1K0pzToDzq5wd5BNdKlt35gFDpfER5fPi9iJ3tvZtt+A9qEJLKko9p5fpFFjdlF+0CxPpXtsdYZkPDXqPMwrce9dZeBJUTGQoqnYciKzZyM6wgQqt244iPqusaiPD/w9sfFY35TXMmayxXzus7tPT/k6qRiAnQ67W4ew9IebcDSG142IiGa2DbtP43c7T6Mzyii3kzoDVtaUoTBflfBS2+5R97UXerKW4cwq0qCyVItmnRGnh4zeUSqKBbODZ3n2e2d4Zk6Qp2Q9M7WjLcDA0yvdzUKSPBKQZqhkz5qcqqY+ffSTEuzZ3R2puVAa/1cip3HxQ52Rs7QfeLoVs4stERFF4nJJ7G0bBgDsjNDAz2Cxo2fMjJXVpSjWqhJeaquUxy6aXRT13HOqS9HQM47uUXPQHsmFs4rCZjwrM6TUFpjMvjLjSRkt2QN7ibJNtFJbifg+LFr+o01pCbbjWWPbYHJHGklIWOz8fw0RUa47qTNg1LO1a/ep8IFni2fm5DlVpSjUqBI+TqV71IQ8EVs57IqqUjT3GyDlZGMhhZLx9E1S9eutAIDKDMp4Kj0yMikYDsTA0+P+jU3pXgJ048EzglLhxt/sDnvfoMGasnXEm6vJ0GQeJVDvWHD78lRQfhkmit0pg+bXpkKiCjmOdUcOxGvv2Yj1v94R8ZxfvdeClf/zLkxJHBBORETpt6fNHWx+dPk87GkbgjPMtptmnbvHwjnVpSjKVyf890P3qBk15YXIV0UPd5QGQwCCMp4LZhXCbHdiZGJyy07XiAlzijXQqlWJW/A0KWW/zHhSTL7356PpXkKQDQkqT6y9Z2NCnicWQ8bUBcvk78DpxJZhHo0S8MSKLXGm5/FtrXhmV+R9ryd1wU2afClvPCz29M4dJSKi5NrXPozauUX40rpF0FscOB6miqhZp0exRoUFswpRqFElvAKve9Ts7UobzYrqycCzNkTGE4C33NZodeDdBh2uOnteglaaGDXl3ONJlHIDegaeilQnhb/81N4UX5ESJkJ0Hri3hYiIKBSH04X97SO4Ytk8XLlsLgB3c7pQTuoMWFFdirw8gWJtMgJPU9TGQorlle6GQvNKNCgvzPe7b4Eyy9OzZ/S1Q90wWB34xlW1iVtsAtxwXg3u/ewqrPQJojMNA0/KOZ//bfjSYUotpblALmKpNxERkb+GXj0MVgeuXDYX80q0WFVThl0h9nlKKdHcb/AGSYX56oQGnjaHCzq9BQtjaCwEAMVaNRbNKUTt3OKg+xb6ZDxdLonn9nTgwkWzsHbx7IStNxHKCvLx9auWZGxjSQBQp3sBRED8e9EinW51sJQPAPQWByrL0ruG6YwloenL4N89Gf2LkYiIpkbZ33n5Une28yPL5+G53R0w25wo1EzuhxwwWDFmsnv3VhZpEjtORTdugUtGH6Xi6yefXY0iTXBoVF6Yj2KNCt2jZmxvGcDpoQn8380XJmytMwkznpSVjFY2KIlF60Bim+QEOtUfeV9fPJIdhjDMiexXW5rTPlaKiIiy2962YZxTVeptcPORs+fB5nThQMAorsnGQu5PyIsSvMezeyy2GZ6+rj23Cld4yoN9CSHcnW3HzNiwuwNVZVp8+ryahK11JmHgmSH4ppiy0Xsn+tO9hJgk/N9XhsZngXFjPHFkv96Kpr7EfZBAREQzi9XhxMGOEb/g7ZLaOdCo8oL2eSqBp1JqW6RJbKltPDM8Y7FwdhHqOkaw89QQ/umK2pg65VIwfteIiKZA5ODHRRtiKI0eSOGIJSIiyh71Z8Zgsbu8TYUAoFCjwrra2dgZsM/zpM6AylItZhdrACgZT0fCKm+6R80xz/CMxYJZhRg12aFV5+Erly5OyHPORFEDTyHEIiHENiFEkxCiUQhxl+f4T4QQPUKIes+fTyd/uZTTWOZHSfJKXVe6lwCZqWlSHyf69FHPeXpHewpWQkRE2WZP2zDyBHDZUv9y1avOnoemPr3fuLvmfj3O8em+WqhRwSUT16eje9QU8wzPWCgjVT6/dgHmeIJlil8sr4YDwPeklOcCuBzAd4QQqzz3PSqlvNDzZ1PSVkk5bypvynMx45QqYWY556wX959J9xKIiIhy2t62YaxZUB40juQjnnmXu04NoalPjxf2dqCl3+htLAS4M54AYE5QuW33qNk7BiURVs8vg0adh298ZEnCnnMmitrVVkrZB6DP87VBCNEEYEGyF0Yzi3MKkZDNOfO6137s4W0JeZ6mGDJblH3YKJaIiFJldMKGfoMFVrsLZrsTR7pGQwZmSjD63VfqvcdqygvwqTXV3tvFnm6yEzaHt/x2OnpGzbhsyZxpP4/iI2fPQ/2Prw/Z9ZZiF9d3TwhRC2AtgP0ArgJwpxDinwDUwZ0VHQ3xmNsB3A4AixezJppC+9ozB3DegvJ0LyPjdQyb0r2ErBVLUOZySeTlMXojIiKKxGJ34hO/2o5Rk93v+NXLK4LOVeUJfH/9SjT0juOS2tlYd9YcLJxd6DdWqzCBGU+704W+cXNcHW2jEUIw6EyAmL+DQogSAK8B+K6UUi+EeALAz+Du7/gzAL8C8I3Ax0kpnwbwNACsW7duhhX4UTwmOCJlRtt2ciDdS8B9b5/AT25cHfU8CZmy7OLIhC01F0JqM6Yc3UJElL22nRzAqMmO769fiRVVJdCo81BWkI/zF4ZOItxyWeTkk1JqG6qz7YDBgmKNGsXa2MKWyRmeieloS4kT045bIUQ+3EHnn6SUrwOAlLJfSumUUroA/A7ApclbZu6zO/kmjFs2Z7YjXWPpXgKe29OR7iVgxY/ewbsNfeleBhERUVhvHevFvBItbr96Ka49twofXV6BCxbN8stixqMwQuB5y+/246dvNcb8XF2j8c/wpNSI+tGBcP8EPQOgSUr5iM/xGs/+TwD4PICG5CxxZnhgU1O6l0BEMdp0XAdVkkpybU4XfvleS1KeOxo27CIiomiMVge2Ng3gK5cuTtjvQmWPp8kWXP3WN2bGhxY7pJQxBbbKDE9mPDNPLDnrqwB8DcBxIYSyK/iHAL4ihLgQ7lLbDgDfSsoKaeZg0peySLiGWK2DhhSvZBKrV4mIKNneP9EPq8OFz15Qk7DnDFdq63C6MGFzYsLmxOmhCSytKIn6XIme4UmJE0tX210IXQTJ8SlERAHMtuzttmxM4T7rqZZjERFRer15tBcLZhVi7aLZCXvOcM2FDJbJ30t724djDDxNqC4rgEadmBmelDh8RYhoRkh3GWkys5GJ+rux4Q8REUUyZrJhR8sg/u78moR2gS/yGafiS2+Z7Jq7t204pufqHjWzzDZDMfCkzMEEyIzGl5+IiCizvdugg8Ml8dkL5if0ecOV2urN7kC0vDAf+9pHYvqAtGc0saNUKHEYeBLRlA0arOleAk3D1qb+dC+BiIiyyFvHerFkXjFWzy9L6PNq1XnIE8GltkrG89qVlRgyWtE6YIz4PA6nCzq9hYFnhmLgSURTlsjxI7lS5Ckz7G9y6QPvh73vqR3tKVwJERFlswGDBXvbhvHZ82sSvk9fCIEijTpExtMdeH5ydTUA9z7PSPrGLXC6JEttMxQDTyLKCKeHJtK9hIwR769znd4S9r6BOLLSbPhDREThvHNcB5dEwstsFYUaVdA4FaW50Or5ZVgwqzDqPs/JUSrMeGYiBp6UOTIrUUSU9Rp6xtO9BCIiyhFv1PdgZXUplleVJuX5izWq4Iynp9S2vCgfly+di33tw3CFGWcGuDvaApzhmakYeBIRZZjAX7yxCmy60BchE0pERBSrzuEJHD4zhpvWLkjaNQrDlNoKAZRo1Lhi2VyMmuxo7g8/L5szPDMbA0/KHKzyoySKtYr0n58/mNyFxKBnzJyQ5+E/KSIiSoS/HumBEMDnLkxOmS3g7mxrtgeOU3GgVKtGXp7AFcvmAog8VqV71MwZnhmMrwoRkY/3mwaS8rzcPklERNlISom/HenBFUvnoqY8eXsnizQqTFiDM55lhfkAgAWzCrF4TlHEBkMDBgsqy5jtzFQMPImIEijciLEYRo8RERFlnPquMXQMm5JaZgt4Mp4h9niWFuR7b1+xdC72tw/DGWafp9HqQGmBOqnrpKlj4EkZo32QXU0p+wV25MtoDIYzkhBivRCiWQjRKoS4J8T9dwshTgghjgkhtgohzvK5zymEqPf8eTO1KyeiXPS3Iz3QqvOwfk11Uq9TpFHDFFhqa3agzCeQvGLZXOgtDjT16UM+h9HCwDOTMfAkIkqgO/54ON1L8IrQ+C+kVI60YeVxaEIIFYDHAdwAYBWArwghVgWcdgTAOinl+QD+AuAhn/vMUsoLPX9uTMmiiShn2Z0uvHWsD9etqkKZT+YxGQrDZDyVUlsAOG9hOQCgJUyDIaPVgRItA89MxcCTiIgoc1wKoFVK2S6ltAF4GcDnfE+QUm6TUpo8N/cBWJjiNRLRDLGjZRAjEzZ8/sLkltkCQFF+8B5Pg8XhF/CWe4JQZb5nIKPFgRJtcgNkmjoGnkQ0I8yEDJtgB6NcsABAl8/tbs+xcL4J4B2f2wVCiDohxD4hxE3hHiSEuN1zXt3g4OD0VkxEOeuvR3owuygf15xTkfRrFWnVMNudfnM63c2FJjOYShmt0RoceLpcEkabAyUstc1YDDyJiFLgT/vPYE/rUFKvETjHMyrGqZko1KsS8oUVQnwVwDoAD/scXiylXAfgFgC/FkIsC/VYKeXTUsp1Usp1FRXJf0NJRNlHb7Fjy4l+fPaC+chXJT9kKNKoAAAWhzvr6XRJGKz+GU+tWgWNKg96iz3o8Sa7E1ICpSy1zVgMPImIUuSW3+9P6vNva2bmKgd0A1jkc3shgN7Ak4QQ1wH4EYAbpZRW5biUstfz33YA2wGsTeZiiSh3bWnsh9XhwudSUGYLTAaeJs8+T6OnnNZ3jyfgznqGKrVVzmfGM3Mx8CQiyhGHOkfTvQSavoMAlgshlgghNABuBuDXnVYIsRbAU3AHnQM+x2cLIbSer+cBuArAiZStnIhyyq7WIcwr0eCixbNScr0ijTtgNHn2eSpZzbKAQLKkQO0NMn0Zre7z2Vwoc/GVIaIZYePxvnQvIfOkcZwKJ7mEJqV0CCHuBLAZgArAs1LKRiHEfQDqpJRvwl1aWwLgz559vWc8HWzPBfCUEMIF9wfLP5dSMvAkorhJKbGnbQiXL52bsv4B3oynZ6TKuNkTeIbMeAaX2hqY8cx4fGWIaEY4qQvdep0o00gpNwHYFHDsxz5fXxfmcXsAnJfc1RHRTHB6aAL9eiuuWDY3ZdcsDCi1VTKegXM5S7X5IZsLKce4xzNzRS21FUIsEkJsE0I0CSEahRB3eY7PEUJsEUKc8vx3dvKXS0REREREybSnbRgAcOWyeSm7ZlG+O/BUZnnqzZ49ngHzQ0u4xzNrxbLH0wHge1LKcwFcDuA7nmHW9wDYKqVcDmCr5zYREREREWWxve3DqC4rQO3copRds9iTqZzwZC6VjGd5jM2FDJ7HcY9n5ooaeEop+6SUhz1fGwA0wT1T7HMAnvec9jyAsPPCiIgo89R3jaV7CUSUZSx2JxuZ5TgpJfa1DePKZanb3wlMltqa7e6MpxJcBmY8S7Wh93gqGc9SbX7QfZQZ4upqK4Sohbs1+34AVVLKPsAdnAKoDPMYDqkmIspANqcr3UsgoizidEnc+eIRfOGJPegdM6d7OZQkLf1GDE/YcHkK93cCweNU9J7mQoGls6UF7j2egbOrlT2exVpVspdKUxRz4CmEKAHwGoDvSin1sT6OQ6qJiChQ6j5DJ6JEeWjzSbzf1A8AaOlnw7ZctadtCABwZaoDz/zgUttSrRqqPP/fGKUFargkMOEJUBVGqwMF+XlQqzgtMlPF9MoIIfLhDjr/JKV83XO4XwhR47m/BsBAuMcTERERUfb6y6FuPPVhOz57wXwAQNvgRJpXRMmyt20Yi+YUYuHs1O3vBHxKbX2aCwWOUgEmM6CBszyNVgdKWGab0WLpaisAPAOgSUr5iM9dbwK41fP1rQDeSPzyiIiIiCidDnWO4IevH8dVZ8/FI1++ALOL8tE6YEz3sigJnC6J/adHcOXS1HWzVWjUechXCZjsk+NUAkepAO5SWwBB+zyNFkfI8ylzxPLqXAXgawCOCyHqPcd+CODnAF4VQnwTwBkAX0rOEomIiIgoHTqGJnD7Hw5h/qwCPH7LRchX5eHsyhK0DTLwzEVNfXqMm+0pnd/pqzBf5ZPxtIfMeCpzOg3WUBlPBp6ZLOqrI6XchfDbca5N7HKIiIiIKFUG9Bbcv7EJHcMT+L+b12LJvGLvfX3jZvzj7/fDJSWeue0SzCrSAACWVZR493pSbtnrmd+ZrsCzSKP22ePpwIJZhUHnKFnNwJEqRgsDz0zH3bdEREREM4zTJfHC3g5c+6sP8W6jDp3DJnzuN7uw85R7AsHIhA1fe+YAxs12/OEbl2FZRYn3scsqSjBktGHMZEvT6ilZ9rQNYWlFMarKCtJy/SKtarLU1mxHWRyltgarI6gDLmUWvjpEREREM8i4yY5bNxxAfdcYrjp7Lu6/6Tyo8wT++fk63LbhIP7rU+fg7WN96Box4flvXIrzFpb7PX5ZpTsr2jZoxMVnzUnHX4GSwGJ34mDHKG5aOz9tayjSTJbaGiyhS23DNxeyo1RbmvxF0pRlX+Apo59CRERERKG909CH+q4x/OIL5+HL6xbB3UcSeO3bV+LfX6nHg++chDpP4Ol/uhiXLw0uuTy7wv3mvm1ggoFnjjjUOYJ7XjsOo9WB61dVp20dRflqmGwOuFwSBqsjTMYzQqktM54Zja8OERER0QzS2KtHqVaNL108GXQCQIlWjae+ejGe39uB2rnF+PjKypCPXzC7EBp1HhsM5QCDxY6HNzfjhX2dmF9eiA1fvwTXrKhI23oKNSqMmmww2hyQEqEznprg5kJSSjYXygJ8dYiIiIhmkIbecZw7vwx5ecG9I/PyBL5+1ZKIj1flCSydV8yRKllGSokdp4bw/ol+dI6YcGZ4At2jZjilxG1X1uI/PnkOitMcuBVrVegZc0Jvdu/fLCsIDjzz8gRKtGq/PZ5Whwt2p2TGM8Nl36sTrr8uEREREUXkdEk09elxy6VnTet5llWUoLF3PEGromQ72DGCh99txoGOEZRq1aidV4zVC8pxw3k1WL+6GhcsmpXuJQIACvPVMNuc0Jvd2cyywtChSmmB2q/U1ujJfpYy45nR+OoQERERzRDtg0ZY7C6snl82redZVlmCdxr6YHU4oVWrErQ6SoTXD3eja8QMm9MJm8OFkzoDdp4aQkWpFj+7aQ3+Yd0iaNSZOdiiSKOCyeaA3hI+4wm4y8J9mwspXzPjmdn46hARUcoJVq8QpUVjrx4AsGZBeZQzI1tWUQyXBDqHTVhRxU6imaKhZxx3v3oUgLskWqPKQ3lhPr6/fiVuu7IWhZrM/pCgSKPChM2n1DbEHk/Ak/G0TpbaKhnPEm3o8ykzMPAkIiIimiEae8ehVedhWUXxtJ5HmevZOmBk4JlBXjnYBa06D/t/eC1mFWnSvZy4FWnUsDlcGDNFzniWFuT7zZFVym7ZXCizZWaenYiIiIgSrqFHj5XVpVCrpvcWcKkncG1jg6GMYbE78bf6Htywpjorg07AnfEEgH69BcDk6JRAJeH2eLLUNqMx8CQiopSTnMlMlHJSSjT2jmP1NMtsAXdmasGsQo5UySDvNuhgsDjw5XWL0r2UKVNKgXVRAs+yAjX0foGnO0PKjGdmY+BJRERENAN0j5qhtzim3VhIsayyBG2DEwl5Lpq+Vw52YdGcQly+dG66lzJlSsZTN25BsUYVNjNfolV7g02AzYWyBQNPIiIiohlAGX+yZv70M56Au8FQ26ARLhdLGNKtc3gCe9uH8eWLF4Wcz5otijTuwFGnt4RtLAS493ha7C7YnS4AgMHKPZ7ZgIEnERER0QzQ2KuHKk/gnOrENAM6u7IEJpvTWxZJ6fNqXRfyBPDFdQvTvZRp8d3jGa6xEDBZgqvs8zRaHMhXCWgzdEwMufHVISIiIpoBGnrGcXZFCQryEzNSQ+lsy32e6eVwuvCXQ924ekUFasoL072caVECzyGjDWWF4bOXSmZTKbE1Wh0o0aohOKsrozHwJCIiIpoBGnv1WL0gMfs7Af+RKpQ+O04Nol9vxT9kcVMhhe+c0cgZT/d9eot7n6fR4uD+zizAwJOIiIgoxw0YLBgwWLE6Qfs7AWBeiQZlBWpmPNPsL4e6MbdYg2vPrUr3UqatWDMZPEbe4+nJeHr2dhqsDpRow59PmYGBJxEREVGOa+zVAwDWJKijLQAIIXB2ZQlO9OohOSMpbU72GXDZ0jnQ5MD+xiK/jGf4DGaoPZ6lbCyU8bL/J5SIiIiIIjrhCTxXJTDwBIBrz63C4TNjeGBjE4PPNBkwWFFZWpDuZSSEX6ltlK62AGBQSm2tLLXNBlEDTyHEs0KIASFEg8+xnwgheoQQ9Z4/n07uMomIiIhoqhp6xnHW3CLvG/ZE+fbHluG2K2vx+12ncd/bJxh8JonZ5gx5fMLqgNHqQFVZbgSeRT6ltqURAklvcyHrZHOhYmY8M14sGc/nAKwPcfxRKeWFnj+bErssIiLKZWw8SJRajb36hM3v9CWEwL2fXYVvfmQJNuzuwL1vNjL4TLBT/Qac95PN3jmsvgYMVgBAVZk21ctKClXe5EiUeMapGCwOzvDMAlEDTynlDgAjKVgLERERESXYhNWBMyMmnFuTmPmdgYQQ+O/PnIvbr16KP+ztxAv7OpNynZmqSWeAwyVxss8QdF+/Z4ZqrpTaApP7PCOV2hbkq6BR5U3u8bTaI2ZIKTNMZ4/nnUKIY55S3NnhThJC3C6EqBNC1A0ODk7jckRERLlPCLFeCNEshGgVQtwT4v67hRAnPL+DtwohzvK571YhxCnPn1tTu3LKVD1jZgDAWXOLk3YNIQR+cMNKzCnWoFkXHCDR1PV5Xr++cXPQfUrgmSsZT2Cy3DZSxhMASgrUMFjssDtdsNhdzHhmgakGnk8AWAbgQgB9AH4V7kQp5dNSynVSynUVFRVTvBwREVHuE0KoADwO4AYAqwB8RQixKuC0IwDWSSnPB/AXAA95HjsHwL0ALgNw5ndP2QAAIABJREFUKYB7I30wTDNH14gJALBwdmFSryOEQIlWjQnPvjtKjL5xi99/fQ16Sm1zKeNZ6M14Rg4kSwvUMFgc3p83Bp6Zb0qBp5SyX0rplFK6APwO7l9wREREND2XAmiVUrZLKW0AXgbwOd8TpJTbpJQmz819ABZ6vv4UgC1SyhEp5SiALQjdo4FmmO5Rd6Zs4eyipF+rSKPCRJhGODQ1vd6MZ3Dg2a+3QKvOixqkZZNiJfCMlvHUqmG0Orzltuxqm/mmFHgKIWp8bn4eQEO4c4mIiChmCwB0+dzu9hwL55sA3on3sdwGM7N0j5qgVedhXokm6ddixjPxImU8BwxWVJUVQORQx7bCGPZ4AkrG0+7tbMs5npkv6iskhHgJwMcAzBNCdMNdxvMxIcSFACSADgDfSuIaiYiIZopQ7x5DtggVQnwVwDoA18T7WCnl0wCeBoB169axBWmO6x41Y+HswpQEJ0VaNcbN9qRfZyZR9nbqwuzxrCzNnf2dwOQez2jNgkoL8tE1YvIGnsx4Zr6or5CU8ishDj+ThLUQERHNdN0AFvncXgigN/AkIcR1AH4E4BoppdXnsR8LeOz2pKySskrXqAmL5iS/zBYASrQqb2koTZ/V4cSQ0YYijQqjJjvMNqc3IwgAA3orzq0pS+MKE69Qo0KRRoV8VeTCzFKte4+n0cI9ntliOl1tiYiIKLEOAlguhFgihNAAuBnAm74nCCHWAngKwI1SygGfuzYD+KQQYranqdAnPcdohlMynqlQpFHDxFLbhOkfd3+udP5C9wxWnd6/3HbAYEVlDnW0BYDqsgLUlEdvlqSU2hqUUltmPDMeA08iIqIMIaV0ALgT7oCxCcCrUspGIcR9QogbPac9DKAEwJ+FEPVCiDc9jx0B8DO4g9eDAO7zHKMZzGCxY8xkT0ljIWCy4QslRq+nvPbis9wNqvt8sskTVgeMVkdOdbQFgLuvX4GXbr886nklBUpzIXdpd4k28p5QSj9+NEBERJRBpJSbAGwKOPZjn6+vi/DYZwE8m7zVUbZRZnimLuOpgsnmhJQypxreJFrrgAFP72jH4jlFWFFVihVVpVg8pwh5ef7fM2V/50WLPYGnT4OhAc8olVya4QkAxVo1imMomy0tyIdLTo6U4R7PzMdXiIiIiChHdY2kbpQK4A4aHC4Jq8OFgnxV9AfMQFJKfP+146jvGoPTNdnb69qVlXjmtkv8zu0dcweaa72B52TGs99TdltVllsZz1gppbW6cQuEAIr485bxGHgSERER5ajuUffI10UpyngqMxhNNicDzzDeqO/Foc5RPPSF8/Hp82twqt+Ax7e1Ym/bMFwu6Zf17Bs3o7wwH3OKNZhTrPHLeCqBZ651tY2V0kyod9yCEo06KFtMmYd7PImIiIhyVPeoGYX5KswpTv4MTwDeEknO8gxtwurAg+804bwF5fjixQtRolVj7eLZuPbcKkzYnN7SaEXfmMXbaKe6rAA6n8BTKTGtnKEZz7IC957OvjEzy2yzBANPIiIiohzVNWJK2QxPwCfwtDHwDOWJ7W3o11vxkxtX+WXoVlSVAABa+g1+5/eOWzB/ljtbXVNegN6AjKdWnYeyGRp0lfiU2nKUSnbIusDz9NBEupdARERElBVSOUoFYMYzkq4RE57e2Y6bLpyPi8+a43ff8qpSAEBLv9HveN+42ZvxrJlVAJ3fHk8rqsoKZmwTJ2WPp8HqYMYzS2Rd4PnollPpXgIRERFRVugeNWHRnNQ0FgIm93hOWJ0pu2a2eGBjE1RC4Ps3rAy6r6wgHzXlBX4ZT7PNiTGT3SfjWYhRkx1mm/t7O2Cw5FxH23iUFkyOT2HGMztkXeBJRERERNGNm+3QWxzMeGaA9kEj3m3U4Y5rlqGmPPTrsaKqFM26ycBT6WDrzXh6/qvzNBUa0FtzboZnPHyDzVJmPLMCA08iIiKiHKR0tE3VKBUAKNYoezyZ8fRV1zEKAPi7C2rCnnNOdSlaB43eEStKB1slUK32BJ5KQDpgsKJyBmc8fQNPZjyzQxYGnjL6KUREREQzXPeoMsMzlRlPpdSWGU9fhzpHMasoH0vnFYc9Z3llCWwOFzqH3f1Mej0dbufPUjKe7texb8wCo9UBo9UxY2d4AoAqT3gDzhJtfpSzKRNkYeBJRERERNFMBp4pzHiyq21Ih86M4qLFsyM2AjqnWmkw5C63VTKe1SFKbQdm+AxPhTfwZKltVmDgSURERJSDukdNKNaoMLsoddkgrToPqjwxIzOeA3oLWgcMQcfHTDa0Dhhx8VmzIz7+7EplpIq7s23fuBnzSjTQqt1Z5IJ892vZO2bGgGeG50zOeAKTeztLWWqbFfgqEREREeWgrhEzFs4uSum4DSEEijSqGdXVVkqJlw924YGNTRACOPij61CQr/Lef+TMGADgosWRA88ijRqL5xSh2ZPx7B2zBDUiqikvhG7cgn5mPAFMZjqZ8cwOWfgqzcxZRURERETx6B41pXR/p6JEq87JjKfeYsctv9uH8sJ8fGxFJT6+sgKFGjXuee0Ydp4awrKKYrQNTmBP2xA+sbLK+7jDZ0ahyhO4YFF51GusqCpFi04ptTWjdq7/ntCa8gL0jlsw6Ml4Vs74jKc7m8/mQtkhC0tt2VyIiCjbCX6ISJRUUkr0jJrTEngWaVQw5WBX28e3taKxV49+vRUPbGrCdY/swEd/8QEOdY7iZzetwaa7PopSrRrvHNf5Pe5Q5yjOrSlFkSZ6cLSiqgSnhyZgc7jQN2bx7utUVJcXQDduRr/egoL8PJTN8EyfUmrLwDM78FUiIiIiyjF6swMGqyOljYUUJVo1jDmW8ewaMWHDrg58fu0CPPLlC9EzZsb25gGcHpzArVfWYtEc9/f52nMrsaWpHw6nC2pVHhxOF+q7xvClixfGdJ1zqkvhcEkc7xmDwepAzSz/Dw7mzyrEqMmOzmETKksLUlpGnYlK2Vwoq/BVIiIiIsoxXZ4ZnovmpCPjqYYpx7raPrS5GXl5wH9+6hwAwIJZhfjHy84KOm/9mmr8rb4XB06P4Mqz5+GkzgCTzYmLojQWUiyvdHe2/bB5EACCM56e0tpj3eNpeW0zDTOe2SVqqa0Q4lkhxIAQosHn2BwhxBYhxCnPf2P710RERERESdftCTzTkfEs1qphzKHmQofPjOKto724/aNLg5r9BLp6RQUK8vPwbqO73PbImVEA0RsLKZZWFEOVJ7C9xR14zg/IeNbMmhypMtP3dwKT8zsZeGaHWPZ4PgdgfcCxewBslVIuB7DVczslJLd4EhERUQ4w25y4+em9uPvVemw50Q+LPXHB2uQMz9RnxYq1qpzJeEopcf/bJ1BRqsW3rlkW9fwijRrXrKjA5kYdXC6JQ52jqCzVxvw6FOSrUDu3CMd7xgEEZzx9A9+Z3tEWcP98F+arMKdYk+6lUAyifjwgpdwhhKgNOPw5AB/zfP08gO0Avp/AdRERERHltJM6Pfa1j0CjysPrh3vw/7d37/FxV3X+x1+fTDK5TJLm0iS9XxJaSrm1kJYiK6AoF0FhEQTd1bJe2EV311V3V1h35beu7uJtdf3JuqJWRVcBsQjLoqByB6EXKBQobdMmbdNb7m0yuUySOfvHfCfNvTO5zUzyfj4e88jMd+b7nTMnM/PNJ59zPifg93HFmXP58nvPwpc2vrl7tc0d5GamMyt76tbwjApMo6q2j2w/wkv7W7jj2jMJxJhVu+KMuTz6+lG21bawdX8z5y4ujGsu5vKyPPbUBzEbuk7nnH63Z/oangDXrJ7PW5fPjvl3I4k11qq2Zc65wwDez9KRHmhmN5vZFjPbUl9fP8an63+8cR9CREREJOFqGoMAPPRXF3D3h9eyrryY+7fWss/bPh4HmiJLqSSi+Exgmqzj2dbVw78+soMVc/K4vnJhzPu9bUUpGT7jJ3/Yx4GmDs6NcX5n1PKyyDzP0rxMMnwD/1TP9vsozMnou3+m86UZpXkKwFPFpC+n4py7yzlX6ZyrLCkpmYDjTUCjRERERBKsuqGdNIPy2blcuLyED54fKVbT3B4a97HrWrsSlhELZKbT0d1Lbzi1/2i749c7OHSsgy/98ZlxZaBnZWfwlorZ/GrbQQBWxzi/M+rUOZHAc6T5pHO87cp4SqoZa+B51MzmAng/6yauSaNrDI7/y1hEREQk0WoagswvzMafHvlzLDpPrSnYPe5jNwVDFCdo3lvAW68yled5/mFPIz99YT8fvmBp3BlLiFS3dQ78vjTOmJ8f177Ly3IBmFcwfGA5z5v3WZavjKeklrEGng8B673r64EHJ6Y5IiIiIjNDdUOQJcWBvtsnAs+ucR+7KRhKWMGVnEwfQMoOt20P9fDZX77K4uIc/vbSU8d0jHeuLMMMzlwwi8x0X1z7Li4OEPD7WNzvvdHfHC/wLNEQU0kxJ52Ja2Y/J1JIaLaZ1QK3A3cA95nZR4D9wPWT2UgREZleHKk9BE9kvJxz1DQE+eNz5vdtm6iMZ0eol47uXgoTFHhGl7YIpmjG8+uP7WJ/Uzs//9g6sv3xBY1Rs3Mz+eu3L+ubrxmPDF8aD3zighGH0l60vIRDLR3kZ6mgjqSWWKravn+Euy6Z4LaIiIiIzAiNwRCtXT0DMp45/nSyMtLGnfFs8uaIJizj6Q21TcXKti/tb2bDc9X86bpFnF9RPK5jfeqdy8e872gB66Wnz+HS0+eM+dgiiTLpxYVEREQGM1SiXGa2moZI5dqlJQOHUxbl+Med8WwOJjbwDKTwUNvvPb2Xohw/t15xWqKbIjLtKPAUERERmWLV0cBz0Dy+olz/+DOeiQ48UzTj2dIe4vc76rh61fy+4cIiMnEUeIqIiIhMsZrGIOlpxoLCgUtmFOb4aWofZ8bTG2pbmJOojGdqzvF8+NXDhHrDXNtv3q2ITBwFniIiIiJTrLohyMKiHNJ9A/8UKw6MP+PZ2JYcQ23bQ6k11HbjS7WcWpbH6fPiW/5ERGKjwFNERERkHNpDPYTD8VVqrm5oZ0lxzpDthQE/zeOd49keIs1gVnbGuI4zVn0ZzxQaalvdEOSl/S1ce858zDQHXWQyKPAUERERGaOunl4uuONx7tl8IOZ9nHPsawyydHbukPuKA37aunro6hl7trApGKIgx48vLTEBVE5G6hUXeuClWtIMrlmtYbYik0WBp4iISBIxs8vNbKeZVZnZrcPcf6GZvWRmPWZ23aD7es1sm3d5aOpaPXMdaGqnub2bnUeOx7xPXWsX7aFels4ePuMJjCvr2RQMUZiTmGwnQLovjayMtJSZ4xkOOza+fJALTpk94tqZIjJ+CjxFRESShJn5gDuBK4CVwPvNbOWgh+0HbgJ+NswhOpxzq7zLeya1sQJATUM7EAkmYxWtaLtkdmDIfcVe4Nk4jnmeTcEQxYHMMe8/EQL+9JQZaru5pona5g4VFRKZZAo8RUREksdaoMo5t9c5FwLuAa7u/wDnXI1z7lUgnIgGykA1jZEg8ujxztj3iQaexUMDz2gl2vFkPJvbQxQGEpfxhMg8z1QJPDe+dJAcv4/LTp+T6KaITGsKPEVERJLHfKD/ZMFab1usssxsi5m9YGbXjPQgM7vZe9yW+vr6sbZVgP1NY8t4+n1pzCvIHnJf0YRkPLsTVtE2KsfvI5gCVW07u3v53+2HueKMueT4tXanyGRS4CkiIpI8hqsGE0+51EXOuUrgA8A3zaxiuAc55+5yzlU65ypLSkrG0k7x1DR6gefxLpyL7VdV3RBkUXHOsMV/ivrmeIbG1J5w2EUynglawzMqN0Uynk/vqqetq4drVs9LdFNEpj0FniIiIsmjFljY7/YC4FCsOzvnDnk/9wJPAqsnsnEy1D5vqG2oN0xLe2zDY2sagywdZn4nQEGOHzNoivFYg7V29tAbdonPeGamp0TG86ld9QT8Ps5bWpzopohMewo8RURk6mmZvJFsBpaZ2VIz8wM3AjFVpzWzQjPL9K7PBi4A3pi0lgrdvWFqmzv6gshYhtuGw459je0jBp6+NKMgO4OmMQ61bWqPZEoTHXjmZvqSPuPpnOOpXfW85ZTZ+NP1J7HIZNOnTEREJEk453qAvwQeBXYA9znnXjezL5jZewDMbI2Z1QLXA981s9e93U8DtpjZK8ATwB3OOQWek+hgcwe9YcfaJUVAbAWGDh/vpKsnPGxhoajCgH/MxYWiAWthojOe/nTakzzw3NsQpLa5g4uWa7i5yFTQLGoREZEk4px7BHhk0LbP97u+mcgQ3MH7PQ+cOekNlD7RirZrlhZx75YDMWU8+yraDrOGZ1RxwD/m4kJNXsBanPCMZzptSR54PrUzUlhLgafI1FDGU0RERGQM9nmFheLJeO71As+RhtpCZEmVsWY8o0WJEl1cKMfvoz3UG3PBpUR4alc95SUBFhaN/E8AEZk4CjxFRERExqCmMUiO38fComzys9KpiyHwrGkIkpWRRlle1oiPKc710zjGqrbJMsczkJlOT9jR1ZOcy812dvfywt5GZTtFppCG2oqIiIiMwb7GdhYXBzAzSvOzYh5qu6Q4QNowS6lEFeb4aW4P4ZzD7MTjfvrCPjZVN9HQ1kVjW4jOnl423LSGipLcvsc0BUNkpqeR4/eN78WNU8B7/vZQL1kZiW3LcF6sbqKrJ6zAU2QKjSvjaWY1ZrbdzLaZ2ZaJapSIiIhIsqtpDLKkODJMsyw/M6ahttWjLKUSVRTw0xt2HO84MUcy1BPm/z30Os9VNdDVE2ZuQRb7Gtt5cW/TgH2bgiGKAv4BAWsiBDIjuY1krWz71M56MtPTWFeuZVREpspEDLV9m3Nulbdg9aSbO2vkoSkiIpIiknfal0hMesOOA02RjCdAaV4WR4+PnvEM9YTZ19g+IEM5nOgw2eiwWYgEuT1hxz9dtZJf3vIWNqxfQ1ZGGnvq2wbs2xwMJXx+J/QLPENJGnjuquO88uKkzMaKTFcpN8dTS7+JiIhIoh1q6aC71/VlPEvzM6lv7Rq1mM6+xiC9YccppTEGnv0q2+462grAsrLIvmlpxtLZuewdFHg2ehnPREvmjOeBpnb21Ac1zFZkio038HTAY2a21cxunogGnUyih46IiIiIRCvaRjOeZXlZhHrDtLSPXI22qi4SJMYeeJ441u6jbZgxIFtaXhLoq5Ib1dyeJIGnN8cz2NWb4JYM9fRuLaMikgjjDTwvcM6dA1wBfMLMLhz8ADO72cy2mNmW+vr6cT4dSV2WW0RERGaG6Bqe0fU4S/MzAUYtMBQNPMtLTj7HEwZmPHfXtbKoKGfA0NCKklwONLXT1XMiuGtSxvOkntpZz/yCbCpO8nsQkYk1rsDTOXfI+1kHPACsHeYxdznnKp1zlSUl+s+SiIiIpL59jUEy008si1KWH/k5WoGhPfVtzC/IJsc/+qICI2U8l5XmDXhcRUmAsDuRfe3uDdPa2ZMcczz90TmeyZXxPNjSwTO7G7jo1BKNohOZYmMOPM0sYGZ50evApcBrE9WwkfQq4ykiIiIJVtPYzuLinL5lUUrzIhnP0QLPqvo2Kk4yzBYgx59OVkZaX8azuzdMdUOwb35nVHTYbXSeZ7O39mdRbhIEnpnRobbJk/F0znHbxu2YwS0XVSS6OSIzzngynmXAs2b2CrAJ+F/n3G8mplkjO1nFOBEREZHJtq8x2De/EyJVbWHkobbhsGNPXZBTTlLRNqoox9+X8axpiFS0XT4o8Iwuy7KnPjLsN1oFtygZMp5JWNX2F1treXpXPZ+9fAULi3IS3RyRGWf0sR6jcM7tBc6ewLaIiIiIJL1w2LGvsX1AcZpsv4/8rHTqRsh4HjrWQUd370kLC0UV5fr7Mp67vbmhg4faBjLTmZOf1bekSpOX8SwMZMT3giZBZnoavjRLmozn0eOd/MvDb7B2SREfXLc40c0RmZFSbjkVERERkUQ62tpJV094QMYToDQ/a8SMZ7SwUKwFbQpz/DR5FXJ3HW0dUtE2qqI0cCLjGR1qmwTFhcyMHL8vKaraOuf43APbCfWE+fJ1Z/UNjxaRqaXAU0RERCQONQ2RYj5LBgWeZfmZI87xjAaHsWY8iwMDM54LC3PI9vuGPK7cW8vTOXdijmcSBJ4AuZnpSZHx/NW2g/xuRx1/d9mpfcOTRWTqKfAUERERicM+bymVxcUD5wmW5mWNWIuiqq6NwpwMinMzY3qOwoCfZm+OZ9XRNpaNELBWlARo7eyhoS3UNyc0GaraAuT4fbQnuKrtaweP8Q8bX+PcxYX82QVLE9oWkZlOgaeIiIhIHGoa28nwGfMKsgdsL83PpL61a9g1x/fUtcWc7YRIxrOtq4dgVw97G9pYVpY37OPKveG3e+rbaG4PkZeVToYvOf68y81Mpy2BGc8jxzr5yI83UxTw850/PQefhtiKJFRyfDOJiIiIjFFNQ5BvP76bK7/1DP/+212T9jx1rZ385rUjPL2rnoWFOUMCmbK8LEK9YVrau4fsW1UfX+BZ6A2X3Xaghe5eN2LGs9ybM7q3PkhjMERxkgyzhciyMO0Jqmob7OrhIz/eTFtnD99fX9lXdVhEEmfMVW1FREREJsOxjm5e3t/M1n3NbDvQQmZ6GvMKspk7K5vZuZFMYFMwRFMwxPaDx3i19hgAJXmZfOfJKm5Ys5D5g7KRY9UR6mXDc9Xcs3k/B5o6APD70vjYhUOHbZbmR4bR1rV29QWOQF9bhysONJJoAPni3kYAlo+Q8Zw3K5usjDT21rfRHAwNeN5EC2Smc7ClY8qftzfs+Jt7t7Hj8HF+sH4Np83Nn/I2iMhQCjxFREQkoZxz7K5r47HXj/DYG0fZfvAYzkGawalz8nHOsam6ieOdJ7JnZpG5jIuKcviHd63gqrPmAXDRV5/gzieq+Nc/PnNcbQqHHQ+8fJCvPbaTw8c6eeuy2aw/fwmrFxVyxvx8MtOHFvopy49k1Y4e7+TUOScCxb6KtvFkPL15mi9UN3n7Dl8UJy3NWDo7lz31bTQFQ8ydlTyZvUCmb8ozngea2rlt43aerWrg9nev5G0rSqf0+UVkZAo8RUREJCGcc/xiSy3feWoP1Q2Rgj2rFxXwyUuWsWZJEasWFhDIPPGnSltXD41tXeRnZZCfnTHsnL0b1izk3s0H+PjFFSwozBlyfyyOHOvkY3dvYfvBY5y1YBbfuGEV68qLT7pfaV4k4zm4sm10nc1T4sl45p4YarugMJsc/8h/spWXBHjt4DG6usOsnJc82b3AFFa1DYcdP31xH3f8+k0M+OI1Z/An5y2akucWkdgo8BQREZEpt7+xndseeJXnqhpZvaiAL15zBu9cWdaXNRxObmY6uZmj/+ny8YtP4b7Ntfznk3vGlPVs7ezmph9uora5g2/esIr3nD0v5nUfo/MIB6/lWVXXRnaGL67hv9GMZ6gnPOIw26iKklx+vf0wvjRLqjmegSlax7O6Ichnf/kqm6qbeOuy2fzbtWeO+Z8OIjJ5FHiKiIjIlHHO8cPnavjqozvxpRlfvOYMPrB2UczB3cnMK8jmhjULuWfz/riznt29YT7+3y+xu66NH960hguXl8T13Nl+H/lZ6dQNynhW1bVRXhKI6zUW5PgxA+cYsbBQVEVJgLCDcK9LujmeHd299IbdpFSU7Q07Njxbzdce24k/PY2vvPcsrq9cgJmq14okI1W1FRERkSlz5xNVfOHhN1hXXsRjn7qQP123eMKCzqiPv60Cw7jziT0x7+Oc4x82bueZ3Q3827Vnxh10RpXmD13Ls6quLa7CQgC+NKMgOwNgxKVUovofuyhJ1vAECHjDgydjnueOw8e59jvP86VHdvDWZSX87tMX8b41CxV0iiQxZTxFRERkSvzmtSN87bFdXLNqHt+4YdWkBQlzZ2Vz49qF/OzF/dxyUQWLik+e9fyP3+/mF1tr+eQly3hf5cIxP3dZfiZ1rScynu2hHg62dHDDmviPWRjw09zefdKM59LZJwoPFSVZxhMg2NVLXlbGuI/nnOPp3Q1seLaap3bVUxTw8633r+bdZ81VwCmSApTxFBERkUm34/BxPn3fNs5eWMAd7z1r0gOFWy6uICvDx00/3DSk2M9g//lkFd/83W6uO3cBf/OOZeN63tK8gRnPvfWRoknxrOEZFZ2vebJ9A5npzPHmxibXUNtI5d/gODOeh4918P1n9vLObzzN+g2beOPwcT71juX87tMX8Z6z5ynoFEkRyniKiIjIpGpo6+KjP95CXlY63/vguWRlDF2KZKLNnZXNj/5sDes3bOL9d73Az29eN2zhov98soqv/GYnV6+axx3XnjnuIKY0P5P61i6cc5jZiYq2Ywg8S/OyWFiUPaCy70gqSgMcOd6ZXBlPfzTjGVvg6Zyjpb2butYu6lo72VPXxiPbj7CpJrKkzNkLZvGNG87myjPn4U9X7kQk1aRc4LlqYQHbDrQkuhkiIjIOGenKUExnzjlqGtt5tbaFV2uP8cSbdTS0dfGLvzif0lGq1k60yiVF/PjDa1m/YRM33vUC9wwKPu98ooqvPhoJOr9+/dmk+8YfzJTlZRHqDfNidRNvHj7OxpcP4kszFscw3HewW69YwfHO7pgeWz47l+eqGpMq8MzxMp7/88ohjnf0UFEaYE5+1oDgvu54J0/urOeJnXU8u7uB1kFB6vKyXD7zzuVcdfa8AUOKRST1pFzg+YHzFinwFBFJcaOtSSip79ZfbufeLQcAyMpI4/R5s/jHq07jrAUFU96WyiVF3P2RtXzoB5u46v8/y8LCbMyMnrDjlQMtXLNqHl9/36oJq7oaDWxvvOsFABYUZvOJiyvITI8/y7uwKPZg9aqz5hIM9ZCflTyfrfLZuczOzeR7z1TzvWeqAUhPMzJ8aaSnGek+o7k9EljPyc/iyrPmsqwsj9K8TErzMplXkB1XH4hIckueb6cYnbNo6k9aIiIiEpvn9zRw75YDvH/tIj5iMoRhAAANgElEQVR0/mKWleZOSCZxPM5dXMRPPnoedz5eRVdPGIfDOfjzi8r5+8tWTOhSHxcun80tF1dwSkku55UXTdl6kueVF3NeefGUPFes5szKYvPnLqG+rYs9dUGq6ts43NJBT9jR3RumuzfM3FnZvO3UUk6bm6e5miLTXMoFnu2hyV+IWEREROLX3Rvm8w++zsKibG5/98opmcsZq3MWFfKDm9ZM+vPkZWXw2ctXTPrzpAozozQvi9K8LM6vSK7AWESmVsrNzD5j3qxEN0FERESG8cPnqqmqa+P2q05PqqBTREQSb1yBp5ldbmY7zazKzG6dqEaNZqIXmRYREUkmJzu3mtmFZvaSmfWY2XWD7ltvZru9y/qpazUcOdbJf/xuN29fUco7VpZN5VOLiEgKGHPgaWY+4E7gCmAl8H4zWzlRDRvN/X9xPgDvOnNOXPudt7RoMppzUsvL4i+hLolXXjJ69byxlMYXERlNjOfW/cBNwM8G7VsE3A6cB6wFbjezwsluc9SXHtlBd9hx+7un5E8BERFJMeOZ47kWqHLO7QUws3uAq4E3JqJho6lcUkTNHVdO9tPELNjVQ3aGb0qysZ++bxsbXzrIln98B5Vf/B2Pf+YiyktGDoD+55VDnLO4EL8vjY5QLxd+9YlhH3fVWXP59gfOAaCqrpV3/PvTXHZ6Gd/9YCUAD796iNbOHm7buJ33VS7gK9edPWD/Jbf+7wS9wrFJpvfDSJxz9IYdod4wYQdn3P4o6WmRyooAG26q5MM/2pLgVg70vQ9V8rG7k6tNE6VycSFb9jUnuhkig5303Oqcq/HuCw/a9zLgt865Ju/+3wKXAz+f7EY/v6eB/3nlEH99yTIWF2vJCxERGcqcc2PbMTK853Ln3Ee92x8EznPO/eWgx90M3AywaNGic/ft2ze+Fsu4NLZ10dwe4pTSPACe2V3PstI85syamHXVttQ0sWJuPrmZ6Rxoaqc418+m6iYqSnJJSzMKczLI8KWx+2gbp83NozfsSDOjqyfMppomws5x8fISjnf28Obh45xXXsxzVQ0U5GRwqKWTtUuKwGBvfRt/8dOtfOmaM5mVk8GaJYnJZieKc45jHd0U5IxtvbbGti5ys9KHLe/vnOMPextZt7SYtDQjHHb0LzR4rKObWdkZQKRoxJM761i9qJCOUC/52ek0toUwiyyX0dMbxp+exptHWkkzo661k7eeUkJ+djpdPWGyMny8cqCFF/Y2cuOaRbR0hNi6r5kX9zbxobcs5kfP1bBqUQFnLyjgWEc3L1Y3cf25C3i2qgHn4OX9zTz4yiFCPWHOmJ9PVV0bn7xkOX+ybhEv72/hx8/XcOsVK7j0G09z7er5bHz5YN/rqLnjSkI9Yd77nef55CXLqG1uZ3ddGw+8fJDPXHoqV5wxhx89X8ONaxYO+OfOAy/X8q3fV/GWimKCXT38atsh/OlpXFBRTH52Bg9uOwTAw3/1Rxxs6eDPf7IVgJK8yKLyAA9+4gKagiH+6cHXqG3uYMWcPJaV5fH2FSWcWpbPZ37xCpesKKWtq4dT5+Rx28btABTkZNDiLT2Q4/cNKLaWl5VOa2cPn37ncvbUt3HLxRVc/s1nBvxu583K4tCxziG/8xvXLOSezQf6bn/ykmX8x+93991eMSePN4+09t1+8m8v5r4tB/jlS7UcPd414FgLCrP5/FUrebX2GHf/oYbjnT2kGYT7nWr+8crT+Ohby4e0YyzMbKtzrnJCDpYEYj23evf9CHjYOXe/d/tvgSzn3Be92/8EdDjnvjbMvhN6bt5c08S3H6/iux88V3M7RURmuJHOzeMJPK8HLht0clzrnPurkfaprKx0W7ZMz+yJiIhMvWkYeMZ8bh0m8Pw7IHNQ4NnunPv6aM+pc7OIiEykkc7N4ykuVAss7Hd7AXBoHMcTERGZ6cZzbtV5WUREktZ4As/NwDIzW2pmfuBG4KGJaZaIiMiMNJ5z66PApWZW6BUVutTbJiIiknBjDjydcz3AXxI5qe0A7nPOvT5RDRMREZlpRjq3mtkXzOw9AGa2xsxqgeuB75rZ696+TcC/EAleNwNfiBYaEhERSbTxVLXFOfcI8MgEtUVERGTGG+7c6pz7fL/rm4kMox1u3w3AhkltoIiIyBiMZ6itiIiIiIiIyEkp8BQREREREZFJpcBTREREREREJpUCTxEREREREZlU5pybuiczqwf2TcChZgMNE3Cc6U79FBv1U2zUT7FRP53cRPbRYudcyQQda0bSuTkh1FexUT/FTn0VG/VT7MbTV8Oem6c08JwoZrbFOVeZ6HYkO/VTbNRPsVE/xUb9dHLqo+lJv9fYqa9io36KnfoqNuqn2E1GX2morYiIiIiIiEwqBZ4iIiIiIiIyqVI18Lwr0Q1IEeqn2KifYqN+io366eTUR9OTfq+xU1/FRv0UO/VVbNRPsZvwvkrJOZ4iIiIiIiKSOlI14ykiIiIiIiIpQoGniIiIiIiITKqUCzzN7HIz22lmVWZ2a6LbMxXMbIOZ1ZnZa/22FZnZb81st/ez0NtuZvYtr39eNbNz+u2z3nv8bjNb32/7uWa23dvnW2ZmU/sKx8/MFprZE2a2w8xeN7NPetvVT/2YWZaZbTKzV7x++mdv+1Ize9F7zfeamd/bnundrvLuX9LvWLd523ea2WX9tk+Lz6iZ+czsZTN72LutPhqGmdV4n4ttZrbF26bP3Qwznd7TEynec5PE/t07k5lZgZndb2Zveu+t8/WeGp6Zfcr77L1mZj/3/g7Se4qJiy/i4pxLmQvgA/YA5YAfeAVYmeh2TcHrvhA4B3it37avALd6128Fvuxdfxfwa8CAdcCL3vYiYK/3s9C7Xujdtwk439vn18AViX7NY+ijucA53vU8YBewUv00pJ8MyPWuZwAveq//PuBGb/t/Abd41z8O/Jd3/UbgXu/6Su/zlwks9T6Xvun0GQU+DfwMeNi7rT4avp9qgNmDtulzN4Mu0+09PcF9E9e5SZfYv3tn8gX4MfBR77ofKNB7ath+mg9UA9ne7fuAm/Se6uufcccX8V5SLeO5Fqhyzu11zoWAe4CrE9ymSeecexpoGrT5aiJfPHg/r+m3/W4X8QJQYGZzgcuA3zrnmpxzzcBvgcu9+/Kdc39wkXfW3f2OlTKcc4edcy9511uBHUS+cNRP/Xivt827meFdHPB24H5v++B+ivbf/cAlXsbpauAe51yXc64aqCLy+ZwWn1EzWwBcCXzfu22oj+Khz93MMhPe02MyhnPTjBbnd++MZGb5RAKGHwA450LOuRb0nhpJOpBtZulADnAYvaeACYsv4pJqged84EC/27XetpmozDl3GCInNqDU2z5SH422vXaY7SnLG+q4mkg2T/00iDeMaRtQR+QP/D1Ai3Oux3tI/9fW1x/e/ceAYuLvv1TzTeDvgbB3uxj10Ugc8JiZbTWzm71t+tzNLNPtPT0pYjw3zXTxfPfOVOVAPfBDb0jy980sgN5TQzjnDgJfA/YTCTiPAVvRe2o08Z6/45Jqgedwc3u0HsxAI/VRvNtTkpnlAr8E/sY5d3y0hw6zbUb0k3Ou1zm3ClhAJFNx2nAP837OuH4ys6uAOufc1v6bh3nojO2jQS5wzp0DXAF8wswuHOWxM72vpiv9nk4ijnPTjDWG796ZKp3I8MjvOOdWA0EiQyJlEG9+4tVEprvMAwJEzlWDzfT3VCwm5LOYaoFnLbCw3+0FwKEEtSXRjkZT3N7POm/7SH002vYFw2xPOWaWQeTE/t/OuY3eZvXTCLyhOU8SGatf4A1DgYGvra8/vPtnERmWEW//pZILgPeYWQ2RIYNvJ/JfePXRMJxzh7yfdcADRP6Zoc/dzDKt3tMTLc5z00wW73fvTFUL1DrnXvRu308kENV7aqh3ANXOuXrnXDewEXgLek+NJt7zd1xSLfDcDCzzqlH5iRTyeCjBbUqUh4Bo5cf1wIP9tn/Iqz61DjjmpcofBS41s0LvP0CXAo9697Wa2TpvLsWH+h0rZXht/wGwwzn37/3uUj/1Y2YlZlbgXc8m8qW8A3gCuM572OB+ivbfdcDj3ly7h4AbLVLRdSmwjEgRmJT/jDrnbnPOLXDOLSHS/sedc3+C+mgIMwuYWV70OpHPy2voczfTTJv39EQbw7lpxhrDd++M5Jw7Ahwws1O9TZcAb6D31HD2A+vMLMf7LEb7Su+pkcV7/o7PyaoPJduFSFWlXUTmpX0u0e2Zotf8cyJj07uJ/MfhI0TmPfwe2O39LPIea8CdXv9sByr7HefDRAqcVAF/1m97JZE/FvcA3wYs0a95DH30R0RS/q8C27zLu9RPQ/rpLOBlr59eAz7vbS8nEhRVAb8AMr3tWd7tKu/+8n7H+pzXFzvpV2l0On1GgYs5UVlRfTS0f8qJVDB9BXg9+lr0uZt5l+nynp6Efonr3KRLX7+d9Lt3Jl+AVcAW7331KyLVwPWeGr6v/hl40zuP/IRIpXm9p9zExRfxXMw7mIiIiIiIiMikSLWhtiIiIiIiIpJiFHiKiIiIiIjIpFLgKSIiIiIiIpNKgaeIiIiIiIhMKgWeIiIiIiIiMqkUeIqIiIiIiMikUuApIiIiIiIik+r/AEGDTP5GjuUOAAAAAElFTkSuQmCC\n",
+      "image/png": "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\n",
       "text/plain": [
        "<Figure size 1152x288 with 2 Axes>"
       ]
@@ -1867,17 +2190,23 @@
       "needs_background": "light"
      },
      "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:23.512588, resuming normal operation.\n"
+     ]
     }
    ],
    "source": [
-    "%%wandb\n",
     "model.train()\n",
-    "# loss_v_node = []\n",
+    "loss_v_node = []\n",
     "# loss_v_edge = []\n",
-    "# acc_v_node = []\n",
+    "acc_v_node = []\n",
     "# acc_v_edge = []\n",
-    "# ep = 0\n",
-    "for epoch in range(50):\n",
+    "ep = 0\n",
+    "for epoch in range(100):\n",
     "    ep += 1\n",
     "    node_correct = 0\n",
     "#     edge_correct = 0\n",
@@ -1930,7 +2259,9 @@
   {
    "cell_type": "code",
    "execution_count": 52,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -3369,955 +3700,1372 @@
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": 42,
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "13.484405994415283 13.484405994415283\n"
-     ]
-    }
-   ],
-   "source": [
-    "torch.cuda.empty_cache()\n",
-    "torch.cuda.reset_max_memory_allocated()\n",
-    "torch.cuda.reset_max_memory_cached()\n",
-    "print(torch.cuda.memory_allocated(0)/1024**3, torch.cuda.max_memory_allocated(0)/1024**3)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
+   "cell_type": "markdown",
    "metadata": {},
-   "outputs": [],
    "source": [
-    "print(full_graphs[0][0])"
+    "### Debug"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 125,
+   "execution_count": 47,
    "metadata": {},
    "outputs": [
     {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "tensor([1.8922e+01, 3.6313e+00, 3.0467e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.2187, -35.0857,   0.6955], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([ 1.8613e+01,  3.5876e+00, -1.0034e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([ 1.8996e+01,  2.9768e+00, -4.8119e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([25.8152, 16.9260, -1.2471], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([25.4800, 16.8262, -1.2453], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([24.8583, 16.6111, -1.2062], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([21.5880, -2.6879,  0.8381], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([16.9862,  3.8774,  0.1122], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([ 41.1885, -32.8211,   1.0185], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([ 40.7710, -30.7252,   1.2782], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([25.7639, 18.2869, -1.1607], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([16.9630,  2.1817,  0.0223], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([24.5119, -4.3527,  0.6603], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([ 44.5465, -35.2413,   1.0523], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([ 45.1856, -40.0252,   1.1841], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([24.6620, 16.4957, -1.1209], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([1.7948e+01, 5.2398e-01, 7.7200e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([ 45.7709, -35.0205,   1.2817], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([ 44.2098, -33.7250,   1.2481], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([22.9125, -3.6225,  0.6602], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([16.7419,  3.0845,  0.0594], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([26.6395, 17.5330, -0.8474], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([23.7234, -3.3299,  1.1437], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([27.5753, 17.9557, -0.5238], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([21.8177, -2.6738,  1.0679], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([ 44.8839, -32.5191,   1.1000], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([21.9020, -3.5113,  1.1277], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([1.8384e+01, 6.1529e-01, 3.2547e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([25.4626, 16.8129, -1.2414], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([25.4351, 17.4593, -1.2281], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([16.8515,  3.8994,  0.0608], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([23.3092, -1.9636,  0.5303], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([25.9646, 17.7169, -1.2468], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.9215, 18.2583, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.9991, -33.8223,   0.1652], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([21.1459, -2.2798,  0.9505], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([23.1696, -3.5011,  1.1510], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([21.5713, -3.3363,  1.0770], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.3713, -3.2696,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.2006, -35.3662,   1.1758], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 43.2096, -32.9716,   1.0000], device='cuda:0')\n",
-      "tensor([1.7263e+01, 1.0393e+00, 1.6066e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.0778,  3.4214,  1.0000], device='cuda:0')\n",
-      "tensor([27.7684, 17.3738,  0.4669], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([45.3506, 18.0112,  0.9953], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([50.5027, 18.5959,  1.0513], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([37.3744, -5.8386,  0.6888], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.2743, -27.2447,   0.5555], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([ 51.6387, -31.0397,   0.8468], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([24.5524, 19.4569,  0.9050], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([24.2394, 18.8239,  0.8832], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([45.0087, 16.7298,  0.2292], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([44.5156, 15.5085,  1.1685], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([ 1.7541e+01,  2.0131e+00, -4.8630e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([48.6423, 16.9927,  1.0624], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([27.6775, 16.9265,  1.0528], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([23.6196, 18.5726,  0.9916], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([1.7953e+01, 9.1990e-03, 5.6586e-01], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([28.0753, 17.4585,  1.0053], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([20.5719, 12.1217, -1.0629], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([21.2473, 11.5207, -0.8434], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([34.1981, -3.6442,  0.7675], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([35.5160, -5.8147,  0.7135], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([17.7641,  0.0203,  0.2386], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([26.3771, 16.5180,  1.0986], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([23.0741,  8.3208, -0.6991], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([21.7606, 12.2207, -1.2206], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([ 51.5355, -31.3089,   0.8295], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([47.0115, 18.1877,  0.6074], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([38.1979, -4.7878,  1.0353], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([24.2371, 19.3842,  0.5825], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([24.3078, 19.6725,  1.0566], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([37.0417, -5.9561,  0.7059], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([ 1.7006e+01,  1.8718e+00, -3.3896e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([ 47.2504, -27.9689,   1.1573], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([20.9418, 12.1344, -1.0992], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([45.6598, 17.6850,  0.9116], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([22.2479, 12.4092, -1.2084], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([47.0971, 18.5995,  1.0467], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([ 48.1816, -27.8349,   1.0276], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([26.3400, 16.4928,  1.0442], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([27.0130, 16.4426,  1.0671], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([36.6436, -5.3281,  0.9428], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([ 49.8435, -29.2734,   0.8564], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([27.7259, 17.4203,  1.0643], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.2559e+01,  1.6479e+01, -7.1920e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([24.3839, 18.9240,  0.9832], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([1.8226e+01, 6.0504e-01, 6.6561e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([ 47.6424, -27.5069,   1.3200], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([18.5114,  0.3200,  0.0315], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([27.6347, 17.0694,  1.0836], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([17.6981,  0.1550,  0.0968], device='cuda:0', grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([ 45.3533, -26.1198,   0.2132], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([28.8183, 17.7870,  0.8339], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([20.1620, 11.9863, -1.1321], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([48.3909, 18.0284,  0.7943], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.5379, 18.5337,  1.0000], device='cuda:0')\n",
-      "tensor([37.8586, -5.2764,  0.7718], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.1128, -26.8198,   1.3595], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([36.0578, -6.1242,  0.8403], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([38.0319, -5.8003,  1.1152], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([1.7983e+01, 1.5616e-02, 4.1088e-01], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([20.5953, 12.0102, -1.1903], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([ 1.7714e+01,  8.4727e-01, -1.6490e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([27.2588, 16.8424,  1.0697], device='cuda:0', grad_fn=<SelectBackward>) tensor([28.3298, 16.5919,  1.0000], device='cuda:0')\n",
-      "tensor([24.0996, 19.1311,  1.1166], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([25.2157, 19.9593,  0.5026], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([37.2529, -6.4199,  0.9335], device='cuda:0', grad_fn=<SelectBackward>) tensor([35.6597, -4.4337,  1.0000], device='cuda:0')\n",
-      "tensor([21.1143, 11.9102, -0.9114], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([24.5080, 18.7854,  0.8182], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([ 1.7304e+01,  1.5815e+00, -2.6718e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([16.4344,  1.3468,  1.0000], device='cuda:0')\n",
-      "tensor([ 52.6274, -29.6235,   0.7102], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.5908, -30.7045,   1.0000], device='cuda:0')\n",
-      "tensor([21.7299, 12.2777, -1.1904], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1091, 12.4644, -1.0000], device='cuda:0')\n",
-      "tensor([24.5432, 19.5908,  1.0037], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.6944, 19.6988,  1.0000], device='cuda:0')\n",
-      "tensor([ 48.1639, -28.5145,  -1.3257], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([32.0019, 26.6397, -1.1649], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([32.1165, 12.5905,  0.0456], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([28.7304, 14.3607,  0.9624], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([2.0859e+01, 8.6323e+00, 3.1196e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([47.7461, -8.3849,  1.1690], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([25.8597, 20.8922, -0.9945], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([46.4431, -6.8762,  0.9621], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([18.2406,  5.1905,  0.0713], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([ 54.1077, -30.4465,  -1.2699], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([17.1021,  3.1857,  0.1222], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([17.2286, 13.7583, -1.1431], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([4.6069e+01, 4.6449e+00, 1.8598e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([24.2882, 11.2915,  1.0395], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([24.4959, 11.5860,  0.8428], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([43.2275,  4.4356, -0.1100], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.4589, -29.3233,  -1.2642], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([29.5395, 13.9458,  1.0556], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([1.5784e+01, 1.2392e+01, 4.4193e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([32.3649, 12.6060,  0.7098], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([ 42.0881, -26.7149,  -0.8660], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([31.0216, 26.6414, -1.1206], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([23.7804, 11.2889,  0.9542], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([ 42.3342, -26.9702,  -1.2818], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([31.6662, 26.6305, -1.1397], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([ 41.3861, -26.5129,  -1.1880], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([30.7623, 25.6517, -0.5856], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.0461, -10.6148,   1.0503], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.8343, -17.1875,  -1.1948], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([1.8842e+01, 4.8756e+00, 1.1441e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([1.7010e+01, 1.0998e+00, 6.0374e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([ 41.6420, -26.5655,  -1.1666], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([27.8856, 23.0059, -0.4784], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([ 4.6144e+01,  4.0165e+00, -1.2932e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([15.9573, 12.7325, -0.0453], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([30.1603, 25.6759, -1.1075], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([33.0890, 28.8386, -0.8282], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([44.9079, -7.6834,  1.2577], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([ 48.7111, -25.7130,  -1.4429], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([ 41.6861, -26.8061,  -1.3106], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([1.7741e+01, 3.0308e-01, 9.8991e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([17.5335,  4.3753,  0.2962], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([33.2634, 12.2586,  0.3365], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([24.2539, 11.3417,  0.9970], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([29.9662, 26.8041, -1.0218], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([49.1592, -7.7543,  1.1602], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([42.5250, -7.2680,  1.1907], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([45.2285, -9.9877,  1.1006], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.4435e+01,  6.0937e+00, -3.4538e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([24.4202, 11.0299,  1.0440], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([29.6907, 24.8335, -1.1392], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([2.8395e+01, 9.9921e+00, 1.9658e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.5632e+01,  4.1621e+00, -3.9749e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([31.0132, 26.7924, -1.1592], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([24.7528, 11.4088,  1.0851], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([46.1363, -8.4528,  1.1295], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([ 41.6044, -27.0621,  -1.0020], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 40.1575, -25.1728,  -1.2345], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.7806e+01,  5.0180e+00, -1.6837e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([4.1045e+01, 6.2937e+00, 1.2046e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([29.7276, 14.2327,  0.9999], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([28.7566, 14.1472,  1.1039], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([1.7636e+01, 1.1737e+01, 2.9489e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([17.8668, 15.0071, -1.1991], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([28.8045, 14.2918,  1.0584], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([3.8797e+01, 6.2271e+00, 3.3374e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([29.5629, 14.0177,  1.0133], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([ 47.2604, -29.8391,  -1.1907], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([1.6598e+01, 1.2691e+01, 2.2851e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([ 39.0897, -25.0488,  -1.1440], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([46.1941, -9.5500,  1.0726], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([4.0250e+01, 6.5744e+00, 1.9062e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([17.0370,  1.2464,  0.0194], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([23.4191, 10.2125,  0.8028], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([ 52.5991, -30.6360,  -1.1983], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.1714, -30.0839,  -1.0000], device='cuda:0')\n",
-      "tensor([22.7708, 11.3404,  0.5429], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([32.0703, 26.3512, -1.1672], device='cuda:0', grad_fn=<SelectBackward>) tensor([32.1656, 27.2873, -1.0000], device='cuda:0')\n",
-      "tensor([ 4.8828e+01,  6.4398e+00, -7.5582e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([16.4979,  2.3589,  0.0554], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([28.8272, 13.8015,  1.0916], device='cuda:0', grad_fn=<SelectBackward>) tensor([29.0483, 13.4259,  1.0000], device='cuda:0')\n",
-      "tensor([ 37.9628, -24.4737,  -0.9050], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 43.8031, -28.4171,  -1.2870], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([1.7140e+01, 6.3404e-05, 6.3291e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.3100,  4.1804,  1.0000], device='cuda:0')\n",
-      "tensor([23.0901, 18.6425, -1.1632], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.6615, 13.3337, -1.0000], device='cuda:0')\n",
-      "tensor([22.5966, 11.1689,  0.8177], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.9298, 10.3572,  1.0000], device='cuda:0')\n",
-      "tensor([49.2041, -8.4592,  1.0448], device='cuda:0', grad_fn=<SelectBackward>) tensor([48.2970, -9.6577,  1.0000], device='cuda:0')\n",
-      "tensor([ 46.2717, -30.4173,  -1.0776], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 41.9591, -26.0762,  -0.9106], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 43.6489, -29.1443,  -1.1057], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.0909, -26.7089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.4414e+01,  4.0448e+00, -8.6032e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.4910,  4.0459,  1.0000], device='cuda:0')\n",
-      "tensor([20.4732,  7.7521, -0.8678], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([ 3.0361e+01, -9.0684e-01,  1.4020e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([2.3867e+01, 1.5737e+00, 6.2276e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([2.8793e+01, 1.6137e-02, 1.9421e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([18.1009,  7.2010, -0.5217], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([20.4995,  6.1244, -0.3843], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([ 2.4375e+01,  5.3006e-01, -2.2653e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.9346e+01, -2.1110e+00,  6.9283e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([ 1.9825e+01,  2.6374e+00, -5.3469e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.2607e+01,  2.6042e+00, -5.4687e-06], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([2.2622e+01, 1.7777e-01, 8.2684e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([19.3176,  7.6769, -0.7170], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([2.3651e+01, 3.5793e-01, 6.9781e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([2.3212e+01, 2.8957e-01, 1.6484e-07], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([20.5678,  6.4029, -0.9347], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([20.6440,  7.0543, -0.5203], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([19.4577,  6.7390, -0.8307], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([25.7861, -2.1049, -0.9565], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([26.9044, -2.0418, -0.9875], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([32.0293, -2.8769,  0.0618], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([ 3.4346e+01, -4.0661e-01,  6.4398e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([25.9423, -1.9959, -0.4250], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([26.4303, -2.0085, -0.1088], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([ 2.1563e+01,  2.6869e+00, -2.6040e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.0031,  2.1301,  1.0000], device='cuda:0')\n",
-      "tensor([26.0292, -1.0818, -0.6359], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([20.7453,  6.8437, -0.9572], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([18.3152,  6.8623, -0.6716], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([28.0052, -2.1346, -0.9193], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([18.1486,  7.7711, -0.3882], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.1449,  7.8380, -1.0000], device='cuda:0')\n",
-      "tensor([26.0147, -2.3663, -0.7187], device='cuda:0', grad_fn=<SelectBackward>) tensor([27.8089, -1.0582, -1.0000], device='cuda:0')\n",
-      "tensor([37.6316, 17.6384,  0.6327], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([38.4320, -5.6872,  1.0864], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([39.4602, 29.9535, -1.1194], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([37.6067, 28.3178, -0.9100], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([41.1823, -6.8072,  0.9684], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.2778, -12.4251,  -1.1322], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([37.0519, 18.6641,  1.0256], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.2364, -11.8132,  -1.0391], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.4481e+01, -6.5600e-01, -5.0757e-08], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([ 30.7749, -12.7462,  -1.1717], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([38.3575, 19.1815,  1.0025], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([41.0319, -3.1314, -0.6708], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([36.5603, 18.9082,  0.9219], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([ 29.2684, -12.0046,  -0.7118], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([40.8006, -8.1951,  0.8819], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.8053e+01, -2.9964e+00,  2.2435e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([23.6557,  5.3420,  0.4148], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([20.6691,  5.0161,  0.4992], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([27.3522,  2.0463,  0.0655], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([39.3495, 30.9496, -1.0776], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([ 28.3781, -12.0150,  -1.0010], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([37.1208, 18.8004,  1.1111], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.9178e+01, -1.0264e+01, -3.6540e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([24.6353,  4.4781,  0.1336], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([39.0446, 18.4038,  1.1690], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([ 29.7751, -11.9870,  -1.0337], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([39.1089, -7.1186,  1.3860], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([39.6200, 29.3303, -0.4647], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([39.4916, 30.8150, -1.0854], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([39.6167, -8.1484,  1.0453], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([43.2562, -3.6169, -0.9345], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([40.7500, -7.5464,  0.9650], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([41.2075, -1.7224, -0.2210], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([41.8914, -6.7456,  1.1842], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([22.6407,  4.9817,  0.0567], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([41.0046, -2.9481, -0.6774], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([37.8384, 29.9754, -1.1338], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([41.1329, 19.6691,  0.1152], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([41.6940, -3.3429,  0.1971], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([ 4.5591e+01, -2.7471e+00,  3.4420e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([40.9958, -6.8056,  0.9397], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([40.8906, -7.7229,  0.9011], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([39.2874, 31.5213, -1.0686], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([ 30.1761, -11.8717,  -1.0767], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([25.5830,  4.6412,  0.3656], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.0866, -11.9596,  -1.0088], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([24.0881,  5.5311,  0.3139], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([43.6374, -3.3421, -0.7984], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([38.3118, 17.2446,  0.8301], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([39.1915, 29.7655, -1.1314], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([36.4061, 18.3137,  1.0203], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([39.7809, -8.1087,  1.0083], device='cuda:0', grad_fn=<SelectBackward>) tensor([38.5897, -6.2761,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.1692e+01,  3.9961e+00, -1.3708e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([38.3595, 19.1461,  1.0342], device='cuda:0', grad_fn=<SelectBackward>) tensor([37.1612, 18.2663,  1.0000], device='cuda:0')\n",
-      "tensor([37.6707, 29.5908, -1.0714], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([40.0692, 32.2023, -1.0258], device='cuda:0', grad_fn=<SelectBackward>) tensor([41.6190, 31.7445, -1.0000], device='cuda:0')\n",
-      "tensor([2.2357e+01, 4.9793e+00, 2.5894e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.3413, -12.3630,  -1.1304], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 30.7383, -12.9980,  -1.0000], device='cuda:0')\n",
-      "tensor([22.5654,  6.4018,  0.1331], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.6845,  5.2091,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.8627e+01, -1.5483e+00,  1.0832e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.2524, -2.5645, -1.0000], device='cuda:0')\n",
-      "tensor([25.0635, 20.6621,  0.9118], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 32.3412, -21.4295,  -0.4783], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([24.8563, 20.7228,  0.9519], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.5998, -21.6088,  -0.9220], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([ 38.3277, -27.7195,  -1.0626], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([24.3583, 21.3949,  1.1643], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([24.7492, 20.6866,  1.0289], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 36.1638, -25.0830,  -1.0250], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([25.0523, 21.1409,  0.4789], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([23.5665, 20.8937,  0.5312], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 32.5937, -21.2133,  -1.0758], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([23.3976, 20.0892,  0.9583], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([24.1440, 20.5512,  1.0356], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 33.6129, -23.0956,  -0.9738], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([ 30.0960, -15.5063,  -1.1366], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([ 38.0785, -29.6126,  -1.0845], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([24.8373, 21.4133,  1.1694], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([23.4217, 19.6150,  0.9108], device='cuda:0', grad_fn=<SelectBackward>) tensor([24.3244, 21.0145,  1.0000], device='cuda:0')\n",
-      "tensor([ 30.4280, -20.8386,  -0.9225], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.3170, -22.2782,  -1.0892], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 29.8802, -19.5947,  -1.0000], device='cuda:0')\n",
-      "tensor([27.2292,  7.9937, -0.8391], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 31.8698, -18.5931,   1.4277], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 48.1254, -30.4452,  -0.8618], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.5653, -19.2922,  -1.1136], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 33.5700, -20.4197,   1.2511], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 39.1715, -22.6338,   1.1657], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 33.3085, -20.2111,   1.0551], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 42.2549, -26.4990,  -1.3056], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([24.7784,  8.8442, -0.4713], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([27.0000,  8.2584, -0.2980], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 44.0308, -23.1981,   0.7422], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 42.6640, -24.9193,   1.0270], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 48.1079, -32.5155,  -0.8624], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 43.0763, -25.1173,  -1.0208], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.7897, -18.1567,  -1.2757], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.2616, -19.1610,   0.9457], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 50.7671, -27.0119,  -1.0360], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 31.1080, -17.7125,   0.6052], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 39.6060, -23.2370,  -1.2991], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([26.9951,  8.1046, -0.8100], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 29.6949, -16.4559,   1.0694], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.1768, -20.4686,   0.6178], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 45.3915, -21.4775,   0.9351], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 29.9549, -18.3827,   1.1334], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.7118, -21.7746,   0.8704], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 51.9191, -35.4677,  -1.1198], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 46.7065, -30.8349,  -1.2729], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 45.9194, -26.0154,  -1.3024], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 27.8645, -16.0591,   1.1560], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([25.9221,  9.7349, -0.3596], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 40.1617, -22.3173,  -1.3455], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 33.0416, -20.6618,   1.0726], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([25.0358,  7.8745, -0.6312], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 35.2067, -17.9522,   1.1347], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([26.5732,  8.0706, -0.7725], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 35.0165, -15.6279,   0.7247], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 48.9671, -30.7986,  -1.3131], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 41.9918, -24.1578,  -1.2832], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 46.2006, -30.1672,  -0.8878], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 43.5084, -25.8403,  -1.3615], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 48.5722, -31.7141,  -1.0249], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([25.8978,  7.6763, -0.7499], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([24.7793,  7.4680, -0.6518], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([24.9587,  6.3740, -0.5758], device='cuda:0', grad_fn=<SelectBackward>) tensor([26.9997,  8.4866, -1.0000], device='cuda:0')\n",
-      "tensor([ 48.6529, -26.0149,  -0.9965], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 46.3356, -30.3369,  -0.7518], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.1559, -27.4095,  -1.0000], device='cuda:0')\n",
-      "tensor([ 50.1795, -34.1627,  -1.0129], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 49.4276, -31.1958,  -1.0000], device='cuda:0')\n",
-      "tensor([ 29.1484, -15.9217,   1.3702], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([ 44.0147, -25.0389,   1.0110], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 42.3723, -23.8952,   1.0000], device='cuda:0')\n",
-      "tensor([ 38.0040, -21.0520,   0.8675], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 32.0675, -16.8338,   1.0000], device='cuda:0')\n",
-      "tensor([19.1694, -8.4264,  0.9726], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([19.3052, 14.7226, -1.2652], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([19.9093, 14.4648, -1.2532], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([43.7420, -9.4681, -0.9711], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([24.6558, -1.0284, -0.7798], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([40.4085, 23.6050, -1.1083], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([ 45.7367, -11.8549,   1.2197], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([15.9912,  1.8245,  0.0539], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([20.4814, 14.6420, -1.1478], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([ 1.7310e+01,  1.3532e+01, -2.5872e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([ 45.8967, -11.2985,   1.1787], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([19.1737,  6.5416,  0.4160], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([17.7633,  4.8228,  0.3674], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.0003e+01,  1.8229e-02, -5.8753e-01], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([45.6128, -9.8662, -1.0718], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([39.9717, -9.6078, -0.5851], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([ 28.3255, -17.3660,  -0.9996], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 50.5374, -10.9733,   1.1294], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([2.2874e+01, 3.3643e-04, 2.0508e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([1.7383e+01, 5.4251e-01, 2.2851e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([41.7526, -9.6131,  1.1053], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([38.8679, 22.0989, -1.0209], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([42.2459, 24.2224, -1.1425], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([23.0029, -0.4130, -0.5072], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([37.1308, 20.9270, -0.6662], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([24.6513, -1.0274, -0.7799], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([36.7437, 21.7721, -0.5055], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([38.8172, 22.1275, -1.0668], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([32.5541, -7.1424, -0.4088], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([ 21.7859, -10.9481,   0.9601], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 27.7086, -17.2293,  -1.0346], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.4475, -15.1250,   1.1521], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 29.3695, -17.8955,  -1.0002], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([17.9851, -7.8031,  1.0950], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.4604e+01, -9.2402e+00, -2.2697e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([ 34.6389, -22.0240,   1.0612], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([2.1917e+01, 3.7318e-04, 1.0870e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([45.7130, -9.6971, -1.1591], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([ 48.5334, -11.1791,   1.1318], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([20.6993, 13.5720, -0.8054], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([ 2.2089e+01, -3.6863e-02, -1.7284e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([ 27.2232, -16.6841,  -1.0463], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 28.3570, -17.2013,  -1.0628], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([18.6096, -8.1778,  1.0952], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 41.1040, -10.5154,  -0.4078], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([2.2622e+01, 4.7181e-05, 9.8465e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.9590, -10.0802,   1.0000], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([ 31.0548, -19.3935,  -0.9932], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 32.7773, -15.3948,   0.4964], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 33.4972, -22.4312,  -1.0192], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 46.2448, -12.3461,   1.2108], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([17.7250,  3.3450,  0.0559], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([ 45.7980, -10.8379,  -1.0088], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([ 47.2279, -11.1517,   1.1422], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([18.1354,  0.1791, -0.6717], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([ 28.9363, -17.8795,  -1.1328], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([21.1007, -9.8037,  1.0609], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 2.0315e+01,  1.5277e+01, -5.1279e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([22.0932, -0.3574, -0.8531], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([17.2614, 13.4807, -0.1066], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([45.1314, -9.8459,  1.3050], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([39.3175, 22.6438, -1.1115], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([45.1563, -9.9030, -1.3124], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([23.0284, -0.3491, -0.1983], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.4631,  0.6105, -1.0000], device='cuda:0')\n",
-      "tensor([17.9584, 13.7529, -0.9381], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([40.2954, 23.0237, -1.1225], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([39.6436, 22.8016, -1.1094], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([16.3021,  4.4033,  0.4693], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([49.8576, -9.7559,  1.2227], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 48.9321, -11.7934,   1.0000], device='cuda:0')\n",
-      "tensor([45.7060, -9.8630, -1.2551], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([ 1.8570e+01,  1.4343e+01, -5.7742e-08], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([36.4904, 20.6650, -0.9052], device='cuda:0', grad_fn=<SelectBackward>) tensor([42.2122, 23.1191, -1.0000], device='cuda:0')\n",
-      "tensor([ 43.3137, -10.5829,   0.0456], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.5450, -9.8693, -1.0000], device='cuda:0')\n",
-      "tensor([16.3764,  2.3267,  0.0347], device='cuda:0', grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([ 26.4741, -15.8986,  -0.2672], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 30.3962, -15.5043,   0.7691], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 1.9314e+01, -3.2709e-01,  8.9996e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([15.7065,  5.4932,  1.0000], device='cuda:0')\n",
-      "tensor([20.2633, 14.9293, -1.2018], device='cuda:0', grad_fn=<SelectBackward>) tensor([19.3354, 15.3564, -1.0000], device='cuda:0')\n",
-      "tensor([19.7943, -8.5712,  1.0701], device='cuda:0', grad_fn=<SelectBackward>) tensor([18.5312, -8.2375,  1.0000], device='cuda:0')\n",
-      "tensor([ 27.5721, -16.4542,  -1.0861], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 26.6597, -15.5906,  -1.0000], device='cuda:0')\n",
-      "tensor([ 36.8004, -14.0253,  -0.1525], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 37.6987, -12.7500,  -0.9818], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 36.8323, -13.1476,  -0.8427], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 37.0691, -13.0756,  -1.2426], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 37.7271, -12.7907,  -1.1204], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.7225e+01,  3.1429e+00, -5.7094e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([4.8059e+01, 4.4811e-01, 1.0074e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([5.0588e+01, 5.3723e-01, 1.1402e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([4.5107e+01, 1.1715e+00, 3.5800e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.4905e+01,  2.2869e+00, -3.3138e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 35.8117, -13.7389,  -0.5532], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.6455e+01,  3.2318e+00, -2.4588e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 37.7274, -12.8226,  -1.1574], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 37.3657, -12.9295,  -1.1164], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([42.8013,  3.1678, -0.0764], device='cuda:0', grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 37.8884, -13.3035,  -1.2201], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.4989e+01,  3.4468e+00, -2.9004e-02], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 36.7744, -12.8364,  -1.1663], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 38.0250, -13.6089,  -1.0000], device='cuda:0')\n",
-      "tensor([ 4.5628e+01,  3.1252e+00, -8.4812e-03], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([ 4.8861e+01,  1.6628e+00, -6.3367e-04], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([47.3939,  0.8490,  1.0000], device='cuda:0')\n",
-      "tensor([21.1452, 14.2958,  1.0402], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 34.3848, -21.0683,   0.4999], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.1567, -22.2870,   0.9020], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([20.7149, -8.4735, -0.9143], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([22.1994, 14.6790,  0.9295], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 31.6820, -19.2839,   1.0733], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([43.4429, -9.6276, -0.5950], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 45.2725, -13.6588,   1.2365], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([ 47.2706, -11.9890,   1.1404], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([37.7684,  9.9255, -0.3758], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([21.2967, -9.2416, -0.7403], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([46.9732, -9.0880, -1.1894], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 41.1978, -11.2936,  -1.3125], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([45.6473, -8.7864, -1.0961], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 33.3934, -13.4733,  -0.0717], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.2767, -13.3457,   1.3039], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([ 35.7915, -23.1989,   1.4267], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([24.5251, -8.3163, -1.0842], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([19.2190, -8.1142, -0.0356], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([23.9683, -9.7375, -1.1503], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([21.8635, -9.6428, -1.1142], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([ 47.6516, -11.7902,   1.0446], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([28.3642, -9.4880, -1.0699], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([45.1132, -8.6117, -0.9859], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([34.4113,  8.6637, -0.7571], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([ 4.4134e+01, -8.3850e+00,  1.2796e-05], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([22.0105, 14.7682,  0.4353], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 42.1805, -14.1110,  -1.3199], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([ 33.1469, -12.6442,  -0.5486], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([22.9424, 13.8233,  0.7787], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 39.9691, -30.4766,   1.3957], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([ 46.1071, -32.6982,   0.8277], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.9858, -22.7988,   0.9687], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([ 47.4768, -12.7926,   0.9172], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([43.5278, -8.5838, -0.9152], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 37.6509, -23.5464,   1.0267], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([36.0453,  9.8700, -0.2599], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([ 37.4979, -26.4122,   1.0523], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([22.5580, 15.2765,  0.9946], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 39.3663, -27.1656,   1.0368], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([20.3253, -8.3980, -1.0026], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([34.1808, -8.9038, -1.1762], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([35.4480,  9.0929, -0.6705], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([36.7542,  9.2998, -0.5362], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([ 35.5665, -14.0888,  -0.1037], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([ 43.2548, -30.9784,   0.8108], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([ 43.7007, -11.5399,   1.3480], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([ 40.7450, -11.0795,   0.8547], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.3603, -22.9301,   0.9941], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([25.3835, -8.7454, -1.0970], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([ 43.7655, -32.5143,   1.4511], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([21.9805, 14.6549,  0.9896], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([ 42.7131, -14.0731,  -1.2423], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([36.3246,  9.1050, -0.6384], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([22.2379, 15.5507,  0.3626], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([41.2401, -9.1022,  0.0708], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 47.5700, -32.0633,   0.7148], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([ 44.4812, -29.9610,   0.1999], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([21.5474, -9.3747, -0.6336], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([22.3830, -9.6972, -1.0111], device='cuda:0', grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([44.0308, -9.5210, -0.1934], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 24.7156, -11.5502,  -1.0125], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.2647, -12.7126,   1.1559], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([21.9339, 13.5515,  0.6462], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([22.3797, 15.6557,  0.4092], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([44.3779, -9.2008, -0.8399], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([39.1298,  8.9210, -0.5924], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([39.6513,  9.4132, -0.8297], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([ 22.2594, -10.0362,  -1.0848], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([21.1108, -8.7940, -1.0000], device='cuda:0')\n",
-      "tensor([ 39.1314, -27.1075,   1.1799], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([ 48.3564, -12.1008,   1.0983], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([28.6191, -9.6940, -0.8227], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([ 43.2633, -15.0926,  -1.2950], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([24.7170, -8.7339, -1.1214], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([29.0598,  3.9818,  0.2646], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([21.7672, 14.6257,  0.9070], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([34.6777,  9.0611, -0.7263], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([25.9458, -8.9930, -1.1087], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([36.9219,  8.8780, -0.7726], device='cuda:0', grad_fn=<SelectBackward>) tensor([36.8643,  8.5166, -1.0000], device='cuda:0')\n",
-      "tensor([ 36.9911, -23.7474,   1.3183], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([34.7247, -9.9405, -0.9778], device='cuda:0', grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n",
-      "tensor([ 34.3366, -22.1937,   0.8130], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([21.8759, 14.8030,  1.0215], device='cuda:0', grad_fn=<SelectBackward>) tensor([22.2387, 15.0933,  1.0000], device='cuda:0')\n",
-      "tensor([46.1893, -9.2882, -1.2502], device='cuda:0', grad_fn=<SelectBackward>) tensor([45.9062, -8.7200, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.0888, -12.8163,   1.2269], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 45.2991, -12.1745,   1.0000], device='cuda:0')\n",
-      "tensor([ 30.9451, -11.3676,  -0.3238], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([ 46.2089, -33.2701,   1.1292], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 46.1681, -33.3355,   1.0000], device='cuda:0')\n",
-      "tensor([26.8774, -9.5045, -1.0295], device='cuda:0', grad_fn=<SelectBackward>) tensor([23.7561, -8.1230, -1.0000], device='cuda:0')\n",
-      "tensor([ 37.6442, -23.3092,   0.8890], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 37.1662, -23.3223,   1.0000], device='cuda:0')\n",
-      "tensor([ 36.6121, -12.8179,  -0.8288], device='cuda:0',\n",
-      "       grad_fn=<SelectBackward>) tensor([ 44.6086, -15.7559,  -1.0000], device='cuda:0')\n"
-     ]
-    }
-   ],
-   "source": [
-    "for pred, dat in zip(node_pred, data.y_nodes):\n",
-    "    print(pred, dat)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 65,
-   "metadata": {
-    "collapsed": true,
-    "jupyter": {
-     "outputs_hidden": true
+     "data": {
+      "text/plain": [
+       "[<matplotlib.lines.Line2D at 0x2aab7fcdaf60>]"
+      ]
+     },
+     "execution_count": 47,
+     "metadata": {},
+     "output_type": "execute_result"
+    },
+    {
+     "data": {
+      "image/png": "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\n",
+      "text/plain": [
+       "<Figure size 1152x288 with 2 Axes>"
+      ]
+     },
+     "metadata": {
+      "needs_background": "light"
+     },
+     "output_type": "display_data"
+    }
+   ],
+   "source": [
+    "fig, axs = plt.subplots(1,2)\n",
+    "fig.set_size_inches(16,4)\n",
+    "axs[0].plot(np.arange(len(loss_v_node)), loss_v_node)\n",
+    "# axs[1].plot(np.arange(len(loss_v_edge)), loss_v_edge)\n",
+    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
+    "# axs[3].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 10,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "0.0 0.0\n"
+     ]
     }
+   ],
+   "source": [
+    "torch.cuda.empty_cache()\n",
+    "torch.cuda.reset_max_memory_allocated()\n",
+    "torch.cuda.reset_max_memory_cached()\n",
+    "print(torch.cuda.memory_allocated(0)/1024**3, torch.cuda.max_memory_allocated(0)/1024**3)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {
+    "heading_collapsed": true
+   },
+   "source": [
+    "## Getting Weights & Bias to Work"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 18,
+   "metadata": {
+    "hidden": true
    },
    "outputs": [
     {
      "data": {
       "text/plain": [
-       "['AGNNConv',\n",
-       " 'APPNP',\n",
-       " 'ARGA',\n",
-       " 'ARGVA',\n",
-       " 'ARMAConv',\n",
-       " 'ChebConv',\n",
-       " 'DNAConv',\n",
-       " 'DataParallel',\n",
-       " 'DeepGraphInfomax',\n",
-       " 'DenseGCNConv',\n",
-       " 'DenseGINConv',\n",
-       " 'DenseSAGEConv',\n",
-       " 'DynamicEdgeConv',\n",
-       " 'ECConv',\n",
-       " 'EdgeConv',\n",
-       " 'FeaStConv',\n",
-       " 'GAE',\n",
-       " 'GATConv',\n",
-       " 'GCNConv',\n",
-       " 'GINConv',\n",
-       " 'GMMConv',\n",
-       " 'GatedGraphConv',\n",
-       " 'GlobalAttention',\n",
-       " 'GraphConv',\n",
-       " 'HypergraphConv',\n",
-       " 'InnerProductDecoder',\n",
-       " 'JumpingKnowledge',\n",
-       " 'MessagePassing',\n",
-       " 'MetaLayer',\n",
-       " 'NNConv',\n",
-       " 'PPFConv',\n",
-       " 'PointConv',\n",
-       " 'RENet',\n",
-       " 'RGCNConv',\n",
-       " 'Reshape',\n",
-       " 'SAGEConv',\n",
-       " 'SAGPooling',\n",
-       " 'SGConv',\n",
-       " 'Set2Set',\n",
-       " 'SignedConv',\n",
-       " 'SignedGCN',\n",
-       " 'SplineConv',\n",
-       " 'TopKPooling',\n",
-       " 'VGAE',\n",
-       " 'XConv',\n",
-       " '__all__',\n",
-       " '__builtins__',\n",
-       " '__cached__',\n",
-       " '__doc__',\n",
-       " '__file__',\n",
-       " '__loader__',\n",
-       " '__name__',\n",
-       " '__package__',\n",
-       " '__path__',\n",
-       " '__spec__',\n",
-       " 'avg_pool',\n",
-       " 'avg_pool_x',\n",
-       " 'conv',\n",
-       " 'data_parallel',\n",
-       " 'dense',\n",
-       " 'dense_diff_pool',\n",
-       " 'fps',\n",
-       " 'glob',\n",
-       " 'global_add_pool',\n",
-       " 'global_max_pool',\n",
-       " 'global_mean_pool',\n",
-       " 'global_sort_pool',\n",
-       " 'graclus',\n",
-       " 'inits',\n",
-       " 'knn',\n",
-       " 'knn_graph',\n",
-       " 'knn_interpolate',\n",
-       " 'max_pool',\n",
-       " 'max_pool_x',\n",
-       " 'meta',\n",
-       " 'models',\n",
-       " 'nearest',\n",
-       " 'pool',\n",
-       " 'radius',\n",
-       " 'radius_graph',\n",
-       " 'reshape',\n",
-       " 'unpool',\n",
-       " 'voxel_grid']"
+       "Sequential(\n",
+       "  (0): Linear(in_features=19, out_features=16, bias=True)\n",
+       "  (1): ReLU()\n",
+       "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
+       "  (3): ReLU()\n",
+       "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
+       ")"
       ]
      },
-     "execution_count": 65,
+     "execution_count": 18,
      "metadata": {},
      "output_type": "execute_result"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "Retry attempt failed:\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
+      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
+      "    raise err\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
+      "    sock.connect(sa)\n",
+      "OSError: [Errno 101] Network is unreachable\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
+      "    chunked=chunked,\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
+      "    self._validate_conn(conn)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
+      "    conn.connect()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 334, in connect\n",
+      "    conn = self._new_conn()\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connection.py\", line 169, in _new_conn\n",
+      "    self, \"Failed to establish a new connection: %s\" % e\n",
+      "urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
+      "    timeout=timeout\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
+      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
+      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
+      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576271582&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=MmIGu%2F4ONY2zZtXV60r4n2VtQ%2F7%2BfOmVBHMam3wT3aKVoHGK84OediGBAASfRnCU%2ByxJnJoe6wgqBm8OA4RFnwbWS%2BT1gP1VBHVekU3e0%2FBjKnK8lLsunIwyrwC9DhNkHSaiPTduRingNiJZ1K096%2BHtW8DSs%2BVkivZt%2FHH4Sh24d1JcpFjjkb8GUWGOc2XuFhCKq%2FQ6v7cIiQPmaCfZ7tIsPYZNaEJ5WnLcgsMIcUFlMpayxtmovih59VHK9%2Bu7pLnnEIleq%2FVVwSp1Nxn3Cuvyf%2FefL9nIOD9RrfbYHqTIWZB2cEMVI4XuNkEPrYUuV5aNadYZ%2BXP1VYzyt%2BGgVQ%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
+      "    url, data=progress, headers=extra_headers)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
+      "    return request('put', url, data=data, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
+      "    raise ConnectionError(e, request=request)\n",
+      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /wandb-production.appspot.com/murnanedaniel/node_regression/fwpw76ra/wandb-metadata.json?Expires=1576271582&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=MmIGu%2F4ONY2zZtXV60r4n2VtQ%2F7%2BfOmVBHMam3wT3aKVoHGK84OediGBAASfRnCU%2ByxJnJoe6wgqBm8OA4RFnwbWS%2BT1gP1VBHVekU3e0%2FBjKnK8lLsunIwyrwC9DhNkHSaiPTduRingNiJZ1K096%2BHtW8DSs%2BVkivZt%2FHH4Sh24d1JcpFjjkb8GUWGOc2XuFhCKq%2FQ6v7cIiQPmaCfZ7tIsPYZNaEJ5WnLcgsMIcUFlMpayxtmovih59VHK9%2Bu7pLnnEIleq%2FVVwSp1Nxn3Cuvyf%2FefL9nIOD9RrfbYHqTIWZB2cEMVI4XuNkEPrYUuV5aNadYZ%2BXP1VYzyt%2BGgVQ%3D%3D (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2aab57fa9fd0>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
+      "\n",
+      "During handling of the above exception, another exception occurred:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/retry.py\", line 95, in __call__\n",
+      "    result = self._call_fn(*args, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 980, in upload_file\n",
+      "    util.sentry_reraise(retry.TransientException(exc=e))\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/util.py\", line 92, in sentry_reraise\n",
+      "    six.reraise(type(exc), exc, sys.exc_info()[2])\n",
+      "  File \"/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/six.py\", line 692, in reraise\n",
+      "    raise value.with_traceback(tb)\n",
+      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/wandb/apis/internal.py\", line 974, in upload_file\n",
+      "    url, data=progress, headers=extra_headers)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 131, in put\n",
+      "    return request('put', url, data=data, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
+      "    return session.request(method=method, url=url, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
+      "    resp = self.send(prep, **send_kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
+      "    r = adapter.send(request, **kwargs)\n",
+      "  File \"/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
+      "    raise ConnectionError(e, request=request)\n",
+      "wandb.retry.TransientException: None\n",
+      "wandb: Network error (TransientException), entering retry loop. See /global/u2/d/danieltm/ExaTrkX/GNN-Sandbox/notebooks/wandb/debug.log for full traceback.\n",
+      "wandb: ERROR Error uploading \"wandb-metadata.json\": CommError, None\n"
+     ]
+    }
+   ],
+   "source": [
+    "model.output_network"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Sweep"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 11,
+   "metadata": {
+    "code_folding": []
+   },
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Create sweep with ID: zra8ov9k\n",
+      "Sweep URL: https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\n"
+     ]
+    }
+   ],
+   "source": [
+    "# System imports\n",
+    "import os\n",
+    "import sys\n",
+    "from pprint import pprint as pp\n",
+    "from time import time as tt\n",
+    "sys.path.append('..')\n",
+    "sys.path.append('/global/common/cori_cle7/software/jupyter/19-11/lib/python3.7/site-packages')\n",
+    "sys.path.append('/global/homes/d/danieltm/.local/lib/python3.7/site-packages')\n",
+    "import wandb\n",
+    "# External imports\n",
+    "import numpy as np\n",
+    "import torch\n",
+    "import torch.nn.functional as F\n",
+    "import torch.nn as nn\n",
+    "\n",
+    "sweep_config = {\n",
+    "    \"name\": \"Track Param Sweep\",\n",
+    "    \"method\": \"random\",\n",
+    "#     \"controller\": \"local\",\n",
+    "    \"metric\": {\n",
+    "        \"name\": \"Best Accuracy\",\n",
+    "        \"goal\": \"maximize\"\n",
+    "    },\n",
+    "#     \"early_terminate\": {\n",
+    "#         \"type\": \"hyperband\",\n",
+    "#         \"min_iter\": 3\n",
+    "#     },\n",
+    "    \"parameters\": {\n",
+    "        \"n_graph_iters\": {\n",
+    "            \"min\": 1,\n",
+    "            \"max\": 8\n",
+    "        },\n",
+    "        \"hidden_dim\": {\n",
+    "            \"min\": 4,\n",
+    "            \"max\": 64\n",
+    "        },\n",
+    "        \"lr\": {\n",
+    "            \"distribution\": \"log_uniform\",\n",
+    "            \"min\": -11.5,\n",
+    "            \"max\": -2.3\n",
+    "        },\n",
+    "#         \"step_size\": {\n",
+    "#             \"min\": 1,\n",
+    "#             \"max\": 100\n",
+    "#         },\n",
+    "#         \"gamma\": {\n",
+    "#             \"min\": 0.01,\n",
+    "#             \"max\": 0.99\n",
+    "#         },\n",
+    "#         \"weight_decay\": {\n",
+    "#             \"distribution\": \"log_uniform\",\n",
+    "#             \"min\": -11.5,\n",
+    "#             \"max\": -4.6\n",
+    "#         },\n",
+    "        \"network\": {\n",
+    "            \"values\": [\"Edge_Track_Truth_Net\"]\n",
+    "        },\n",
+    "        \"optimizer\": {\n",
+    "            \"values\": [\"AdamW\"] #, \"Adam\", \"Adamax\", \"SGD\"] \n",
+    "        },\n",
+    "        \"train_size\": {\n",
+    "            \"min\": 100,\n",
+    "            \"max\": 800\n",
+    "        },\n",
+    "        \"epochs\": {\n",
+    "            \"min\": 30,\n",
+    "            \"max\": 250\n",
+    "        }\n",
+    "    }\n",
+    "}\n",
+    "\n",
+    "sweep_id = wandb.sweep(sweep_config, entity= \"murnanedaniel\", project= \"node_regression_sweep\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {
+    "code_folding": [
+     38,
+     64,
+     109,
+     150,
+     163
+    ]
+   },
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "wandb: Agent Starting Run: fsh2uyeg with config:\n",
+      "\tepochs: 77\n",
+      "\thidden_dim: 61\n",
+      "\tlr: 1.8854813537267455e-05\n",
+      "\tn_graph_iters: 7\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 535\n",
+      "wandb: Agent Started Run: fsh2uyeg\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fsh2uyeg\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fsh2uyeg</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 77, 'hidden_dim': 61, 'lr': 1.8854813537267455e-05, 'n_graph_iters': 7, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 535}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 61, 'n_graph_iters': 7, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  3.2173675537109374 , validation accuracy:  0.0 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  2 , validation loss:  2.0348384857177733 , validation accuracy:  12.014543408394923 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  3 , validation loss:  2.0008333206176756 , validation accuracy:  11.867377966303442 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  4 , validation loss:  1.9651144027709961 , validation accuracy:  11.491889669202385 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  5 , validation loss:  1.9387147903442383 , validation accuracy:  10.85164785618185 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  6 , validation loss:  1.9064964294433593 , validation accuracy:  11.70542384008022 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  7 , validation loss:  1.890129852294922 , validation accuracy:  13.788824804590986 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  8 , validation loss:  1.8820430755615234 , validation accuracy:  13.578897629842842 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  9 , validation loss:  1.8787841796875 , validation accuracy:  11.21487236644195 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  10 , validation loss:  1.8771022796630858 , validation accuracy:  11.056164536735452 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  11 , validation loss:  1.8764215469360352 , validation accuracy:  11.019012476599613 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  12 , validation loss:  1.8761882781982422 , validation accuracy:  10.811249499529287 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  13 , validation loss:  1.8757246017456055 , validation accuracy:  10.970678728461724 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  14 , validation loss:  1.876316452026367 , validation accuracy:  10.584369442971587 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  15 , validation loss:  1.8753456115722655 , validation accuracy:  10.922344980323837 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  16 , validation loss:  1.8752079010009766 , validation accuracy:  10.863190243796868 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  17 , validation loss:  1.875006866455078 , validation accuracy:  10.96779313155797 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  18 , validation loss:  1.8757440567016601 , validation accuracy:  10.549020880900596 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  19 , validation loss:  1.8747888565063477 , validation accuracy:  10.907916995805063 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  20 , validation loss:  1.8747465133666992 , validation accuracy:  11.078527912739549 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  21 , validation loss:  1.875246238708496 , validation accuracy:  10.577155450712201 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  22 , validation loss:  1.8748184204101563 , validation accuracy:  10.700514718347707 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  23 , validation loss:  1.874533462524414 , validation accuracy:  10.796100115784576 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  24 , validation loss:  1.8743282318115235 , validation accuracy:  10.906113497740217 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  25 , validation loss:  1.8766510009765625 , validation accuracy:  10.305187942533339 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  26 , validation loss:  1.8745595932006835 , validation accuracy:  10.62476779962415 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  27 , validation loss:  1.8743480682373046 , validation accuracy:  10.694382824927228 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  28 , validation loss:  1.874081802368164 , validation accuracy:  10.794657317332698 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  29 , validation loss:  1.874489974975586 , validation accuracy:  10.600600925555206 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  30 , validation loss:  1.8739404678344727 , validation accuracy:  10.782754230104711 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  31 , validation loss:  1.8737707138061523 , validation accuracy:  10.869322137217347 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  32 , validation loss:  1.8737693786621095 , validation accuracy:  11.079610011578458 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  33 , validation loss:  1.873524284362793 , validation accuracy:  10.967071732332032 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  34 , validation loss:  1.8760786056518555 , validation accuracy:  10.297252551048013 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  35 , validation loss:  1.8733858108520507 , validation accuracy:  10.929558972583223 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  36 , validation loss:  1.873359489440918 , validation accuracy:  10.8675186391525 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  37 , validation loss:  1.8745513916015626 , validation accuracy:  10.4725525629511 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  38 , validation loss:  1.873743438720703 , validation accuracy:  10.606732818975685 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  39 , validation loss:  1.873090934753418 , validation accuracy:  10.928476873744314 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  40 , validation loss:  1.8730995178222656 , validation accuracy:  10.821349088692427 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  41 , validation loss:  1.872916030883789 , validation accuracy:  10.940019261359332 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  42 , validation loss:  1.872874641418457 , validation accuracy:  10.948676052070597 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  43 , validation loss:  1.872788429260254 , validation accuracy:  10.936772964842609 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  44 , validation loss:  1.8731853485107421 , validation accuracy:  10.664444757050775 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  45 , validation loss:  1.873497772216797 , validation accuracy:  10.554070675482166 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  46 , validation loss:  1.8727989196777344 , validation accuracy:  10.749209166098565 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  47 , validation loss:  1.8724172592163086 , validation accuracy:  11.001338195564117 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  48 , validation loss:  1.8723691940307616 , validation accuracy:  10.912606090773664 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  49 , validation loss:  1.8739023208618164 , validation accuracy:  10.422415316748365 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  50 , validation loss:  1.8724851608276367 , validation accuracy:  10.743437972291057 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  51 , validation loss:  1.872181510925293 , validation accuracy:  10.971039428074695 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  52 , validation loss:  1.873704719543457 , validation accuracy:  10.418086921392733 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  53 , validation loss:  1.8720338821411133 , validation accuracy:  10.8310879782426 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  54 , validation loss:  1.871882438659668 , validation accuracy:  10.990517207175037 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  55 , validation loss:  1.8719385147094727 , validation accuracy:  10.90503139890131 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  56 , validation loss:  1.871800994873047 , validation accuracy:  10.859222548054207 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  57 , validation loss:  1.8717533111572267 , validation accuracy:  11.043540050281527 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  58 , validation loss:  1.871912384033203 , validation accuracy:  10.728649288159314 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  59 , validation loss:  1.8718534469604493 , validation accuracy:  10.737666778483547 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  60 , validation loss:  1.872329330444336 , validation accuracy:  11.382597686472682 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  61 , validation loss:  1.8713041305541993 , validation accuracy:  10.897456707028953 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  62 , validation loss:  1.8715900421142577 , validation accuracy:  11.208379773408502 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  63 , validation loss:  1.872120475769043 , validation accuracy:  10.523050508766804 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  64 , validation loss:  1.8751829147338868 , validation accuracy:  10.188321267931281 %, lr:  1.8854813537267455e-05\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  65 , validation loss:  1.8711935043334962 , validation accuracy:  10.775900937458294 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  66 , validation loss:  1.8734149932861328 , validation accuracy:  10.322862223568833 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  67 , validation loss:  1.8712543487548827 , validation accuracy:  10.665166156276715 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  68 , validation loss:  1.8707679748535155 , validation accuracy:  10.887717817478782 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  69 , validation loss:  1.8706295013427734 , validation accuracy:  11.042818651055587 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  70 , validation loss:  1.8704252243041992 , validation accuracy:  10.954807945491075 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  71 , validation loss:  1.8705272674560547 , validation accuracy:  10.855615551924513 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  72 , validation loss:  1.870419692993164 , validation accuracy:  10.818102792175704 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  73 , validation loss:  1.8703176498413085 , validation accuracy:  10.871125635282192 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  74 , validation loss:  1.8700416564941407 , validation accuracy:  10.9991739978863 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  75 , validation loss:  1.8704484939575194 , validation accuracy:  10.661559160147021 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  76 , validation loss:  1.8717390060424806 , validation accuracy:  10.413037126811163 %, lr:  1.8854813537267455e-05\n",
+      "Epoch:  77 , validation loss:  1.8696632385253906 , validation accuracy:  10.933165968712915 %, lr:  1.8854813537267455e-05\n",
+      "wandb: Agent Finished Run: fsh2uyeg \n",
+      "\n",
+      "wandb: Agent Starting Run: b1emq1m4 with config:\n",
+      "\tepochs: 37\n",
+      "\thidden_dim: 58\n",
+      "\tlr: 1.5547456939150375e-05\n",
+      "\tn_graph_iters: 2\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 454\n",
+      "wandb: Agent Started Run: b1emq1m4\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/b1emq1m4\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/b1emq1m4</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 37, 'hidden_dim': 58, 'lr': 1.5547456939150375e-05, 'n_graph_iters': 2, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 454}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 58, 'n_graph_iters': 2, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  2.8571355819702147 , validation accuracy:  0.0 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  2 , validation loss:  2.7673583984375 , validation accuracy:  0.0 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  3 , validation loss:  1.944607925415039 , validation accuracy:  11.817962119326646 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  4 , validation loss:  1.9348716735839844 , validation accuracy:  11.49946436107474 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  5 , validation loss:  1.9292457580566407 , validation accuracy:  11.388368880280192 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  6 , validation loss:  1.9213788986206055 , validation accuracy:  11.606592146126628 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  7 , validation loss:  1.9147760391235351 , validation accuracy:  12.027528594461819 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  8 , validation loss:  1.9084299087524415 , validation accuracy:  11.432734932675418 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  9 , validation loss:  1.9026792526245118 , validation accuracy:  11.524713333982593 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  10 , validation loss:  1.8961021423339843 , validation accuracy:  13.350574774833266 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  11 , validation loss:  1.891566848754883 , validation accuracy:  13.70802809128586 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  12 , validation loss:  1.8860797882080078 , validation accuracy:  12.530704554554012 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  13 , validation loss:  1.8821338653564452 , validation accuracy:  11.904890726052251 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  14 , validation loss:  1.8819236755371094 , validation accuracy:  10.720713896673988 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  15 , validation loss:  1.8784551620483398 , validation accuracy:  11.182048701661742 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  16 , validation loss:  1.8777942657470703 , validation accuracy:  10.970318028848755 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  17 , validation loss:  1.8781505584716798 , validation accuracy:  10.632342491496507 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  18 , validation loss:  1.877005386352539 , validation accuracy:  11.154635531076075 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  19 , validation loss:  1.8768970489501953 , validation accuracy:  10.782754230104711 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  20 , validation loss:  1.8767522811889648 , validation accuracy:  10.75750525719686 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  21 , validation loss:  1.877646255493164 , validation accuracy:  10.52557540605759 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  22 , validation loss:  1.8781600952148438 , validation accuracy:  10.412676427198193 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  23 , validation loss:  1.876469039916992 , validation accuracy:  10.716385501318356 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  24 , validation loss:  1.8765369415283204 , validation accuracy:  10.67310154776204 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  25 , validation loss:  1.8760759353637695 , validation accuracy:  10.79357521849379 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  26 , validation loss:  1.8757495880126953 , validation accuracy:  10.915852387290387 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  27 , validation loss:  1.8774555206298829 , validation accuracy:  10.436843301267137 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  28 , validation loss:  1.876645851135254 , validation accuracy:  10.569220059226875 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  29 , validation loss:  1.8755924224853515 , validation accuracy:  10.794657317332698 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  30 , validation loss:  1.8755172729492187 , validation accuracy:  10.79790361384942 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  31 , validation loss:  1.875286865234375 , validation accuracy:  11.000977495951147 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  32 , validation loss:  1.8753164291381836 , validation accuracy:  10.836498472437139 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  33 , validation loss:  1.8752912521362304 , validation accuracy:  10.803314108043963 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  34 , validation loss:  1.8750947952270507 , validation accuracy:  10.923066379549775 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  35 , validation loss:  1.875575065612793 , validation accuracy:  10.623325001172274 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  36 , validation loss:  1.875286865234375 , validation accuracy:  10.697989821056922 %, lr:  1.5547456939150375e-05\n",
+      "Epoch:  37 , validation loss:  1.8749725341796875 , validation accuracy:  10.793214518880822 %, lr:  1.5547456939150375e-05\n",
+      "wandb: Agent Finished Run: b1emq1m4 \n",
+      "\n",
+      "wandb: Agent Starting Run: fid9vcvf with config:\n",
+      "\tepochs: 84\n",
+      "\thidden_dim: 6\n",
+      "\tlr: 0.07936130195768072\n",
+      "\tn_graph_iters: 4\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 687\n",
+      "wandb: Agent Started Run: fid9vcvf\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fid9vcvf\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fid9vcvf</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 84, 'hidden_dim': 6, 'lr': 0.07936130195768072, 'n_graph_iters': 4, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 687}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 6, 'n_graph_iters': 4, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.890950584411621 , validation accuracy:  11.508842551011943 %, lr:  0.07936130195768072\n",
+      "Epoch:  2 , validation loss:  1.8901582717895509 , validation accuracy:  11.364202006211247 %, lr:  0.07936130195768072\n",
+      "Epoch:  3 , validation loss:  1.8889724731445312 , validation accuracy:  10.965628933880154 %, lr:  0.07936130195768072\n",
+      "Epoch:  4 , validation loss:  1.8894882202148438 , validation accuracy:  10.685726034215966 %, lr:  0.07936130195768072\n",
+      "Epoch:  5 , validation loss:  1.8927127838134765 , validation accuracy:  10.200224355159266 %, lr:  0.07936130195768072\n",
+      "Epoch:  6 , validation loss:  1.889016342163086 , validation accuracy:  11.019012476599613 %, lr:  0.07936130195768072\n",
+      "Epoch:  7 , validation loss:  1.8891872406005858 , validation accuracy:  10.806921104173655 %, lr:  0.07936130195768072\n",
+      "Epoch:  8 , validation loss:  1.8889984130859374 , validation accuracy:  10.868240038378438 %, lr:  0.07936130195768072\n",
+      "Epoch:  9 , validation loss:  1.8891313552856446 , validation accuracy:  11.029112065762753 %, lr:  0.07936130195768072\n",
+      "Epoch:  10 , validation loss:  1.8889781951904296 , validation accuracy:  10.941822759424179 %, lr:  0.07936130195768072\n",
+      "Epoch:  11 , validation loss:  1.888910675048828 , validation accuracy:  10.911523991934757 %, lr:  0.07936130195768072\n",
+      "Epoch:  12 , validation loss:  1.889869499206543 , validation accuracy:  11.377547891891112 %, lr:  0.07936130195768072\n",
+      "Epoch:  13 , validation loss:  1.8890119552612306 , validation accuracy:  11.061935730542961 %, lr:  0.07936130195768072\n",
+      "Epoch:  14 , validation loss:  1.8887672424316406 , validation accuracy:  10.947954652844658 %, lr:  0.07936130195768072\n",
+      "Epoch:  15 , validation loss:  1.8891851425170898 , validation accuracy:  10.755341059519044 %, lr:  0.07936130195768072\n",
+      "Epoch:  16 , validation loss:  1.8896678924560546 , validation accuracy:  10.600600925555206 %, lr:  0.07936130195768072\n",
+      "Epoch:  17 , validation loss:  1.8887239456176759 , validation accuracy:  10.937133664455578 %, lr:  0.07936130195768072\n",
+      "Epoch:  18 , validation loss:  1.8889545440673827 , validation accuracy:  11.032358362279478 %, lr:  0.07936130195768072\n",
+      "Epoch:  19 , validation loss:  1.893239974975586 , validation accuracy:  10.136019824050729 %, lr:  0.07936130195768072\n",
+      "Epoch:  20 , validation loss:  1.8903152465820312 , validation accuracy:  10.4996050339238 %, lr:  0.07936130195768072\n",
+      "Epoch:  21 , validation loss:  1.8907855987548827 , validation accuracy:  10.33548671002276 %, lr:  0.07936130195768072\n",
+      "Epoch:  22 , validation loss:  1.8935272216796875 , validation accuracy:  10.095621467398166 %, lr:  0.07936130195768072\n",
+      "Epoch:  23 , validation loss:  1.8899717330932617 , validation accuracy:  11.392336576022855 %, lr:  0.07936130195768072\n",
+      "Epoch:  24 , validation loss:  1.8887479782104493 , validation accuracy:  10.892767612060354 %, lr:  0.07936130195768072\n",
+      "Epoch:  25 , validation loss:  1.8905900955200194 , validation accuracy:  11.473854688553919 %, lr:  0.07936130195768072\n",
+      "Epoch:  26 , validation loss:  1.8886688232421875 , validation accuracy:  11.019012476599613 %, lr:  0.07936130195768072\n",
+      "Epoch:  27 , validation loss:  1.8977415084838867 , validation accuracy:  9.76594202114421 %, lr:  0.07936130195768072\n",
+      "Epoch:  28 , validation loss:  1.8891681671142577 , validation accuracy:  11.126861660877438 %, lr:  0.07936130195768072\n",
+      "Epoch:  29 , validation loss:  1.891387367248535 , validation accuracy:  10.30951633788897 %, lr:  0.07936130195768072\n",
+      "Epoch:  30 , validation loss:  1.8889190673828125 , validation accuracy:  10.76255505177843 %, lr:  0.07936130195768072\n",
+      "Epoch:  31 , validation loss:  1.8893285751342774 , validation accuracy:  10.668773152406407 %, lr:  0.07936130195768072\n",
+      "Epoch:  32 , validation loss:  1.889305877685547 , validation accuracy:  10.679233441182518 %, lr:  0.07936130195768072\n",
+      "Epoch:  33 , validation loss:  1.8897727966308593 , validation accuracy:  11.364562705824216 %, lr:  0.07936130195768072\n",
+      "Epoch:  34 , validation loss:  1.8895675659179687 , validation accuracy:  10.624046400398212 %, lr:  0.07936130195768072\n",
+      "Epoch:  35 , validation loss:  1.8955631256103516 , validation accuracy:  9.952423721049348 %, lr:  0.023808390587304214\n",
+      "Epoch:  36 , validation loss:  1.8886144638061524 , validation accuracy:  10.943986957101995 %, lr:  0.023808390587304214\n",
+      "Epoch:  37 , validation loss:  1.8891597747802735 , validation accuracy:  10.696186322992075 %, lr:  0.023808390587304214\n",
+      "Epoch:  38 , validation loss:  1.8901126861572266 , validation accuracy:  10.510065322699909 %, lr:  0.023808390587304214\n",
+      "Epoch:  39 , validation loss:  1.8885255813598634 , validation accuracy:  10.96310403658937 %, lr:  0.023808390587304214\n",
+      "Epoch:  40 , validation loss:  1.8884716033935547 , validation accuracy:  10.970678728461724 %, lr:  0.023808390587304214\n",
+      "Epoch:  41 , validation loss:  1.8892208099365235 , validation accuracy:  10.679954840408456 %, lr:  0.023808390587304214\n",
+      "Epoch:  42 , validation loss:  1.8883905410766602 , validation accuracy:  11.024783670407121 %, lr:  0.023808390587304214\n",
+      "Epoch:  43 , validation loss:  1.890584373474121 , validation accuracy:  10.400051940744268 %, lr:  0.023808390587304214\n",
+      "Epoch:  44 , validation loss:  1.8887283325195312 , validation accuracy:  11.13623985081464 %, lr:  0.023808390587304214\n",
+      "Epoch:  45 , validation loss:  1.889310073852539 , validation accuracy:  10.631981791883538 %, lr:  0.023808390587304214\n",
+      "Epoch:  46 , validation loss:  1.8886383056640625 , validation accuracy:  10.897096007415984 %, lr:  0.023808390587304214\n",
+      "Epoch:  47 , validation loss:  1.8885383605957031 , validation accuracy:  10.942183459037148 %, lr:  0.023808390587304214\n",
+      "Epoch:  48 , validation loss:  1.88861026763916 , validation accuracy:  10.872207734121101 %, lr:  0.023808390587304214\n",
+      "Epoch:  49 , validation loss:  1.8905147552490233 , validation accuracy:  10.41484062487601 %, lr:  0.023808390587304214\n",
+      "Epoch:  50 , validation loss:  1.8885833740234375 , validation accuracy:  10.841548267018709 %, lr:  0.023808390587304214\n",
+      "Epoch:  51 , validation loss:  1.8892995834350585 , validation accuracy:  10.650377472144973 %, lr:  0.023808390587304214\n",
+      "Epoch:  52 , validation loss:  1.8884614944458007 , validation accuracy:  10.97789272072111 %, lr:  0.023808390587304214\n",
+      "Epoch:  53 , validation loss:  1.8883832931518554 , validation accuracy:  11.003863092854901 %, lr:  0.023808390587304214\n",
+      "Epoch:  54 , validation loss:  1.8884735107421875 , validation accuracy:  10.986549511432374 %, lr:  0.023808390587304214\n",
+      "Epoch:  55 , validation loss:  1.8884414672851562 , validation accuracy:  10.933887367938855 %, lr:  0.023808390587304214\n",
+      "Epoch:  56 , validation loss:  1.8891193389892578 , validation accuracy:  10.659394962469205 %, lr:  0.023808390587304214\n",
+      "Epoch:  57 , validation loss:  1.8901399612426757 , validation accuracy:  10.463174373013898 %, lr:  0.023808390587304214\n",
+      "Epoch:  58 , validation loss:  1.8885015487670898 , validation accuracy:  11.017208978534766 %, lr:  0.023808390587304214\n",
+      "Epoch:  59 , validation loss:  1.888559913635254 , validation accuracy:  10.853090654633728 %, lr:  0.023808390587304214\n",
+      "Epoch:  60 , validation loss:  1.8885417938232423 , validation accuracy:  10.92486987761462 %, lr:  0.007142517176191264\n",
+      "Epoch:  61 , validation loss:  1.8884889602661132 , validation accuracy:  10.982221116076744 %, lr:  0.007142517176191264\n",
+      "Epoch:  62 , validation loss:  1.8888664245605469 , validation accuracy:  10.766162047908123 %, lr:  0.007142517176191264\n",
+      "Epoch:  63 , validation loss:  1.8885644912719726 , validation accuracy:  10.89312831167332 %, lr:  0.007142517176191264\n",
+      "Epoch:  64 , validation loss:  1.888533592224121 , validation accuracy:  10.957693542394829 %, lr:  0.007142517176191264\n",
+      "Epoch:  65 , validation loss:  1.888840103149414 , validation accuracy:  10.7722939413286 %, lr:  0.007142517176191264\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  66 , validation loss:  1.8886472702026367 , validation accuracy:  10.89348901128629 %, lr:  0.007142517176191264\n",
+      "Epoch:  67 , validation loss:  1.8885601043701172 , validation accuracy:  10.897096007415984 %, lr:  0.007142517176191264\n",
+      "Epoch:  68 , validation loss:  1.8888973236083983 , validation accuracy:  10.769769044037817 %, lr:  0.007142517176191264\n",
+      "Epoch:  69 , validation loss:  1.8889055252075195 , validation accuracy:  10.76724414674703 %, lr:  0.007142517176191264\n",
+      "Epoch:  70 , validation loss:  1.8888429641723632 , validation accuracy:  10.771572542102662 %, lr:  0.007142517176191264\n",
+      "Epoch:  71 , validation loss:  1.8885353088378907 , validation accuracy:  10.942183459037148 %, lr:  0.007142517176191264\n",
+      "Epoch:  72 , validation loss:  1.8887718200683594 , validation accuracy:  10.787443325073312 %, lr:  0.007142517176191264\n",
+      "Epoch:  73 , validation loss:  1.8888639450073241 , validation accuracy:  10.774458139006416 %, lr:  0.007142517176191264\n",
+      "Epoch:  74 , validation loss:  1.889153289794922 , validation accuracy:  10.68356183653815 %, lr:  0.007142517176191264\n",
+      "Epoch:  75 , validation loss:  1.8888444900512695 , validation accuracy:  10.779868633200957 %, lr:  0.007142517176191264\n",
+      "Epoch:  76 , validation loss:  1.8886754989624024 , validation accuracy:  10.860665346506083 %, lr:  0.007142517176191264\n",
+      "Epoch:  77 , validation loss:  1.88846435546875 , validation accuracy:  11.023701571568214 %, lr:  0.007142517176191264\n",
+      "Epoch:  78 , validation loss:  1.8917648315429687 , validation accuracy:  10.265510985106713 %, lr:  0.007142517176191264\n",
+      "Epoch:  79 , validation loss:  1.8891443252563476 , validation accuracy:  10.68284043731221 %, lr:  0.007142517176191264\n",
+      "Epoch:  80 , validation loss:  1.8884172439575195 , validation accuracy:  10.919459383420081 %, lr:  0.007142517176191264\n",
+      "Epoch:  81 , validation loss:  1.8888059616088868 , validation accuracy:  10.782032830878773 %, lr:  0.002142755152857379\n",
+      "Epoch:  82 , validation loss:  1.8887155532836915 , validation accuracy:  10.803314108043963 %, lr:  0.002142755152857379\n",
+      "Epoch:  83 , validation loss:  1.8885906219482422 , validation accuracy:  10.870043536443285 %, lr:  0.002142755152857379\n",
+      "Epoch:  84 , validation loss:  1.8885770797729493 , validation accuracy:  10.866075840700622 %, lr:  0.002142755152857379\n",
+      "wandb: Agent Finished Run: fid9vcvf \n",
+      "\n",
+      "wandb: Agent Starting Run: 72hns7u5 with config:\n",
+      "\tepochs: 140\n",
+      "\thidden_dim: 63\n",
+      "\tlr: 0.00040529151979869715\n",
+      "\tn_graph_iters: 8\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 245\n",
+      "wandb: Agent Started Run: 72hns7u5\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/72hns7u5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/72hns7u5</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 140, 'hidden_dim': 63, 'lr': 0.00040529151979869715, 'n_graph_iters': 8, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 245}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 63, 'n_graph_iters': 8, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.882688331604004 , validation accuracy:  10.684643935377057 %, lr:  0.00040529151979869715\n",
+      "Epoch:  2 , validation loss:  1.8795074462890624 , validation accuracy:  10.439007498944953 %, lr:  0.00040529151979869715\n",
+      "Epoch:  3 , validation loss:  1.8895965576171876 , validation accuracy:  9.626351270925086 %, lr:  0.00040529151979869715\n",
+      "Epoch:  4 , validation loss:  1.8758415222167968 , validation accuracy:  10.391755849645973 %, lr:  0.00040529151979869715\n",
+      "Epoch:  5 , validation loss:  1.8731542587280274 , validation accuracy:  12.400852693885058 %, lr:  0.00040529151979869715\n",
+      "Epoch:  6 , validation loss:  1.8710269927978516 , validation accuracy:  11.491889669202385 %, lr:  0.00040529151979869715\n",
+      "Epoch:  7 , validation loss:  1.8722675323486329 , validation accuracy:  12.973282979667363 %, lr:  0.00040529151979869715\n",
+      "Epoch:  8 , validation loss:  1.8742469787597655 , validation accuracy:  10.631260392657598 %, lr:  0.00040529151979869715\n",
+      "Epoch:  9 , validation loss:  1.8775257110595702 , validation accuracy:  10.234130118778383 %, lr:  0.00040529151979869715\n",
+      "Epoch:  10 , validation loss:  1.872615432739258 , validation accuracy:  11.073478118157979 %, lr:  0.00040529151979869715\n",
+      "Epoch:  11 , validation loss:  1.8748590469360351 , validation accuracy:  12.601762378308967 %, lr:  0.00040529151979869715\n",
+      "Epoch:  12 , validation loss:  1.8722930908203126 , validation accuracy:  12.550182333654355 %, lr:  0.00040529151979869715\n",
+      "Epoch:  13 , validation loss:  1.8745834350585937 , validation accuracy:  12.872647787648924 %, lr:  0.00040529151979869715\n",
+      "Epoch:  14 , validation loss:  1.869740104675293 , validation accuracy:  12.56893871352876 %, lr:  0.00040529151979869715\n",
+      "Epoch:  15 , validation loss:  1.870656967163086 , validation accuracy:  11.535895021984642 %, lr:  0.00040529151979869715\n",
+      "Epoch:  16 , validation loss:  1.868846321105957 , validation accuracy:  13.02847002045167 %, lr:  0.00040529151979869715\n",
+      "Epoch:  17 , validation loss:  1.8704694747924804 , validation accuracy:  12.355404542650925 %, lr:  0.00040529151979869715\n",
+      "Epoch:  18 , validation loss:  1.868006134033203 , validation accuracy:  12.69518357806802 %, lr:  0.00040529151979869715\n",
+      "Epoch:  19 , validation loss:  1.8698230743408204 , validation accuracy:  13.030994917742452 %, lr:  0.00040529151979869715\n",
+      "Epoch:  20 , validation loss:  1.8681161880493165 , validation accuracy:  12.991317960315829 %, lr:  0.00040529151979869715\n",
+      "Epoch:  21 , validation loss:  1.8675399780273438 , validation accuracy:  13.562305447646256 %, lr:  0.00040529151979869715\n",
+      "Epoch:  22 , validation loss:  1.867624282836914 , validation accuracy:  11.617413134515706 %, lr:  0.00040529151979869715\n",
+      "Epoch:  23 , validation loss:  1.8706693649291992 , validation accuracy:  12.325466474774473 %, lr:  0.00040529151979869715\n",
+      "Epoch:  24 , validation loss:  1.8673109054565429 , validation accuracy:  11.768185572736881 %, lr:  0.00040529151979869715\n",
+      "Epoch:  25 , validation loss:  1.8689140319824218 , validation accuracy:  11.334624637947764 %, lr:  0.00040529151979869715\n",
+      "Epoch:  26 , validation loss:  1.865308952331543 , validation accuracy:  12.098947117829741 %, lr:  0.00040529151979869715\n",
+      "Epoch:  27 , validation loss:  1.8659494400024415 , validation accuracy:  13.890902795061299 %, lr:  0.00040529151979869715\n",
+      "Epoch:  28 , validation loss:  1.8721323013305664 , validation accuracy:  12.260901244052965 %, lr:  0.00040529151979869715\n",
+      "Epoch:  29 , validation loss:  1.871261215209961 , validation accuracy:  13.187177850158166 %, lr:  0.00040529151979869715\n",
+      "Epoch:  30 , validation loss:  1.8716968536376952 , validation accuracy:  11.63653021400308 %, lr:  0.00040529151979869715\n",
+      "Epoch:  31 , validation loss:  1.869661521911621 , validation accuracy:  13.008270842125386 %, lr:  0.00040529151979869715\n",
+      "Epoch:  32 , validation loss:  1.8712310791015625 , validation accuracy:  11.81038742745429 %, lr:  0.00040529151979869715\n",
+      "Epoch:  33 , validation loss:  1.871405792236328 , validation accuracy:  11.635087415551203 %, lr:  0.00040529151979869715\n",
+      "Epoch:  34 , validation loss:  1.8749662399291993 , validation accuracy:  10.8675186391525 %, lr:  0.00040529151979869715\n",
+      "Epoch:  35 , validation loss:  1.8670331954956054 , validation accuracy:  12.364061333362189 %, lr:  0.00040529151979869715\n",
+      "Epoch:  36 , validation loss:  1.8678709030151368 , validation accuracy:  12.466860723058444 %, lr:  0.00040529151979869715\n",
+      "Epoch:  37 , validation loss:  1.8675003051757812 , validation accuracy:  13.55437005616093 %, lr:  0.00040529151979869715\n",
+      "Epoch:  38 , validation loss:  1.8702310562133788 , validation accuracy:  10.807281803786625 %, lr:  0.00040529151979869715\n",
+      "Epoch:  39 , validation loss:  1.865042495727539 , validation accuracy:  12.6742630005158 %, lr:  0.00040529151979869715\n",
+      "Epoch:  40 , validation loss:  1.8638404846191405 , validation accuracy:  13.597654009717248 %, lr:  0.00040529151979869715\n",
+      "Epoch:  41 , validation loss:  1.8689132690429688 , validation accuracy:  10.645327677563401 %, lr:  0.00040529151979869715\n",
+      "Epoch:  42 , validation loss:  1.8671974182128905 , validation accuracy:  11.017569678147735 %, lr:  0.00040529151979869715\n",
+      "Epoch:  43 , validation loss:  1.8631256103515625 , validation accuracy:  13.510004003765705 %, lr:  0.00040529151979869715\n",
+      "Epoch:  44 , validation loss:  1.8669515609741212 , validation accuracy:  11.444638019903405 %, lr:  0.00040529151979869715\n",
+      "Epoch:  45 , validation loss:  1.8629352569580078 , validation accuracy:  12.340615858519184 %, lr:  0.00040529151979869715\n",
+      "Epoch:  46 , validation loss:  1.8622636795043945 , validation accuracy:  12.388949606657071 %, lr:  0.00040529151979869715\n",
+      "Epoch:  47 , validation loss:  1.8580398559570312 , validation accuracy:  12.34710845155263 %, lr:  0.00040529151979869715\n",
+      "Epoch:  48 , validation loss:  1.8606000900268556 , validation accuracy:  11.366726903502032 %, lr:  0.00040529151979869715\n",
+      "Epoch:  49 , validation loss:  1.869348907470703 , validation accuracy:  11.068789023189378 %, lr:  0.00040529151979869715\n",
+      "Epoch:  50 , validation loss:  1.8583181381225586 , validation accuracy:  12.56929941314173 %, lr:  0.00040529151979869715\n",
+      "Epoch:  51 , validation loss:  1.875990867614746 , validation accuracy:  10.327912018150405 %, lr:  0.00040529151979869715\n",
+      "Epoch:  52 , validation loss:  1.8635055541992187 , validation accuracy:  11.962241964514373 %, lr:  0.00040529151979869715\n",
+      "Epoch:  53 , validation loss:  1.8605792999267579 , validation accuracy:  13.062736483683754 %, lr:  0.00040529151979869715\n",
+      "Epoch:  54 , validation loss:  1.8537044525146484 , validation accuracy:  13.890902795061299 %, lr:  0.00040529151979869715\n",
+      "Epoch:  55 , validation loss:  1.863745880126953 , validation accuracy:  12.067566251501411 %, lr:  0.00040529151979869715\n",
+      "Epoch:  56 , validation loss:  1.8601160049438477 , validation accuracy:  12.52709755842432 %, lr:  0.00040529151979869715\n",
+      "Epoch:  57 , validation loss:  1.8506528854370117 , validation accuracy:  12.06864835034032 %, lr:  0.00040529151979869715\n",
+      "Epoch:  58 , validation loss:  1.814938735961914 , validation accuracy:  12.49571669209599 %, lr:  0.00040529151979869715\n",
+      "Epoch:  59 , validation loss:  1.8314273834228516 , validation accuracy:  14.125718243104323 %, lr:  0.00040529151979869715\n",
+      "Epoch:  60 , validation loss:  1.7999895095825196 , validation accuracy:  14.385782664055203 %, lr:  0.00040529151979869715\n",
+      "Epoch:  61 , validation loss:  1.8970146179199219 , validation accuracy:  13.794595998398492 %, lr:  0.00040529151979869715\n",
+      "Epoch:  62 , validation loss:  1.6219976425170899 , validation accuracy:  16.4240961769448 %, lr:  0.00040529151979869715\n",
+      "Epoch:  63 , validation loss:  1.870442771911621 , validation accuracy:  11.65781149116827 %, lr:  0.00040529151979869715\n",
+      "Epoch:  64 , validation loss:  1.7534782409667968 , validation accuracy:  14.458643985875003 %, lr:  0.00040529151979869715\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  65 , validation loss:  1.7953168869018554 , validation accuracy:  16.591100097749596 %, lr:  0.00040529151979869715\n",
+      "Epoch:  66 , validation loss:  1.8660079956054687 , validation accuracy:  13.17996385789878 %, lr:  0.00040529151979869715\n",
+      "Epoch:  67 , validation loss:  1.6023454666137695 , validation accuracy:  19.290936700824922 %, lr:  0.00040529151979869715\n",
+      "Epoch:  68 , validation loss:  1.9239873886108398 , validation accuracy:  18.91256280682011 %, lr:  0.00040529151979869715\n",
+      "Epoch:  69 , validation loss:  1.7817808151245118 , validation accuracy:  13.802892089496787 %, lr:  0.00040529151979869715\n",
+      "Epoch:  70 , validation loss:  1.634653663635254 , validation accuracy:  12.754338314594987 %, lr:  0.00040529151979869715\n",
+      "Epoch:  71 , validation loss:  1.5395904541015626 , validation accuracy:  22.38321448281086 %, lr:  0.00040529151979869715\n",
+      "Epoch:  72 , validation loss:  1.4895971298217774 , validation accuracy:  22.2299171472989 %, lr:  0.00040529151979869715\n",
+      "Epoch:  73 , validation loss:  1.5465834617614747 , validation accuracy:  20.48737731704414 %, lr:  0.00040529151979869715\n",
+      "Epoch:  74 , validation loss:  1.7435176849365235 , validation accuracy:  12.89140416752333 %, lr:  0.00040529151979869715\n",
+      "Epoch:  75 , validation loss:  2.0652864456176756 , validation accuracy:  10.23521221761729 %, lr:  0.00040529151979869715\n",
+      "Epoch:  76 , validation loss:  1.6491647720336915 , validation accuracy:  20.824992154783416 %, lr:  0.00040529151979869715\n",
+      "Epoch:  77 , validation loss:  1.6111122131347657 , validation accuracy:  14.679752848625194 %, lr:  0.00040529151979869715\n",
+      "Epoch:  78 , validation loss:  1.3881535530090332 , validation accuracy:  23.55693102341301 %, lr:  0.00040529151979869715\n",
+      "Epoch:  79 , validation loss:  1.7228122711181642 , validation accuracy:  12.843791818611377 %, lr:  0.00040529151979869715\n",
+      "Epoch:  80 , validation loss:  1.4816035270690917 , validation accuracy:  20.141827087819536 %, lr:  0.00040529151979869715\n",
+      "Epoch:  81 , validation loss:  1.2203012466430665 , validation accuracy:  23.076839838550853 %, lr:  0.00040529151979869715\n",
+      "Epoch:  82 , validation loss:  1.338029670715332 , validation accuracy:  26.523685340085628 %, lr:  0.00040529151979869715\n",
+      "Epoch:  83 , validation loss:  1.5771217346191406 , validation accuracy:  18.531303315911543 %, lr:  0.00040529151979869715\n",
+      "Epoch:  84 , validation loss:  1.5024579048156739 , validation accuracy:  22.37311489364772 %, lr:  0.00040529151979869715\n",
+      "Epoch:  85 , validation loss:  1.664764976501465 , validation accuracy:  13.308012220502889 %, lr:  0.00040529151979869715\n",
+      "Epoch:  86 , validation loss:  1.4394637107849122 , validation accuracy:  28.71709968655204 %, lr:  0.00040529151979869715\n",
+      "Epoch:  87 , validation loss:  1.738860511779785 , validation accuracy:  22.278972294662726 %, lr:  0.00040529151979869715\n",
+      "Epoch:  88 , validation loss:  1.8669649124145509 , validation accuracy:  22.211160767424495 %, lr:  0.00040529151979869715\n",
+      "Epoch:  89 , validation loss:  1.1751954078674316 , validation accuracy:  28.287145747892612 %, lr:  0.00040529151979869715\n",
+      "Epoch:  90 , validation loss:  1.753047561645508 , validation accuracy:  21.61239940989543 %, lr:  0.00040529151979869715\n",
+      "Epoch:  91 , validation loss:  1.5224130630493165 , validation accuracy:  14.439526906387629 %, lr:  0.00040529151979869715\n",
+      "Epoch:  92 , validation loss:  1.3494009017944335 , validation accuracy:  25.77090524781867 %, lr:  0.00040529151979869715\n",
+      "Epoch:  93 , validation loss:  1.4178248405456544 , validation accuracy:  23.581819296707895 %, lr:  0.00040529151979869715\n",
+      "Epoch:  94 , validation loss:  1.1727103233337401 , validation accuracy:  24.425134991830152 %, lr:  0.00040529151979869715\n",
+      "Epoch:  95 , validation loss:  1.5962361335754394 , validation accuracy:  18.78126814769928 %, lr:  0.00040529151979869715\n",
+      "Epoch:  96 , validation loss:  1.1153325080871581 , validation accuracy:  25.95919044578865 %, lr:  0.00040529151979869715\n",
+      "Epoch:  97 , validation loss:  1.5793312072753907 , validation accuracy:  16.594346394266317 %, lr:  0.00040529151979869715\n",
+      "Epoch:  98 , validation loss:  1.2693220138549806 , validation accuracy:  26.790963753295895 %, lr:  0.00040529151979869715\n",
+      "Epoch:  99 , validation loss:  1.168563461303711 , validation accuracy:  24.993958281482765 %, lr:  0.00040529151979869715\n",
+      "Epoch:  100 , validation loss:  1.333677101135254 , validation accuracy:  16.455116343660166 %, lr:  0.00040529151979869715\n",
+      "Epoch:  101 , validation loss:  1.6238197326660155 , validation accuracy:  12.446300845119193 %, lr:  0.00040529151979869715\n",
+      "Epoch:  102 , validation loss:  1.374245548248291 , validation accuracy:  20.769083714773174 %, lr:  0.00040529151979869715\n",
+      "Epoch:  103 , validation loss:  1.6903800964355469 , validation accuracy:  17.918113973863704 %, lr:  0.00040529151979869715\n",
+      "Epoch:  104 , validation loss:  1.1714872360229491 , validation accuracy:  28.53566778122847 %, lr:  0.00040529151979869715\n",
+      "Epoch:  105 , validation loss:  1.1454018592834472 , validation accuracy:  24.802066087383086 %, lr:  0.00040529151979869715\n",
+      "Epoch:  106 , validation loss:  1.891851806640625 , validation accuracy:  18.224347945274655 %, lr:  0.00040529151979869715\n",
+      "Epoch:  107 , validation loss:  1.985902976989746 , validation accuracy:  15.438304134699662 %, lr:  0.00040529151979869715\n",
+      "Epoch:  108 , validation loss:  1.8504314422607422 , validation accuracy:  13.615328290752743 %, lr:  0.00040529151979869715\n",
+      "Epoch:  109 , validation loss:  1.8092126846313477 , validation accuracy:  15.234508853372 %, lr:  0.00040529151979869715\n",
+      "Epoch:  110 , validation loss:  1.4013818740844726 , validation accuracy:  22.48240687637742 %, lr:  0.00040529151979869715\n",
+      "Epoch:  111 , validation loss:  2.0715915679931642 , validation accuracy:  21.323118320294043 %, lr:  0.00040529151979869715\n",
+      "Epoch:  112 , validation loss:  1.082310104370117 , validation accuracy:  24.477436435710704 %, lr:  0.00040529151979869715\n",
+      "Epoch:  113 , validation loss:  1.2288690567016602 , validation accuracy:  26.14278654879003 %, lr:  0.00040529151979869715\n",
+      "Epoch:  114 , validation loss:  1.0748522758483887 , validation accuracy:  23.22616947832015 %, lr:  0.00040529151979869715\n",
+      "Epoch:  115 , validation loss:  1.6727092742919922 , validation accuracy:  15.417744256760413 %, lr:  0.00040529151979869715\n",
+      "Epoch:  116 , validation loss:  1.2935080528259277 , validation accuracy:  24.87997720378446 %, lr:  0.00040529151979869715\n",
+      "Epoch:  117 , validation loss:  1.1843378067016601 , validation accuracy:  29.423710228358924 %, lr:  0.00040529151979869715\n",
+      "Epoch:  118 , validation loss:  1.2883545875549316 , validation accuracy:  18.694339540973672 %, lr:  0.00040529151979869715\n",
+      "Epoch:  119 , validation loss:  1.7033748626708984 , validation accuracy:  14.651978978426555 %, lr:  0.00040529151979869715\n",
+      "Epoch:  120 , validation loss:  1.673853874206543 , validation accuracy:  13.187899249384106 %, lr:  0.00040529151979869715\n",
+      "Epoch:  121 , validation loss:  1.2839898109436034 , validation accuracy:  21.970213425960992 %, lr:  0.00040529151979869715\n",
+      "Epoch:  122 , validation loss:  1.594283103942871 , validation accuracy:  15.701614852167264 %, lr:  0.00040529151979869715\n",
+      "Epoch:  123 , validation loss:  1.7626672744750977 , validation accuracy:  16.06123236629767 %, lr:  0.00040529151979869715\n",
+      "Epoch:  124 , validation loss:  1.680528450012207 , validation accuracy:  19.029068781809197 %, lr:  0.00040529151979869715\n",
+      "Epoch:  125 , validation loss:  1.209015464782715 , validation accuracy:  19.303921886891814 %, lr:  0.00040529151979869715\n",
+      "Epoch:  126 , validation loss:  1.0501109123229981 , validation accuracy:  28.291474143248248 %, lr:  0.00040529151979869715\n",
+      "Epoch:  127 , validation loss:  1.7532888412475587 , validation accuracy:  24.19031954378713 %, lr:  0.00040529151979869715\n",
+      "Epoch:  128 , validation loss:  0.9601589202880859 , validation accuracy:  29.871338448053848 %, lr:  0.00040529151979869715\n",
+      "Epoch:  129 , validation loss:  1.261592483520508 , validation accuracy:  24.335681487813762 %, lr:  0.00040529151979869715\n",
+      "Epoch:  130 , validation loss:  1.4924325942993164 , validation accuracy:  24.007084140398717 %, lr:  0.00040529151979869715\n",
+      "Epoch:  131 , validation loss:  1.4112680435180665 , validation accuracy:  30.455671821064133 %, lr:  0.00040529151979869715\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  132 , validation loss:  1.2047532081604004 , validation accuracy:  29.49116105598419 %, lr:  0.00040529151979869715\n",
+      "Epoch:  133 , validation loss:  1.0326483726501465 , validation accuracy:  28.328626203384083 %, lr:  0.00040529151979869715\n",
+      "Epoch:  134 , validation loss:  1.688622283935547 , validation accuracy:  15.944004992082645 %, lr:  0.00040529151979869715\n",
+      "Epoch:  135 , validation loss:  1.291691493988037 , validation accuracy:  16.344020862865612 %, lr:  0.00040529151979869715\n",
+      "Epoch:  136 , validation loss:  1.4093527793884277 , validation accuracy:  20.38061023160522 %, lr:  0.00040529151979869715\n",
+      "Epoch:  137 , validation loss:  1.0362444877624513 , validation accuracy:  32.688041725731225 %, lr:  0.00040529151979869715\n",
+      "Epoch:  138 , validation loss:  1.3224504470825196 , validation accuracy:  27.16212365504132 %, lr:  0.00040529151979869715\n",
+      "Epoch:  139 , validation loss:  1.3797142028808593 , validation accuracy:  27.14084237787613 %, lr:  0.00040529151979869715\n",
+      "Epoch:  140 , validation loss:  0.982572364807129 , validation accuracy:  24.499078412488863 %, lr:  0.00040529151979869715\n",
+      "wandb: Agent Finished Run: 72hns7u5 \n",
+      "\n",
+      "wandb: Agent Starting Run: ooxxqerw with config:\n",
+      "\tepochs: 188\n",
+      "\thidden_dim: 37\n",
+      "\tlr: 0.00331255104784123\n",
+      "\tn_graph_iters: 1\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 172\n",
+      "wandb: Agent Started Run: ooxxqerw\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/zra8ov9k</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ooxxqerw\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/ooxxqerw</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 188, 'hidden_dim': 37, 'lr': 0.00331255104784123, 'n_graph_iters': 1, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 172}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 37, 'n_graph_iters': 1, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.882065200805664 , validation accuracy:  11.232185947864478 %, lr:  0.00331255104784123\n",
+      "Epoch:  2 , validation loss:  1.8823436737060546 , validation accuracy:  10.10355685888349 %, lr:  0.00331255104784123\n",
+      "Epoch:  3 , validation loss:  1.8830812454223633 , validation accuracy:  9.850345730579031 %, lr:  0.00331255104784123\n",
+      "Epoch:  4 , validation loss:  1.874594497680664 , validation accuracy:  12.040153080915744 %, lr:  0.00331255104784123\n",
+      "Epoch:  5 , validation loss:  1.8763639450073242 , validation accuracy:  11.25707422115936 %, lr:  0.00331255104784123\n",
+      "Epoch:  6 , validation loss:  1.8824262619018555 , validation accuracy:  14.567935968604706 %, lr:  0.00331255104784123\n",
+      "Epoch:  7 , validation loss:  1.8726068496704102 , validation accuracy:  12.170726340810637 %, lr:  0.00331255104784123\n",
+      "Epoch:  8 , validation loss:  1.8732316970825196 , validation accuracy:  12.723678847492598 %, lr:  0.00331255104784123\n",
+      "Epoch:  9 , validation loss:  1.8713899612426759 , validation accuracy:  12.476238912995646 %, lr:  0.00331255104784123\n",
+      "Epoch:  10 , validation loss:  1.8762117385864259 , validation accuracy:  11.103416186034433 %, lr:  0.00331255104784123\n",
+      "Epoch:  11 , validation loss:  1.871786117553711 , validation accuracy:  11.80605903209866 %, lr:  0.00331255104784123\n",
+      "Epoch:  12 , validation loss:  1.870396041870117 , validation accuracy:  13.541024170481064 %, lr:  0.00331255104784123\n",
+      "Epoch:  13 , validation loss:  1.871455192565918 , validation accuracy:  12.11662139886524 %, lr:  0.00331255104784123\n",
+      "Epoch:  14 , validation loss:  1.8766464233398437 , validation accuracy:  14.85108516478562 %, lr:  0.00331255104784123\n",
+      "Epoch:  15 , validation loss:  1.8716753005981446 , validation accuracy:  10.981860416463773 %, lr:  0.00331255104784123\n",
+      "Epoch:  16 , validation loss:  1.8730657577514649 , validation accuracy:  11.282323194067214 %, lr:  0.00331255104784123\n",
+      "Epoch:  17 , validation loss:  1.870351791381836 , validation accuracy:  11.51064604907679 %, lr:  0.00331255104784123\n",
+      "Epoch:  18 , validation loss:  1.8701696395874023 , validation accuracy:  12.961740592052346 %, lr:  0.00331255104784123\n",
+      "Epoch:  19 , validation loss:  1.8696847915649415 , validation accuracy:  13.061293685231876 %, lr:  0.00331255104784123\n",
+      "Epoch:  20 , validation loss:  1.8739299774169922 , validation accuracy:  11.477461684683613 %, lr:  0.00331255104784123\n",
+      "Epoch:  21 , validation loss:  1.8694843292236327 , validation accuracy:  12.539361345265277 %, lr:  0.00331255104784123\n",
+      "Epoch:  22 , validation loss:  1.8715950012207032 , validation accuracy:  12.059991559629056 %, lr:  0.00331255104784123\n",
+      "Epoch:  23 , validation loss:  1.8702875137329102 , validation accuracy:  11.839604096104805 %, lr:  0.00331255104784123\n",
+      "Epoch:  24 , validation loss:  1.871748161315918 , validation accuracy:  10.453796183076696 %, lr:  0.00331255104784123\n",
+      "Epoch:  25 , validation loss:  1.8724369049072265 , validation accuracy:  11.487561273846753 %, lr:  0.00331255104784123\n",
+      "Epoch:  26 , validation loss:  1.8698192596435548 , validation accuracy:  13.055883191037335 %, lr:  0.00331255104784123\n",
+      "Epoch:  27 , validation loss:  1.874199676513672 , validation accuracy:  11.055443137509513 %, lr:  0.00331255104784123\n",
+      "Epoch:  28 , validation loss:  1.8697532653808593 , validation accuracy:  13.773675420846274 %, lr:  0.00331255104784123\n",
+      "Epoch:  29 , validation loss:  1.8747045516967773 , validation accuracy:  14.462611681617666 %, lr:  0.00331255104784123\n",
+      "Epoch:  30 , validation loss:  1.8724985122680664 , validation accuracy:  12.241784164565592 %, lr:  0.00331255104784123\n",
+      "Epoch:  31 , validation loss:  1.8701698303222656 , validation accuracy:  13.757804637875623 %, lr:  0.00331255104784123\n",
+      "Epoch:  32 , validation loss:  1.8694328308105468 , validation accuracy:  13.90605217880601 %, lr:  0.00331255104784123\n",
+      "Epoch:  33 , validation loss:  1.8822919845581054 , validation accuracy:  10.455960380754512 %, lr:  0.00331255104784123\n",
+      "Epoch:  34 , validation loss:  1.8692310333251954 , validation accuracy:  11.763496477768278 %, lr:  0.00331255104784123\n",
+      "Epoch:  35 , validation loss:  1.8702274322509767 , validation accuracy:  11.623184328323216 %, lr:  0.00331255104784123\n",
+      "Epoch:  36 , validation loss:  1.8697088241577149 , validation accuracy:  12.36838972871782 %, lr:  0.00331255104784123\n",
+      "Epoch:  37 , validation loss:  1.8702306747436523 , validation accuracy:  12.541525542943091 %, lr:  0.00331255104784123\n",
+      "Epoch:  38 , validation loss:  1.8698314666748046 , validation accuracy:  11.593967659672701 %, lr:  0.00331255104784123\n",
+      "Epoch:  39 , validation loss:  1.8700551986694336 , validation accuracy:  12.337369562002461 %, lr:  0.00331255104784123\n",
+      "Epoch:  40 , validation loss:  1.8700996398925782 , validation accuracy:  10.689693729958629 %, lr:  0.00331255104784123\n",
+      "Epoch:  41 , validation loss:  1.869683074951172 , validation accuracy:  11.292422783230354 %, lr:  0.00331255104784123\n",
+      "Epoch:  42 , validation loss:  1.868921661376953 , validation accuracy:  11.454737609066544 %, lr:  0.00331255104784123\n",
+      "Epoch:  43 , validation loss:  1.868988609313965 , validation accuracy:  12.645407031478257 %, lr:  0.00331255104784123\n",
+      "Epoch:  44 , validation loss:  1.8691446304321289 , validation accuracy:  12.386424709366286 %, lr:  0.00331255104784123\n",
+      "Epoch:  45 , validation loss:  1.8691146850585938 , validation accuracy:  12.91701384004415 %, lr:  0.00331255104784123\n",
+      "Epoch:  46 , validation loss:  1.8704069137573243 , validation accuracy:  11.951060276512324 %, lr:  0.00331255104784123\n",
+      "Epoch:  47 , validation loss:  1.8699045181274414 , validation accuracy:  12.088847528666602 %, lr:  0.00331255104784123\n",
+      "Epoch:  48 , validation loss:  1.8695255279541017 , validation accuracy:  12.592384188371767 %, lr:  0.00331255104784123\n",
+      "Epoch:  49 , validation loss:  1.8689369201660155 , validation accuracy:  13.274467156496742 %, lr:  0.00331255104784123\n",
+      "Epoch:  50 , validation loss:  1.868934440612793 , validation accuracy:  13.444356674205288 %, lr:  0.00331255104784123\n",
+      "Epoch:  51 , validation loss:  1.8686878204345703 , validation accuracy:  11.502349957978495 %, lr:  0.00331255104784123\n",
+      "Epoch:  52 , validation loss:  1.8701282501220704 , validation accuracy:  12.028610693300726 %, lr:  0.00331255104784123\n",
+      "Epoch:  53 , validation loss:  1.870278549194336 , validation accuracy:  13.777282416975966 %, lr:  0.00331255104784123\n",
+      "Epoch:  54 , validation loss:  1.8705215454101562 , validation accuracy:  12.219060088948524 %, lr:  0.00331255104784123\n",
+      "Epoch:  55 , validation loss:  1.8694734573364258 , validation accuracy:  13.70802809128586 %, lr:  0.00331255104784123\n",
+      "Epoch:  56 , validation loss:  1.872582244873047 , validation accuracy:  10.553349276256228 %, lr:  0.00331255104784123\n",
+      "Epoch:  57 , validation loss:  1.8699373245239257 , validation accuracy:  13.778364515814875 %, lr:  0.00331255104784123\n",
+      "Epoch:  58 , validation loss:  1.8687967300415038 , validation accuracy:  12.366225531040005 %, lr:  0.00331255104784123\n",
+      "Epoch:  59 , validation loss:  1.8698480606079102 , validation accuracy:  13.72786656999917 %, lr:  0.00331255104784123\n",
+      "Epoch:  60 , validation loss:  1.8682516098022461 , validation accuracy:  12.475156814156739 %, lr:  0.00331255104784123\n",
+      "Epoch:  61 , validation loss:  1.872650146484375 , validation accuracy:  10.806560404560686 %, lr:  0.00331255104784123\n",
+      "Epoch:  62 , validation loss:  1.868748092651367 , validation accuracy:  13.11792352446806 %, lr:  0.00331255104784123\n",
+      "Epoch:  63 , validation loss:  1.869330596923828 , validation accuracy:  12.149445063645446 %, lr:  0.00331255104784123\n",
+      "Epoch:  64 , validation loss:  1.868980598449707 , validation accuracy:  11.097644992226924 %, lr:  0.00331255104784123\n",
+      "Epoch:  65 , validation loss:  1.869577980041504 , validation accuracy:  11.178081005919081 %, lr:  0.00331255104784123\n",
+      "Epoch:  66 , validation loss:  1.8683965682983399 , validation accuracy:  13.011877838255078 %, lr:  0.00331255104784123\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  67 , validation loss:  1.8699874877929688 , validation accuracy:  12.682919791227064 %, lr:  0.00331255104784123\n",
+      "Epoch:  68 , validation loss:  1.8684236526489257 , validation accuracy:  12.551625132106233 %, lr:  0.00331255104784123\n",
+      "Epoch:  69 , validation loss:  1.87042293548584 , validation accuracy:  11.204051378052872 %, lr:  0.00331255104784123\n",
+      "Epoch:  70 , validation loss:  1.868545150756836 , validation accuracy:  11.93663229199355 %, lr:  0.00331255104784123\n",
+      "Epoch:  71 , validation loss:  1.8689748764038085 , validation accuracy:  12.251883753728732 %, lr:  0.00331255104784123\n",
+      "Epoch:  72 , validation loss:  1.8699264526367188 , validation accuracy:  11.745461497119813 %, lr:  0.00331255104784123\n",
+      "Epoch:  73 , validation loss:  1.8683002471923829 , validation accuracy:  12.127442387254318 %, lr:  0.00331255104784123\n",
+      "Epoch:  74 , validation loss:  1.8694063186645509 , validation accuracy:  14.143753223752793 %, lr:  0.00331255104784123\n",
+      "Epoch:  75 , validation loss:  1.8683568954467773 , validation accuracy:  12.317170383676178 %, lr:  0.00331255104784123\n",
+      "Epoch:  76 , validation loss:  1.871821403503418 , validation accuracy:  12.665606209804537 %, lr:  0.00331255104784123\n",
+      "Epoch:  77 , validation loss:  1.8687334060668945 , validation accuracy:  12.255851449471395 %, lr:  0.00331255104784123\n",
+      "Epoch:  78 , validation loss:  1.8687294006347657 , validation accuracy:  12.551625132106233 %, lr:  0.00331255104784123\n",
+      "Epoch:  79 , validation loss:  1.8694564819335937 , validation accuracy:  12.717186254459149 %, lr:  0.00331255104784123\n",
+      "Epoch:  80 , validation loss:  1.8681028366088868 , validation accuracy:  13.291420038306297 %, lr:  0.00331255104784123\n",
+      "Epoch:  81 , validation loss:  1.8690059661865235 , validation accuracy:  12.256212149084364 %, lr:  0.000993765314352369\n",
+      "Epoch:  82 , validation loss:  1.8692968368530274 , validation accuracy:  13.862407525636725 %, lr:  0.000993765314352369\n",
+      "Epoch:  83 , validation loss:  1.868107223510742 , validation accuracy:  12.656949419093275 %, lr:  0.000993765314352369\n",
+      "Epoch:  84 , validation loss:  1.8678018569946289 , validation accuracy:  12.678230696258463 %, lr:  0.000993765314352369\n",
+      "Epoch:  85 , validation loss:  1.8693119049072267 , validation accuracy:  11.74113310176418 %, lr:  0.000993765314352369\n",
+      "Epoch:  86 , validation loss:  1.8680143356323242 , validation accuracy:  13.09664224730287 %, lr:  0.000993765314352369\n",
+      "Epoch:  87 , validation loss:  1.8676862716674805 , validation accuracy:  12.792933173182705 %, lr:  0.000993765314352369\n",
+      "Epoch:  88 , validation loss:  1.8674808502197267 , validation accuracy:  12.523490562294626 %, lr:  0.000993765314352369\n",
+      "Epoch:  89 , validation loss:  1.8676340103149414 , validation accuracy:  12.439447552472776 %, lr:  0.000993765314352369\n",
+      "Epoch:  90 , validation loss:  1.8675603866577148 , validation accuracy:  13.34336078257388 %, lr:  0.000993765314352369\n",
+      "Epoch:  91 , validation loss:  1.8673301696777345 , validation accuracy:  13.065261380974539 %, lr:  0.000993765314352369\n",
+      "Epoch:  92 , validation loss:  1.8677633285522461 , validation accuracy:  13.136319204729494 %, lr:  0.000993765314352369\n",
+      "Epoch:  93 , validation loss:  1.868004035949707 , validation accuracy:  12.308152893351945 %, lr:  0.000993765314352369\n",
+      "Epoch:  94 , validation loss:  1.869160270690918 , validation accuracy:  13.409729511360236 %, lr:  0.000993765314352369\n",
+      "Epoch:  95 , validation loss:  1.867790985107422 , validation accuracy:  12.958854995148592 %, lr:  0.000993765314352369\n",
+      "Epoch:  96 , validation loss:  1.8674156188964843 , validation accuracy:  13.028830720064638 %, lr:  0.000993765314352369\n",
+      "Epoch:  97 , validation loss:  1.8671699523925782 , validation accuracy:  13.029191419677607 %, lr:  0.000993765314352369\n",
+      "Epoch:  98 , validation loss:  1.866811180114746 , validation accuracy:  12.873729886487832 %, lr:  0.000993765314352369\n",
+      "Epoch:  99 , validation loss:  1.867242431640625 , validation accuracy:  12.497520190160836 %, lr:  0.000993765314352369\n",
+      "Epoch:  100 , validation loss:  1.8675439834594727 , validation accuracy:  12.527458258037289 %, lr:  0.000993765314352369\n",
+      "Epoch:  101 , validation loss:  1.8682445526123046 , validation accuracy:  13.168060770670792 %, lr:  0.000993765314352369\n",
+      "Epoch:  102 , validation loss:  1.8670730590820312 , validation accuracy:  13.316669011214152 %, lr:  0.000993765314352369\n",
+      "Epoch:  103 , validation loss:  1.866716194152832 , validation accuracy:  12.5061769808721 %, lr:  0.000993765314352369\n",
+      "Epoch:  104 , validation loss:  1.8666818618774415 , validation accuracy:  13.1644537745411 %, lr:  0.000993765314352369\n",
+      "Epoch:  105 , validation loss:  1.8690311431884765 , validation accuracy:  12.470467719188138 %, lr:  0.000993765314352369\n",
+      "Epoch:  106 , validation loss:  1.8667095184326172 , validation accuracy:  12.543329041007938 %, lr:  0.000993765314352369\n",
+      "Epoch:  107 , validation loss:  1.866444969177246 , validation accuracy:  12.198139511396304 %, lr:  0.000993765314352369\n",
+      "Epoch:  108 , validation loss:  1.8626653671264648 , validation accuracy:  13.31197991624555 %, lr:  0.000993765314352369\n",
+      "Epoch:  109 , validation loss:  1.852446937561035 , validation accuracy:  13.192227644739738 %, lr:  0.000993765314352369\n",
+      "Epoch:  110 , validation loss:  1.8487260818481446 , validation accuracy:  13.3913338310988 %, lr:  0.000993765314352369\n",
+      "Epoch:  111 , validation loss:  1.8205499649047852 , validation accuracy:  14.358008793856564 %, lr:  0.000993765314352369\n",
+      "Epoch:  112 , validation loss:  1.8011066436767578 , validation accuracy:  14.188840675373957 %, lr:  0.000993765314352369\n",
+      "Epoch:  113 , validation loss:  1.9319509506225585 , validation accuracy:  12.303103098770375 %, lr:  0.000993765314352369\n",
+      "Epoch:  114 , validation loss:  1.766097068786621 , validation accuracy:  15.87763626329629 %, lr:  0.000993765314352369\n",
+      "Epoch:  115 , validation loss:  1.7657604217529297 , validation accuracy:  16.254567358849222 %, lr:  0.000993765314352369\n",
+      "Epoch:  116 , validation loss:  1.7315216064453125 , validation accuracy:  17.787180014355844 %, lr:  0.000993765314352369\n",
+      "Epoch:  117 , validation loss:  1.7192726135253906 , validation accuracy:  18.396040961048048 %, lr:  0.000993765314352369\n",
+      "Epoch:  118 , validation loss:  1.7632301330566407 , validation accuracy:  14.895811916793814 %, lr:  0.000993765314352369\n",
+      "Epoch:  119 , validation loss:  1.6823776245117188 , validation accuracy:  19.574446596618802 %, lr:  0.000993765314352369\n",
+      "Epoch:  120 , validation loss:  1.660214614868164 , validation accuracy:  18.481526769321775 %, lr:  0.000993765314352369\n",
+      "Epoch:  121 , validation loss:  1.660712432861328 , validation accuracy:  17.78032672170943 %, lr:  0.000993765314352369\n",
+      "Epoch:  122 , validation loss:  1.6951280593872071 , validation accuracy:  20.776658406645527 %, lr:  0.000993765314352369\n",
+      "Epoch:  123 , validation loss:  1.7055862426757813 , validation accuracy:  18.75457637633955 %, lr:  0.000993765314352369\n",
+      "Epoch:  124 , validation loss:  1.612380027770996 , validation accuracy:  21.248453500409394 %, lr:  0.000993765314352369\n",
+      "Epoch:  125 , validation loss:  1.5855119705200196 , validation accuracy:  20.9227417498981 %, lr:  0.000993765314352369\n",
+      "Epoch:  126 , validation loss:  1.7729598999023437 , validation accuracy:  19.420067162267934 %, lr:  0.000993765314352369\n",
+      "Epoch:  127 , validation loss:  1.7467927932739258 , validation accuracy:  12.340976558132153 %, lr:  0.000993765314352369\n",
+      "Epoch:  128 , validation loss:  1.6998685836791991 , validation accuracy:  16.784435090301148 %, lr:  0.000993765314352369\n",
+      "Epoch:  129 , validation loss:  1.7539676666259765 , validation accuracy:  11.670796677235165 %, lr:  0.000993765314352369\n",
+      "Epoch:  130 , validation loss:  1.569759464263916 , validation accuracy:  18.84366918074297 %, lr:  0.000993765314352369\n",
+      "Epoch:  131 , validation loss:  2.015633201599121 , validation accuracy:  21.074235587345214 %, lr:  0.000993765314352369\n",
+      "Epoch:  132 , validation loss:  1.470371150970459 , validation accuracy:  21.686342830554143 %, lr:  0.000993765314352369\n",
+      "Epoch:  133 , validation loss:  1.6732473373413086 , validation accuracy:  14.674703054043622 %, lr:  0.000993765314352369\n",
+      "Epoch:  134 , validation loss:  1.5662439346313477 , validation accuracy:  18.402533554081497 %, lr:  0.000993765314352369\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  135 , validation loss:  1.5204621315002442 , validation accuracy:  23.15799725146895 %, lr:  0.000993765314352369\n",
+      "Epoch:  136 , validation loss:  1.461225986480713 , validation accuracy:  25.668105858122413 %, lr:  0.000993765314352369\n",
+      "Epoch:  137 , validation loss:  1.7022897720336914 , validation accuracy:  21.15178600413362 %, lr:  0.000993765314352369\n",
+      "Epoch:  138 , validation loss:  1.6106029510498048 , validation accuracy:  21.990773303900248 %, lr:  0.000993765314352369\n",
+      "Epoch:  139 , validation loss:  1.5011514663696288 , validation accuracy:  24.60584549792778 %, lr:  0.000993765314352369\n",
+      "Epoch:  140 , validation loss:  1.5479843139648437 , validation accuracy:  24.160020776297706 %, lr:  0.000993765314352369\n",
+      "Epoch:  141 , validation loss:  1.4775799751281737 , validation accuracy:  20.968911300358176 %, lr:  0.000993765314352369\n",
+      "Epoch:  142 , validation loss:  1.471799945831299 , validation accuracy:  16.269716742593936 %, lr:  0.000993765314352369\n",
+      "Epoch:  143 , validation loss:  1.4868105888366698 , validation accuracy:  25.290814062956514 %, lr:  0.000993765314352369\n",
+      "Epoch:  144 , validation loss:  1.4819032669067382 , validation accuracy:  22.432991029400625 %, lr:  0.000993765314352369\n",
+      "Epoch:  145 , validation loss:  1.5382058143615722 , validation accuracy:  17.03584272054076 %, lr:  0.000993765314352369\n",
+      "Epoch:  146 , validation loss:  1.5711252212524414 , validation accuracy:  22.33091303893031 %, lr:  0.000993765314352369\n",
+      "Epoch:  147 , validation loss:  1.4734992980957031 , validation accuracy:  26.93344010041877 %, lr:  0.000993765314352369\n",
+      "Epoch:  148 , validation loss:  1.5031538963317872 , validation accuracy:  27.111986408838582 %, lr:  0.000993765314352369\n",
+      "Epoch:  149 , validation loss:  1.4686474800109863 , validation accuracy:  22.733453807004064 %, lr:  0.000993765314352369\n",
+      "Epoch:  150 , validation loss:  1.4981348991394043 , validation accuracy:  25.575766757202267 %, lr:  0.000993765314352369\n",
+      "Epoch:  151 , validation loss:  1.563105010986328 , validation accuracy:  17.77455552790192 %, lr:  0.000993765314352369\n",
+      "Epoch:  152 , validation loss:  1.4533620834350587 , validation accuracy:  24.660311139486147 %, lr:  0.000993765314352369\n",
+      "Epoch:  153 , validation loss:  1.5119709014892577 , validation accuracy:  20.895328579312434 %, lr:  0.000993765314352369\n",
+      "Epoch:  154 , validation loss:  1.4439645767211915 , validation accuracy:  23.135273175851882 %, lr:  0.000993765314352369\n",
+      "Epoch:  155 , validation loss:  1.6100240707397462 , validation accuracy:  23.053394363707845 %, lr:  0.000993765314352369\n",
+      "Epoch:  156 , validation loss:  1.4522889137268067 , validation accuracy:  24.319089305617176 %, lr:  0.000993765314352369\n",
+      "Epoch:  157 , validation loss:  1.7037908554077148 , validation accuracy:  19.077041830334114 %, lr:  0.000993765314352369\n",
+      "Epoch:  158 , validation loss:  1.4359628677368164 , validation accuracy:  21.98175581357601 %, lr:  0.000993765314352369\n",
+      "Epoch:  159 , validation loss:  1.3940927505493164 , validation accuracy:  25.787858129628226 %, lr:  0.000993765314352369\n",
+      "Epoch:  160 , validation loss:  1.4702397346496583 , validation accuracy:  26.094092101039173 %, lr:  0.000993765314352369\n",
+      "Epoch:  161 , validation loss:  1.4399585723876953 , validation accuracy:  19.331695757090454 %, lr:  0.000993765314352369\n",
+      "Epoch:  162 , validation loss:  1.5577592849731445 , validation accuracy:  20.541842958602505 %, lr:  0.000993765314352369\n",
+      "Epoch:  163 , validation loss:  1.3700648307800294 , validation accuracy:  24.399886018922302 %, lr:  0.000993765314352369\n",
+      "Epoch:  164 , validation loss:  1.4281825065612792 , validation accuracy:  24.522523887331868 %, lr:  0.000993765314352369\n",
+      "Epoch:  165 , validation loss:  1.4671483993530274 , validation accuracy:  23.113270499460754 %, lr:  0.000993765314352369\n",
+      "Epoch:  166 , validation loss:  1.8202281951904298 , validation accuracy:  24.967627209736005 %, lr:  0.000993765314352369\n",
+      "Epoch:  167 , validation loss:  1.669172477722168 , validation accuracy:  21.131586825807336 %, lr:  0.000993765314352369\n",
+      "Epoch:  168 , validation loss:  1.4692268371582031 , validation accuracy:  19.426199055688414 %, lr:  0.000993765314352369\n",
+      "Epoch:  169 , validation loss:  1.4339914321899414 , validation accuracy:  26.652815801528646 %, lr:  0.000993765314352369\n"
+     ]
+    }
+   ],
+   "source": [
+    "def train():\n",
+    "           \n",
+    "    print(\"Initialising W&B...\")\n",
+    "    wandb.init()\n",
+    "\n",
+    "    from torch_geometric.data import Data\n",
+    "    from torch_geometric.data import DataLoader\n",
+    "    from torch_scatter import scatter_add\n",
+    "    \n",
+    "    # Local imports\n",
+    "    from utils.toy_utils import load_data, make_mlp\n",
+    "\n",
+    "    class TwoHopAttNetwork(nn.Module):\n",
+    "        \"\"\"\n",
+    "        A module which computes new node features on the graph.\n",
+    "        For each node, it aggregates the neighbor node features\n",
+    "        (separately on the input and output side), and combines\n",
+    "        them with the node's previous features in a fully-connected\n",
+    "        network to compute the new features.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
+    "                     layer_norm=True):\n",
+    "            super(TwoHopAttNetwork, self).__init__()\n",
+    "            self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                    hidden_activation=hidden_activation,\n",
+    "                                    output_activation=hidden_activation,\n",
+    "                                    layer_norm=layer_norm)\n",
+    "\n",
+    "        def forward(self, x, e, edge_index):\n",
+    "            start, end = edge_index\n",
+    "            # Aggregate edge-weighted incoming/outgoing features\n",
+    "            mi = scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mi2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mo = scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            mo2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
+    "            return self.network(node_inputs)\n",
+    "\n",
+    "    class TwoHopNetwork(nn.Module):\n",
+    "        \"\"\"\n",
+    "        A module which computes new node features on the graph.\n",
+    "        For each node, it aggregates the neighbor node features\n",
+    "        (separately on the input and output side), and combines\n",
+    "        them with the node's previous features in a fully-connected\n",
+    "        network to compute the new features.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
+    "                     layer_norm=True):\n",
+    "            super(TwoHopNetwork, self).__init__()\n",
+    "            self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                    hidden_activation=hidden_activation,\n",
+    "                                    output_activation=hidden_activation,\n",
+    "                                    layer_norm=layer_norm)\n",
+    "\n",
+    "        def forward(self, x, e, edge_index):\n",
+    "            start, end = edge_index\n",
+    "            # Aggregate edge-weighted incoming/outgoing features\n",
+    "            mi = scatter_add(x[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mi2 = scatter_add(scatter_add(x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mo = scatter_add(x[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            mo2 = scatter_add(scatter_add(x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
+    "            return self.network(node_inputs)\n",
+    "\n",
+    "    class Edge_Track_Net(nn.Module):\n",
+    "        \"\"\"\n",
+    "        Segment classification graph neural network model.\n",
+    "        Consists of an input network, an edge network, and a node network.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
+    "                     output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
+    "            super(Edge_Track_Net, self).__init__()\n",
+    "            self.n_graph_iters = n_graph_iters\n",
+    "            # Setup the input network\n",
+    "            self.input_network = make_mlp(input_dim, [hidden_dim],\n",
+    "                                          hidden_activation=nn.ReLU,\n",
+    "                                          layer_norm=False)\n",
+    "            # Setup the edge network\n",
+    "            self.edge_network = EdgeNetwork(input_dim+hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation, layer_norm=layer_norm)\n",
+    "            # Setup the node layers\n",
+    "            self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation=nn.ReLU, layer_norm=False)\n",
+    "\n",
+    "    #         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
+    "    #                                         layer_norm=False)\n",
+    "            self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, output_dim],\n",
+    "                                           hidden_activation=nn.ReLU,\n",
+    "                                          output_activation=None,\n",
+    "                                          layer_norm=False)\n",
+    "\n",
+    "        def forward(self, inputs):\n",
+    "            \"\"\"Apply forward pass of the model\"\"\"\n",
+    "            # Apply input network to get hidden representation\n",
+    "            x = self.input_network(inputs.x)\n",
+    "            # Shortcut connect the inputs onto the hidden representation\n",
+    "            x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Loop over iterations of edge and node networks\n",
+    "            for i in range(self.n_graph_iters):\n",
+    "                # Apply edge network\n",
+    "                e = torch.sigmoid(self.edge_network(x, inputs.edge_index))\n",
+    "                # Apply node network\n",
+    "                x = self.node_network(x, e, inputs.edge_index)\n",
+    "                # Shortcut connect the inputs onto the hidden representation\n",
+    "                x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Apply final edge network\n",
+    "            e = self.edge_network(x, inputs.edge_index)\n",
+    "            return e, self.output_network(x)\n",
+    "\n",
+    "    class Edge_Track_Truth_Net(nn.Module):\n",
+    "        \"\"\"\n",
+    "        Segment classification graph neural network model.\n",
+    "        Consists of an input network, an edge network, and a node network.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
+    "                     output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
+    "            super(Edge_Track_Truth_Net, self).__init__()\n",
+    "            self.n_graph_iters = n_graph_iters\n",
+    "            # Setup the input network\n",
+    "            self.input_network = make_mlp(input_dim, [hidden_dim],\n",
+    "                                          hidden_activation=nn.ReLU,\n",
+    "                                          layer_norm=False)\n",
+    "            # Setup the node layers\n",
+    "            self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation=nn.ReLU, layer_norm=False)\n",
+    "\n",
+    "    #         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
+    "    #                                         layer_norm=False)\n",
+    "            self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                           hidden_activation=nn.ReLU,\n",
+    "                                          output_activation=None,\n",
+    "                                          layer_norm=False)\n",
+    "\n",
+    "        def forward(self, inputs):\n",
+    "            \"\"\"Apply forward pass of the model\"\"\"\n",
+    "            # Apply input network to get hidden representation\n",
+    "            x = self.input_network(inputs.x)\n",
+    "            # Shortcut connect the inputs onto the hidden representation\n",
+    "            x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Loop over iterations of edge and node networks\n",
+    "            for i in range(self.n_graph_iters):\n",
+    "                # Apply edge network\n",
+    "                e = inputs.y_edges\n",
+    "                # Apply node network\n",
+    "                x = self.node_network(x, e, inputs.edge_index)\n",
+    "                # Shortcut connect the inputs onto the hidden representation\n",
+    "                x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Apply final edge network\n",
+    "            return self.output_network(x)\n",
+    "\n",
+    "    def validate(model, val_loader, val_size):\n",
+    "        model = model.eval()\n",
+    "        node_correct, node_total, loss = 0, 0, 0\n",
+    "        for batch in val_loader:\n",
+    "            data = batch.to(device)\n",
+    "#             print(len(data.y_params))\n",
+    "            node_pred = model(data)\n",
+    "            node_correct += (((node_pred - data.y_params)/data.y_params)**2 < 0.1**2).sum().item()\n",
+    "            node_total += len(node_pred)\n",
+    "            loss += F.mse_loss(node_pred, data.y_params)\n",
+    "        acc = node_correct / node_total\n",
+    "        return acc, loss.item()/val_size\n",
+    "\n",
+    "    def get_lr(optimizer):\n",
+    "        for param_group in optimizer.param_groups:\n",
+    "            return param_group['lr']\n",
+    "    \n",
+    "    print(\"Loading data...\")\n",
+    "    train_dataset, val_dataset = load_data(train_size=wandb.config.get(\"train_size\",0), test_size=20)\n",
+    "    train_loader, val_loader = DataLoader(train_dataset, batch_size=2, shuffle=True), DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
+    "    \n",
+    "    print(\"config:\", dict(wandb.config.user_items()))\n",
+    "\n",
+    "    device = torch.device('cuda') # if torch.cuda.is_available() else 'cpu')\n",
+    "    print(\"Using \", device)\n",
+    "    \n",
+    "    m_dic = [\"hidden_dim\", \"n_graph_iters\"]\n",
+    "    m_configs = {k:wandb.config.get(k,0) for k in m_dic} \n",
+    "    m_configs = {'input_dim': 3, **m_configs, 'output_dim': 1}\n",
+    "        \n",
+    "    print(\"Loading model...\")\n",
+    "    print(\"Model configs: \", m_configs)\n",
+    "    model = Edge_Track_Truth_Net(**m_configs).to(device)\n",
+    "    wandb.watch(model, log='all')\n",
+    "    \n",
+    "    print(\"Loading optimiser\")\n",
+    "    o_dic = [\"lr\"]\n",
+    "    o_configs = {k:wandb.config.get(k,0) for k in o_dic} \n",
+    "    optimizer_fn = getattr(torch.optim, wandb.config.get(\"optimizer\",0))\n",
+    "#     optimizer_kwargs = {\"Adam\": {}, \"SGD\": {}}\n",
+    "    optimizer = optimizer_fn(model.parameters(), amsgrad=True, **o_configs)\n",
+    "    \n",
+    "    print(\"Loading scheduler...\")\n",
+    "#     s_dic = [\"step_size\", \"gamma\"]\n",
+    "#     s_configs = {k:wandb.config.get(k,0) for k in s_dic} \n",
+    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30)\n",
+    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.3, patience=20)\n",
+    "    \n",
+    "    model.train()\n",
+    "    \n",
+    "    print(\"Training...\")\n",
+    "    \n",
+    "    ep = 0\n",
+    "    best_acc = 0\n",
+    "    for epoch in range(wandb.config.get(\"epochs\", 0)):\n",
+    "        for batch in train_loader:\n",
+    "            optimizer.zero_grad()\n",
+    "            data = batch.to(device)\n",
+    "#             print(len(data.y_params))\n",
+    "            node_pred = model(data)\n",
+    "            loss = F.mse_loss(node_pred, data.y_params)\n",
+    "#             print(loss)\n",
+    "            loss.backward()\n",
+    "            optimizer.step()\n",
+    "        ep += 1\n",
+    "#         print(\"Evaluating...\")\n",
+    "        val_acc, val_loss = validate(model, val_loader, 20)\n",
+    "        if (val_acc > best_acc): best_acc = val_acc\n",
+    "        scheduler.step(val_loss)\n",
+    "#         scheduler.step()\n",
+    "        lr = get_lr(optimizer)\n",
+    "        print(\"Epoch: \" , ep, \", validation loss: \", val_loss, \", validation accuracy: \", val_acc*100, \"%, lr: \", lr)\n",
+    "        wandb.log({\"Validation Accuracy\": val_acc, \"Best Accuracy\": best_acc, \"Validation Loss\": val_loss, \"Learning Rate\": lr})\n",
+    "    \n",
+    "wandb.agent(sweep_id, function=train)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 6,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:11.240625, resuming normal operation.\n"
+     ]
+    },
+    {
+     "ename": "ControllerError",
+     "evalue": "Only sweeps with a local controller are currently supported.",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mControllerError\u001b[0m                           Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-6-d64628e1e9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msweep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[0;32m~/.local/lib/python3.7/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, verbose, print_status, print_actions, print_debug)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mprint_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mprint_debug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_if_not_started\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m~/.local/lib/python3.7/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36m_start_if_not_started\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mis_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sweep_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'controller'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'local'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mControllerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only sweeps with a local controller are currently supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;31m# reset controller state, we might want to parse this and decide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;31mControllerError\u001b[0m: Only sweeps with a local controller are currently supported."
+     ]
     }
    ],
    "source": [
-    "dir(tnn)"
+    "sweep = wandb.controller(sweep_id)\n",
+    "sweep.run()"
    ]
   },
   {
diff --git a/notebooks/ToyModelTrackML.ipynb b/notebooks/ToyModelTrackML.ipynb
index d3f957d..99145d1 100644
--- a/notebooks/ToyModelTrackML.ipynb
+++ b/notebooks/ToyModelTrackML.ipynb
@@ -11,10 +11,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 3,
    "metadata": {
     "cell_style": "center",
-    "code_folding": []
+    "code_folding": [
+     0
+    ]
    },
    "outputs": [],
    "source": [
@@ -33,6 +35,9 @@
     "import matplotlib.colors\n",
     "import numpy as np\n",
     "import torch\n",
+    "import torch.multiprocessing as mp\n",
+    "import torch.nn as nn\n",
+    "# mp.set_start_method(\"forkserver\", force=True)\n",
     "from torch_geometric.data import Data\n",
     "from torch_geometric.data import DataLoader\n",
     "import seaborn as sns\n",
@@ -43,17 +48,18 @@
     "from ipywidgets import interact, interact_manual\n",
     "\n",
     "# Limit CPU usage on Jupyter\n",
-    "os.environ['OMP_NUM_THREADS'] = '4'\n",
+    "os.environ['OMP_NUM_THREADS'] = '1'\n",
     "\n",
     "# Local imports\n",
-    "from utils.toy_utils import *\n",
-    "from datasets.hitgraphs_params import *\n",
+    "from utils.toy_utils import load_data, make_mlp\n",
     "%matplotlib inline"
    ]
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "## Loading TrackML Dataset"
    ]
@@ -61,7 +67,9 @@
   {
    "cell_type": "code",
    "execution_count": 6,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -79,7 +87,9 @@
   {
    "cell_type": "code",
    "execution_count": 2,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "input_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/\"\n",
@@ -90,7 +100,9 @@
   {
    "cell_type": "code",
    "execution_count": 3,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "full_graphs = [load_graph(fi) for fi in filenames]"
@@ -99,7 +111,9 @@
   {
    "cell_type": "code",
    "execution_count": 5,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "cut_mask = [~(np.isnan(g[3]).any()) for g in full_graphs]\n",
@@ -109,7 +123,9 @@
   {
    "cell_type": "code",
    "execution_count": 4,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
     "cut_full_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),\n",
@@ -117,6 +133,15 @@
     "                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in full_graphs]"
    ]
   },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "metadata": {
+    "hidden": true
+   },
+   "outputs": [],
+   "source": []
+  },
   {
    "cell_type": "markdown",
    "metadata": {
@@ -1440,19 +1465,15 @@
     "## Combined Edge & Track Param Classifier"
    ]
   },
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "How to do a double scatter..."
-   ]
-  },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 4,
    "metadata": {
     "code_folding": [
-     52
+     0,
+     26,
+     52,
+     97
     ]
    },
    "outputs": [],
@@ -1598,37 +1619,43 @@
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "#### Generate data"
    ]
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "#### Load data"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
-   "metadata": {},
+   "execution_count": 3,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [],
    "source": [
-    "train_size = int(0.5 * len(cut_full_dataset))\n",
-    "test_size = int(0.1 * len(cut_full_dataset))\n",
-    "train_dataset = cut_full_dataset[:train_size]\n",
-    "test_dataset = cut_full_dataset[-test_size:]\n",
-    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
+    "train_size, test_size = 300, 50\n",
+    "train_dataset, test_dataset = load_data(train_size, test_size)\n",
+    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
     "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
     "t_configs = {'train_size': train_size, 'test_size': test_size}"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
-   "metadata": {},
+   "execution_count": 4,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -1642,7 +1669,8 @@
     "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
     "print(\"Using \", device)\n",
     "# model = Edge_Class_Net( input_dim=2, hidden_dim=64, n_graph_iters=4).to(device)\n",
-    "m_configs = {'input_dim': 3, 'hidden_dim': 16, 'n_graph_iters': 3, 'output_dim': 1}\n",
+    "m_configs = {'hidden_dim': 16, 'n_graph_iters': 3}\n",
+    "m_configs = {'input_dim': 3, **m_configs, 'output_dim': 1}\n",
     "model = Edge_Track_Truth_Net(**m_configs).to(device)\n",
     "# data = dataset[0].to(device)\n",
     "o_configs = {'lr': 0.001, 'weight_decay': 1e-4}\n",
@@ -1664,7 +1692,9 @@
   {
    "cell_type": "code",
    "execution_count": 9,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "data": {
@@ -1719,66 +1749,21 @@
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": 16,
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Traceback (most recent call last):\r\n",
-      "  File \"/global/homes/d/danieltm/.local/bin/wandb\", line 6, in <module>\r\n",
-      "    from wandb.cli import cli\r\n",
-      "ModuleNotFoundError: No module named 'wandb'\r\n"
-     ]
-    }
-   ],
-   "source": [
-    "!wandb"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 47,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "[<matplotlib.lines.Line2D at 0x2aab7fcdaf60>]"
-      ]
-     },
-     "execution_count": 47,
-     "metadata": {},
-     "output_type": "execute_result"
-    },
-    {
-     "data": {
-      "image/png": "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\n",
-      "text/plain": [
-       "<Figure size 1152x288 with 2 Axes>"
-      ]
-     },
-     "metadata": {
-      "needs_background": "light"
-     },
-     "output_type": "display_data"
-    }
-   ],
+   "cell_type": "markdown",
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
-    "fig, axs = plt.subplots(1,2)\n",
-    "fig.set_size_inches(16,4)\n",
-    "axs[0].plot(np.arange(len(loss_v_node)), loss_v_node)\n",
-    "# axs[1].plot(np.arange(len(loss_v_edge)), loss_v_edge)\n",
-    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
-    "# axs[3].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
+    "### Training and Validation"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 10,
-   "metadata": {},
+   "metadata": {
+    "code_folding": [],
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stderr",
@@ -2276,7 +2261,9 @@
   {
    "cell_type": "code",
    "execution_count": 52,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
@@ -3714,16 +3701,66 @@
     "    print('Accuracy: {:.4f}%'.format(acc))"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "metadata": {
+    "heading_collapsed": true
+   },
+   "source": [
+    "### Debug"
+   ]
+  },
   {
    "cell_type": "code",
-   "execution_count": 42,
-   "metadata": {},
+   "execution_count": 47,
+   "metadata": {
+    "hidden": true
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "[<matplotlib.lines.Line2D at 0x2aab7fcdaf60>]"
+      ]
+     },
+     "execution_count": 47,
+     "metadata": {},
+     "output_type": "execute_result"
+    },
+    {
+     "data": {
+      "image/png": "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\n",
+      "text/plain": [
+       "<Figure size 1152x288 with 2 Axes>"
+      ]
+     },
+     "metadata": {
+      "needs_background": "light"
+     },
+     "output_type": "display_data"
+    }
+   ],
+   "source": [
+    "fig, axs = plt.subplots(1,2)\n",
+    "fig.set_size_inches(16,4)\n",
+    "axs[0].plot(np.arange(len(loss_v_node)), loss_v_node)\n",
+    "# axs[1].plot(np.arange(len(loss_v_edge)), loss_v_edge)\n",
+    "axs[1].plot(np.arange(len(acc_v_node)), acc_v_node)\n",
+    "# axs[3].plot(np.arange(len(acc_v_edge)), acc_v_edge)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 10,
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "13.484405994415283 13.484405994415283\n"
+      "0.0 0.0\n"
      ]
     }
    ],
@@ -3736,7 +3773,9 @@
   },
   {
    "cell_type": "markdown",
-   "metadata": {},
+   "metadata": {
+    "heading_collapsed": true
+   },
    "source": [
     "## Getting Weights & Bias to Work"
    ]
@@ -3744,7 +3783,9 @@
   {
    "cell_type": "code",
    "execution_count": 18,
-   "metadata": {},
+   "metadata": {
+    "hidden": true
+   },
    "outputs": [
     {
      "data": {
@@ -3852,6 +3893,1578 @@
     "model.output_network"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Sweep"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 28,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "1.013009359863071e-05"
+      ]
+     },
+     "execution_count": 28,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "import numpy as np\n",
+    "np.exp(-11.5)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 29,
+   "metadata": {
+    "code_folding": []
+   },
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Create sweep with ID: 94oxvjm5\n",
+      "Sweep URL: https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\n"
+     ]
+    }
+   ],
+   "source": [
+    "# System imports\n",
+    "import os\n",
+    "import sys\n",
+    "from pprint import pprint as pp\n",
+    "from time import time as tt\n",
+    "sys.path.append('..')\n",
+    "sys.path.append('/global/common/cori_cle7/software/jupyter/19-11/lib/python3.7/site-packages')\n",
+    "sys.path.append('/global/homes/d/danieltm/.local/lib/python3.7/site-packages')\n",
+    "import wandb\n",
+    "# External imports\n",
+    "import numpy as np\n",
+    "import torch\n",
+    "import torch.nn.functional as F\n",
+    "import torch.nn as nn\n",
+    "\n",
+    "sweep_config = {\n",
+    "    \"name\": \"Track Param Sweep\",\n",
+    "    \"method\": \"bayes\",\n",
+    "#     \"controller\": \"local\",\n",
+    "    \"metric\": {\n",
+    "        \"name\": \"Best Accuracy\",\n",
+    "        \"goal\": \"maximize\"\n",
+    "    },\n",
+    "#     \"early_terminate\": {\n",
+    "#         \"type\": \"hyperband\",\n",
+    "#         \"min_iter\": 3\n",
+    "#     },\n",
+    "    \"parameters\": {\n",
+    "        \"n_graph_iters\": {\n",
+    "            \"min\": 1,\n",
+    "            \"max\": 8\n",
+    "        },\n",
+    "        \"hidden_dim\": {\n",
+    "            \"distribution\": \"q_log_normal\",\n",
+    "            \"mu\": 2.8,\n",
+    "            \"sigma\": 0.8,\n",
+    "            \"min\": 1.386,\n",
+    "            \"max\": 4.159\n",
+    "        },\n",
+    "        \"lr\": {\n",
+    "            \"distribution\": \"log_normal\",\n",
+    "            \"mu\": -6.9,\n",
+    "            \"sigma\": 1.5,\n",
+    "            \"min\": -11.5,\n",
+    "            \"max\": -2.3\n",
+    "        },\n",
+    "#         \"step_size\": {\n",
+    "#             \"min\": 1,\n",
+    "#             \"max\": 100\n",
+    "#         },\n",
+    "#         \"gamma\": {\n",
+    "#             \"min\": 0.01,\n",
+    "#             \"max\": 0.99\n",
+    "#         },\n",
+    "        \"weight_decay\": {\n",
+    "            \"distribution\": \"log_uniform\",\n",
+    "            \"min\": -11.5,\n",
+    "            \"max\": -4.6\n",
+    "        },\n",
+    "        \"network\": {\n",
+    "            \"values\": [\"Edge_Track_Truth_Net\"]\n",
+    "        },\n",
+    "        \"optimizer\": {\n",
+    "            \"values\": [\"AdamW\"] #, \"Adam\", \"Adamax\", \"SGD\"] \n",
+    "        },\n",
+    "        \"train_size\": {\n",
+    "            \"min\": 100,\n",
+    "            \"max\": 800\n",
+    "        },\n",
+    "        \"epochs\": {\n",
+    "            \"distribution\": \"q_normal\",\n",
+    "            \"mu\": 150,\n",
+    "            \"sigma\": 50,\n",
+    "            \"min\": 50,\n",
+    "            \"max\": 250\n",
+    "        }\n",
+    "    }\n",
+    "}\n",
+    "\n",
+    "sweep_id = wandb.sweep(sweep_config, entity= \"murnanedaniel\", project= \"node_regression_sweep\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {
+    "code_folding": [
+     12,
+     38,
+     64,
+     109,
+     150,
+     163
+    ]
+   },
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "wandb: Agent Starting Run: 6z6w77bj with config:\n",
+      "\tepochs: 145\n",
+      "\thidden_dim: 6\n",
+      "\tlr: 0.0005593278476713466\n",
+      "\tn_graph_iters: 4\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 440\n",
+      "\tweight_decay: 0.0031799247808893863\n",
+      "wandb: Agent Started Run: 6z6w77bj\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/6z6w77bj\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/6z6w77bj</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 145, 'hidden_dim': 6, 'lr': 0.0005593278476713466, 'n_graph_iters': 4, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 440, 'weight_decay': 0.0031799247808893863}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 6, 'n_graph_iters': 4, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.9531721115112304 , validation accuracy:  12.093897323248171 %, lr:  0.0005593278476713466\n",
+      "Epoch:  2 , validation loss:  1.8986032485961915 , validation accuracy:  14.847117469042956 %, lr:  0.0005593278476713466\n",
+      "Epoch:  3 , validation loss:  1.8829172134399415 , validation accuracy:  11.77359606693142 %, lr:  0.0005593278476713466\n",
+      "Epoch:  4 , validation loss:  1.8784471511840821 , validation accuracy:  10.659034262856236 %, lr:  0.0005593278476713466\n",
+      "Epoch:  5 , validation loss:  1.876345443725586 , validation accuracy:  10.855976251537482 %, lr:  0.0005593278476713466\n",
+      "Epoch:  6 , validation loss:  1.8762018203735351 , validation accuracy:  11.13587915120167 %, lr:  0.0005593278476713466\n",
+      "Epoch:  7 , validation loss:  1.8785106658935546 , validation accuracy:  10.260100490912173 %, lr:  0.0005593278476713466\n",
+      "Epoch:  8 , validation loss:  1.8760208129882812 , validation accuracy:  10.635228088400261 %, lr:  0.0005593278476713466\n",
+      "Epoch:  9 , validation loss:  1.8757272720336915 , validation accuracy:  10.700514718347707 %, lr:  0.0005593278476713466\n",
+      "Epoch:  10 , validation loss:  1.8760305404663087 , validation accuracy:  11.195394587341607 %, lr:  0.0005593278476713466\n",
+      "Epoch:  11 , validation loss:  1.87591552734375 , validation accuracy:  10.564891663871245 %, lr:  0.0005593278476713466\n",
+      "Epoch:  12 , validation loss:  1.875634765625 , validation accuracy:  11.108465980616003 %, lr:  0.0005593278476713466\n",
+      "Epoch:  13 , validation loss:  1.8752923965454102 , validation accuracy:  11.01576618008289 %, lr:  0.0005593278476713466\n",
+      "Epoch:  14 , validation loss:  1.8754623413085938 , validation accuracy:  11.131911455459008 %, lr:  0.0005593278476713466\n",
+      "Epoch:  15 , validation loss:  1.8750825881958009 , validation accuracy:  10.83685917205011 %, lr:  0.0005593278476713466\n",
+      "Epoch:  16 , validation loss:  1.8768203735351563 , validation accuracy:  10.354603789510133 %, lr:  0.0005593278476713466\n",
+      "Epoch:  17 , validation loss:  1.878851318359375 , validation accuracy:  11.750150592088415 %, lr:  0.0005593278476713466\n",
+      "Epoch:  18 , validation loss:  1.8759288787841797 , validation accuracy:  10.497801535858953 %, lr:  0.0005593278476713466\n",
+      "Epoch:  19 , validation loss:  1.8781431198120118 , validation accuracy:  10.17208978534766 %, lr:  0.0005593278476713466\n",
+      "Epoch:  20 , validation loss:  1.8748552322387695 , validation accuracy:  11.00999498627538 %, lr:  0.0005593278476713466\n",
+      "Epoch:  21 , validation loss:  1.8747251510620118 , validation accuracy:  10.84695876121325 %, lr:  0.0005593278476713466\n",
+      "Epoch:  22 , validation loss:  1.8746698379516602 , validation accuracy:  10.845155263148403 %, lr:  0.0005593278476713466\n",
+      "Epoch:  23 , validation loss:  1.8746694564819335 , validation accuracy:  10.89384971089926 %, lr:  0.0005593278476713466\n",
+      "Epoch:  24 , validation loss:  1.8746658325195313 , validation accuracy:  11.037408156861048 %, lr:  0.0005593278476713466\n",
+      "Epoch:  25 , validation loss:  1.8744884490966798 , validation accuracy:  10.859222548054207 %, lr:  0.0005593278476713466\n",
+      "Epoch:  26 , validation loss:  1.874483299255371 , validation accuracy:  10.933165968712915 %, lr:  0.0005593278476713466\n",
+      "Epoch:  27 , validation loss:  1.8747350692749023 , validation accuracy:  11.13696125004058 %, lr:  0.0005593278476713466\n",
+      "Epoch:  28 , validation loss:  1.8755889892578126 , validation accuracy:  10.486980547469873 %, lr:  0.0005593278476713466\n",
+      "Epoch:  29 , validation loss:  1.8743471145629882 , validation accuracy:  10.95697214316889 %, lr:  0.0005593278476713466\n",
+      "Epoch:  30 , validation loss:  1.8745080947875976 , validation accuracy:  10.705925212542247 %, lr:  0.0005593278476713466\n",
+      "Epoch:  31 , validation loss:  1.8742305755615234 , validation accuracy:  10.879421726380487 %, lr:  0.0005593278476713466\n",
+      "Epoch:  32 , validation loss:  1.8741748809814454 , validation accuracy:  10.922705679936806 %, lr:  0.0005593278476713466\n",
+      "Epoch:  33 , validation loss:  1.8742094039916992 , validation accuracy:  11.035243959183232 %, lr:  0.0005593278476713466\n",
+      "Epoch:  34 , validation loss:  1.875585174560547 , validation accuracy:  10.446942890430279 %, lr:  0.0005593278476713466\n",
+      "Epoch:  35 , validation loss:  1.874079704284668 , validation accuracy:  10.856336951150451 %, lr:  0.0005593278476713466\n",
+      "Epoch:  36 , validation loss:  1.8742612838745116 , validation accuracy:  10.680315540021427 %, lr:  0.0005593278476713466\n",
+      "Epoch:  37 , validation loss:  1.8806612014770507 , validation accuracy:  9.946652527241838 %, lr:  0.0005593278476713466\n",
+      "Epoch:  38 , validation loss:  1.8741384506225587 , validation accuracy:  11.079249311965489 %, lr:  0.0005593278476713466\n",
+      "Epoch:  39 , validation loss:  1.8739400863647462 , validation accuracy:  10.774458139006416 %, lr:  0.0005593278476713466\n",
+      "Epoch:  40 , validation loss:  1.8738052368164062 , validation accuracy:  10.928476873744314 %, lr:  0.0005593278476713466\n",
+      "Epoch:  41 , validation loss:  1.8740049362182618 , validation accuracy:  10.717106900544296 %, lr:  0.0005593278476713466\n",
+      "Epoch:  42 , validation loss:  1.8736364364624023 , validation accuracy:  10.859943947280144 %, lr:  0.0005593278476713466\n",
+      "Epoch:  43 , validation loss:  1.8737987518310546 , validation accuracy:  10.716746200931325 %, lr:  0.0005593278476713466\n",
+      "Epoch:  44 , validation loss:  1.873812484741211 , validation accuracy:  10.697989821056922 %, lr:  0.0005593278476713466\n",
+      "Epoch:  45 , validation loss:  1.8740493774414062 , validation accuracy:  10.614307510848041 %, lr:  0.0005593278476713466\n",
+      "Epoch:  46 , validation loss:  1.873581314086914 , validation accuracy:  10.990877906788006 %, lr:  0.0005593278476713466\n",
+      "Epoch:  47 , validation loss:  1.8734973907470702 , validation accuracy:  11.008912887436471 %, lr:  0.0005593278476713466\n",
+      "Epoch:  48 , validation loss:  1.8737653732299804 , validation accuracy:  10.670937350084223 %, lr:  0.0005593278476713466\n",
+      "Epoch:  49 , validation loss:  1.8738153457641602 , validation accuracy:  10.636670886852139 %, lr:  0.0005593278476713466\n",
+      "Epoch:  50 , validation loss:  1.8734216690063477 , validation accuracy:  11.01540548046992 %, lr:  0.0005593278476713466\n",
+      "Epoch:  51 , validation loss:  1.87474365234375 , validation accuracy:  11.412535754349136 %, lr:  0.0005593278476713466\n",
+      "Epoch:  52 , validation loss:  1.8732982635498048 , validation accuracy:  10.86174744534499 %, lr:  0.0005593278476713466\n",
+      "Epoch:  53 , validation loss:  1.874091911315918 , validation accuracy:  10.521247010701957 %, lr:  0.0005593278476713466\n",
+      "Epoch:  54 , validation loss:  1.8741378784179688 , validation accuracy:  10.507179725796153 %, lr:  0.0005593278476713466\n",
+      "Epoch:  55 , validation loss:  1.8731197357177733 , validation accuracy:  10.808003203012563 %, lr:  0.0005593278476713466\n",
+      "Epoch:  56 , validation loss:  1.8743284225463868 , validation accuracy:  11.380072789181897 %, lr:  0.0005593278476713466\n",
+      "Epoch:  57 , validation loss:  1.8730255126953126 , validation accuracy:  10.770129743650784 %, lr:  0.0005593278476713466\n",
+      "Epoch:  58 , validation loss:  1.8798282623291016 , validation accuracy:  9.986690184281432 %, lr:  0.0005593278476713466\n",
+      "Epoch:  59 , validation loss:  1.8750036239624024 , validation accuracy:  10.34630769841184 %, lr:  0.0005593278476713466\n",
+      "Epoch:  60 , validation loss:  1.8743223190307616 , validation accuracy:  11.42083184544743 %, lr:  0.0005593278476713466\n",
+      "Epoch:  61 , validation loss:  1.8728771209716797 , validation accuracy:  11.033801160731354 %, lr:  0.0005593278476713466\n",
+      "Epoch:  62 , validation loss:  1.8729375839233398 , validation accuracy:  10.70989290828491 %, lr:  0.0005593278476713466\n",
+      "Epoch:  63 , validation loss:  1.8727472305297852 , validation accuracy:  10.870764935669223 %, lr:  0.0005593278476713466\n",
+      "Epoch:  64 , validation loss:  1.8730810165405274 , validation accuracy:  10.640277882981831 %, lr:  0.0005593278476713466\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  65 , validation loss:  1.8728822708129882 , validation accuracy:  11.16762071714297 %, lr:  0.0005593278476713466\n",
+      "Epoch:  66 , validation loss:  1.873237419128418 , validation accuracy:  11.219200761797582 %, lr:  0.0005593278476713466\n",
+      "Epoch:  67 , validation loss:  1.8739568710327148 , validation accuracy:  10.423136715974305 %, lr:  0.0005593278476713466\n",
+      "Epoch:  68 , validation loss:  1.8724334716796875 , validation accuracy:  10.933887367938855 %, lr:  0.0005593278476713466\n",
+      "Epoch:  69 , validation loss:  1.8733497619628907 , validation accuracy:  10.510426022312878 %, lr:  0.0005593278476713466\n",
+      "Epoch:  70 , validation loss:  1.8725914001464843 , validation accuracy:  10.647852574854188 %, lr:  0.0005593278476713466\n",
+      "Epoch:  71 , validation loss:  1.8733623504638672 , validation accuracy:  10.460288776110144 %, lr:  0.0005593278476713466\n",
+      "Epoch:  72 , validation loss:  1.872760009765625 , validation accuracy:  10.624046400398212 %, lr:  0.0005593278476713466\n",
+      "Epoch:  73 , validation loss:  1.8734073638916016 , validation accuracy:  10.465699270304682 %, lr:  0.0005593278476713466\n",
+      "Epoch:  74 , validation loss:  1.8740711212158203 , validation accuracy:  10.345225599572931 %, lr:  0.0005593278476713466\n",
+      "Epoch:  75 , validation loss:  1.873086166381836 , validation accuracy:  10.485177049405026 %, lr:  0.0005593278476713466\n",
+      "Epoch:  76 , validation loss:  1.8723190307617188 , validation accuracy:  10.686447433441904 %, lr:  0.0005593278476713466\n",
+      "Epoch:  77 , validation loss:  1.8722063064575196 , validation accuracy:  10.79357521849379 %, lr:  0.0005593278476713466\n",
+      "Epoch:  78 , validation loss:  1.8723901748657226 , validation accuracy:  10.743437972291057 %, lr:  0.0005593278476713466\n",
+      "Epoch:  79 , validation loss:  1.8726631164550782 , validation accuracy:  10.568859359613906 %, lr:  0.0005593278476713466\n",
+      "Epoch:  80 , validation loss:  1.8723976135253906 , validation accuracy:  10.633785289948385 %, lr:  0.0005593278476713466\n",
+      "Epoch:  81 , validation loss:  1.8728776931762696 , validation accuracy:  11.350495420918413 %, lr:  0.0005593278476713466\n",
+      "Epoch:  82 , validation loss:  1.8732707977294922 , validation accuracy:  10.409790830294439 %, lr:  0.0005593278476713466\n",
+      "Epoch:  83 , validation loss:  1.8721363067626953 , validation accuracy:  10.660116361695144 %, lr:  0.0005593278476713466\n",
+      "Epoch:  84 , validation loss:  1.873846435546875 , validation accuracy:  10.367588975577029 %, lr:  0.0005593278476713466\n",
+      "Epoch:  85 , validation loss:  1.8753582000732423 , validation accuracy:  10.202749252450053 %, lr:  0.0005593278476713466\n",
+      "Epoch:  86 , validation loss:  1.8721250534057616 , validation accuracy:  10.61971800504258 %, lr:  0.0005593278476713466\n",
+      "Epoch:  87 , validation loss:  1.8717048645019532 , validation accuracy:  10.78311492971768 %, lr:  0.0005593278476713466\n",
+      "Epoch:  88 , validation loss:  1.8716144561767578 , validation accuracy:  10.923787778775713 %, lr:  0.0005593278476713466\n",
+      "Epoch:  89 , validation loss:  1.872230339050293 , validation accuracy:  11.156078329527952 %, lr:  0.0005593278476713466\n",
+      "Epoch:  90 , validation loss:  1.872199821472168 , validation accuracy:  10.57751615032517 %, lr:  0.0005593278476713466\n",
+      "Epoch:  91 , validation loss:  1.87149658203125 , validation accuracy:  11.011798484340227 %, lr:  0.0005593278476713466\n",
+      "Epoch:  92 , validation loss:  1.8724693298339843 , validation accuracy:  10.496719437020044 %, lr:  0.0005593278476713466\n",
+      "Epoch:  93 , validation loss:  1.8725467681884767 , validation accuracy:  11.377547891891112 %, lr:  0.0005593278476713466\n",
+      "Epoch:  94 , validation loss:  1.8720304489135742 , validation accuracy:  10.57282705535657 %, lr:  0.0005593278476713466\n",
+      "Epoch:  95 , validation loss:  1.871638298034668 , validation accuracy:  10.727567189320405 %, lr:  0.0005593278476713466\n",
+      "Epoch:  96 , validation loss:  1.8758441925048828 , validation accuracy:  10.142151717471206 %, lr:  0.0005593278476713466\n",
+      "Epoch:  97 , validation loss:  1.8727903366088867 , validation accuracy:  10.437925400106046 %, lr:  0.0005593278476713466\n",
+      "Epoch:  98 , validation loss:  1.8712970733642578 , validation accuracy:  10.806199704947716 %, lr:  0.0005593278476713466\n",
+      "Epoch:  99 , validation loss:  1.8715742111206055 , validation accuracy:  11.127583060103378 %, lr:  0.0005593278476713466\n",
+      "Epoch:  100 , validation loss:  1.8743104934692383 , validation accuracy:  10.273807076205008 %, lr:  0.0005593278476713466\n",
+      "Epoch:  101 , validation loss:  1.875387191772461 , validation accuracy:  10.231605221487596 %, lr:  0.0005593278476713466\n",
+      "Epoch:  102 , validation loss:  1.8710893630981444 , validation accuracy:  10.978253420334081 %, lr:  0.0005593278476713466\n",
+      "Epoch:  103 , validation loss:  1.8753400802612306 , validation accuracy:  10.253247198265756 %, lr:  0.0005593278476713466\n",
+      "Epoch:  104 , validation loss:  1.8711185455322266 , validation accuracy:  11.244449734705436 %, lr:  0.0005593278476713466\n",
+      "Epoch:  105 , validation loss:  1.8725625991821289 , validation accuracy:  10.564530964258276 %, lr:  0.0005593278476713466\n",
+      "Epoch:  106 , validation loss:  1.8724369049072265 , validation accuracy:  10.618635906203673 %, lr:  0.0005593278476713466\n",
+      "Epoch:  107 , validation loss:  1.8702205657958983 , validation accuracy:  11.394140074087701 %, lr:  0.0005593278476713466\n",
+      "Epoch:  108 , validation loss:  1.870070457458496 , validation accuracy:  11.418306948156646 %, lr:  0.0005593278476713466\n",
+      "Epoch:  109 , validation loss:  1.87020263671875 , validation accuracy:  11.693160053239263 %, lr:  0.0005593278476713466\n",
+      "Epoch:  110 , validation loss:  1.8698701858520508 , validation accuracy:  12.048809871627007 %, lr:  0.0005593278476713466\n",
+      "Epoch:  111 , validation loss:  1.8709693908691407 , validation accuracy:  11.240121339349802 %, lr:  0.0005593278476713466\n",
+      "Epoch:  112 , validation loss:  1.86944637298584 , validation accuracy:  11.83743989842699 %, lr:  0.0005593278476713466\n",
+      "Epoch:  113 , validation loss:  1.8698274612426757 , validation accuracy:  11.622462929097278 %, lr:  0.0005593278476713466\n",
+      "Epoch:  114 , validation loss:  1.8692007064819336 , validation accuracy:  12.067926951114382 %, lr:  0.0005593278476713466\n",
+      "Epoch:  115 , validation loss:  1.8693349838256836 , validation accuracy:  11.876395456627675 %, lr:  0.0005593278476713466\n",
+      "Epoch:  116 , validation loss:  1.8705448150634765 , validation accuracy:  11.471690490876103 %, lr:  0.0005593278476713466\n",
+      "Epoch:  117 , validation loss:  1.8692947387695313 , validation accuracy:  11.54743740959966 %, lr:  0.0005593278476713466\n",
+      "Epoch:  118 , validation loss:  1.8686590194702148 , validation accuracy:  12.09029032711848 %, lr:  0.0005593278476713466\n",
+      "Epoch:  119 , validation loss:  1.868765640258789 , validation accuracy:  11.754478987444045 %, lr:  0.0005593278476713466\n",
+      "Epoch:  120 , validation loss:  1.8686065673828125 , validation accuracy:  11.960438466449526 %, lr:  0.0005593278476713466\n",
+      "Epoch:  121 , validation loss:  1.8688928604125976 , validation accuracy:  12.473353316091892 %, lr:  0.0005593278476713466\n",
+      "Epoch:  122 , validation loss:  1.8681529998779296 , validation accuracy:  12.181547329199717 %, lr:  0.0005593278476713466\n",
+      "Epoch:  123 , validation loss:  1.8675992965698243 , validation accuracy:  12.107243208928036 %, lr:  0.0005593278476713466\n",
+      "Epoch:  124 , validation loss:  1.8673004150390624 , validation accuracy:  12.44341524821544 %, lr:  0.0005593278476713466\n",
+      "Epoch:  125 , validation loss:  1.867083740234375 , validation accuracy:  12.122031893059779 %, lr:  0.0005593278476713466\n",
+      "Epoch:  126 , validation loss:  1.868708038330078 , validation accuracy:  11.38981167873207 %, lr:  0.0005593278476713466\n",
+      "Epoch:  127 , validation loss:  1.8743803024291992 , validation accuracy:  10.79862501307536 %, lr:  0.0005593278476713466\n",
+      "Epoch:  128 , validation loss:  1.8697063446044921 , validation accuracy:  11.192869690050824 %, lr:  0.0005593278476713466\n",
+      "Epoch:  129 , validation loss:  1.8624420166015625 , validation accuracy:  12.196336013331457 %, lr:  0.0005593278476713466\n",
+      "Epoch:  130 , validation loss:  1.8629697799682616 , validation accuracy:  12.894289764427084 %, lr:  0.0005593278476713466\n",
+      "Epoch:  131 , validation loss:  1.8520706176757813 , validation accuracy:  12.308874292577885 %, lr:  0.0005593278476713466\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  132 , validation loss:  1.8433355331420898 , validation accuracy:  12.08451913331097 %, lr:  0.0005593278476713466\n",
+      "Epoch:  133 , validation loss:  1.8090879440307617 , validation accuracy:  16.35628464970657 %, lr:  0.0005593278476713466\n",
+      "Epoch:  134 , validation loss:  1.7933950424194336 , validation accuracy:  17.422512705643868 %, lr:  0.0005593278476713466\n",
+      "Epoch:  135 , validation loss:  1.764554214477539 , validation accuracy:  17.012036546084786 %, lr:  0.0005593278476713466\n",
+      "Epoch:  136 , validation loss:  1.7395240783691406 , validation accuracy:  17.03079292595919 %, lr:  0.0005593278476713466\n",
+      "Epoch:  137 , validation loss:  1.743990707397461 , validation accuracy:  14.98237982390645 %, lr:  0.0005593278476713466\n",
+      "Epoch:  138 , validation loss:  1.9159671783447265 , validation accuracy:  12.620879457796342 %, lr:  0.0005593278476713466\n",
+      "Epoch:  139 , validation loss:  1.6613945007324218 , validation accuracy:  16.275848636014416 %, lr:  0.0005593278476713466\n",
+      "Epoch:  140 , validation loss:  1.655807876586914 , validation accuracy:  17.8629269330794 %, lr:  0.0005593278476713466\n",
+      "Epoch:  141 , validation loss:  1.610279655456543 , validation accuracy:  15.686826168035523 %, lr:  0.0005593278476713466\n",
+      "Epoch:  142 , validation loss:  1.578897762298584 , validation accuracy:  16.797420276368044 %, lr:  0.0005593278476713466\n",
+      "Epoch:  143 , validation loss:  1.6376007080078125 , validation accuracy:  15.476177594061442 %, lr:  0.0005593278476713466\n",
+      "Epoch:  144 , validation loss:  1.5420040130615233 , validation accuracy:  16.543848448450614 %, lr:  0.0005593278476713466\n",
+      "Epoch:  145 , validation loss:  1.5786247253417969 , validation accuracy:  15.273464411572688 %, lr:  0.0005593278476713466\n",
+      "wandb: Agent Finished Run: 6z6w77bj \n",
+      "\n",
+      "wandb: Agent Starting Run: fa00gpx7 with config:\n",
+      "\tepochs: 76\n",
+      "\thidden_dim: 14\n",
+      "\tlr: 4.40904555309555e-05\n",
+      "\tn_graph_iters: 1\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 372\n",
+      "\tweight_decay: 0.003791854713708926\n",
+      "wandb: Agent Started Run: fa00gpx7\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fa00gpx7\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/fa00gpx7</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 76, 'hidden_dim': 14, 'lr': 4.40904555309555e-05, 'n_graph_iters': 1, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 372, 'weight_decay': 0.003791854713708926}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 14, 'n_graph_iters': 1, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  3.7278114318847657 , validation accuracy:  0.0 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  2 , validation loss:  3.5292301177978516 , validation accuracy:  0.0 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  3 , validation loss:  3.1365425109863283 , validation accuracy:  0.0 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  4 , validation loss:  2.4351242065429686 , validation accuracy:  0.7801932628526289 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  5 , validation loss:  1.9298881530761718 , validation accuracy:  14.903747308279138 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  6 , validation loss:  1.9044965744018554 , validation accuracy:  12.562446120495313 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  7 , validation loss:  1.8998361587524415 , validation accuracy:  12.05782736195124 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  8 , validation loss:  1.896632766723633 , validation accuracy:  11.948174679608568 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  9 , validation loss:  1.8947435379028321 , validation accuracy:  11.577375477476112 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  10 , validation loss:  1.8924917221069335 , validation accuracy:  11.572686382507511 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  11 , validation loss:  1.891324234008789 , validation accuracy:  11.28340529290612 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  12 , validation loss:  1.8891416549682618 , validation accuracy:  11.333542539108855 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  13 , validation loss:  1.8877214431762694 , validation accuracy:  11.169424215207817 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  14 , validation loss:  1.8865743637084962 , validation accuracy:  11.055803837122482 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  15 , validation loss:  1.885369110107422 , validation accuracy:  11.079610011578458 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  16 , validation loss:  1.88439998626709 , validation accuracy:  11.073478118157979 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  17 , validation loss:  1.8839008331298828 , validation accuracy:  10.922705679936806 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  18 , validation loss:  1.8829462051391601 , validation accuracy:  10.987992309884252 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  19 , validation loss:  1.882455062866211 , validation accuracy:  10.907195596579125 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  20 , validation loss:  1.8817428588867187 , validation accuracy:  10.945790455166842 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  21 , validation loss:  1.8817691802978516 , validation accuracy:  10.757865956809828 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  22 , validation loss:  1.8816070556640625 , validation accuracy:  10.675987144665793 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  23 , validation loss:  1.8806774139404296 , validation accuracy:  10.823513286370243 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  24 , validation loss:  1.8802175521850586 , validation accuracy:  10.923066379549775 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  25 , validation loss:  1.8805282592773438 , validation accuracy:  10.64677047601528 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  26 , validation loss:  1.8801979064941405 , validation accuracy:  10.663362658211868 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  27 , validation loss:  1.8799709320068358 , validation accuracy:  10.656148665952482 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  28 , validation loss:  1.8795246124267577 , validation accuracy:  10.7358632804187 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  29 , validation loss:  1.8793952941894532 , validation accuracy:  10.716385501318356 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  30 , validation loss:  1.8790878295898437 , validation accuracy:  10.786000526621436 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  31 , validation loss:  1.8790809631347656 , validation accuracy:  10.719271098222112 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  32 , validation loss:  1.8787851333618164 , validation accuracy:  10.776261637071263 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  33 , validation loss:  1.8788272857666015 , validation accuracy:  10.692218627249412 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  34 , validation loss:  1.8786537170410156 , validation accuracy:  10.71530340247945 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  35 , validation loss:  1.878653335571289 , validation accuracy:  10.674544346213917 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  36 , validation loss:  1.878767967224121 , validation accuracy:  10.613586111622102 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  37 , validation loss:  1.878911590576172 , validation accuracy:  10.537117793672607 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  38 , validation loss:  1.8780746459960938 , validation accuracy:  10.808003203012563 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  39 , validation loss:  1.8780241012573242 , validation accuracy:  10.790689621590035 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  40 , validation loss:  1.8779815673828124 , validation accuracy:  10.76724414674703 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  41 , validation loss:  1.8777515411376953 , validation accuracy:  10.835055673985263 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  42 , validation loss:  1.8779356002807617 , validation accuracy:  10.71963179783508 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  43 , validation loss:  1.8786104202270508 , validation accuracy:  10.49347314050332 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  44 , validation loss:  1.8776227951049804 , validation accuracy:  10.790689621590035 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  45 , validation loss:  1.877530288696289 , validation accuracy:  10.801871309592084 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  46 , validation loss:  1.8777795791625977 , validation accuracy:  10.659394962469205 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  47 , validation loss:  1.877604866027832 , validation accuracy:  10.712778505188664 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  48 , validation loss:  1.8773717880249023 , validation accuracy:  10.788164724299252 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  49 , validation loss:  1.8773452758789062 , validation accuracy:  10.759308755261705 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  50 , validation loss:  1.877370262145996 , validation accuracy:  10.718549698996172 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  51 , validation loss:  1.8776838302612304 , validation accuracy:  10.56849866000094 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  52 , validation loss:  1.877716636657715 , validation accuracy:  10.552988576643257 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  53 , validation loss:  1.8776115417480468 , validation accuracy:  10.565252363484214 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  54 , validation loss:  1.877252197265625 , validation accuracy:  10.675626445052824 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  55 , validation loss:  1.8772390365600586 , validation accuracy:  10.669855251245314 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  56 , validation loss:  1.877573013305664 , validation accuracy:  10.523411208379773 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  57 , validation loss:  1.8770433425903321 , validation accuracy:  10.692579326862383 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  58 , validation loss:  1.8770627975463867 , validation accuracy:  10.675626445052824 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  59 , validation loss:  1.8769197463989258 , validation accuracy:  10.713139204801633 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  60 , validation loss:  1.876671028137207 , validation accuracy:  10.810167400690379 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  61 , validation loss:  1.8770305633544921 , validation accuracy:  10.64099928220777 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  62 , validation loss:  1.8769170761108398 , validation accuracy:  10.659394962469205 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  63 , validation loss:  1.8766788482666015 , validation accuracy:  10.735141881192762 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  64 , validation loss:  1.877183723449707 , validation accuracy:  10.548660181287625 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  65 , validation loss:  1.8764652252197265 , validation accuracy:  10.811610199142256 %, lr:  4.40904555309555e-05\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  66 , validation loss:  1.8765291213989257 , validation accuracy:  10.747766367646687 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  67 , validation loss:  1.8764829635620117 , validation accuracy:  10.769408344424846 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  68 , validation loss:  1.8766719818115234 , validation accuracy:  10.661559160147021 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  69 , validation loss:  1.876531219482422 , validation accuracy:  10.69366142570129 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  70 , validation loss:  1.8769996643066407 , validation accuracy:  10.537117793672607 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  71 , validation loss:  1.8764623641967773 , validation accuracy:  10.682119038086272 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  72 , validation loss:  1.87647705078125 , validation accuracy:  10.654705867500605 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  73 , validation loss:  1.8765375137329101 , validation accuracy:  10.640277882981831 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  74 , validation loss:  1.8769598007202148 , validation accuracy:  10.52449330721868 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  75 , validation loss:  1.8761428833007812 , validation accuracy:  10.76796554597297 %, lr:  4.40904555309555e-05\n",
+      "Epoch:  76 , validation loss:  1.8763301849365235 , validation accuracy:  10.654345167887636 %, lr:  4.40904555309555e-05\n",
+      "wandb: Agent Finished Run: fa00gpx7 \n",
+      "\n",
+      "wandb: Agent Starting Run: zlxg59he with config:\n",
+      "\tepochs: 198\n",
+      "\thidden_dim: 60\n",
+      "\tlr: 0.0010998056123547838\n",
+      "\tn_graph_iters: 4\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 171\n",
+      "\tweight_decay: 5.067397328613272e-05\n",
+      "wandb: Agent Started Run: zlxg59he\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/zlxg59he\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/zlxg59he</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 198, 'hidden_dim': 60, 'lr': 0.0010998056123547838, 'n_graph_iters': 4, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 171, 'weight_decay': 5.067397328613272e-05}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 60, 'n_graph_iters': 4, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.8804880142211915 , validation accuracy:  10.674183646600948 %, lr:  0.0010998056123547838\n",
+      "Epoch:  2 , validation loss:  1.8809379577636718 , validation accuracy:  11.175916808241265 %, lr:  0.0010998056123547838\n",
+      "Epoch:  3 , validation loss:  1.8764944076538086 , validation accuracy:  10.852729955020758 %, lr:  0.0010998056123547838\n",
+      "Epoch:  4 , validation loss:  1.8746135711669922 , validation accuracy:  10.964546835041245 %, lr:  0.0010998056123547838\n",
+      "Epoch:  5 , validation loss:  1.8747282028198242 , validation accuracy:  10.776983036297203 %, lr:  0.0010998056123547838\n",
+      "Epoch:  6 , validation loss:  1.876715087890625 , validation accuracy:  11.854392780236548 %, lr:  0.0010998056123547838\n",
+      "Epoch:  7 , validation loss:  1.8733579635620117 , validation accuracy:  11.350856120531382 %, lr:  0.0010998056123547838\n",
+      "Epoch:  8 , validation loss:  1.8727087020874023 , validation accuracy:  11.423356742738216 %, lr:  0.0010998056123547838\n",
+      "Epoch:  9 , validation loss:  1.880712127685547 , validation accuracy:  12.458925331573118 %, lr:  0.0010998056123547838\n",
+      "Epoch:  10 , validation loss:  1.878457260131836 , validation accuracy:  12.15305205977514 %, lr:  0.0010998056123547838\n",
+      "Epoch:  11 , validation loss:  1.867630958557129 , validation accuracy:  11.162210222948431 %, lr:  0.0010998056123547838\n",
+      "Epoch:  12 , validation loss:  1.8823205947875976 , validation accuracy:  13.240200693264656 %, lr:  0.0010998056123547838\n",
+      "Epoch:  13 , validation loss:  1.868910026550293 , validation accuracy:  13.174553363704241 %, lr:  0.0010998056123547838\n",
+      "Epoch:  14 , validation loss:  1.8684541702270507 , validation accuracy:  12.54296834139497 %, lr:  0.0010998056123547838\n",
+      "Epoch:  15 , validation loss:  1.865360641479492 , validation accuracy:  11.539502018114336 %, lr:  0.0010998056123547838\n",
+      "Epoch:  16 , validation loss:  1.8706296920776366 , validation accuracy:  14.104076266326166 %, lr:  0.0010998056123547838\n",
+      "Epoch:  17 , validation loss:  1.8618343353271485 , validation accuracy:  12.262344042504843 %, lr:  0.0010998056123547838\n",
+      "Epoch:  18 , validation loss:  1.8622201919555663 , validation accuracy:  13.341557284509035 %, lr:  0.0010998056123547838\n",
+      "Epoch:  19 , validation loss:  1.860888671875 , validation accuracy:  12.339894459293244 %, lr:  0.0010998056123547838\n",
+      "Epoch:  20 , validation loss:  1.8606908798217774 , validation accuracy:  12.607172872503508 %, lr:  0.0010998056123547838\n",
+      "Epoch:  21 , validation loss:  1.8602066040039062 , validation accuracy:  12.786079880536288 %, lr:  0.0010998056123547838\n",
+      "Epoch:  22 , validation loss:  1.8641481399536133 , validation accuracy:  13.135237105890585 %, lr:  0.0010998056123547838\n",
+      "Epoch:  23 , validation loss:  1.860236358642578 , validation accuracy:  12.062877156532812 %, lr:  0.0010998056123547838\n",
+      "Epoch:  24 , validation loss:  1.858870506286621 , validation accuracy:  12.555232128235927 %, lr:  0.0010998056123547838\n",
+      "Epoch:  25 , validation loss:  1.8607519149780274 , validation accuracy:  13.420550499749314 %, lr:  0.0010998056123547838\n",
+      "Epoch:  26 , validation loss:  1.859197998046875 , validation accuracy:  13.128383813244168 %, lr:  0.0010998056123547838\n",
+      "Epoch:  27 , validation loss:  1.8562294006347657 , validation accuracy:  11.913547516763515 %, lr:  0.0010998056123547838\n",
+      "Epoch:  28 , validation loss:  1.861759567260742 , validation accuracy:  12.064680654597657 %, lr:  0.0010998056123547838\n",
+      "Epoch:  29 , validation loss:  1.8633956909179688 , validation accuracy:  11.04642564718528 %, lr:  0.0010998056123547838\n",
+      "Epoch:  30 , validation loss:  1.8228670120239259 , validation accuracy:  10.986910211045343 %, lr:  0.0010998056123547838\n",
+      "Epoch:  31 , validation loss:  1.8704645156860351 , validation accuracy:  12.496077391708958 %, lr:  0.0010998056123547838\n",
+      "Epoch:  32 , validation loss:  1.8449693679809571 , validation accuracy:  17.385360645508026 %, lr:  0.0010998056123547838\n",
+      "Epoch:  33 , validation loss:  1.6817790985107421 , validation accuracy:  17.662738647881433 %, lr:  0.0010998056123547838\n",
+      "Epoch:  34 , validation loss:  1.589747428894043 , validation accuracy:  13.695764304444902 %, lr:  0.0010998056123547838\n",
+      "Epoch:  35 , validation loss:  1.9052196502685548 , validation accuracy:  9.591724108080033 %, lr:  0.0010998056123547838\n",
+      "Epoch:  36 , validation loss:  1.8695035934448243 , validation accuracy:  13.01764903206259 %, lr:  0.0010998056123547838\n",
+      "Epoch:  37 , validation loss:  1.8073549270629883 , validation accuracy:  14.356565995404688 %, lr:  0.0010998056123547838\n",
+      "Epoch:  38 , validation loss:  1.5407707214355468 , validation accuracy:  18.0804287996999 %, lr:  0.0010998056123547838\n",
+      "Epoch:  39 , validation loss:  1.5230661392211915 , validation accuracy:  22.47338938605319 %, lr:  0.0010998056123547838\n",
+      "Epoch:  40 , validation loss:  1.6076337814331054 , validation accuracy:  15.072915426761746 %, lr:  0.0010998056123547838\n",
+      "Epoch:  41 , validation loss:  1.9421550750732421 , validation accuracy:  16.28161982982192 %, lr:  0.0010998056123547838\n",
+      "Epoch:  42 , validation loss:  1.5564777374267578 , validation accuracy:  22.16787681386818 %, lr:  0.0010998056123547838\n",
+      "Epoch:  43 , validation loss:  1.1987333297729492 , validation accuracy:  25.688665736061665 %, lr:  0.0010998056123547838\n",
+      "Epoch:  44 , validation loss:  1.876369094848633 , validation accuracy:  11.14706083920372 %, lr:  0.0010998056123547838\n",
+      "Epoch:  45 , validation loss:  1.8256284713745117 , validation accuracy:  11.270059407226256 %, lr:  0.0010998056123547838\n",
+      "Epoch:  46 , validation loss:  1.7095735549926758 , validation accuracy:  12.144755968676845 %, lr:  0.0010998056123547838\n",
+      "Epoch:  47 , validation loss:  1.5456589698791503 , validation accuracy:  18.03173435194904 %, lr:  0.0010998056123547838\n",
+      "Epoch:  48 , validation loss:  1.5109309196472167 , validation accuracy:  17.303121133751024 %, lr:  0.0010998056123547838\n",
+      "Epoch:  49 , validation loss:  1.7015897750854492 , validation accuracy:  17.420709207579023 %, lr:  0.0010998056123547838\n",
+      "Epoch:  50 , validation loss:  1.9876705169677735 , validation accuracy:  13.44940646878686 %, lr:  0.0010998056123547838\n",
+      "Epoch:  51 , validation loss:  1.1941940307617187 , validation accuracy:  25.788218829241195 %, lr:  0.0010998056123547838\n",
+      "Epoch:  52 , validation loss:  1.617880630493164 , validation accuracy:  19.013919398064484 %, lr:  0.0010998056123547838\n",
+      "Epoch:  53 , validation loss:  1.5946200370788575 , validation accuracy:  14.793733926323496 %, lr:  0.0010998056123547838\n",
+      "Epoch:  54 , validation loss:  1.6764551162719727 , validation accuracy:  16.748004429391248 %, lr:  0.0010998056123547838\n",
+      "Epoch:  55 , validation loss:  1.3535801887512207 , validation accuracy:  12.240702065726683 %, lr:  0.0010998056123547838\n",
+      "Epoch:  56 , validation loss:  1.0796710968017578 , validation accuracy:  22.44633691508049 %, lr:  0.0010998056123547838\n",
+      "Epoch:  57 , validation loss:  1.4280570983886718 , validation accuracy:  21.86164284245723 %, lr:  0.0010998056123547838\n",
+      "Epoch:  58 , validation loss:  1.2952659606933594 , validation accuracy:  23.19082091624916 %, lr:  0.0010998056123547838\n",
+      "Epoch:  59 , validation loss:  1.4412117958068849 , validation accuracy:  22.39295337236103 %, lr:  0.0010998056123547838\n",
+      "Epoch:  60 , validation loss:  1.1516200065612794 , validation accuracy:  32.46945776027182 %, lr:  0.0010998056123547838\n",
+      "Epoch:  61 , validation loss:  1.4659558296203614 , validation accuracy:  16.570900919423316 %, lr:  0.0010998056123547838\n",
+      "Epoch:  62 , validation loss:  1.9254838943481445 , validation accuracy:  18.646727192061725 %, lr:  0.0010998056123547838\n",
+      "Epoch:  63 , validation loss:  1.6719303131103516 , validation accuracy:  21.780485429539134 %, lr:  0.0010998056123547838\n",
+      "Epoch:  64 , validation loss:  1.184373378753662 , validation accuracy:  24.980612395802897 %, lr:  0.0010998056123547838\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  65 , validation loss:  1.223193359375 , validation accuracy:  27.123168096840633 %, lr:  0.0010998056123547838\n",
+      "Epoch:  66 , validation loss:  1.3013081550598145 , validation accuracy:  20.71930716818341 %, lr:  0.0010998056123547838\n",
+      "Epoch:  67 , validation loss:  1.0981802940368652 , validation accuracy:  25.346001103740818 %, lr:  0.0010998056123547838\n",
+      "Epoch:  68 , validation loss:  1.2725021362304687 , validation accuracy:  19.96580567669051 %, lr:  0.0010998056123547838\n",
+      "Epoch:  69 , validation loss:  1.104786491394043 , validation accuracy:  25.251137105529885 %, lr:  0.0010998056123547838\n",
+      "Epoch:  70 , validation loss:  1.1228708267211913 , validation accuracy:  29.617045220910477 %, lr:  0.0010998056123547838\n",
+      "Epoch:  71 , validation loss:  1.1528669357299806 , validation accuracy:  30.050606155699594 %, lr:  0.0010998056123547838\n",
+      "Epoch:  72 , validation loss:  1.0938784599304199 , validation accuracy:  29.087177489458554 %, lr:  0.0010998056123547838\n",
+      "Epoch:  73 , validation loss:  1.203708553314209 , validation accuracy:  29.36708038912274 %, lr:  0.0010998056123547838\n",
+      "Epoch:  74 , validation loss:  1.6982343673706055 , validation accuracy:  13.071032574782047 %, lr:  0.0010998056123547838\n",
+      "Epoch:  75 , validation loss:  1.5860557556152344 , validation accuracy:  16.328150079894964 %, lr:  0.0010998056123547838\n",
+      "Epoch:  76 , validation loss:  1.5915766716003419 , validation accuracy:  15.746702303788428 %, lr:  0.0010998056123547838\n",
+      "Epoch:  77 , validation loss:  1.8569202423095703 , validation accuracy:  14.473071970393775 %, lr:  0.00027495140308869594\n",
+      "Epoch:  78 , validation loss:  1.8321142196655273 , validation accuracy:  14.619516013259318 %, lr:  0.00027495140308869594\n",
+      "Epoch:  79 , validation loss:  1.6553125381469727 , validation accuracy:  16.269716742593936 %, lr:  0.00027495140308869594\n",
+      "Epoch:  80 , validation loss:  1.387154769897461 , validation accuracy:  21.310133134227147 %, lr:  0.00027495140308869594\n",
+      "Epoch:  81 , validation loss:  1.2863231658935548 , validation accuracy:  22.057502732299568 %, lr:  0.00027495140308869594\n",
+      "Epoch:  82 , validation loss:  1.2347162246704102 , validation accuracy:  23.108220704879184 %, lr:  0.00027495140308869594\n",
+      "Epoch:  83 , validation loss:  1.1674013137817383 , validation accuracy:  21.789863619476336 %, lr:  0.00027495140308869594\n",
+      "Epoch:  84 , validation loss:  1.2193695068359376 , validation accuracy:  25.73339248806986 %, lr:  0.00027495140308869594\n",
+      "Epoch:  85 , validation loss:  0.8428991317749024 , validation accuracy:  31.671950915996668 %, lr:  0.00027495140308869594\n",
+      "Epoch:  86 , validation loss:  0.9680530548095703 , validation accuracy:  29.611995426328907 %, lr:  0.00027495140308869594\n",
+      "Epoch:  87 , validation loss:  1.1704620361328124 , validation accuracy:  26.40717936509654 %, lr:  0.00027495140308869594\n",
+      "Epoch:  88 , validation loss:  1.1110698699951171 , validation accuracy:  32.49651023124452 %, lr:  0.00027495140308869594\n",
+      "Epoch:  89 , validation loss:  0.9000499725341797 , validation accuracy:  35.133585101663186 %, lr:  0.00027495140308869594\n",
+      "Epoch:  90 , validation loss:  0.809166145324707 , validation accuracy:  36.651769772651036 %, lr:  0.00027495140308869594\n",
+      "Epoch:  91 , validation loss:  1.2224457740783692 , validation accuracy:  33.08986109457904 %, lr:  0.00027495140308869594\n",
+      "Epoch:  92 , validation loss:  0.9432615280151367 , validation accuracy:  34.03886177630132 %, lr:  0.00027495140308869594\n",
+      "Epoch:  93 , validation loss:  0.7712730884552002 , validation accuracy:  33.3243158430091 %, lr:  0.00027495140308869594\n",
+      "Epoch:  94 , validation loss:  0.751514482498169 , validation accuracy:  37.042768153109776 %, lr:  0.00027495140308869594\n",
+      "Epoch:  95 , validation loss:  0.6952875137329102 , validation accuracy:  37.35296982026338 %, lr:  0.00027495140308869594\n",
+      "Epoch:  96 , validation loss:  0.8873835563659668 , validation accuracy:  31.029544905298316 %, lr:  0.00027495140308869594\n",
+      "Epoch:  97 , validation loss:  0.9883424758911132 , validation accuracy:  32.697419915668426 %, lr:  0.00027495140308869594\n",
+      "Epoch:  98 , validation loss:  0.7669062614440918 , validation accuracy:  38.74022053174337 %, lr:  0.00027495140308869594\n",
+      "Epoch:  99 , validation loss:  0.7671233177185058 , validation accuracy:  36.625438700904276 %, lr:  0.00027495140308869594\n",
+      "Epoch:  100 , validation loss:  1.0379324913024903 , validation accuracy:  32.502642124665 %, lr:  0.00027495140308869594\n",
+      "Epoch:  101 , validation loss:  0.7907675266265869 , validation accuracy:  33.84877308026649 %, lr:  0.00027495140308869594\n",
+      "Epoch:  102 , validation loss:  0.7562479496002197 , validation accuracy:  40.816768203607715 %, lr:  0.00027495140308869594\n",
+      "Epoch:  103 , validation loss:  0.6872929573059082 , validation accuracy:  41.247082841880115 %, lr:  0.00027495140308869594\n",
+      "Epoch:  104 , validation loss:  0.9396573066711426 , validation accuracy:  34.59614267833891 %, lr:  0.00027495140308869594\n",
+      "Epoch:  105 , validation loss:  0.7277446269989014 , validation accuracy:  39.87678501220968 %, lr:  0.00027495140308869594\n",
+      "Epoch:  106 , validation loss:  0.9121726989746094 , validation accuracy:  34.69208877538875 %, lr:  0.00027495140308869594\n",
+      "Epoch:  107 , validation loss:  0.8201107978820801 , validation accuracy:  37.34647722722993 %, lr:  0.00027495140308869594\n",
+      "Epoch:  108 , validation loss:  0.8217795372009278 , validation accuracy:  36.44436749519368 %, lr:  0.00027495140308869594\n",
+      "Epoch:  109 , validation loss:  0.6884310722351075 , validation accuracy:  40.25443750698855 %, lr:  0.00027495140308869594\n",
+      "Epoch:  110 , validation loss:  1.60977783203125 , validation accuracy:  31.886927885326376 %, lr:  0.00027495140308869594\n",
+      "Epoch:  111 , validation loss:  0.6492956638336181 , validation accuracy:  40.7734842500514 %, lr:  0.00027495140308869594\n",
+      "Epoch:  112 , validation loss:  0.9390439987182617 , validation accuracy:  36.198731058761574 %, lr:  0.00027495140308869594\n",
+      "Epoch:  113 , validation loss:  0.7007219314575195 , validation accuracy:  39.70112430069362 %, lr:  0.00027495140308869594\n",
+      "Epoch:  114 , validation loss:  0.7170003414154053 , validation accuracy:  40.969344139893735 %, lr:  0.00027495140308869594\n",
+      "Epoch:  115 , validation loss:  1.1309728622436523 , validation accuracy:  32.61373760545955 %, lr:  0.00027495140308869594\n",
+      "Epoch:  116 , validation loss:  0.8066009521484375 , validation accuracy:  39.57271523847655 %, lr:  0.00027495140308869594\n",
+      "Epoch:  117 , validation loss:  0.7073366165161132 , validation accuracy:  39.553598158989175 %, lr:  0.00027495140308869594\n",
+      "Epoch:  118 , validation loss:  0.7368218421936035 , validation accuracy:  31.40106550665671 %, lr:  0.00027495140308869594\n",
+      "Epoch:  119 , validation loss:  0.7520876884460449 , validation accuracy:  38.96890408636591 %, lr:  0.00027495140308869594\n",
+      "Epoch:  120 , validation loss:  0.63698410987854 , validation accuracy:  42.686274297627676 %, lr:  0.00027495140308869594\n",
+      "Epoch:  121 , validation loss:  1.1586243629455566 , validation accuracy:  33.19302118388827 %, lr:  0.00027495140308869594\n",
+      "Epoch:  122 , validation loss:  1.0879854202270507 , validation accuracy:  32.15564909698852 %, lr:  0.00027495140308869594\n",
+      "Epoch:  123 , validation loss:  0.8918576240539551 , validation accuracy:  32.30533943637079 %, lr:  0.00027495140308869594\n",
+      "Epoch:  124 , validation loss:  0.8480853080749512 , validation accuracy:  35.15883407457104 %, lr:  0.00027495140308869594\n",
+      "Epoch:  125 , validation loss:  0.6434503555297851 , validation accuracy:  40.79368342837768 %, lr:  0.00027495140308869594\n",
+      "Epoch:  126 , validation loss:  0.6971195220947266 , validation accuracy:  38.18041473241499 %, lr:  0.00027495140308869594\n",
+      "Epoch:  127 , validation loss:  1.0523551940917968 , validation accuracy:  31.37112743878026 %, lr:  0.00027495140308869594\n",
+      "Epoch:  128 , validation loss:  0.925447940826416 , validation accuracy:  36.93816526534867 %, lr:  0.00027495140308869594\n",
+      "Epoch:  129 , validation loss:  0.8280756950378418 , validation accuracy:  35.60646229426595 %, lr:  0.00027495140308869594\n",
+      "Epoch:  130 , validation loss:  1.0375274658203124 , validation accuracy:  34.15176075516071 %, lr:  0.00027495140308869594\n",
+      "Epoch:  131 , validation loss:  2.04476375579834 , validation accuracy:  24.89548728714214 %, lr:  0.00027495140308869594\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  132 , validation loss:  0.6809628963470459 , validation accuracy:  36.735091383246946 %, lr:  0.00027495140308869594\n",
+      "Epoch:  133 , validation loss:  0.7266085624694825 , validation accuracy:  37.258466521665426 %, lr:  0.00027495140308869594\n",
+      "Epoch:  134 , validation loss:  0.8204427719116211 , validation accuracy:  34.74330812043039 %, lr:  0.00027495140308869594\n",
+      "Epoch:  135 , validation loss:  0.7137044906616211 , validation accuracy:  42.02078351169929 %, lr:  0.00027495140308869594\n",
+      "Epoch:  136 , validation loss:  0.6515226364135742 , validation accuracy:  42.373908432796256 %, lr:  0.00027495140308869594\n",
+      "Epoch:  137 , validation loss:  1.5637449264526366 , validation accuracy:  33.075433110060274 %, lr:  0.00027495140308869594\n",
+      "Epoch:  138 , validation loss:  0.5935778141021728 , validation accuracy:  43.2385054050837 %, lr:  0.00027495140308869594\n",
+      "Epoch:  139 , validation loss:  1.4328564643859862 , validation accuracy:  28.35171097861412 %, lr:  0.00027495140308869594\n",
+      "Epoch:  140 , validation loss:  0.7898599624633789 , validation accuracy:  30.77416957931604 %, lr:  0.00027495140308869594\n",
+      "Epoch:  141 , validation loss:  0.808933162689209 , validation accuracy:  38.02495319922522 %, lr:  0.00027495140308869594\n",
+      "Epoch:  142 , validation loss:  0.9372072219848633 , validation accuracy:  19.049989359361415 %, lr:  0.00027495140308869594\n",
+      "Epoch:  143 , validation loss:  0.9323240280151367 , validation accuracy:  39.566583345056074 %, lr:  0.00027495140308869594\n",
+      "Epoch:  144 , validation loss:  1.0887378692626952 , validation accuracy:  22.774934262495535 %, lr:  0.00027495140308869594\n",
+      "Epoch:  145 , validation loss:  0.7360490798950196 , validation accuracy:  37.27036960889341 %, lr:  0.00027495140308869594\n",
+      "Epoch:  146 , validation loss:  0.7560807704925537 , validation accuracy:  31.680247007094962 %, lr:  0.00027495140308869594\n",
+      "Epoch:  147 , validation loss:  0.7457723617553711 , validation accuracy:  35.28399684027139 %, lr:  0.00027495140308869594\n",
+      "Epoch:  148 , validation loss:  0.9706264495849609 , validation accuracy:  25.96387954075725 %, lr:  0.00027495140308869594\n",
+      "Epoch:  149 , validation loss:  0.7975692272186279 , validation accuracy:  38.40116289555222 %, lr:  0.00027495140308869594\n",
+      "Epoch:  150 , validation loss:  0.8338151931762695 , validation accuracy:  27.261676748220847 %, lr:  0.00027495140308869594\n",
+      "Epoch:  151 , validation loss:  0.7029540061950683 , validation accuracy:  42.848228423850905 %, lr:  0.00027495140308869594\n",
+      "Epoch:  152 , validation loss:  0.8298867225646973 , validation accuracy:  31.271213645987757 %, lr:  0.00027495140308869594\n",
+      "Epoch:  153 , validation loss:  2.2880168914794923 , validation accuracy:  20.477638427493964 %, lr:  0.00027495140308869594\n",
+      "Epoch:  154 , validation loss:  0.9128743171691894 , validation accuracy:  24.02656191949906 %, lr:  0.00027495140308869594\n",
+      "Epoch:  155 , validation loss:  0.6542701244354248 , validation accuracy:  42.003469930276765 %, lr:  0.00027495140308869594\n",
+      "Epoch:  156 , validation loss:  1.0826393127441407 , validation accuracy:  30.74423151143959 %, lr:  0.00027495140308869594\n",
+      "Epoch:  157 , validation loss:  0.7239350318908692 , validation accuracy:  38.528489858930385 %, lr:  0.00027495140308869594\n",
+      "Epoch:  158 , validation loss:  1.1827194213867187 , validation accuracy:  36.10422776016362 %, lr:  0.00027495140308869594\n",
+      "Epoch:  159 , validation loss:  1.3067131042480469 , validation accuracy:  17.814232485328542 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  160 , validation loss:  1.0633733749389649 , validation accuracy:  30.312834774328284 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  161 , validation loss:  0.8475107192993164 , validation accuracy:  36.407576134670805 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  162 , validation loss:  0.7335079193115235 , validation accuracy:  39.49263992439736 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  163 , validation loss:  0.6830977916717529 , validation accuracy:  42.25992735509795 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  164 , validation loss:  0.6655040740966797 , validation accuracy:  42.95355271083794 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  165 , validation loss:  0.6505826473236084 , validation accuracy:  44.704388632191 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  166 , validation loss:  0.5872902870178223 , validation accuracy:  45.59820227312896 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  167 , validation loss:  0.6719779968261719 , validation accuracy:  41.45845281508013 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  168 , validation loss:  0.5927112579345704 , validation accuracy:  43.96784002250765 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  169 , validation loss:  0.5814720153808594 , validation accuracy:  44.92874379145791 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  170 , validation loss:  0.5212488174438477 , validation accuracy:  45.12568578013916 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  171 , validation loss:  0.530148983001709 , validation accuracy:  45.18808681318285 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  172 , validation loss:  0.5105440616607666 , validation accuracy:  46.19948852794881 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  173 , validation loss:  0.5285354137420655 , validation accuracy:  44.4280927286565 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  174 , validation loss:  0.7527753829956054 , validation accuracy:  42.20329751586176 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  175 , validation loss:  0.5471701622009277 , validation accuracy:  45.80416175213444 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  176 , validation loss:  0.49657063484191893 , validation accuracy:  47.47456165979534 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  177 , validation loss:  0.6203741550445556 , validation accuracy:  44.33899992425308 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  178 , validation loss:  0.7675585269927978 , validation accuracy:  42.71116257092256 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  179 , validation loss:  0.5257921695709229 , validation accuracy:  47.18023077561237 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  180 , validation loss:  0.4708272457122803 , validation accuracy:  46.85956881968266 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  181 , validation loss:  0.4894553184509277 , validation accuracy:  47.039557926554345 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  182 , validation loss:  0.4755051612854004 , validation accuracy:  48.388213779446616 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  183 , validation loss:  0.5741712093353272 , validation accuracy:  45.84600290723888 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  184 , validation loss:  0.5091753005981445 , validation accuracy:  47.49187524121787 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  185 , validation loss:  0.5825141429901123 , validation accuracy:  44.33936062386606 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  186 , validation loss:  0.46875290870666503 , validation accuracy:  48.09929338945819 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  187 , validation loss:  0.46094274520874023 , validation accuracy:  47.45219828379124 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  188 , validation loss:  0.5164411544799805 , validation accuracy:  46.345932570814355 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  189 , validation loss:  0.4544966220855713 , validation accuracy:  48.73520680712309 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  190 , validation loss:  0.5234704971313476 , validation accuracy:  46.85920812006969 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  191 , validation loss:  0.4672117233276367 , validation accuracy:  48.84305599140092 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  192 , validation loss:  0.5883543491363525 , validation accuracy:  47.947078152785146 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  193 , validation loss:  0.4720164775848389 , validation accuracy:  49.06957534834565 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  194 , validation loss:  1.0803923606872559 , validation accuracy:  43.67639473522845 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  195 , validation loss:  1.1951002120971679 , validation accuracy:  35.57652422638951 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  196 , validation loss:  0.5861899852752686 , validation accuracy:  45.31685657501289 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  197 , validation loss:  0.5122312068939209 , validation accuracy:  48.12562446120495 %, lr:  6.873785077217399e-05\n",
+      "Epoch:  198 , validation loss:  0.4820733070373535 , validation accuracy:  49.84039042126108 %, lr:  6.873785077217399e-05\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "wandb: Agent Finished Run: zlxg59he \n",
+      "\n",
+      "wandb: Agent Starting Run: m53bcj9b with config:\n",
+      "\tepochs: 206\n",
+      "\thidden_dim: 80\n",
+      "\tlr: 0.0019509450014441824\n",
+      "\tn_graph_iters: 3\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 335\n",
+      "\tweight_decay: 0.00010403123724988511\n",
+      "wandb: Agent Started Run: m53bcj9b\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/m53bcj9b\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/m53bcj9b</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 206, 'hidden_dim': 80, 'lr': 0.0019509450014441824, 'n_graph_iters': 3, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 335, 'weight_decay': 0.00010403123724988512}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 80, 'n_graph_iters': 3, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.8786066055297852 , validation accuracy:  10.971039428074695 %, lr:  0.0019509450014441824\n",
+      "Epoch:  2 , validation loss:  1.8782693862915039 , validation accuracy:  10.679594140795487 %, lr:  0.0019509450014441824\n",
+      "Epoch:  3 , validation loss:  1.8710878372192383 , validation accuracy:  13.461309556014847 %, lr:  0.0019509450014441824\n",
+      "Epoch:  4 , validation loss:  1.8756616592407227 , validation accuracy:  14.773534747997216 %, lr:  0.0019509450014441824\n",
+      "Epoch:  5 , validation loss:  1.8677028656005858 , validation accuracy:  13.689632411024421 %, lr:  0.0019509450014441824\n",
+      "Epoch:  6 , validation loss:  1.8787412643432617 , validation accuracy:  10.303023744855523 %, lr:  0.0019509450014441824\n",
+      "Epoch:  7 , validation loss:  1.8655065536499023 , validation accuracy:  12.53250805261886 %, lr:  0.0019509450014441824\n",
+      "Epoch:  8 , validation loss:  1.8646997451782226 , validation accuracy:  10.908277695418032 %, lr:  0.0019509450014441824\n",
+      "Epoch:  9 , validation loss:  1.8652782440185547 , validation accuracy:  13.930219052874957 %, lr:  0.0019509450014441824\n",
+      "Epoch:  10 , validation loss:  1.8621599197387695 , validation accuracy:  13.640937963273567 %, lr:  0.0019509450014441824\n",
+      "Epoch:  11 , validation loss:  1.862212562561035 , validation accuracy:  13.175274762930178 %, lr:  0.0019509450014441824\n",
+      "Epoch:  12 , validation loss:  1.866836166381836 , validation accuracy:  14.509141931690708 %, lr:  0.0019509450014441824\n",
+      "Epoch:  13 , validation loss:  1.8614608764648437 , validation accuracy:  12.549460934428417 %, lr:  0.0019509450014441824\n",
+      "Epoch:  14 , validation loss:  1.8637140274047852 , validation accuracy:  13.281320449143157 %, lr:  0.0019509450014441824\n",
+      "Epoch:  15 , validation loss:  1.8640703201293944 , validation accuracy:  13.914348269904306 %, lr:  0.0019509450014441824\n",
+      "Epoch:  16 , validation loss:  1.865628433227539 , validation accuracy:  10.288595760336749 %, lr:  0.0019509450014441824\n",
+      "Epoch:  17 , validation loss:  1.8623275756835938 , validation accuracy:  12.652260324124672 %, lr:  0.0019509450014441824\n",
+      "Epoch:  18 , validation loss:  1.8633394241333008 , validation accuracy:  12.761913006467344 %, lr:  0.0019509450014441824\n",
+      "Epoch:  19 , validation loss:  1.8663330078125 , validation accuracy:  11.070953220867194 %, lr:  0.0019509450014441824\n",
+      "Epoch:  20 , validation loss:  1.8665576934814454 , validation accuracy:  11.081413509643303 %, lr:  0.0019509450014441824\n",
+      "Epoch:  21 , validation loss:  1.8608633041381837 , validation accuracy:  13.834272955825119 %, lr:  0.0019509450014441824\n",
+      "Epoch:  22 , validation loss:  1.8612655639648437 , validation accuracy:  12.779587287502842 %, lr:  0.0019509450014441824\n",
+      "Epoch:  23 , validation loss:  1.8594850540161132 , validation accuracy:  12.762273706080313 %, lr:  0.0019509450014441824\n",
+      "Epoch:  24 , validation loss:  1.8651239395141601 , validation accuracy:  11.623184328323216 %, lr:  0.0019509450014441824\n",
+      "Epoch:  25 , validation loss:  1.862035369873047 , validation accuracy:  13.502790011506319 %, lr:  0.0019509450014441824\n",
+      "Epoch:  26 , validation loss:  1.8599885940551757 , validation accuracy:  12.896093262491929 %, lr:  0.0019509450014441824\n",
+      "Epoch:  27 , validation loss:  1.8614229202270507 , validation accuracy:  13.789185504203955 %, lr:  0.0019509450014441824\n",
+      "Epoch:  28 , validation loss:  1.8626832962036133 , validation accuracy:  14.286229570875669 %, lr:  0.0019509450014441824\n",
+      "Epoch:  29 , validation loss:  1.8765235900878907 , validation accuracy:  15.656166700933131 %, lr:  0.0019509450014441824\n",
+      "Epoch:  30 , validation loss:  1.8625097274780273 , validation accuracy:  11.865574468238597 %, lr:  0.0019509450014441824\n",
+      "Epoch:  31 , validation loss:  1.854081153869629 , validation accuracy:  12.308513592964914 %, lr:  0.0019509450014441824\n",
+      "Epoch:  32 , validation loss:  1.8177900314331055 , validation accuracy:  17.270297468970817 %, lr:  0.0019509450014441824\n",
+      "Epoch:  33 , validation loss:  1.758751678466797 , validation accuracy:  21.41942511695685 %, lr:  0.0019509450014441824\n",
+      "Epoch:  34 , validation loss:  1.972437286376953 , validation accuracy:  10.400412640357237 %, lr:  0.0019509450014441824\n",
+      "Epoch:  35 , validation loss:  1.8682178497314452 , validation accuracy:  12.48958479867551 %, lr:  0.0019509450014441824\n",
+      "Epoch:  36 , validation loss:  1.8398284912109375 , validation accuracy:  12.59021999069395 %, lr:  0.0019509450014441824\n",
+      "Epoch:  37 , validation loss:  1.8796850204467774 , validation accuracy:  10.829284480177753 %, lr:  0.0019509450014441824\n",
+      "Epoch:  38 , validation loss:  1.9462556838989258 , validation accuracy:  15.664102092418455 %, lr:  0.0019509450014441824\n",
+      "Epoch:  39 , validation loss:  1.856736946105957 , validation accuracy:  10.844794563535434 %, lr:  0.0019509450014441824\n",
+      "Epoch:  40 , validation loss:  1.700748825073242 , validation accuracy:  14.182348082340507 %, lr:  0.0019509450014441824\n",
+      "Epoch:  41 , validation loss:  1.7534305572509765 , validation accuracy:  15.425679648245739 %, lr:  0.0019509450014441824\n",
+      "Epoch:  42 , validation loss:  1.844413948059082 , validation accuracy:  21.852625352133 %, lr:  0.0019509450014441824\n",
+      "Epoch:  43 , validation loss:  1.871408462524414 , validation accuracy:  12.092815224409264 %, lr:  0.0019509450014441824\n",
+      "Epoch:  44 , validation loss:  1.769573974609375 , validation accuracy:  15.154794238905781 %, lr:  0.0019509450014441824\n",
+      "Epoch:  45 , validation loss:  1.8694799423217774 , validation accuracy:  11.34724912440169 %, lr:  0.0019509450014441824\n",
+      "Epoch:  46 , validation loss:  1.3860053062438964 , validation accuracy:  22.828678504827966 %, lr:  0.0019509450014441824\n",
+      "Epoch:  47 , validation loss:  1.8968608856201172 , validation accuracy:  9.82978585263978 %, lr:  0.0019509450014441824\n",
+      "Epoch:  48 , validation loss:  1.1702320098876953 , validation accuracy:  23.36936722466897 %, lr:  0.0019509450014441824\n",
+      "Epoch:  49 , validation loss:  1.2571595191955567 , validation accuracy:  23.238793964774075 %, lr:  0.0019509450014441824\n",
+      "Epoch:  50 , validation loss:  1.435786247253418 , validation accuracy:  30.46505001100134 %, lr:  0.0019509450014441824\n",
+      "Epoch:  51 , validation loss:  1.4227595329284668 , validation accuracy:  14.816818701553533 %, lr:  0.0019509450014441824\n",
+      "Epoch:  52 , validation loss:  1.2467803001403808 , validation accuracy:  20.884868290536325 %, lr:  0.0019509450014441824\n",
+      "Epoch:  53 , validation loss:  1.3239605903625489 , validation accuracy:  23.366120928152245 %, lr:  0.0019509450014441824\n",
+      "Epoch:  54 , validation loss:  0.9355545043945312 , validation accuracy:  30.6547780074232 %, lr:  0.0019509450014441824\n",
+      "Epoch:  55 , validation loss:  0.9834405899047851 , validation accuracy:  30.349986834464126 %, lr:  0.0019509450014441824\n",
+      "Epoch:  56 , validation loss:  0.9517420768737793 , validation accuracy:  28.937126450463317 %, lr:  0.0019509450014441824\n",
+      "Epoch:  57 , validation loss:  1.7789113998413086 , validation accuracy:  7.3146274514047445 %, lr:  0.0019509450014441824\n",
+      "Epoch:  58 , validation loss:  1.2767094612121581 , validation accuracy:  24.70143089536465 %, lr:  0.0019509450014441824\n",
+      "Epoch:  59 , validation loss:  1.1853848457336427 , validation accuracy:  23.854868903725666 %, lr:  0.0019509450014441824\n",
+      "Epoch:  60 , validation loss:  1.026286506652832 , validation accuracy:  27.117396903033125 %, lr:  0.0019509450014441824\n",
+      "Epoch:  61 , validation loss:  1.249859619140625 , validation accuracy:  20.468981636782704 %, lr:  0.0019509450014441824\n",
+      "Epoch:  62 , validation loss:  0.9777093887329101 , validation accuracy:  39.60084980828816 %, lr:  0.0019509450014441824\n",
+      "Epoch:  63 , validation loss:  2.0440711975097656 , validation accuracy:  17.706383301050717 %, lr:  0.0019509450014441824\n",
+      "Epoch:  64 , validation loss:  1.2315041542053222 , validation accuracy:  33.7005255393361 %, lr:  0.0019509450014441824\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  65 , validation loss:  1.209358310699463 , validation accuracy:  29.811101612687967 %, lr:  0.0019509450014441824\n",
+      "Epoch:  66 , validation loss:  0.9612137794494628 , validation accuracy:  30.592737673992477 %, lr:  0.0019509450014441824\n",
+      "Epoch:  67 , validation loss:  1.8065809249877929 , validation accuracy:  20.55987793925097 %, lr:  0.0019509450014441824\n",
+      "Epoch:  68 , validation loss:  1.4440691947937012 , validation accuracy:  21.29209815357868 %, lr:  0.0019509450014441824\n",
+      "Epoch:  69 , validation loss:  1.3182085037231446 , validation accuracy:  19.52250585235122 %, lr:  0.0019509450014441824\n",
+      "Epoch:  70 , validation loss:  2.1577728271484373 , validation accuracy:  11.166899317917032 %, lr:  0.0019509450014441824\n",
+      "Epoch:  71 , validation loss:  1.617380142211914 , validation accuracy:  12.662359913287812 %, lr:  0.0019509450014441824\n",
+      "Epoch:  72 , validation loss:  0.9095877647399903 , validation accuracy:  45.262390933454526 %, lr:  0.0019509450014441824\n",
+      "Epoch:  73 , validation loss:  0.981831169128418 , validation accuracy:  25.821403193634374 %, lr:  0.0019509450014441824\n",
+      "Epoch:  74 , validation loss:  1.2978593826293945 , validation accuracy:  25.295503157925108 %, lr:  0.0019509450014441824\n",
+      "Epoch:  75 , validation loss:  1.2169734954833984 , validation accuracy:  18.696143039038517 %, lr:  0.0019509450014441824\n",
+      "Epoch:  76 , validation loss:  0.8900398254394531 , validation accuracy:  50.02146162697167 %, lr:  0.0019509450014441824\n",
+      "Epoch:  77 , validation loss:  0.8896054267883301 , validation accuracy:  49.57419410688972 %, lr:  0.0019509450014441824\n",
+      "Epoch:  78 , validation loss:  1.0974490165710449 , validation accuracy:  31.293216322378886 %, lr:  0.0019509450014441824\n",
+      "Epoch:  79 , validation loss:  1.0445905685424806 , validation accuracy:  13.97025670991455 %, lr:  0.0019509450014441824\n",
+      "Epoch:  80 , validation loss:  0.9451469421386719 , validation accuracy:  44.72819480664697 %, lr:  0.0019509450014441824\n",
+      "Epoch:  81 , validation loss:  0.8261227607727051 , validation accuracy:  46.92413405040416 %, lr:  0.0019509450014441824\n",
+      "Epoch:  82 , validation loss:  1.0545530319213867 , validation accuracy:  31.231175988948163 %, lr:  0.0019509450014441824\n",
+      "Epoch:  83 , validation loss:  0.8809507369995118 , validation accuracy:  39.42915679251476 %, lr:  0.0019509450014441824\n",
+      "Epoch:  84 , validation loss:  0.8979884147644043 , validation accuracy:  38.37483182380546 %, lr:  0.0019509450014441824\n",
+      "Epoch:  85 , validation loss:  1.133774757385254 , validation accuracy:  37.59211366366204 %, lr:  0.0019509450014441824\n",
+      "Epoch:  86 , validation loss:  4.217976379394531 , validation accuracy:  19.635404831210614 %, lr:  0.0019509450014441824\n",
+      "Epoch:  87 , validation loss:  0.8414728164672851 , validation accuracy:  41.238426051168844 %, lr:  0.0019509450014441824\n",
+      "Epoch:  88 , validation loss:  0.743592643737793 , validation accuracy:  55.42185623234827 %, lr:  0.0019509450014441824\n",
+      "Epoch:  89 , validation loss:  1.611656379699707 , validation accuracy:  32.116332839174866 %, lr:  0.0019509450014441824\n",
+      "Epoch:  90 , validation loss:  1.2386603355407715 , validation accuracy:  32.57947114222746 %, lr:  0.0019509450014441824\n",
+      "Epoch:  91 , validation loss:  0.9443319320678711 , validation accuracy:  43.316416521485074 %, lr:  0.0019509450014441824\n",
+      "Epoch:  92 , validation loss:  0.984136962890625 , validation accuracy:  40.77168075198656 %, lr:  0.0019509450014441824\n",
+      "Epoch:  93 , validation loss:  0.8043224334716796 , validation accuracy:  55.699234234721665 %, lr:  0.0019509450014441824\n",
+      "Epoch:  94 , validation loss:  0.8559206008911133 , validation accuracy:  57.705445482056994 %, lr:  0.0019509450014441824\n",
+      "Epoch:  95 , validation loss:  1.3867619514465332 , validation accuracy:  33.40944095166986 %, lr:  0.0019509450014441824\n",
+      "Epoch:  96 , validation loss:  0.868318748474121 , validation accuracy:  46.21247371401571 %, lr:  0.0019509450014441824\n",
+      "Epoch:  97 , validation loss:  0.8313344955444336 , validation accuracy:  45.0546279563842 %, lr:  0.0019509450014441824\n",
+      "Epoch:  98 , validation loss:  0.911567211151123 , validation accuracy:  27.099722621997625 %, lr:  0.0019509450014441824\n",
+      "Epoch:  99 , validation loss:  0.8493999481201172 , validation accuracy:  37.98744043947641 %, lr:  0.0019509450014441824\n",
+      "Epoch:  100 , validation loss:  1.7672330856323242 , validation accuracy:  29.295301166141847 %, lr:  0.0019509450014441824\n",
+      "Epoch:  101 , validation loss:  0.9901809692382812 , validation accuracy:  48.852794880951095 %, lr:  0.0019509450014441824\n",
+      "Epoch:  102 , validation loss:  1.068626594543457 , validation accuracy:  37.88572314861906 %, lr:  0.0019509450014441824\n",
+      "Epoch:  103 , validation loss:  1.023319149017334 , validation accuracy:  47.496925035799435 %, lr:  0.0019509450014441824\n",
+      "Epoch:  104 , validation loss:  1.057414722442627 , validation accuracy:  34.822662035283635 %, lr:  0.0019509450014441824\n",
+      "Epoch:  105 , validation loss:  0.8837257385253906 , validation accuracy:  47.556079772326406 %, lr:  0.0019509450014441824\n",
+      "Epoch:  106 , validation loss:  0.872529411315918 , validation accuracy:  40.5736566644664 %, lr:  0.0019509450014441824\n",
+      "Epoch:  107 , validation loss:  0.898589038848877 , validation accuracy:  51.54902448789672 %, lr:  0.0019509450014441824\n",
+      "Epoch:  108 , validation loss:  1.2426024436950684 , validation accuracy:  36.33182921594725 %, lr:  0.0019509450014441824\n",
+      "Epoch:  109 , validation loss:  0.855132007598877 , validation accuracy:  49.67374720006926 %, lr:  0.0004877362503610456\n",
+      "Epoch:  110 , validation loss:  0.7456775665283203 , validation accuracy:  51.305191549529475 %, lr:  0.0004877362503610456\n",
+      "Epoch:  111 , validation loss:  0.8293814659118652 , validation accuracy:  45.548065026926224 %, lr:  0.0004877362503610456\n",
+      "Epoch:  112 , validation loss:  0.8208703994750977 , validation accuracy:  54.74157676228813 %, lr:  0.0004877362503610456\n",
+      "Epoch:  113 , validation loss:  0.8336319923400879 , validation accuracy:  51.12556314227075 %, lr:  0.0004877362503610456\n",
+      "Epoch:  114 , validation loss:  0.7700819969177246 , validation accuracy:  62.10237376415295 %, lr:  0.0004877362503610456\n",
+      "Epoch:  115 , validation loss:  0.82876615524292 , validation accuracy:  35.62341517607552 %, lr:  0.0004877362503610456\n",
+      "Epoch:  116 , validation loss:  0.8021468162536621 , validation accuracy:  41.84656559863511 %, lr:  0.0004877362503610456\n",
+      "Epoch:  117 , validation loss:  0.8142526626586915 , validation accuracy:  57.81870516052936 %, lr:  0.0004877362503610456\n",
+      "Epoch:  118 , validation loss:  1.1453731536865235 , validation accuracy:  19.891140856805862 %, lr:  0.0004877362503610456\n",
+      "Epoch:  119 , validation loss:  0.6933659076690674 , validation accuracy:  60.7605712039071 %, lr:  0.0004877362503610456\n",
+      "Epoch:  120 , validation loss:  1.2938881874084474 , validation accuracy:  38.68647628941094 %, lr:  0.0004877362503610456\n",
+      "Epoch:  121 , validation loss:  0.7388401031494141 , validation accuracy:  55.58056406205476 %, lr:  0.0004877362503610456\n",
+      "Epoch:  122 , validation loss:  0.9403007507324219 , validation accuracy:  55.066206413960515 %, lr:  0.0004877362503610456\n",
+      "Epoch:  123 , validation loss:  0.891459846496582 , validation accuracy:  57.18748083783306 %, lr:  0.0004877362503610456\n",
+      "Epoch:  124 , validation loss:  1.4743412017822266 , validation accuracy:  44.068475214526096 %, lr:  0.0004877362503610456\n",
+      "Epoch:  125 , validation loss:  0.6914991855621337 , validation accuracy:  62.11499825060688 %, lr:  0.0004877362503610456\n",
+      "Epoch:  126 , validation loss:  0.7369442462921143 , validation accuracy:  59.147883234321284 %, lr:  0.0004877362503610456\n",
+      "Epoch:  127 , validation loss:  0.7017169952392578 , validation accuracy:  63.058949137747575 %, lr:  0.0004877362503610456\n",
+      "Epoch:  128 , validation loss:  0.6852250099182129 , validation accuracy:  59.04905154036769 %, lr:  0.0004877362503610456\n",
+      "Epoch:  129 , validation loss:  0.6800144672393799 , validation accuracy:  59.120109364122655 %, lr:  0.0004877362503610456\n",
+      "Epoch:  130 , validation loss:  1.5152138710021972 , validation accuracy:  15.353539725651874 %, lr:  0.0004877362503610456\n",
+      "Epoch:  131 , validation loss:  0.7226577281951905 , validation accuracy:  55.47812537197147 %, lr:  0.0004877362503610456\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  132 , validation loss:  0.6683269023895264 , validation accuracy:  61.030735214021114 %, lr:  0.0004877362503610456\n",
+      "Epoch:  133 , validation loss:  0.9818598747253418 , validation accuracy:  36.314154934911755 %, lr:  0.0004877362503610456\n",
+      "Epoch:  134 , validation loss:  0.7247912406921386 , validation accuracy:  50.47666453853895 %, lr:  0.0004877362503610456\n",
+      "Epoch:  135 , validation loss:  0.7033191204071045 , validation accuracy:  64.48515540742825 %, lr:  0.0004877362503610456\n",
+      "Epoch:  136 , validation loss:  0.927092456817627 , validation accuracy:  60.09327691991386 %, lr:  0.0004877362503610456\n",
+      "Epoch:  137 , validation loss:  0.803974723815918 , validation accuracy:  57.29677282056276 %, lr:  0.0004877362503610456\n",
+      "Epoch:  138 , validation loss:  0.7068964004516601 , validation accuracy:  55.8269218977128 %, lr:  0.0004877362503610456\n",
+      "Epoch:  139 , validation loss:  0.8232707023620606 , validation accuracy:  38.42424767078224 %, lr:  0.0004877362503610456\n",
+      "Epoch:  140 , validation loss:  0.7775422096252441 , validation accuracy:  57.22210800067812 %, lr:  0.0004877362503610456\n",
+      "Epoch:  141 , validation loss:  0.7350801944732666 , validation accuracy:  61.69406180227168 %, lr:  0.0004877362503610456\n",
+      "Epoch:  142 , validation loss:  0.8122686386108399 , validation accuracy:  48.52960802773059 %, lr:  0.0004877362503610456\n",
+      "Epoch:  143 , validation loss:  0.7598538875579834 , validation accuracy:  57.461612543689746 %, lr:  0.0004877362503610456\n",
+      "Epoch:  144 , validation loss:  0.8349418640136719 , validation accuracy:  50.27719765256692 %, lr:  0.0004877362503610456\n",
+      "Epoch:  145 , validation loss:  0.6952539920806885 , validation accuracy:  60.18741951889886 %, lr:  0.0004877362503610456\n",
+      "Epoch:  146 , validation loss:  1.10844144821167 , validation accuracy:  46.39751261546896 %, lr:  0.0004877362503610456\n",
+      "Epoch:  147 , validation loss:  0.7978050231933593 , validation accuracy:  51.71530700947557 %, lr:  0.0004877362503610456\n",
+      "Epoch:  148 , validation loss:  0.7862689971923829 , validation accuracy:  45.49937057917537 %, lr:  0.0004877362503610456\n",
+      "Epoch:  149 , validation loss:  0.6751112461090087 , validation accuracy:  62.99726950392982 %, lr:  0.0004877362503610456\n",
+      "Epoch:  150 , validation loss:  0.8188907623291015 , validation accuracy:  56.835438015575015 %, lr:  0.0004877362503610456\n",
+      "Epoch:  151 , validation loss:  0.6792582035064697 , validation accuracy:  60.66751070376102 %, lr:  0.0004877362503610456\n",
+      "Epoch:  152 , validation loss:  0.8795321464538575 , validation accuracy:  53.832974437218425 %, lr:  0.0004877362503610456\n",
+      "Epoch:  153 , validation loss:  0.7438652038574218 , validation accuracy:  58.58843813460588 %, lr:  0.0001219340625902614\n",
+      "Epoch:  154 , validation loss:  0.6574145793914795 , validation accuracy:  65.62965527937989 %, lr:  0.0001219340625902614\n",
+      "Epoch:  155 , validation loss:  0.6457901954650879 , validation accuracy:  65.8305649638038 %, lr:  0.0001219340625902614\n",
+      "Epoch:  156 , validation loss:  0.6480757236480713 , validation accuracy:  66.7297890989363 %, lr:  0.0001219340625902614\n",
+      "Epoch:  157 , validation loss:  0.6548999786376953 , validation accuracy:  66.67640555621684 %, lr:  0.0001219340625902614\n",
+      "Epoch:  158 , validation loss:  0.6399177551269531 , validation accuracy:  67.55182351689336 %, lr:  0.0001219340625902614\n",
+      "Epoch:  159 , validation loss:  0.6409730911254883 , validation accuracy:  67.29392329362031 %, lr:  0.0001219340625902614\n",
+      "Epoch:  160 , validation loss:  0.6333166599273682 , validation accuracy:  67.8923239515364 %, lr:  0.0001219340625902614\n",
+      "Epoch:  161 , validation loss:  0.6293494224548339 , validation accuracy:  67.42666075119301 %, lr:  0.0001219340625902614\n",
+      "Epoch:  162 , validation loss:  0.6189291954040528 , validation accuracy:  67.42413585390223 %, lr:  0.0001219340625902614\n",
+      "Epoch:  163 , validation loss:  0.6484195232391358 , validation accuracy:  67.68023257911044 %, lr:  0.0001219340625902614\n",
+      "Epoch:  164 , validation loss:  0.6274388313293457 , validation accuracy:  68.13146779493505 %, lr:  0.0001219340625902614\n",
+      "Epoch:  165 , validation loss:  0.6168939113616944 , validation accuracy:  67.99800893813641 %, lr:  0.0001219340625902614\n",
+      "Epoch:  166 , validation loss:  0.6138340473175049 , validation accuracy:  67.74191221292818 %, lr:  0.0001219340625902614\n",
+      "Epoch:  167 , validation loss:  0.6156038761138916 , validation accuracy:  68.24075977766476 %, lr:  0.0001219340625902614\n",
+      "Epoch:  168 , validation loss:  0.6255978584289551 , validation accuracy:  67.37183441002168 %, lr:  0.0001219340625902614\n",
+      "Epoch:  169 , validation loss:  0.6264249324798584 , validation accuracy:  67.58753277857733 %, lr:  0.0001219340625902614\n",
+      "Epoch:  170 , validation loss:  0.6171433925628662 , validation accuracy:  68.57909601462998 %, lr:  0.0001219340625902614\n",
+      "Epoch:  171 , validation loss:  0.6271149635314941 , validation accuracy:  67.74335501138007 %, lr:  0.0001219340625902614\n",
+      "Epoch:  172 , validation loss:  0.6531253337860108 , validation accuracy:  67.9099982325719 %, lr:  0.0001219340625902614\n",
+      "Epoch:  173 , validation loss:  0.6129745483398438 , validation accuracy:  68.0932336359603 %, lr:  0.0001219340625902614\n",
+      "Epoch:  174 , validation loss:  0.656800651550293 , validation accuracy:  65.70287730081266 %, lr:  0.0001219340625902614\n",
+      "Epoch:  175 , validation loss:  0.6197683811187744 , validation accuracy:  68.08962663983061 %, lr:  0.0001219340625902614\n",
+      "Epoch:  176 , validation loss:  0.6233066558837891 , validation accuracy:  67.81838053087769 %, lr:  0.0001219340625902614\n",
+      "Epoch:  177 , validation loss:  0.6368563652038575 , validation accuracy:  68.42002748531051 %, lr:  0.0001219340625902614\n",
+      "Epoch:  178 , validation loss:  0.6292835712432862 , validation accuracy:  67.97384206406747 %, lr:  0.0001219340625902614\n",
+      "Epoch:  179 , validation loss:  0.6194416522979737 , validation accuracy:  68.58053881308184 %, lr:  0.0001219340625902614\n",
+      "Epoch:  180 , validation loss:  0.6635502815246582 , validation accuracy:  66.29911376105093 %, lr:  0.0001219340625902614\n",
+      "Epoch:  181 , validation loss:  0.6682697772979737 , validation accuracy:  67.31953296614113 %, lr:  0.0001219340625902614\n",
+      "Epoch:  182 , validation loss:  0.6071826934814453 , validation accuracy:  68.21947850049956 %, lr:  0.0001219340625902614\n",
+      "Epoch:  183 , validation loss:  0.6324788093566894 , validation accuracy:  67.89557024805313 %, lr:  0.0001219340625902614\n",
+      "Epoch:  184 , validation loss:  0.6495352268218995 , validation accuracy:  67.67301858685106 %, lr:  0.0001219340625902614\n",
+      "Epoch:  185 , validation loss:  0.7714958190917969 , validation accuracy:  65.80928368663861 %, lr:  0.0001219340625902614\n",
+      "Epoch:  186 , validation loss:  0.6095489978790283 , validation accuracy:  68.60109869102111 %, lr:  0.0001219340625902614\n",
+      "Epoch:  187 , validation loss:  0.6970382690429687 , validation accuracy:  65.28771204628498 %, lr:  0.0001219340625902614\n",
+      "Epoch:  188 , validation loss:  0.6454607009887695 , validation accuracy:  68.00955132575143 %, lr:  0.0001219340625902614\n",
+      "Epoch:  189 , validation loss:  0.6158596992492675 , validation accuracy:  68.23643138230912 %, lr:  0.0001219340625902614\n",
+      "Epoch:  190 , validation loss:  0.6323732852935791 , validation accuracy:  68.27610833973576 %, lr:  0.0001219340625902614\n",
+      "Epoch:  191 , validation loss:  0.6060991764068604 , validation accuracy:  69.00616435638565 %, lr:  0.0001219340625902614\n",
+      "Epoch:  192 , validation loss:  0.626446008682251 , validation accuracy:  68.90625056359315 %, lr:  0.0001219340625902614\n",
+      "Epoch:  193 , validation loss:  0.6512579441070556 , validation accuracy:  67.58500788128654 %, lr:  0.0001219340625902614\n",
+      "Epoch:  194 , validation loss:  0.6022409915924072 , validation accuracy:  68.50875959010096 %, lr:  0.0001219340625902614\n",
+      "Epoch:  195 , validation loss:  0.6096962928771973 , validation accuracy:  68.6130017782491 %, lr:  0.0001219340625902614\n",
+      "Epoch:  196 , validation loss:  0.6191065788269043 , validation accuracy:  68.20829681249751 %, lr:  0.0001219340625902614\n",
+      "Epoch:  197 , validation loss:  0.6002427101135254 , validation accuracy:  68.96612669934605 %, lr:  0.0001219340625902614\n",
+      "Epoch:  198 , validation loss:  0.6319704532623291 , validation accuracy:  68.85106352280884 %, lr:  0.0001219340625902614\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  199 , validation loss:  0.6109198570251465 , validation accuracy:  69.02456003664707 %, lr:  0.0001219340625902614\n",
+      "Epoch:  200 , validation loss:  0.6160407543182373 , validation accuracy:  68.56683222778902 %, lr:  0.0001219340625902614\n",
+      "Epoch:  201 , validation loss:  0.7015598773956299 , validation accuracy:  64.85595460956071 %, lr:  0.0001219340625902614\n",
+      "Epoch:  202 , validation loss:  0.6093051433563232 , validation accuracy:  69.4674991613734 %, lr:  0.0001219340625902614\n",
+      "Epoch:  203 , validation loss:  0.6078874111175537 , validation accuracy:  69.35748577941776 %, lr:  0.0001219340625902614\n",
+      "Epoch:  204 , validation loss:  0.6075682640075684 , validation accuracy:  69.2921991494703 %, lr:  0.0001219340625902614\n",
+      "Epoch:  205 , validation loss:  0.6509428024291992 , validation accuracy:  67.38049120073293 %, lr:  0.0001219340625902614\n",
+      "Epoch:  206 , validation loss:  0.6278217792510986 , validation accuracy:  69.41736191517066 %, lr:  0.0001219340625902614\n",
+      "wandb: Agent Finished Run: m53bcj9b \n",
+      "\n",
+      "wandb: Agent Starting Run: 1l0yvgp6 with config:\n",
+      "\tepochs: 216\n",
+      "\thidden_dim: 33\n",
+      "\tlr: 0.005504271066812322\n",
+      "\tn_graph_iters: 4\n",
+      "\tnetwork: Edge_Track_Truth_Net\n",
+      "\toptimizer: AdamW\n",
+      "\ttrain_size: 435\n",
+      "\tweight_decay: 0.00010101959319459329\n",
+      "wandb: Agent Started Run: 1l0yvgp6\n",
+      "Initialising W&B...\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep</a><br/>\n",
+       "                Sweep page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/sweeps/94oxvjm5</a><br/>\n",
+       "Run page: <a href=\"https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/1l0yvgp6\" target=\"_blank\">https://app.wandb.ai/murnanedaniel/node_regression_sweep/runs/1l0yvgp6</a><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: psutil not installed, only GPU stats will be reported.  Install with pip install psutil\n",
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
+      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
+      "wandb:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loading data...\n",
+      "config: {'epochs': 216, 'hidden_dim': 33, 'lr': 0.005504271066812322, 'n_graph_iters': 4, 'network': 'Edge_Track_Truth_Net', 'optimizer': 'AdamW', 'train_size': 435, 'weight_decay': 0.00010101959319459328}\n",
+      "Using  cuda\n",
+      "Loading model...\n",
+      "Model configs:  {'input_dim': 3, 'hidden_dim': 33, 'n_graph_iters': 4, 'output_dim': 1}\n",
+      "Loading optimiser\n",
+      "Loading scheduler...\n",
+      "Training...\n",
+      "Epoch:  1 , validation loss:  1.8830764770507813 , validation accuracy:  11.70542384008022 %, lr:  0.005504271066812322\n",
+      "Epoch:  2 , validation loss:  1.8752113342285157 , validation accuracy:  11.470608392037196 %, lr:  0.005504271066812322\n",
+      "Epoch:  3 , validation loss:  1.8727277755737304 , validation accuracy:  11.346167025562782 %, lr:  0.005504271066812322\n",
+      "Epoch:  4 , validation loss:  1.8829900741577148 , validation accuracy:  9.946291827628869 %, lr:  0.005504271066812322\n",
+      "Epoch:  5 , validation loss:  1.8687103271484375 , validation accuracy:  12.035103286334174 %, lr:  0.005504271066812322\n",
+      "Epoch:  6 , validation loss:  1.8662878036499024 , validation accuracy:  13.047587099939042 %, lr:  0.005504271066812322\n",
+      "Epoch:  7 , validation loss:  1.8676963806152345 , validation accuracy:  11.916793813280238 %, lr:  0.005504271066812322\n",
+      "Epoch:  8 , validation loss:  1.8671096801757812 , validation accuracy:  11.345084926723874 %, lr:  0.005504271066812322\n",
+      "Epoch:  9 , validation loss:  1.8637683868408204 , validation accuracy:  12.667049008256415 %, lr:  0.005504271066812322\n",
+      "Epoch:  10 , validation loss:  1.8620649337768556 , validation accuracy:  12.060352259242025 %, lr:  0.005504271066812322\n",
+      "Epoch:  11 , validation loss:  1.8619945526123047 , validation accuracy:  12.818542845703526 %, lr:  0.005504271066812322\n",
+      "Epoch:  12 , validation loss:  1.8630561828613281 , validation accuracy:  12.243948362243408 %, lr:  0.005504271066812322\n",
+      "Epoch:  13 , validation loss:  1.8664371490478515 , validation accuracy:  14.77100985070643 %, lr:  0.005504271066812322\n",
+      "Epoch:  14 , validation loss:  1.8647958755493164 , validation accuracy:  14.203990059118665 %, lr:  0.005504271066812322\n",
+      "Epoch:  15 , validation loss:  1.862708854675293 , validation accuracy:  13.645987757855135 %, lr:  0.005504271066812322\n",
+      "Epoch:  16 , validation loss:  1.8653985977172851 , validation accuracy:  10.507179725796153 %, lr:  0.005504271066812322\n",
+      "Epoch:  17 , validation loss:  1.8641954421997071 , validation accuracy:  11.192148290824884 %, lr:  0.005504271066812322\n",
+      "Epoch:  18 , validation loss:  1.8651912689208985 , validation accuracy:  11.935910892767613 %, lr:  0.005504271066812322\n",
+      "Epoch:  19 , validation loss:  1.8618144989013672 , validation accuracy:  11.694242152078171 %, lr:  0.005504271066812322\n",
+      "Epoch:  20 , validation loss:  1.8630619049072266 , validation accuracy:  12.228798978498697 %, lr:  0.005504271066812322\n",
+      "Epoch:  21 , validation loss:  1.8708112716674805 , validation accuracy:  15.051994849209526 %, lr:  0.005504271066812322\n",
+      "Epoch:  22 , validation loss:  1.8629562377929687 , validation accuracy:  12.171087040423606 %, lr:  0.005504271066812322\n",
+      "Epoch:  23 , validation loss:  1.8606342315673827 , validation accuracy:  12.101111315507557 %, lr:  0.005504271066812322\n",
+      "Epoch:  24 , validation loss:  1.8600664138793945 , validation accuracy:  11.738968904086367 %, lr:  0.005504271066812322\n",
+      "Epoch:  25 , validation loss:  1.8646934509277344 , validation accuracy:  13.498822315763656 %, lr:  0.005504271066812322\n",
+      "Epoch:  26 , validation loss:  1.868267822265625 , validation accuracy:  10.569220059226875 %, lr:  0.005504271066812322\n",
+      "Epoch:  27 , validation loss:  1.8597536087036133 , validation accuracy:  10.889521315543629 %, lr:  0.005504271066812322\n",
+      "Epoch:  28 , validation loss:  1.863563346862793 , validation accuracy:  11.30035817471568 %, lr:  0.005504271066812322\n",
+      "Epoch:  29 , validation loss:  1.8608974456787108 , validation accuracy:  10.686808133054873 %, lr:  0.005504271066812322\n",
+      "Epoch:  30 , validation loss:  1.8605823516845703 , validation accuracy:  11.80497693325975 %, lr:  0.005504271066812322\n",
+      "Epoch:  31 , validation loss:  1.8621368408203125 , validation accuracy:  11.344002827884966 %, lr:  0.005504271066812322\n",
+      "Epoch:  32 , validation loss:  1.8603382110595703 , validation accuracy:  11.988212336648163 %, lr:  0.005504271066812322\n",
+      "Epoch:  33 , validation loss:  1.8618968963623046 , validation accuracy:  12.540804143717155 %, lr:  0.005504271066812322\n",
+      "Epoch:  34 , validation loss:  1.860761833190918 , validation accuracy:  12.092093825183326 %, lr:  0.005504271066812322\n",
+      "Epoch:  35 , validation loss:  1.8648487091064454 , validation accuracy:  12.429708662922605 %, lr:  0.005504271066812322\n",
+      "Epoch:  36 , validation loss:  1.8607948303222657 , validation accuracy:  12.087765429827693 %, lr:  0.005504271066812322\n",
+      "Epoch:  37 , validation loss:  1.8598634719848632 , validation accuracy:  12.034381887108236 %, lr:  0.005504271066812322\n",
+      "Epoch:  38 , validation loss:  1.8550800323486327 , validation accuracy:  12.940098615274188 %, lr:  0.005504271066812322\n",
+      "Epoch:  39 , validation loss:  1.8482398986816406 , validation accuracy:  13.79676019607631 %, lr:  0.005504271066812322\n",
+      "Epoch:  40 , validation loss:  1.8076255798339844 , validation accuracy:  18.61678912418527 %, lr:  0.005504271066812322\n",
+      "Epoch:  41 , validation loss:  1.7891168594360352 , validation accuracy:  21.281277165189604 %, lr:  0.005504271066812322\n",
+      "Epoch:  42 , validation loss:  1.7147556304931642 , validation accuracy:  11.564750991022187 %, lr:  0.005504271066812322\n",
+      "Epoch:  43 , validation loss:  1.8840946197509765 , validation accuracy:  11.39377937447473 %, lr:  0.005504271066812322\n",
+      "Epoch:  44 , validation loss:  1.4262019157409669 , validation accuracy:  18.910037909529322 %, lr:  0.005504271066812322\n",
+      "Epoch:  45 , validation loss:  1.38551607131958 , validation accuracy:  14.55459008292484 %, lr:  0.005504271066812322\n",
+      "Epoch:  46 , validation loss:  1.8895103454589843 , validation accuracy:  10.736945379257607 %, lr:  0.005504271066812322\n",
+      "Epoch:  47 , validation loss:  1.8894172668457032 , validation accuracy:  10.774097439393447 %, lr:  0.005504271066812322\n",
+      "Epoch:  48 , validation loss:  1.8901329040527344 , validation accuracy:  10.597715328651452 %, lr:  0.005504271066812322\n",
+      "Epoch:  49 , validation loss:  1.889408493041992 , validation accuracy:  10.774097439393447 %, lr:  0.005504271066812322\n",
+      "Epoch:  50 , validation loss:  1.8895605087280274 , validation accuracy:  10.718549698996172 %, lr:  0.005504271066812322\n",
+      "Epoch:  51 , validation loss:  1.8891094207763672 , validation accuracy:  10.894571110125199 %, lr:  0.005504271066812322\n",
+      "Epoch:  52 , validation loss:  1.8897050857543944 , validation accuracy:  10.682119038086272 %, lr:  0.005504271066812322\n",
+      "Epoch:  53 , validation loss:  1.8892635345458983 , validation accuracy:  10.763997850230307 %, lr:  0.005504271066812322\n",
+      "Epoch:  54 , validation loss:  1.889105987548828 , validation accuracy:  10.911884691547726 %, lr:  0.005504271066812322\n",
+      "Epoch:  55 , validation loss:  1.8892614364624023 , validation accuracy:  10.763997850230307 %, lr:  0.005504271066812322\n",
+      "Epoch:  56 , validation loss:  1.8894954681396485 , validation accuracy:  10.736584679644638 %, lr:  0.005504271066812322\n",
+      "Epoch:  57 , validation loss:  1.889375877380371 , validation accuracy:  10.784197028556589 %, lr:  0.005504271066812322\n",
+      "Epoch:  58 , validation loss:  1.8893178939819335 , validation accuracy:  10.757144557583889 %, lr:  0.005504271066812322\n",
+      "Epoch:  59 , validation loss:  1.8893512725830077 , validation accuracy:  10.802592708818024 %, lr:  0.005504271066812322\n",
+      "Epoch:  60 , validation loss:  1.8891422271728515 , validation accuracy:  10.824234685596181 %, lr:  0.005504271066812322\n",
+      "Epoch:  61 , validation loss:  1.889732551574707 , validation accuracy:  10.655787966339512 %, lr:  0.005504271066812322\n",
+      "Epoch:  62 , validation loss:  1.8891448974609375 , validation accuracy:  10.832170077081507 %, lr:  0.005504271066812322\n",
+      "Epoch:  63 , validation loss:  1.8890993118286132 , validation accuracy:  10.943265557876057 %, lr:  0.005504271066812322\n",
+      "Epoch:  64 , validation loss:  1.8892597198486327 , validation accuracy:  10.763997850230307 %, lr:  0.005504271066812322\n",
+      "Epoch:  65 , validation loss:  1.8893621444702149 , validation accuracy:  10.784918427782527 %, lr:  0.005504271066812322\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  66 , validation loss:  1.8890983581542968 , validation accuracy:  10.942544158650119 %, lr:  0.0013760677667030805\n",
+      "Epoch:  67 , validation loss:  1.8892406463623046 , validation accuracy:  10.779507933587986 %, lr:  0.0013760677667030805\n",
+      "Epoch:  68 , validation loss:  1.8892759323120116 , validation accuracy:  10.755701759132013 %, lr:  0.0013760677667030805\n",
+      "Epoch:  69 , validation loss:  1.8892385482788085 , validation accuracy:  10.780950732039866 %, lr:  0.0013760677667030805\n",
+      "Epoch:  70 , validation loss:  1.8892494201660157 , validation accuracy:  10.776622336684232 %, lr:  0.0013760677667030805\n",
+      "Epoch:  71 , validation loss:  1.8892845153808593 , validation accuracy:  10.755701759132013 %, lr:  0.0013760677667030805\n",
+      "Epoch:  72 , validation loss:  1.8894477844238282 , validation accuracy:  10.766883447134061 %, lr:  0.0013760677667030805\n",
+      "Epoch:  73 , validation loss:  1.8892578125 , validation accuracy:  10.770490443263753 %, lr:  0.0013760677667030805\n",
+      "Epoch:  74 , validation loss:  1.8892572402954102 , validation accuracy:  10.770490443263753 %, lr:  0.0013760677667030805\n",
+      "Epoch:  75 , validation loss:  1.889268684387207 , validation accuracy:  10.76147295293952 %, lr:  0.0013760677667030805\n",
+      "Epoch:  76 , validation loss:  1.889402198791504 , validation accuracy:  10.795378716558638 %, lr:  0.0013760677667030805\n",
+      "Epoch:  77 , validation loss:  1.8893381118774415 , validation accuracy:  10.797182214623485 %, lr:  0.0013760677667030805\n",
+      "Epoch:  78 , validation loss:  1.8892482757568358 , validation accuracy:  10.779147233975019 %, lr:  0.0013760677667030805\n",
+      "Epoch:  79 , validation loss:  1.889381217956543 , validation accuracy:  10.779507933587986 %, lr:  0.0013760677667030805\n",
+      "Epoch:  80 , validation loss:  1.889337158203125 , validation accuracy:  10.79393591810676 %, lr:  0.0013760677667030805\n",
+      "Epoch:  81 , validation loss:  1.8893436431884765 , validation accuracy:  10.79970711191427 %, lr:  0.0013760677667030805\n",
+      "Epoch:  82 , validation loss:  1.889366340637207 , validation accuracy:  10.782393530491742 %, lr:  0.0013760677667030805\n",
+      "Epoch:  83 , validation loss:  1.8893524169921876 , validation accuracy:  10.801510609979116 %, lr:  0.0013760677667030805\n",
+      "Epoch:  84 , validation loss:  1.8892948150634765 , validation accuracy:  10.750291264937474 %, lr:  0.0013760677667030805\n",
+      "Epoch:  85 , validation loss:  1.8892358779907226 , validation accuracy:  10.785639827008465 %, lr:  0.0013760677667030805\n",
+      "Epoch:  86 , validation loss:  1.889162826538086 , validation accuracy:  10.858861848441236 %, lr:  0.0013760677667030805\n",
+      "Epoch:  87 , validation loss:  1.8892230987548828 , validation accuracy:  10.782754230104711 %, lr:  0.0003440169416757701\n",
+      "Epoch:  88 , validation loss:  1.889232063293457 , validation accuracy:  10.782032830878773 %, lr:  0.0003440169416757701\n",
+      "Epoch:  89 , validation loss:  1.8892593383789062 , validation accuracy:  10.763997850230307 %, lr:  0.0003440169416757701\n",
+      "Epoch:  90 , validation loss:  1.889252281188965 , validation accuracy:  10.772654640941571 %, lr:  0.0003440169416757701\n",
+      "Epoch:  91 , validation loss:  1.8892633438110351 , validation accuracy:  10.763997850230307 %, lr:  0.0003440169416757701\n",
+      "Epoch:  92 , validation loss:  1.8892845153808593 , validation accuracy:  10.755701759132013 %, lr:  0.0003440169416757701\n",
+      "Epoch:  93 , validation loss:  1.889274787902832 , validation accuracy:  10.762915751391398 %, lr:  0.0003440169416757701\n",
+      "Epoch:  94 , validation loss:  1.8892656326293946 , validation accuracy:  10.766883447134061 %, lr:  0.0003440169416757701\n",
+      "Epoch:  95 , validation loss:  1.8892684936523438 , validation accuracy:  10.76147295293952 %, lr:  0.0003440169416757701\n",
+      "Epoch:  96 , validation loss:  1.8892623901367187 , validation accuracy:  10.763997850230307 %, lr:  0.0003440169416757701\n",
+      "Epoch:  97 , validation loss:  1.889279556274414 , validation accuracy:  10.74740566803372 %, lr:  0.0003440169416757701\n",
+      "Epoch:  98 , validation loss:  1.8892942428588868 , validation accuracy:  10.750291264937474 %, lr:  0.0003440169416757701\n",
+      "Epoch:  99 , validation loss:  1.8892707824707031 , validation accuracy:  10.762915751391398 %, lr:  0.0003440169416757701\n",
+      "Epoch:  100 , validation loss:  1.8892805099487304 , validation accuracy:  10.754258960680135 %, lr:  0.0003440169416757701\n",
+      "Epoch:  101 , validation loss:  1.8892793655395508 , validation accuracy:  10.751012664163412 %, lr:  0.0003440169416757701\n",
+      "Epoch:  102 , validation loss:  1.889307403564453 , validation accuracy:  10.760030154487644 %, lr:  0.0003440169416757701\n",
+      "Epoch:  103 , validation loss:  1.8892808914184571 , validation accuracy:  10.752094763002319 %, lr:  0.0003440169416757701\n",
+      "Epoch:  104 , validation loss:  1.889286422729492 , validation accuracy:  10.749569865711534 %, lr:  0.0003440169416757701\n",
+      "Epoch:  105 , validation loss:  1.8892807006835937 , validation accuracy:  10.754258960680135 %, lr:  0.0003440169416757701\n",
+      "Epoch:  106 , validation loss:  1.8892929077148437 , validation accuracy:  10.75173406338935 %, lr:  0.0003440169416757701\n",
+      "Epoch:  107 , validation loss:  1.889295768737793 , validation accuracy:  10.750291264937474 %, lr:  0.0003440169416757701\n",
+      "Epoch:  108 , validation loss:  1.889286994934082 , validation accuracy:  10.748487766872627 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  109 , validation loss:  1.8892892837524413 , validation accuracy:  10.755341059519044 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  110 , validation loss:  1.8892845153808593 , validation accuracy:  10.755701759132013 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  111 , validation loss:  1.8892829895019532 , validation accuracy:  10.752094763002319 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  112 , validation loss:  1.8892810821533204 , validation accuracy:  10.752094763002319 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  113 , validation loss:  1.8892837524414063 , validation accuracy:  10.752094763002319 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  114 , validation loss:  1.8892797470092773 , validation accuracy:  10.74740566803372 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  115 , validation loss:  1.889286994934082 , validation accuracy:  10.748487766872627 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  116 , validation loss:  1.8892938613891601 , validation accuracy:  10.75173406338935 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  117 , validation loss:  1.8892879486083984 , validation accuracy:  10.752094763002319 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  118 , validation loss:  1.88928165435791 , validation accuracy:  10.752094763002319 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  119 , validation loss:  1.8892824172973632 , validation accuracy:  10.752094763002319 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  120 , validation loss:  1.8892868041992188 , validation accuracy:  10.748487766872627 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  121 , validation loss:  1.889284896850586 , validation accuracy:  10.755701759132013 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  122 , validation loss:  1.8892799377441407 , validation accuracy:  10.751012664163412 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  123 , validation loss:  1.8892818450927735 , validation accuracy:  10.752094763002319 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  124 , validation loss:  1.8892787933349608 , validation accuracy:  10.75245546261529 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  125 , validation loss:  1.8892782211303711 , validation accuracy:  10.75245546261529 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  126 , validation loss:  1.8892772674560547 , validation accuracy:  10.75245546261529 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  127 , validation loss:  1.8892766952514648 , validation accuracy:  10.755701759132013 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  128 , validation loss:  1.8892755508422852 , validation accuracy:  10.755701759132013 %, lr:  8.600423541894253e-05\n",
+      "Epoch:  129 , validation loss:  1.889267921447754 , validation accuracy:  10.76147295293952 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  130 , validation loss:  1.8892715454101563 , validation accuracy:  10.766162047908123 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  131 , validation loss:  1.8892732620239259 , validation accuracy:  10.769769044037817 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  132 , validation loss:  1.8892719268798828 , validation accuracy:  10.766162047908123 %, lr:  2.1501058854735633e-05\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  133 , validation loss:  1.8892709732055664 , validation accuracy:  10.766162047908123 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  134 , validation loss:  1.8892717361450195 , validation accuracy:  10.766162047908123 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  135 , validation loss:  1.8892707824707031 , validation accuracy:  10.766162047908123 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  136 , validation loss:  1.889272117614746 , validation accuracy:  10.769769044037817 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  137 , validation loss:  1.8892719268798828 , validation accuracy:  10.766162047908123 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  138 , validation loss:  1.8892717361450195 , validation accuracy:  10.766162047908123 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  139 , validation loss:  1.8892717361450195 , validation accuracy:  10.766162047908123 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  140 , validation loss:  1.889273452758789 , validation accuracy:  10.769769044037817 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  141 , validation loss:  1.8892738342285156 , validation accuracy:  10.762915751391398 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  142 , validation loss:  1.8892745971679688 , validation accuracy:  10.762915751391398 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  143 , validation loss:  1.889273452758789 , validation accuracy:  10.769769044037817 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  144 , validation loss:  1.8892732620239259 , validation accuracy:  10.769769044037817 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  145 , validation loss:  1.8892742156982423 , validation accuracy:  10.762915751391398 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  146 , validation loss:  1.8892728805541992 , validation accuracy:  10.769769044037817 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  147 , validation loss:  1.889273452758789 , validation accuracy:  10.769769044037817 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  148 , validation loss:  1.8892738342285156 , validation accuracy:  10.762915751391398 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  149 , validation loss:  1.889273452758789 , validation accuracy:  10.769769044037817 %, lr:  2.1501058854735633e-05\n",
+      "Epoch:  150 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  151 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  152 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  153 , validation loss:  1.8892728805541992 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  154 , validation loss:  1.8892724990844727 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  155 , validation loss:  1.8892724990844727 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  156 , validation loss:  1.8892723083496095 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  157 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  158 , validation loss:  1.8892724990844727 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  159 , validation loss:  1.8892728805541992 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  160 , validation loss:  1.8892724990844727 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  161 , validation loss:  1.8892724990844727 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  162 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  163 , validation loss:  1.8892728805541992 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  164 , validation loss:  1.8892724990844727 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  165 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  166 , validation loss:  1.8892723083496095 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  167 , validation loss:  1.8892728805541992 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  168 , validation loss:  1.889273452758789 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  169 , validation loss:  1.889273452758789 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  170 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  5.375264713683908e-06\n",
+      "Epoch:  171 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  172 , validation loss:  1.8892728805541992 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  173 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  174 , validation loss:  1.8892724990844727 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  175 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  176 , validation loss:  1.8892724990844727 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  177 , validation loss:  1.8892724990844727 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  178 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  179 , validation loss:  1.8892724990844727 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  180 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  181 , validation loss:  1.8892728805541992 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  182 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  183 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  184 , validation loss:  1.8892728805541992 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  185 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  186 , validation loss:  1.8892728805541992 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  187 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  188 , validation loss:  1.889272689819336 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  189 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  190 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  191 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  1.343816178420977e-06\n",
+      "Epoch:  192 , validation loss:  1.8892728805541992 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n",
+      "Epoch:  193 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n",
+      "Epoch:  194 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n",
+      "Epoch:  195 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n",
+      "Epoch:  196 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n",
+      "Epoch:  197 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n",
+      "Epoch:  198 , validation loss:  1.889273452758789 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n",
+      "Epoch:  199 , validation loss:  1.889273452758789 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch:  200 , validation loss:  1.8892732620239259 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n",
+      "Epoch:  201 , validation loss:  1.8892732620239259 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n",
+      "Epoch:  202 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n",
+      "Epoch:  203 , validation loss:  1.8892730712890624 , validation accuracy:  10.769769044037817 %, lr:  3.3595404460524426e-07\n"
+     ]
+    }
+   ],
+   "source": [
+    "def train():\n",
+    "           \n",
+    "    print(\"Initialising W&B...\")\n",
+    "    wandb.init()\n",
+    "\n",
+    "    from torch_geometric.data import Data\n",
+    "    from torch_geometric.data import DataLoader\n",
+    "    from torch_scatter import scatter_add\n",
+    "    \n",
+    "    # Local imports\n",
+    "    from utils.toy_utils import load_data, make_mlp\n",
+    "\n",
+    "    class TwoHopAttNetwork(nn.Module):\n",
+    "        \"\"\"\n",
+    "        A module which computes new node features on the graph.\n",
+    "        For each node, it aggregates the neighbor node features\n",
+    "        (separately on the input and output side), and combines\n",
+    "        them with the node's previous features in a fully-connected\n",
+    "        network to compute the new features.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
+    "                     layer_norm=True):\n",
+    "            super(TwoHopAttNetwork, self).__init__()\n",
+    "            self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                    hidden_activation=hidden_activation,\n",
+    "                                    output_activation=hidden_activation,\n",
+    "                                    layer_norm=layer_norm)\n",
+    "\n",
+    "        def forward(self, x, e, edge_index):\n",
+    "            start, end = edge_index\n",
+    "            # Aggregate edge-weighted incoming/outgoing features\n",
+    "            mi = scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mi2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mo = scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            mo2 = scatter_add(e[:, None]*scatter_add(e[:, None] * x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
+    "            return self.network(node_inputs)\n",
+    "\n",
+    "    class TwoHopNetwork(nn.Module):\n",
+    "        \"\"\"\n",
+    "        A module which computes new node features on the graph.\n",
+    "        For each node, it aggregates the neighbor node features\n",
+    "        (separately on the input and output side), and combines\n",
+    "        them with the node's previous features in a fully-connected\n",
+    "        network to compute the new features.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim, hidden_dim, output_dim, hidden_activation=nn.ReLU,\n",
+    "                     layer_norm=True):\n",
+    "            super(TwoHopNetwork, self).__init__()\n",
+    "            self.network = make_mlp(input_dim*5, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                    hidden_activation=hidden_activation,\n",
+    "                                    output_activation=hidden_activation,\n",
+    "                                    layer_norm=layer_norm)\n",
+    "\n",
+    "        def forward(self, x, e, edge_index):\n",
+    "            start, end = edge_index\n",
+    "            # Aggregate edge-weighted incoming/outgoing features\n",
+    "            mi = scatter_add(x[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mi2 = scatter_add(scatter_add(x[start], end, dim=0, dim_size=x.shape[0])[start], end, dim=0, dim_size=x.shape[0])\n",
+    "            mo = scatter_add(x[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            mo2 = scatter_add(scatter_add(x[end], start, dim=0, dim_size=x.shape[0])[end], start, dim=0, dim_size=x.shape[0])\n",
+    "            node_inputs = torch.cat([mi, mi2, mo, mo2, x], dim=1)\n",
+    "            return self.network(node_inputs)\n",
+    "\n",
+    "    class Edge_Track_Net(nn.Module):\n",
+    "        \"\"\"\n",
+    "        Segment classification graph neural network model.\n",
+    "        Consists of an input network, an edge network, and a node network.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
+    "                     output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
+    "            super(Edge_Track_Net, self).__init__()\n",
+    "            self.n_graph_iters = n_graph_iters\n",
+    "            # Setup the input network\n",
+    "            self.input_network = make_mlp(input_dim, [hidden_dim],\n",
+    "                                          hidden_activation=nn.ReLU,\n",
+    "                                          layer_norm=False)\n",
+    "            # Setup the edge network\n",
+    "            self.edge_network = EdgeNetwork(input_dim+hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation, layer_norm=layer_norm)\n",
+    "            # Setup the node layers\n",
+    "            self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation=nn.ReLU, layer_norm=False)\n",
+    "\n",
+    "    #         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
+    "    #                                         layer_norm=False)\n",
+    "            self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, output_dim],\n",
+    "                                           hidden_activation=nn.ReLU,\n",
+    "                                          output_activation=None,\n",
+    "                                          layer_norm=False)\n",
+    "\n",
+    "        def forward(self, inputs):\n",
+    "            \"\"\"Apply forward pass of the model\"\"\"\n",
+    "            # Apply input network to get hidden representation\n",
+    "            x = self.input_network(inputs.x)\n",
+    "            # Shortcut connect the inputs onto the hidden representation\n",
+    "            x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Loop over iterations of edge and node networks\n",
+    "            for i in range(self.n_graph_iters):\n",
+    "                # Apply edge network\n",
+    "                e = torch.sigmoid(self.edge_network(x, inputs.edge_index))\n",
+    "                # Apply node network\n",
+    "                x = self.node_network(x, e, inputs.edge_index)\n",
+    "                # Shortcut connect the inputs onto the hidden representation\n",
+    "                x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Apply final edge network\n",
+    "            e = self.edge_network(x, inputs.edge_index)\n",
+    "            return e, self.output_network(x)\n",
+    "\n",
+    "    class Edge_Track_Truth_Net(nn.Module):\n",
+    "        \"\"\"\n",
+    "        Segment classification graph neural network model.\n",
+    "        Consists of an input network, an edge network, and a node network.\n",
+    "        \"\"\"\n",
+    "        def __init__(self, input_dim=3, hidden_dim=8, n_graph_iters=3,\n",
+    "                     output_dim=3, hidden_activation=nn.ReLU, layer_norm=True):\n",
+    "            super(Edge_Track_Truth_Net, self).__init__()\n",
+    "            self.n_graph_iters = n_graph_iters\n",
+    "            # Setup the input network\n",
+    "            self.input_network = make_mlp(input_dim, [hidden_dim],\n",
+    "                                          hidden_activation=nn.ReLU,\n",
+    "                                          layer_norm=False)\n",
+    "            # Setup the node layers\n",
+    "            self.node_network = TwoHopAttNetwork(input_dim+hidden_dim, hidden_dim, hidden_dim,\n",
+    "                                            hidden_activation=nn.ReLU, layer_norm=False)\n",
+    "\n",
+    "    #         self.output_network = NodeNetwork(input_dim+hidden_dim, hidden_dim, output_dim,\n",
+    "    #                                         layer_norm=False)\n",
+    "            self.output_network = make_mlp(input_dim+hidden_dim, [hidden_dim, hidden_dim, hidden_dim, output_dim],\n",
+    "                                           hidden_activation=nn.ReLU,\n",
+    "                                          output_activation=None,\n",
+    "                                          layer_norm=False)\n",
+    "\n",
+    "        def forward(self, inputs):\n",
+    "            \"\"\"Apply forward pass of the model\"\"\"\n",
+    "            # Apply input network to get hidden representation\n",
+    "            x = self.input_network(inputs.x)\n",
+    "            # Shortcut connect the inputs onto the hidden representation\n",
+    "            x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Loop over iterations of edge and node networks\n",
+    "            for i in range(self.n_graph_iters):\n",
+    "                # Apply edge network\n",
+    "                e = inputs.y_edges\n",
+    "                # Apply node network\n",
+    "                x = self.node_network(x, e, inputs.edge_index)\n",
+    "                # Shortcut connect the inputs onto the hidden representation\n",
+    "                x = torch.cat([x, inputs.x], dim=-1)\n",
+    "            # Apply final edge network\n",
+    "            return self.output_network(x)\n",
+    "\n",
+    "    def validate(model, val_loader, val_size):\n",
+    "        model = model.eval()\n",
+    "        node_correct, node_total, loss = 0, 0, 0\n",
+    "        for batch in val_loader:\n",
+    "            data = batch.to(device)\n",
+    "#             print(len(data.y_params))\n",
+    "            node_pred = model(data)\n",
+    "            node_correct += (((node_pred - data.y_params)/data.y_params)**2 < 0.1**2).sum().item()\n",
+    "            node_total += len(node_pred)\n",
+    "            loss += F.mse_loss(node_pred, data.y_params)\n",
+    "        acc = node_correct / node_total\n",
+    "        return acc, loss.item()/val_size\n",
+    "\n",
+    "    def get_lr(optimizer):\n",
+    "        for param_group in optimizer.param_groups:\n",
+    "            return param_group['lr']\n",
+    "    \n",
+    "    print(\"Loading data...\")\n",
+    "    train_dataset, val_dataset = load_data(train_size=wandb.config.get(\"train_size\",0), test_size=20)\n",
+    "    train_loader, val_loader = DataLoader(train_dataset, batch_size=2, shuffle=True), DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
+    "    \n",
+    "    print(\"config:\", dict(wandb.config.user_items()))\n",
+    "\n",
+    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
+    "    print(\"Using \", device)\n",
+    "    \n",
+    "    m_dic = [\"hidden_dim\", \"n_graph_iters\"]\n",
+    "    m_configs = {k:wandb.config.get(k,0) for k in m_dic} \n",
+    "    m_configs = {'input_dim': 3, **m_configs, 'output_dim': 1}\n",
+    "        \n",
+    "    print(\"Loading model...\")\n",
+    "    print(\"Model configs: \", m_configs)\n",
+    "    model = Edge_Track_Truth_Net(**m_configs).to(device)\n",
+    "    wandb.watch(model, log='all')\n",
+    "    \n",
+    "    print(\"Loading optimiser\")\n",
+    "    o_dic = [\"lr\", \"weight_decay\"]\n",
+    "    o_configs = {k:wandb.config.get(k,0) for k in o_dic} \n",
+    "    optimizer_fn = getattr(torch.optim, wandb.config.get(\"optimizer\",0))\n",
+    "#     optimizer_kwargs = {\"Adam\": {}, \"SGD\": {}}\n",
+    "    optimizer = optimizer_fn(model.parameters(), amsgrad=True, **o_configs)\n",
+    "    \n",
+    "    print(\"Loading scheduler...\")\n",
+    "#     s_dic = [\"step_size\", \"gamma\"]\n",
+    "#     s_configs = {k:wandb.config.get(k,0) for k in s_dic} \n",
+    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30)\n",
+    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.25, patience=20)\n",
+    "    \n",
+    "    model.train()\n",
+    "    \n",
+    "    print(\"Training...\")\n",
+    "    \n",
+    "    ep = 0\n",
+    "    best_acc = 0\n",
+    "    for epoch in range(wandb.config.get(\"epochs\", 0)):\n",
+    "        for batch in train_loader:\n",
+    "            optimizer.zero_grad()\n",
+    "            data = batch.to(device)\n",
+    "            node_pred = model(data)\n",
+    "            loss = F.mse_loss(node_pred, data.y_params)\n",
+    "            loss.backward()\n",
+    "            optimizer.step()\n",
+    "        ep += 1\n",
+    "        val_acc, val_loss = validate(model, val_loader, 20)\n",
+    "        if (val_acc > best_acc): best_acc = val_acc\n",
+    "        scheduler.step(val_loss)\n",
+    "        lr = get_lr(optimizer)\n",
+    "        print(\"Epoch: \" , ep, \", validation loss: \", val_loss, \", validation accuracy: \", val_acc*100, \"%, lr: \", lr)\n",
+    "        wandb.log({\"Validation Accuracy\": val_acc, \"Best Accuracy\": best_acc, \"Validation Loss\": val_loss, \"Learning Rate\": lr})\n",
+    "        if (lr < 6e-6): break\n",
+    "    \n",
+    "wandb.agent(sweep_id, function=train)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 6,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Network error resolved after 0:00:11.240625, resuming normal operation.\n"
+     ]
+    },
+    {
+     "ename": "ControllerError",
+     "evalue": "Only sweeps with a local controller are currently supported.",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mControllerError\u001b[0m                           Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-6-d64628e1e9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msweep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[0;32m~/.local/lib/python3.7/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, verbose, print_status, print_actions, print_debug)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mprint_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mprint_debug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_if_not_started\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m~/.local/lib/python3.7/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36m_start_if_not_started\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mis_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sweep_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'controller'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'local'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mControllerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only sweeps with a local controller are currently supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;31m# reset controller state, we might want to parse this and decide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;31mControllerError\u001b[0m: Only sweeps with a local controller are currently supported."
+     ]
+    }
+   ],
+   "source": [
+    "sweep = wandb.controller(sweep_id)\n",
+    "sweep.run()"
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
diff --git a/notebooks/wandb/settings b/notebooks/wandb/settings
index 8e3b553..cc0e984 100644
--- a/notebooks/wandb/settings
+++ b/notebooks/wandb/settings
@@ -1,4 +1,4 @@
 [default]
 entity = murnanedaniel
-project = node_regression
+project = node_regression_sweep
 
diff --git a/utils/.ipynb_checkpoints/toy_utils-checkpoint.py b/utils/.ipynb_checkpoints/toy_utils-checkpoint.py
index 20e86d3..aa58cda 100644
--- a/utils/.ipynb_checkpoints/toy_utils-checkpoint.py
+++ b/utils/.ipynb_checkpoints/toy_utils-checkpoint.py
@@ -25,7 +25,24 @@ from torch_scatter import *
 
 # Locals
 from torch_geometric.data import Batch
-
+from datasets.hitgraphs_params import *
+
+
+# Data Loading
+
+def load_data(train_size=300, test_size=10):
+    input_dir = "/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/"
+    filenames = [os.path.join(input_dir, f) for f in os.listdir(input_dir)
+                         if f.endswith('.npz') and not f.endswith('_ID.npz')]
+    train_graphs = [load_graph(fi) for fi in filenames[:train_size]]
+    test_graphs = [load_graph(fi) for fi in filenames[:test_size]]
+    train_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),
+                                         edge_index=torch.from_numpy(di[1]), y_edges=torch.from_numpy(di[2]), 
+                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in train_graphs]
+    test_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),
+                                         edge_index=torch.from_numpy(di[1]), y_edges=torch.from_numpy(di[2]), 
+                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in test_graphs]
+    return train_dataset, test_dataset
 
 # Some dumb circle calculations
 def y1(x, r, a, sign):
diff --git a/utils/__pycache__/toy_utils.cpython-36.pyc b/utils/__pycache__/toy_utils.cpython-36.pyc
index a995810..28d2864 100644
Binary files a/utils/__pycache__/toy_utils.cpython-36.pyc and b/utils/__pycache__/toy_utils.cpython-36.pyc differ
diff --git a/utils/toy_utils.py b/utils/toy_utils.py
index 20e86d3..aa58cda 100644
--- a/utils/toy_utils.py
+++ b/utils/toy_utils.py
@@ -25,7 +25,24 @@ from torch_scatter import *
 
 # Locals
 from torch_geometric.data import Batch
-
+from datasets.hitgraphs_params import *
+
+
+# Data Loading
+
+def load_data(train_size=300, test_size=10):
+    input_dir = "/global/cscratch1/sd/danieltm/ExaTrkX/node_tracker_data/hitgraphs_med_000/"
+    filenames = [os.path.join(input_dir, f) for f in os.listdir(input_dir)
+                         if f.endswith('.npz') and not f.endswith('_ID.npz')]
+    train_graphs = [load_graph(fi) for fi in filenames[:train_size]]
+    test_graphs = [load_graph(fi) for fi in filenames[:test_size]]
+    train_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),
+                                         edge_index=torch.from_numpy(di[1]), y_edges=torch.from_numpy(di[2]), 
+                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in train_graphs]
+    test_dataset = [torch_geometric.data.Data(x=torch.from_numpy(di[0]),
+                                         edge_index=torch.from_numpy(di[1]), y_edges=torch.from_numpy(di[2]), 
+                                         y_params=(torch.from_numpy(di[3][:,0]).unsqueeze(1)), pid=torch.from_numpy(di[4])) for di in test_graphs]
+    return train_dataset, test_dataset
 
 # Some dumb circle calculations
 def y1(x, r, a, sign):
