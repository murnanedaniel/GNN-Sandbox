2019-11-08 13:34:19,419 INFO Initialized rank 0 out of 1
2019-11-08 13:34:19,419 INFO Configuration: {'output_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/counter_results/counter001', 'trainer': {'name': 'gnn_sparse'}, 'data': {'name': 'hitgraphs_sparse', 'input_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/counter_data/hitgraphs_small_000', 'n_train': 1000, 'n_valid': 100, 'real_weight': 3.0, 'batch_size': 1, 'n_workers': 4}, 'model': {'name': 'counter', 'input_dim': 3, 'hidden_dim': 64, 'layer_norm': True, 'n_graph_iters': 4, 'max_tracks': 40, 'loss_func': 'cross_entropy'}, 'optimizer': {'name': 'Adam', 'learning_rate': 0.1, 'lr_scaling': 'sqrt', 'lr_warmup_epochs': 5, 'lr_decay_schedule': [{'start_epoch': 10, 'end_epoch': 30, 'factor': 0.5}, {'start_epoch': 30, 'end_epoch': 50, 'factor': 0.1}, {'start_epoch': 50, 'end_epoch': 70, 'factor': 0.05}, {'start_epoch': 70, 'end_epoch': 90, 'factor': 0.01}]}, 'training': {'n_epochs': 90}, 'n_ranks': 1}
2019-11-08 13:34:19,419 INFO Saving job outputs to /global/cscratch1/sd/danieltm/ExaTrkX/counter_results/counter001
2019-11-08 13:34:19,420 INFO Writing config via pickle to /global/cscratch1/sd/danieltm/ExaTrkX/counter_results/counter001/config.pkl
2019-11-08 13:34:20,537 INFO Loaded 1000 training samples
2019-11-08 13:34:20,538 INFO Loaded 100 validation samples
2019-11-08 13:34:20,538 INFO Choosing GPU 0
2019-11-08 13:34:23,813 INFO Model: 
GNNTrackCounter(
  (input_network): Sequential(
    (0): Linear(in_features=3, out_features=64, bias=True)
    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (2): Tanh()
  )
  (edge_network): EdgeNetwork(
    (network): Sequential(
      (0): Linear(in_features=134, out_features=64, bias=True)
      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (2): Tanh()
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (5): Tanh()
      (6): Linear(in_features=64, out_features=64, bias=True)
      (7): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (8): Tanh()
      (9): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (node_network): NodeNetwork(
    (network): Sequential(
      (0): Linear(in_features=201, out_features=64, bias=True)
      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (2): Tanh()
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (5): Tanh()
      (6): Linear(in_features=64, out_features=64, bias=True)
      (7): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (8): Tanh()
      (9): Linear(in_features=64, out_features=64, bias=True)
      (10): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (11): Tanh()
    )
  )
  (output_network): OutputNetwork(
    (network): Sequential(
      (0): Linear(in_features=67, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): Tanh()
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): Tanh()
      (6): Linear(in_features=64, out_features=41, bias=True)
    )
  )
)
Parameters: 59050
2019-11-08 13:34:23,813 INFO Epoch 0
2019-11-08 13:34:47,494 INFO   Training loss: 13.636
2019-11-08 13:34:48,364 INFO   Validation loss: 19.530 acc: 0.080
2019-11-08 13:34:48,385 INFO Epoch 1
/global/u2/d/danieltm/ExaTrkX/eta-tracker/trainers/gnn_sparse.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  batch_pred = m(batch_output)
2019-11-08 13:35:09,608 INFO   Training loss: 13.539
2019-11-08 13:35:10,431 INFO   Validation loss: 10.537 acc: 0.080
2019-11-08 13:35:10,448 INFO Epoch 2
