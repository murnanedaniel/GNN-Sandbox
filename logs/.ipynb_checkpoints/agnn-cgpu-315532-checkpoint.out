2019-11-07 15:19:21,475 INFO Initialized rank 0 out of 1
2019-11-07 15:19:21,475 INFO Configuration: {'output_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/counter_results/counter001', 'trainer': {'name': 'gnn_sparse'}, 'data': {'name': 'hitgraphs_sparse', 'input_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/counter_data/hitgraphs_small_000', 'n_train': 160, 'n_valid': 40, 'real_weight': 3.0, 'batch_size': 1, 'n_workers': 4}, 'model': {'name': 'counter', 'input_dim': 3, 'hidden_dim': 64, 'layer_norm': True, 'n_graph_iters': 4, 'max_tracks': 40, 'loss_func': 'cross_entropy'}, 'optimizer': {'name': 'Adam', 'learning_rate': 0.1, 'lr_scaling': 'sqrt', 'lr_warmup_epochs': 5, 'lr_decay_schedule': [{'start_epoch': 10, 'end_epoch': 20, 'factor': 0.5}, {'start_epoch': 20, 'end_epoch': 40, 'factor': 0.1}, {'start_epoch': 40, 'end_epoch': 50, 'factor': 0.05}, {'start_epoch': 50, 'end_epoch': 64, 'factor': 0.01}]}, 'training': {'n_epochs': 64}, 'n_ranks': 1}
2019-11-07 15:19:21,475 INFO Saving job outputs to /global/cscratch1/sd/danieltm/ExaTrkX/counter_results/counter001
2019-11-07 15:19:21,475 INFO Writing config via pickle to /global/cscratch1/sd/danieltm/ExaTrkX/counter_results/counter001/config.pkl
2019-11-07 15:19:22,418 INFO Loaded 160 training samples
2019-11-07 15:19:22,419 INFO Loaded 40 validation samples
2019-11-07 15:19:22,419 INFO Choosing GPU 0
2019-11-07 15:19:25,210 INFO Model: 
GNNTrackCounter(
  (input_network): Sequential(
    (0): Linear(in_features=3, out_features=64, bias=True)
    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (2): Tanh()
  )
  (edge_network): EdgeNetwork(
    (network): Sequential(
      (0): Linear(in_features=134, out_features=64, bias=True)
      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (2): Tanh()
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (5): Tanh()
      (6): Linear(in_features=64, out_features=64, bias=True)
      (7): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (8): Tanh()
      (9): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (node_network): NodeNetwork(
    (network): Sequential(
      (0): Linear(in_features=201, out_features=64, bias=True)
      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (2): Tanh()
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (5): Tanh()
      (6): Linear(in_features=64, out_features=64, bias=True)
      (7): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (8): Tanh()
      (9): Linear(in_features=64, out_features=64, bias=True)
      (10): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (11): Tanh()
    )
  )
  (output_network): OutputNetwork(
    (network): Sequential(
      (0): Linear(in_features=67, out_features=64, bias=True)
      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (2): Tanh()
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (5): Tanh()
      (6): Linear(in_features=64, out_features=64, bias=True)
      (7): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (8): Tanh()
      (9): Linear(in_features=64, out_features=41, bias=True)
    )
  )
)
Parameters: 59434
2019-11-07 15:19:25,210 INFO Epoch 0
2019-11-07 15:19:28,823 INFO   Training loss: 5.146
Traceback (most recent call last):
  File "train.py", line 184, in <module>
    main()
  File "train.py", line 160, in main
    **config['training'])
  File "/global/u2/d/danieltm/ExaTrkX/eta-tracker/trainers/gnn_base.py", line 204, in train
    summary.update(self.evaluate(valid_data_loader))
  File "/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/autograd/grad_mode.py", line 49, in decorate_no_grad
    return func(*args, **kwargs)
  File "/global/u2/d/danieltm/ExaTrkX/eta-tracker/trainers/gnn_sparse.py", line 67, in evaluate
    batch_loss = self.loss_func(batch_output, batch.y).item()
  File "/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/functional.py", line 1995, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/functional.py", line 1316, in log_softmax
    ret = input.log_softmax(dim)
IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)
srun: error: cgpu07: task 0: Exited with exit code 1
srun: Terminating job step 315532.0
